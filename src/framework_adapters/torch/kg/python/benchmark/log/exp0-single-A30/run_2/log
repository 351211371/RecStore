Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 2 parts
part 0 has 241571 edges
part 1 has 241571 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_FB15k_2', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 1.137 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.2206073954179883
[proc 0][Train](1000/10000) average neg_loss: 0.23324586229026317
[proc 0][Train](1000/10000) average loss: 0.22692662870138883
[proc 0][Train](1000/10000) average regularization: 1.073271195923553e-05
[proc 0][Train] 1000 steps take 25.915 seconds
[proc 0] 1000 steps, sample: 1.359, forward: 10.918, backward: 2.616, update: 11.015
[proc 1][Train](1000/10000) average pos_loss: 0.21987131542712451
[proc 1][Train](1000/10000) average neg_loss: 0.23446974515914917
[proc 1][Train](1000/10000) average loss: 0.22717053005844354
[proc 1][Train](1000/10000) average regularization: 1.070230841241937e-05
[proc 1][Train] 1000 steps take 25.908 seconds
[proc 1] 1000 steps, sample: 1.333, forward: 10.825, backward: 2.624, update: 10.916
[proc 1][Train](2000/10000) average pos_loss: 0.0768477997854352
[proc 1][Train](2000/10000) average neg_loss: 0.10846352628618479
[proc 1][Train](2000/10000) average loss: 0.09265566300600767
[proc 1][Train](2000/10000) average regularization: 1.5231356272124685e-05
[proc 1][Train] 1000 steps take 23.976 seconds
[proc 1] 2000 steps, sample: 1.241, forward: 9.226, backward: 2.739, update: 10.764
[proc 0][Train](2000/10000) average pos_loss: 0.07699199479818344
[proc 0][Train](2000/10000) average neg_loss: 0.10822429770231247
[proc 0][Train](2000/10000) average loss: 0.09260814625024795
[proc 0][Train](2000/10000) average regularization: 1.5222695363263483e-05
[proc 0][Train] 1000 steps take 23.976 seconds
[proc 0] 2000 steps, sample: 1.241, forward: 9.255, backward: 2.631, update: 10.819
[proc 0][Train](3000/10000) average pos_loss: 0.06348725843429566
[proc 0][Train](3000/10000) average neg_loss: 0.09280924601107836
[proc 0][Train](3000/10000) average loss: 0.07814825217425823
[proc 0][Train](3000/10000) average regularization: 1.711264246478095e-05
[proc 0][Train] 1000 steps take 24.059 seconds
[proc 0] 3000 steps, sample: 1.237, forward: 9.245, backward: 2.734, update: 10.836
[proc 1][Train](3000/10000) average pos_loss: 0.06313641162216663
[proc 1][Train](3000/10000) average neg_loss: 0.09269586338847875
[proc 1][Train](3000/10000) average loss: 0.07791613740473986
[proc 1][Train](3000/10000) average regularization: 1.7124967047493557e-05
[proc 1][Train] 1000 steps take 24.059 seconds
[proc 1] 3000 steps, sample: 1.234, forward: 9.237, backward: 2.762, update: 10.771
[proc 0][Train](4000/10000) average pos_loss: 0.05723688789457083
[proc 0][Train](4000/10000) average neg_loss: 0.08520677767321468
[proc 0][Train](4000/10000) average loss: 0.07122183274105191
[proc 0][Train](4000/10000) average regularization: 1.8316696106921883e-05
[proc 0][Train] 1000 steps take 24.131 seconds
[proc 0] 4000 steps, sample: 1.314, forward: 9.256, backward: 2.742, update: 10.812
[proc 1][Train](4000/10000) average pos_loss: 0.05696327370405197
[proc 1][Train](4000/10000) average neg_loss: 0.0850743915438652
[proc 1][Train](4000/10000) average loss: 0.071018832616508
[proc 1][Train](4000/10000) average regularization: 1.8332123901927845e-05
[proc 1][Train] 1000 steps take 24.131 seconds
[proc 1] 4000 steps, sample: 1.317, forward: 9.218, backward: 2.748, update: 10.750
[proc 0][Train](5000/10000) average pos_loss: 0.053500522907823325
[proc 0][Train](5000/10000) average neg_loss: 0.08060588002204895
[proc 0][Train](5000/10000) average loss: 0.0670532014220953
[proc 0][Train](5000/10000) average regularization: 1.9207445342544815e-05
[proc 0][Train] 1000 steps take 24.080 seconds
[proc 0] 5000 steps, sample: 1.257, forward: 9.266, backward: 2.716, update: 10.835
[proc 1][Train](5000/10000) average pos_loss: 0.05323736825585365
[proc 1][Train](5000/10000) average neg_loss: 0.08052001717686653
[proc 1][Train](5000/10000) average loss: 0.06687869264557958
[proc 1][Train](5000/10000) average regularization: 1.9219582576624816e-05
[proc 1][Train] 1000 steps take 24.080 seconds
[proc 1] 5000 steps, sample: 1.260, forward: 9.224, backward: 2.723, update: 10.761
[proc 0][Train](6000/10000) average pos_loss: 0.0510475313924253
[proc 0][Train](6000/10000) average neg_loss: 0.07746577537059784
[proc 0][Train](6000/10000) average loss: 0.06425665330514312
[proc 0][Train](6000/10000) average regularization: 1.9902975560398774e-05
[proc 0][Train] 1000 steps take 24.048 seconds
[proc 0] 6000 steps, sample: 1.242, forward: 9.256, backward: 2.715, update: 10.829
[proc 1][Train](6000/10000) average pos_loss: 0.05082917097955942
[proc 1][Train](6000/10000) average neg_loss: 0.07739340679720044
[proc 1][Train](6000/10000) average loss: 0.06411128886044025
[proc 1][Train](6000/10000) average regularization: 1.9922691277315606e-05
[proc 1][Train] 1000 steps take 24.048 seconds
[proc 1] 6000 steps, sample: 1.243, forward: 9.226, backward: 2.729, update: 10.767
[proc 0][Train](7000/10000) average pos_loss: 0.04913209366798401
[proc 0][Train](7000/10000) average neg_loss: 0.07505053575709462
[proc 0][Train](7000/10000) average loss: 0.06209131463244558
[proc 0][Train](7000/10000) average regularization: 2.0487563951974152e-05
[proc 0][Train] 1000 steps take 24.065 seconds
[proc 0] 7000 steps, sample: 1.237, forward: 9.270, backward: 2.744, update: 10.808
[proc 1][Train](7000/10000) average pos_loss: 0.0489176470823586
[proc 1][Train](7000/10000) average neg_loss: 0.07515184797719121
[proc 1][Train](7000/10000) average loss: 0.06203474758192897
[proc 1][Train](7000/10000) average regularization: 2.049952520428633e-05
[proc 1][Train] 1000 steps take 24.065 seconds
[proc 1] 7000 steps, sample: 1.236, forward: 9.231, backward: 2.762, update: 10.757
[proc 0][Train](8000/10000) average pos_loss: 0.04766853177919984
[proc 0][Train](8000/10000) average neg_loss: 0.07321541720628738
[proc 0][Train](8000/10000) average loss: 0.06044197445735335
[proc 0][Train](8000/10000) average regularization: 2.0976803156372626e-05
[proc 0][Train] 1000 steps take 24.112 seconds
[proc 0] 8000 steps, sample: 1.300, forward: 9.253, backward: 2.732, update: 10.822
[proc 1][Train](8000/10000) average pos_loss: 0.04745770031958819
[proc 1][Train](8000/10000) average neg_loss: 0.0732186866402626
[proc 1][Train](8000/10000) average loss: 0.060338193442672494
[proc 1][Train](8000/10000) average regularization: 2.0995847675294498e-05
[proc 1][Train] 1000 steps take 24.112 seconds
[proc 1] 8000 steps, sample: 1.299, forward: 9.229, backward: 2.755, update: 10.757
[proc 0][Train](9000/10000) average pos_loss: 0.04653917273879051
[proc 0][Train](9000/10000) average neg_loss: 0.07183925584331155
[proc 0][Train](9000/10000) average loss: 0.05918921421840787
[proc 0][Train](9000/10000) average regularization: 2.140505517309066e-05
[proc 0][Train] 1000 steps take 24.042 seconds
[proc 0] 9000 steps, sample: 1.249, forward: 9.247, backward: 2.723, update: 10.817
[proc 1][Train](9000/10000) average pos_loss: 0.04633545595034957
[proc 1][Train](9000/10000) average neg_loss: 0.07184156381711364
[proc 1][Train](9000/10000) average loss: 0.05908850998431444
[proc 1][Train](9000/10000) average regularization: 2.1423772181151436e-05
[proc 1][Train] 1000 steps take 24.042 seconds
[proc 1] 9000 steps, sample: 1.249, forward: 9.206, backward: 2.746, update: 10.743
[proc 1][Train](10000/10000) average pos_loss: 0.04533312353864312
[proc 1][Train](10000/10000) average neg_loss: 0.07058474368229509
[proc 1][Train](10000/10000) average loss: 0.057958933673799035
[proc 1][Train](10000/10000) average regularization: 2.180212878556631e-05
[proc 1][Train] 1000 steps take 23.997 seconds
[proc 1] 10000 steps, sample: 1.234, forward: 9.230, backward: 2.756, update: 10.771
[proc 0][Train](10000/10000) average pos_loss: 0.04554814838990569
[proc 0][Train](10000/10000) average neg_loss: 0.07048570525273681
[proc 0][Train](10000/10000) average loss: 0.05801692681759596
[proc 0][Train](10000/10000) average regularization: 2.1783744412459783e-05
[proc 0][Train] 1000 steps take 23.997 seconds
[proc 0] 10000 steps, sample: 1.235, forward: 9.284, backward: 2.640, update: 10.831
proc 1 takes 242.418 seconds
proc 0 takes 242.425 seconds
Successfully xmh. training takes 242.94532465934753 seconds
