Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 3 parts
part 0 has 101575884 edges
part 1 has 101575884 edges
part 2 has 101575882 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=3, num_proc=3, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_Freebase_3', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 733.619 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 1][Train](1000/10000) average pos_loss: 0.6721927297711372
[proc 1][Train](1000/10000) average neg_loss: 0.6902864033281804
[proc 1][Train](1000/10000) average loss: 0.6812395664453507
[proc 1][Train](1000/10000) average regularization: 8.05175756340759e-06
[proc 1][Train] 1000 steps take 43.898 seconds
[proc 1] 1000 steps, sample: 21.517, forward: 13.278, backward: 2.497, update: 6.598
[proc 0][Train](1000/10000) average pos_loss: 0.6685204318761826
[proc 0][Train](1000/10000) average neg_loss: 0.6971851187944412
[proc 0][Train](1000/10000) average loss: 0.6828527750968933
[proc 0][Train](1000/10000) average regularization: 7.972808099793838e-06
[proc 0][Train] 1000 steps take 44.371 seconds
[proc 0] 1000 steps, sample: 21.001, forward: 12.985, backward: 2.607, update: 6.172
[proc 2][Train](1000/10000) average pos_loss: 0.6681119202375412
[proc 2][Train](1000/10000) average neg_loss: 0.6966202044487
[proc 2][Train](1000/10000) average loss: 0.6823660628795624
[proc 2][Train](1000/10000) average regularization: 7.97928276233506e-06
[proc 2][Train] 1000 steps take 43.406 seconds
[proc 2] 1000 steps, sample: 20.226, forward: 12.914, backward: 2.640, update: 6.295
[proc 1][Train](2000/10000) average pos_loss: 0.6805531511306763
[proc 1][Train](2000/10000) average neg_loss: 0.6836745172739029
[proc 1][Train](2000/10000) average loss: 0.6821138335466385
[proc 1][Train](2000/10000) average regularization: 7.904526108632126e-06
[proc 1][Train] 1000 steps take 19.138 seconds
[proc 1] 2000 steps, sample: 2.455, forward: 7.449, backward: 2.568, update: 6.658
[proc 0][Train](2000/10000) average pos_loss: 0.6790461550951004
[proc 0][Train](2000/10000) average neg_loss: 0.6849966455698013
[proc 0][Train](2000/10000) average loss: 0.6820213985443115
[proc 0][Train](2000/10000) average regularization: 7.911225056432159e-06
[proc 0][Train] 1000 steps take 19.138 seconds
[proc 0] 2000 steps, sample: 2.386, forward: 7.338, backward: 2.680, update: 6.066
[proc 2][Train](2000/10000) average pos_loss: 0.679331848204136
[proc 2][Train](2000/10000) average neg_loss: 0.6850116782188416
[proc 2][Train](2000/10000) average loss: 0.682171761572361
[proc 2][Train](2000/10000) average regularization: 7.908308282367215e-06
[proc 2][Train] 1000 steps take 19.138 seconds
[proc 2] 2000 steps, sample: 2.426, forward: 7.469, backward: 2.607, update: 6.114
[proc 1][Train](3000/10000) average pos_loss: 0.6897030543088913
[proc 1][Train](3000/10000) average neg_loss: 0.6794861370325088
[proc 1][Train](3000/10000) average loss: 0.6845945955514908
[proc 1][Train](3000/10000) average regularization: 6.947453151042282e-06
[proc 1][Train] 1000 steps take 17.910 seconds
[proc 1] 3000 steps, sample: 2.434, forward: 6.233, backward: 2.613, update: 6.622
[proc 2][Train](3000/10000) average pos_loss: 0.6895210689902306
[proc 2][Train](3000/10000) average neg_loss: 0.6802352240681648
[proc 2][Train](3000/10000) average loss: 0.6848781458735466
[proc 2][Train](3000/10000) average regularization: 6.952361561616272e-06
[proc 2][Train] 1000 steps take 17.910 seconds
[proc 2] 3000 steps, sample: 2.436, forward: 6.434, backward: 2.563, update: 6.052
[proc 0][Train](3000/10000) average pos_loss: 0.6890807058811188
[proc 0][Train](3000/10000) average neg_loss: 0.680913793683052
[proc 0][Train](3000/10000) average loss: 0.6849972499608994
[proc 0][Train](3000/10000) average regularization: 6.957937787774426e-06
[proc 0][Train] 1000 steps take 17.910 seconds
[proc 0] 3000 steps, sample: 2.386, forward: 6.295, backward: 2.732, update: 5.943
[proc 1][Train](4000/10000) average pos_loss: 0.6947789296507836
[proc 1][Train](4000/10000) average neg_loss: 0.6759706594347954
[proc 1][Train](4000/10000) average loss: 0.6853747945427895
[proc 1][Train](4000/10000) average regularization: 6.4798893454280915e-06
[proc 1][Train] 1000 steps take 17.371 seconds
[proc 1] 4000 steps, sample: 2.476, forward: 5.845, backward: 2.568, update: 6.476
[proc 0][Train](4000/10000) average pos_loss: 0.6959733771681785
[proc 0][Train](4000/10000) average neg_loss: 0.6752078971862793
[proc 0][Train](4000/10000) average loss: 0.685590637087822
[proc 0][Train](4000/10000) average regularization: 6.4772051673571694e-06
[proc 0][Train] 1000 steps take 17.372 seconds
[proc 0] 4000 steps, sample: 2.373, forward: 5.992, backward: 2.722, update: 5.805
[proc 2][Train](4000/10000) average pos_loss: 0.6950638974905015
[proc 2][Train](4000/10000) average neg_loss: 0.6765007711052895
[proc 2][Train](4000/10000) average loss: 0.6857823345065117
[proc 2][Train](4000/10000) average regularization: 6.480239394022647e-06
[proc 2][Train] 1000 steps take 17.372 seconds
[proc 2] 4000 steps, sample: 2.339, forward: 5.890, backward: 2.603, update: 5.967
[proc 1][Train](5000/10000) average pos_loss: 0.700470545053482
[proc 1][Train](5000/10000) average neg_loss: 0.669034764111042
[proc 1][Train](5000/10000) average loss: 0.6847526544332504
[proc 1][Train](5000/10000) average regularization: 6.409107438685169e-06
[proc 1][Train] 1000 steps take 17.340 seconds
[proc 1] 5000 steps, sample: 2.569, forward: 5.625, backward: 2.623, update: 6.515
[proc 2][Train](5000/10000) average pos_loss: 0.6994901260733605
[proc 2][Train](5000/10000) average neg_loss: 0.6705208120942115
[proc 2][Train](5000/10000) average loss: 0.6850054691433907
[proc 2][Train](5000/10000) average regularization: 6.405772285688727e-06
[proc 2][Train] 1000 steps take 17.340 seconds
[proc 2] 5000 steps, sample: 2.518, forward: 5.766, backward: 2.582, update: 5.906
[proc 0][Train](5000/10000) average pos_loss: 0.7005366164445878
[proc 0][Train](5000/10000) average neg_loss: 0.671710569858551
[proc 0][Train](5000/10000) average loss: 0.6861235929727554
[proc 0][Train](5000/10000) average regularization: 6.404452908554958e-06
[proc 0][Train] 1000 steps take 17.340 seconds
[proc 0] 5000 steps, sample: 2.488, forward: 5.795, backward: 2.682, update: 5.956
[proc 1][Train](6000/10000) average pos_loss: 0.7034495638608933
[proc 1][Train](6000/10000) average neg_loss: 0.6648722431063652
[proc 1][Train](6000/10000) average loss: 0.6841609048247337
[proc 1][Train](6000/10000) average regularization: 6.455380575971503e-06
[proc 1][Train] 1000 steps take 16.973 seconds
[proc 1] 6000 steps, sample: 2.409, forward: 5.536, backward: 2.574, update: 6.447
[proc 2][Train](6000/10000) average pos_loss: 0.7051441057324409
[proc 2][Train](6000/10000) average neg_loss: 0.6642408220767975
[proc 2][Train](6000/10000) average loss: 0.6846924635767937
[proc 2][Train](6000/10000) average regularization: 6.459759008066612e-06
[proc 2][Train] 1000 steps take 16.973 seconds
[proc 2] 6000 steps, sample: 2.413, forward: 5.751, backward: 2.622, update: 5.937
[proc 0][Train](6000/10000) average pos_loss: 0.7024500588178635
[proc 0][Train](6000/10000) average neg_loss: 0.6650156984925271
[proc 0][Train](6000/10000) average loss: 0.6837328780889511
[proc 0][Train](6000/10000) average regularization: 6.45665673800977e-06
[proc 0][Train] 1000 steps take 16.973 seconds
[proc 0] 6000 steps, sample: 2.344, forward: 5.678, backward: 2.653, update: 5.861
[proc 1][Train](7000/10000) average pos_loss: 0.7057882508039475
[proc 1][Train](7000/10000) average neg_loss: 0.6586515915393829
[proc 1][Train](7000/10000) average loss: 0.6822199221849442
[proc 1][Train](7000/10000) average regularization: 6.532169576985325e-06
[proc 1][Train] 1000 steps take 16.879 seconds
[proc 1] 7000 steps, sample: 2.401, forward: 5.527, backward: 2.603, update: 6.341
[proc 2][Train](7000/10000) average pos_loss: 0.7071885744929314
[proc 2][Train](7000/10000) average neg_loss: 0.6591747889518738
[proc 2][Train](7000/10000) average loss: 0.6831816808581352
[proc 2][Train](7000/10000) average regularization: 6.533467875215138e-06
[proc 2][Train] 1000 steps take 16.879 seconds
[proc 2] 7000 steps, sample: 2.377, forward: 5.755, backward: 2.573, update: 5.829
[proc 0][Train](7000/10000) average pos_loss: 0.7064208003878594
[proc 0][Train](7000/10000) average neg_loss: 0.6583798351287842
[proc 0][Train](7000/10000) average loss: 0.6824003185033798
[proc 0][Train](7000/10000) average regularization: 6.530912681682821e-06
[proc 0][Train] 1000 steps take 16.879 seconds
[proc 0] 7000 steps, sample: 2.288, forward: 5.661, backward: 2.601, update: 5.823
[proc 1][Train](8000/10000) average pos_loss: 0.708311932682991
[proc 1][Train](8000/10000) average neg_loss: 0.6529198954105377
[proc 1][Train](8000/10000) average loss: 0.6806159137487412
[proc 1][Train](8000/10000) average regularization: 6.6178212900922515e-06
[proc 1][Train] 1000 steps take 16.888 seconds
[proc 1] 8000 steps, sample: 2.422, forward: 5.511, backward: 2.588, update: 6.359
[proc 2][Train](8000/10000) average pos_loss: 0.7097160033583642
[proc 2][Train](8000/10000) average neg_loss: 0.6526150416135788
[proc 2][Train](8000/10000) average loss: 0.6811655220389367
[proc 2][Train](8000/10000) average regularization: 6.617222230033804e-06
[proc 2][Train] 1000 steps take 16.888 seconds
[proc 2] 8000 steps, sample: 2.393, forward: 5.636, backward: 2.597, update: 5.829
[proc 0][Train](8000/10000) average pos_loss: 0.7085444695949554
[proc 0][Train](8000/10000) average neg_loss: 0.6545325559973717
[proc 0][Train](8000/10000) average loss: 0.6815385127067566
[proc 0][Train](8000/10000) average regularization: 6.6156800439785e-06
[proc 0][Train] 1000 steps take 16.888 seconds
[proc 0] 8000 steps, sample: 2.274, forward: 5.639, backward: 2.587, update: 5.893
[proc 1][Train](9000/10000) average pos_loss: 0.709303905248642
[proc 1][Train](9000/10000) average neg_loss: 0.6477181259989738
[proc 1][Train](9000/10000) average loss: 0.6785110154747963
[proc 1][Train](9000/10000) average regularization: 6.700770275529066e-06
[proc 1][Train] 1000 steps take 16.993 seconds
[proc 1] 9000 steps, sample: 2.562, forward: 5.493, backward: 2.579, update: 6.352
[proc 2][Train](9000/10000) average pos_loss: 0.7096821129918098
[proc 2][Train](9000/10000) average neg_loss: 0.6472544308304786
[proc 2][Train](9000/10000) average loss: 0.6784682717323304
[proc 2][Train](9000/10000) average regularization: 6.7056214111289596e-06
[proc 2][Train] 1000 steps take 16.993 seconds
[proc 2] 9000 steps, sample: 2.488, forward: 5.621, backward: 2.582, update: 5.844
[proc 0][Train](9000/10000) average pos_loss: 0.7099179356694222
[proc 0][Train](9000/10000) average neg_loss: 0.6480378504991532
[proc 0][Train](9000/10000) average loss: 0.6789778929948806
[proc 0][Train](9000/10000) average regularization: 6.701952377625275e-06
[proc 0][Train] 1000 steps take 16.993 seconds
[proc 0] 9000 steps, sample: 2.502, forward: 5.663, backward: 2.586, update: 5.813
[proc 1][Train](10000/10000) average pos_loss: 0.7115149670243264
[proc 1][Train](10000/10000) average neg_loss: 0.6422633652687073
[proc 1][Train](10000/10000) average loss: 0.6768891665935516
[proc 1][Train](10000/10000) average regularization: 6.793502523123607e-06
[proc 1][Train] 1000 steps take 16.803 seconds
[proc 1] 10000 steps, sample: 2.427, forward: 5.473, backward: 2.582, update: 6.314
proc 1 takes 200.194 seconds
[proc 2][Train](10000/10000) average pos_loss: 0.7096158275008202
[proc 2][Train](10000/10000) average neg_loss: 0.6421259233355522
[proc 2][Train](10000/10000) average loss: 0.6758708756566048
[proc 2][Train](10000/10000) average regularization: 6.79091969414003e-06
[proc 2][Train] 1000 steps take 16.803 seconds
[proc 2] 10000 steps, sample: 2.403, forward: 5.679, backward: 2.543, update: 5.781
proc 2 takes 199.703 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.7104202134609222
[proc 0][Train](10000/10000) average neg_loss: 0.641362406373024
[proc 0][Train](10000/10000) average loss: 0.6758913095593453
[proc 0][Train](10000/10000) average regularization: 6.792842971208301e-06
[proc 0][Train] 1000 steps take 16.803 seconds
[proc 0] 10000 steps, sample: 2.273, forward: 5.681, backward: 2.625, update: 5.807
proc 0 takes 200.667 seconds
Successfully xmh. training takes 214.25082564353943 seconds
