Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 2 parts
part 0 has 241571 edges
part 1 has 241571 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_FB15k_8', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 1.021 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.21334746968746185
[proc 0][Train](1000/10000) average neg_loss: 0.22963446448743344
[proc 0][Train](1000/10000) average loss: 0.2214909674152732
[proc 0][Train](1000/10000) average regularization: 1.081164408742552e-05
[proc 0][Train] 1000 steps take 16.221 seconds
[proc 0] 1000 steps, sample: 1.977, forward: 6.948, backward: 2.577, update: 4.711
[proc 1][Train](1000/10000) average pos_loss: 0.21551827705651522
[proc 1][Train](1000/10000) average neg_loss: 0.23618922278285026
[proc 1][Train](1000/10000) average loss: 0.2258537500873208
[proc 1][Train](1000/10000) average regularization: 1.0704493569164697e-05
[proc 1][Train] 1000 steps take 16.163 seconds
[proc 1] 1000 steps, sample: 1.794, forward: 6.773, backward: 2.522, update: 4.589
[proc 0][Train](2000/10000) average pos_loss: 0.07673631147667766
[proc 0][Train](2000/10000) average neg_loss: 0.1080080062970519
[proc 0][Train](2000/10000) average loss: 0.09237215881794691
[proc 0][Train](2000/10000) average regularization: 1.5349880685789684e-05
[proc 0][Train] 1000 steps take 13.966 seconds
[proc 0] 2000 steps, sample: 1.858, forward: 4.906, backward: 2.523, update: 4.671
[proc 1][Train](2000/10000) average pos_loss: 0.07646393343806267
[proc 1][Train](2000/10000) average neg_loss: 0.10780369637906552
[proc 1][Train](2000/10000) average loss: 0.09213381493091584
[proc 1][Train](2000/10000) average regularization: 1.5310139876419272e-05
[proc 1][Train] 1000 steps take 13.966 seconds
[proc 1] 2000 steps, sample: 1.773, forward: 4.812, backward: 2.475, update: 4.591
[proc 0][Train](3000/10000) average pos_loss: 0.06327203769981861
[proc 0][Train](3000/10000) average neg_loss: 0.09274412743747235
[proc 0][Train](3000/10000) average loss: 0.07800808253139258
[proc 0][Train](3000/10000) average regularization: 1.723629969092144e-05
[proc 0][Train] 1000 steps take 13.780 seconds
[proc 0] 3000 steps, sample: 1.787, forward: 4.899, backward: 2.530, update: 4.557
[proc 1][Train](3000/10000) average pos_loss: 0.06304814736172556
[proc 1][Train](3000/10000) average neg_loss: 0.0922599521651864
[proc 1][Train](3000/10000) average loss: 0.07765404970198869
[proc 1][Train](3000/10000) average regularization: 1.7237168285646477e-05
[proc 1][Train] 1000 steps take 13.779 seconds
[proc 1] 3000 steps, sample: 1.765, forward: 4.857, backward: 2.453, update: 4.596
[proc 1][Train](4000/10000) average pos_loss: 0.05683829491585493
[proc 1][Train](4000/10000) average neg_loss: 0.08473943399265409
[proc 1][Train](4000/10000) average loss: 0.07078886445611715
[proc 1][Train](4000/10000) average regularization: 1.8456940786563793e-05
[proc 1][Train] 1000 steps take 13.996 seconds
[proc 1] 4000 steps, sample: 1.950, forward: 4.825, backward: 2.554, update: 4.660
[proc 0][Train](4000/10000) average pos_loss: 0.05718312906846404
[proc 0][Train](4000/10000) average neg_loss: 0.0853279593102634
[proc 0][Train](4000/10000) average loss: 0.07125554420053959
[proc 0][Train](4000/10000) average regularization: 1.844623104443599e-05
[proc 0][Train] 1000 steps take 13.997 seconds
[proc 0] 4000 steps, sample: 1.967, forward: 4.794, backward: 2.565, update: 4.566
[proc 1][Train](5000/10000) average pos_loss: 0.05313640996068716
[proc 1][Train](5000/10000) average neg_loss: 0.08027987159788609
[proc 1][Train](5000/10000) average loss: 0.06670814071595668
[proc 1][Train](5000/10000) average regularization: 1.9344770187672112e-05
[proc 1][Train] 1000 steps take 13.782 seconds
[proc 1] 5000 steps, sample: 1.815, forward: 4.838, backward: 2.506, update: 4.615
[proc 0][Train](5000/10000) average pos_loss: 0.05360482916980982
[proc 0][Train](5000/10000) average neg_loss: 0.08070743940025568
[proc 0][Train](5000/10000) average loss: 0.06715613426640629
[proc 0][Train](5000/10000) average regularization: 1.9336689700139688e-05
[proc 0][Train] 1000 steps take 13.782 seconds
[proc 0] 5000 steps, sample: 1.790, forward: 4.809, backward: 2.571, update: 4.548
[proc 1][Train](6000/10000) average pos_loss: 0.05064514606446028
[proc 1][Train](6000/10000) average neg_loss: 0.07706022219359875
[proc 1][Train](6000/10000) average loss: 0.06385268408805132
[proc 1][Train](6000/10000) average regularization: 2.005445407849038e-05
[proc 1][Train] 1000 steps take 13.769 seconds
[proc 1] 6000 steps, sample: 1.804, forward: 4.740, backward: 2.547, update: 4.672
[proc 0][Train](6000/10000) average pos_loss: 0.0510300088301301
[proc 0][Train](6000/10000) average neg_loss: 0.07760105438902974
[proc 0][Train](6000/10000) average loss: 0.06431553159281611
[proc 0][Train](6000/10000) average regularization: 2.0044516653797472e-05
[proc 0][Train] 1000 steps take 13.768 seconds
[proc 0] 6000 steps, sample: 1.765, forward: 4.800, backward: 2.563, update: 4.592
[proc 1][Train](7000/10000) average pos_loss: 0.048792672600597144
[proc 1][Train](7000/10000) average neg_loss: 0.0747876534461975
[proc 1][Train](7000/10000) average loss: 0.06179016309604049
[proc 1][Train](7000/10000) average regularization: 2.0627109155611834e-05
[proc 1][Train] 1000 steps take 13.690 seconds
[proc 1] 7000 steps, sample: 1.754, forward: 4.787, backward: 2.662, update: 4.480
[proc 0][Train](7000/10000) average pos_loss: 0.04913774912059307
[proc 0][Train](7000/10000) average neg_loss: 0.07522312811762094
[proc 0][Train](7000/10000) average loss: 0.062180438615381715
[proc 0][Train](7000/10000) average regularization: 2.0627554344173403e-05
[proc 0][Train] 1000 steps take 13.690 seconds
[proc 0] 7000 steps, sample: 1.736, forward: 4.775, backward: 2.542, update: 4.553
[proc 1][Train](8000/10000) average pos_loss: 0.0473863655179739
[proc 1][Train](8000/10000) average neg_loss: 0.07291767781972885
[proc 1][Train](8000/10000) average loss: 0.060152021568268536
[proc 1][Train](8000/10000) average regularization: 2.1124190472619376e-05
[proc 1][Train] 1000 steps take 13.952 seconds
[proc 1] 8000 steps, sample: 1.933, forward: 4.842, backward: 2.620, update: 4.550
[proc 0][Train](8000/10000) average pos_loss: 0.0477070878110826
[proc 0][Train](8000/10000) average neg_loss: 0.07331092374399305
[proc 0][Train](8000/10000) average loss: 0.06050900575891137
[proc 0][Train](8000/10000) average regularization: 2.111237581993919e-05
[proc 0][Train] 1000 steps take 13.952 seconds
[proc 0] 8000 steps, sample: 1.870, forward: 4.840, backward: 2.539, update: 4.571
[proc 1][Train](9000/10000) average pos_loss: 0.046273614313453434
[proc 1][Train](9000/10000) average neg_loss: 0.07161114619672299
[proc 1][Train](9000/10000) average loss: 0.058942380234599114
[proc 1][Train](9000/10000) average regularization: 2.1557026790105738e-05
[proc 1][Train] 1000 steps take 14.016 seconds
[proc 1] 9000 steps, sample: 1.912, forward: 4.860, backward: 2.592, update: 4.645
[proc 0][Train](9000/10000) average pos_loss: 0.04651351355388761
[proc 0][Train](9000/10000) average neg_loss: 0.07189345424994827
[proc 0][Train](9000/10000) average loss: 0.05920348381623626
[proc 0][Train](9000/10000) average regularization: 2.1544477676798123e-05
[proc 0][Train] 1000 steps take 14.016 seconds
[proc 0] 9000 steps, sample: 1.759, forward: 4.788, backward: 2.551, update: 4.528
[proc 1][Train](10000/10000) average pos_loss: 0.04525164058804512
[proc 1][Train](10000/10000) average neg_loss: 0.07037989889457821
[proc 1][Train](10000/10000) average loss: 0.0578157698251307
[proc 1][Train](10000/10000) average regularization: 2.193495428218739e-05
[proc 1][Train] 1000 steps take 13.890 seconds
[proc 1] 10000 steps, sample: 1.833, forward: 4.716, backward: 2.616, update: 4.718
proc 1 takes 141.005 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.04567555168643594
[proc 0][Train](10000/10000) average neg_loss: 0.07078685796260833
[proc 0][Train](10000/10000) average loss: 0.05823120482638478
[proc 0][Train](10000/10000) average regularization: 2.1919993065239397e-05
[proc 0][Train] 1000 steps take 13.890 seconds
[proc 0] 10000 steps, sample: 1.722, forward: 4.760, backward: 2.553, update: 4.609
proc 0 takes 141.064 seconds
Successfully xmh. training takes 141.4521026611328 seconds
