Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 2 parts
part 0 has 241571 edges
part 1 has 241571 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_FB15k_18', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 0.983 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.21447607234865426
[proc 0][Train](1000/10000) average neg_loss: 0.23157730320841075
[proc 0][Train](1000/10000) average loss: 0.22302668768912554
[proc 0][Train](1000/10000) average regularization: 1.0743694695065642e-05
[proc 0] 1000 steps, total: 15.538, sample: 1.851, forward: 6.073, backward: 2.642, update: 4.965
[proc 1][Train](1000/10000) average pos_loss: 0.21553750689327716
[proc 1][Train](1000/10000) average neg_loss: 0.23525252681970596
[proc 1][Train](1000/10000) average loss: 0.22539501721411945
[proc 1][Train](1000/10000) average regularization: 1.0700744265932371e-05
[proc 1] 1000 steps, total: 15.538, sample: 1.716, forward: 6.422, backward: 2.682, update: 4.554
[proc 0][Train](2000/10000) average pos_loss: 0.07668147934228182
[proc 0][Train](2000/10000) average neg_loss: 0.1077611835822463
[proc 0][Train](2000/10000) average loss: 0.09222133148461581
[proc 0][Train](2000/10000) average regularization: 1.530618498873082e-05
[proc 0] 2000 steps, total: 13.534, sample: 1.680, forward: 4.259, backward: 2.742, update: 4.846
[proc 1][Train](2000/10000) average pos_loss: 0.07657905802503229
[proc 1][Train](2000/10000) average neg_loss: 0.10811418156325817
[proc 1][Train](2000/10000) average loss: 0.09234661983698607
[proc 1][Train](2000/10000) average regularization: 1.528008704462991e-05
[proc 1] 2000 steps, total: 13.534, sample: 1.582, forward: 4.609, backward: 2.651, update: 4.505
[proc 0][Train](3000/10000) average pos_loss: 0.06313032427057624
[proc 0][Train](3000/10000) average neg_loss: 0.09233621004223823
[proc 0][Train](3000/10000) average loss: 0.07773326719552279
[proc 0][Train](3000/10000) average regularization: 1.7208693461725487e-05
[proc 0] 3000 steps, total: 13.643, sample: 1.713, forward: 4.293, backward: 2.737, update: 4.892
[proc 1][Train](3000/10000) average pos_loss: 0.06312369806319475
[proc 1][Train](3000/10000) average neg_loss: 0.09257908186316491
[proc 1][Train](3000/10000) average loss: 0.07785139008238912
[proc 1][Train](3000/10000) average regularization: 1.7192224357131635e-05
[proc 1] 3000 steps, total: 13.643, sample: 1.578, forward: 4.581, backward: 2.647, update: 4.492
[proc 0][Train](4000/10000) average pos_loss: 0.05712694775313139
[proc 0][Train](4000/10000) average neg_loss: 0.08487065202742815
[proc 0][Train](4000/10000) average loss: 0.07099879998713732
[proc 0][Train](4000/10000) average regularization: 1.8430971680572837e-05
[proc 0] 4000 steps, total: 14.482, sample: 2.108, forward: 4.547, backward: 2.768, update: 5.050
[proc 1][Train](4000/10000) average pos_loss: 0.05686906211078167
[proc 1][Train](4000/10000) average neg_loss: 0.08520390318706632
[proc 1][Train](4000/10000) average loss: 0.0710364827401936
[proc 1][Train](4000/10000) average regularization: 1.8396114041024702e-05
[proc 1] 4000 steps, total: 14.482, sample: 1.808, forward: 4.705, backward: 2.695, update: 4.601
[proc 0][Train](5000/10000) average pos_loss: 0.05331512048840523
[proc 0][Train](5000/10000) average neg_loss: 0.0804013049788773
[proc 0][Train](5000/10000) average loss: 0.06685821276158094
[proc 0][Train](5000/10000) average regularization: 1.9321869216582856e-05
[proc 0] 5000 steps, total: 14.093, sample: 1.853, forward: 4.467, backward: 2.740, update: 5.024
[proc 1][Train](5000/10000) average pos_loss: 0.05327837694436312
[proc 1][Train](5000/10000) average neg_loss: 0.08050261677056551
[proc 1][Train](5000/10000) average loss: 0.06689049676433205
[proc 1][Train](5000/10000) average regularization: 1.9298606763186397e-05
[proc 1] 5000 steps, total: 14.093, sample: 1.651, forward: 4.646, backward: 2.655, update: 4.543
[proc 1][Train](6000/10000) average pos_loss: 0.05088327765837312
[proc 1][Train](6000/10000) average neg_loss: 0.07738817933946848
[proc 1][Train](6000/10000) average loss: 0.06413572849333286
[proc 1][Train](6000/10000) average regularization: 2.0005451673569042e-05
[proc 1] 6000 steps, total: 13.483, sample: 1.627, forward: 4.580, backward: 2.669, update: 4.479
[proc 0][Train](6000/10000) average pos_loss: 0.05065423615276814
[proc 0][Train](6000/10000) average neg_loss: 0.07716306393966078
[proc 0][Train](6000/10000) average loss: 0.06390865008533
[proc 0][Train](6000/10000) average regularization: 2.00131971432711e-05
[proc 0] 6000 steps, total: 13.485, sample: 1.685, forward: 4.241, backward: 2.684, update: 4.867
[proc 0][Train](7000/10000) average pos_loss: 0.0490448678098619
[proc 0][Train](7000/10000) average neg_loss: 0.07496605154871941
[proc 0][Train](7000/10000) average loss: 0.0620054596811533
[proc 0][Train](7000/10000) average regularization: 2.0606978905561847e-05
[proc 0] 7000 steps, total: 13.978, sample: 1.872, forward: 4.398, backward: 2.693, update: 5.007
[proc 1][Train](7000/10000) average pos_loss: 0.048879172049462793
[proc 1][Train](7000/10000) average neg_loss: 0.0750723692253232
[proc 1][Train](7000/10000) average loss: 0.061975770652294156
[proc 1][Train](7000/10000) average regularization: 2.0583826646543456e-05
[proc 1] 7000 steps, total: 13.979, sample: 1.579, forward: 4.558, backward: 2.654, update: 4.472
[proc 0][Train](8000/10000) average pos_loss: 0.047429926004260776
[proc 0][Train](8000/10000) average neg_loss: 0.07308462001383305
[proc 0][Train](8000/10000) average loss: 0.06025727297738195
[proc 0][Train](8000/10000) average regularization: 2.1103968127135887e-05
[proc 0] 8000 steps, total: 13.681, sample: 1.815, forward: 4.279, backward: 2.705, update: 4.875
[proc 1][Train](8000/10000) average pos_loss: 0.04755254166573286
[proc 1][Train](8000/10000) average neg_loss: 0.07324116201326251
[proc 1][Train](8000/10000) average loss: 0.06039685178175568
[proc 1][Train](8000/10000) average regularization: 2.1085491551275482e-05
[proc 1] 8000 steps, total: 13.681, sample: 1.706, forward: 4.635, backward: 2.660, update: 4.531
[proc 0][Train](9000/10000) average pos_loss: 0.046374459620565175
[proc 0][Train](9000/10000) average neg_loss: 0.07165798412635922
[proc 0][Train](9000/10000) average loss: 0.059016221921890974
[proc 0][Train](9000/10000) average regularization: 2.1526307242311305e-05
[proc 0] 9000 steps, total: 13.424, sample: 1.664, forward: 4.209, backward: 2.737, update: 4.807
[proc 1][Train](9000/10000) average pos_loss: 0.04639327987655997
[proc 1][Train](9000/10000) average neg_loss: 0.07181884720921516
[proc 1][Train](9000/10000) average loss: 0.05910606345161796
[proc 1][Train](9000/10000) average regularization: 2.1518035615372355e-05
[proc 1] 9000 steps, total: 13.423, sample: 1.622, forward: 4.589, backward: 2.648, update: 4.501
[proc 1][Train](10000/10000) average pos_loss: 0.04545256650447845
[proc 1][Train](10000/10000) average neg_loss: 0.07061533203721046
[proc 1][Train](10000/10000) average loss: 0.058033949289470914
[proc 1][Train](10000/10000) average regularization: 2.1899615181609987e-05
[proc 1] 10000 steps, total: 13.497, sample: 1.636, forward: 4.664, backward: 2.646, update: 4.545
proc 1 takes 139.355 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.04536368268355727
[proc 0][Train](10000/10000) average neg_loss: 0.07050493942946195
[proc 0][Train](10000/10000) average loss: 0.057934311036020515
[proc 0][Train](10000/10000) average regularization: 2.1913865306487425e-05
[proc 0] 10000 steps, total: 13.498, sample: 1.640, forward: 4.194, backward: 2.739, update: 4.798
proc 0 takes 139.355 seconds
Successfully xmh. training takes 139.79757022857666 seconds
