Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 2 parts
part 0 has 152363825 edges
part 1 has 152363825 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_Freebase_11', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 744.835 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 1][Train](1000/10000) average pos_loss: 0.6648252543061972
[proc 1][Train](1000/10000) average neg_loss: 0.6945989091396332
[proc 1][Train](1000/10000) average loss: 0.6797120811939239
[proc 1][Train](1000/10000) average regularization: 6.771500389504581e-06
[proc 1] 1000 steps, total: 53.620, sample: 31.902, forward: 12.560, backward: 2.621, update: 6.529
[proc 0][Train](1000/10000) average pos_loss: 0.6722298769652844
[proc 0][Train](1000/10000) average neg_loss: 0.6997969898581505
[proc 0][Train](1000/10000) average loss: 0.6860134335756302
[proc 0][Train](1000/10000) average regularization: 6.617429512971285e-06
[proc 0] 1000 steps, total: 54.130, sample: 30.484, forward: 12.445, backward: 2.763, update: 6.160
[proc 1][Train](2000/10000) average pos_loss: 0.6713956026434899
[proc 1][Train](2000/10000) average neg_loss: 0.6866184905767441
[proc 1][Train](2000/10000) average loss: 0.6790070472359657
[proc 1][Train](2000/10000) average regularization: 7.206093098375277e-06
[proc 1] 2000 steps, total: 18.706, sample: 2.347, forward: 7.194, backward: 2.960, update: 6.197
[proc 0][Train](2000/10000) average pos_loss: 0.672430384516716
[proc 0][Train](2000/10000) average neg_loss: 0.6858649806976318
[proc 0][Train](2000/10000) average loss: 0.679147682249546
[proc 0][Train](2000/10000) average regularization: 7.205507724847848e-06
[proc 0] 2000 steps, total: 18.706, sample: 2.281, forward: 7.440, backward: 2.774, update: 6.083
[proc 1][Train](3000/10000) average pos_loss: 0.6814617013931275
[proc 1][Train](3000/10000) average neg_loss: 0.6839982764720917
[proc 1][Train](3000/10000) average loss: 0.682729988515377
[proc 1][Train](3000/10000) average regularization: 6.975644291742355e-06
[proc 1] 3000 steps, total: 17.543, sample: 2.399, forward: 6.049, backward: 2.864, update: 6.223
[proc 0][Train](3000/10000) average pos_loss: 0.6809510436058045
[proc 0][Train](3000/10000) average neg_loss: 0.6840601636767387
[proc 0][Train](3000/10000) average loss: 0.6825056047439575
[proc 0][Train](3000/10000) average regularization: 6.981613409152487e-06
[proc 0] 3000 steps, total: 17.543, sample: 2.261, forward: 6.247, backward: 2.704, update: 5.929
[proc 0][Train](4000/10000) average pos_loss: 0.6876842860579491
[proc 0][Train](4000/10000) average neg_loss: 0.6815880249142647
[proc 0][Train](4000/10000) average loss: 0.6846361556649208
[proc 0][Train](4000/10000) average regularization: 6.594510376544349e-06
[proc 0] 4000 steps, total: 16.942, sample: 2.307, forward: 5.868, backward: 2.742, update: 6.017
[proc 1][Train](4000/10000) average pos_loss: 0.6877958222031594
[proc 1][Train](4000/10000) average neg_loss: 0.680766577064991
[proc 1][Train](4000/10000) average loss: 0.6842811990380288
[proc 1][Train](4000/10000) average regularization: 6.6060347103302775e-06
[proc 1] 4000 steps, total: 16.943, sample: 2.235, forward: 5.413, backward: 1.862, update: 6.366
[proc 1][Train](5000/10000) average pos_loss: 0.692298636674881
[proc 1][Train](5000/10000) average neg_loss: 0.6787688559889793
[proc 1][Train](5000/10000) average loss: 0.6855337464213371
[proc 1][Train](5000/10000) average regularization: 6.354967052175197e-06
[proc 1] 5000 steps, total: 16.890, sample: 2.499, forward: 5.466, backward: 2.781, update: 6.136
[proc 0][Train](5000/10000) average pos_loss: 0.6924722023010254
[proc 0][Train](5000/10000) average neg_loss: 0.6779408032894134
[proc 0][Train](5000/10000) average loss: 0.685206503033638
[proc 0][Train](5000/10000) average regularization: 6.35639067604643e-06
[proc 0] 5000 steps, total: 16.891, sample: 2.409, forward: 5.646, backward: 2.691, update: 5.856
[proc 0][Train](6000/10000) average pos_loss: 0.6962779570817947
[proc 0][Train](6000/10000) average neg_loss: 0.6743264013528824
[proc 0][Train](6000/10000) average loss: 0.6853021783828736
[proc 0][Train](6000/10000) average regularization: 6.283320137754345e-06
[proc 0] 6000 steps, total: 16.523, sample: 2.304, forward: 5.649, backward: 2.699, update: 5.864
[proc 1][Train](6000/10000) average pos_loss: 0.6958922169804573
[proc 1][Train](6000/10000) average neg_loss: 0.6756897412538528
[proc 1][Train](6000/10000) average loss: 0.6857909802794456
[proc 1][Train](6000/10000) average regularization: 6.2831463842485395e-06
[proc 1] 6000 steps, total: 16.525, sample: 2.185, forward: 5.150, backward: 2.762, update: 5.925
[proc 0][Train](7000/10000) average pos_loss: 0.6986082793474198
[proc 0][Train](7000/10000) average neg_loss: 0.6702595316171646
[proc 0][Train](7000/10000) average loss: 0.684433906853199
[proc 0][Train](7000/10000) average regularization: 6.2956536626188604e-06
[proc 0] 7000 steps, total: 16.528, sample: 2.279, forward: 5.635, backward: 2.779, update: 5.827
[proc 1][Train](7000/10000) average pos_loss: 0.6982709339857102
[proc 1][Train](7000/10000) average neg_loss: 0.671168628692627
[proc 1][Train](7000/10000) average loss: 0.684719781935215
[proc 1][Train](7000/10000) average regularization: 6.295805520494469e-06
[proc 1] 7000 steps, total: 16.529, sample: 2.297, forward: 5.284, backward: 2.771, update: 5.979
[proc 1][Train](8000/10000) average pos_loss: 0.7021360623836518
[proc 1][Train](8000/10000) average neg_loss: 0.6676850715875625
[proc 1][Train](8000/10000) average loss: 0.6849105674624443
[proc 1][Train](8000/10000) average regularization: 6.336603594263579e-06
[proc 1] 8000 steps, total: 16.329, sample: 2.316, forward: 5.308, backward: 2.735, update: 5.961
[proc 0][Train](8000/10000) average pos_loss: 0.7016455605626106
[proc 0][Train](8000/10000) average neg_loss: 0.6671416025161743
[proc 0][Train](8000/10000) average loss: 0.6843935806155205
[proc 0][Train](8000/10000) average regularization: 6.336673009627703e-06
[proc 0] 8000 steps, total: 16.331, sample: 2.256, forward: 5.535, backward: 2.702, update: 5.693
[proc 0][Train](9000/10000) average pos_loss: 0.703596903860569
[proc 0][Train](9000/10000) average neg_loss: 0.6634091718196868
[proc 0][Train](9000/10000) average loss: 0.6835030383467674
[proc 0][Train](9000/10000) average regularization: 6.392184192463901e-06
[proc 0] 9000 steps, total: 16.591, sample: 2.542, forward: 5.590, backward: 2.711, update: 5.739
[proc 1][Train](9000/10000) average pos_loss: 0.704138162791729
[proc 1][Train](9000/10000) average neg_loss: 0.6629557269215584
[proc 1][Train](9000/10000) average loss: 0.6835469450354577
[proc 1][Train](9000/10000) average regularization: 6.392348142526316e-06
[proc 1] 9000 steps, total: 16.592, sample: 2.468, forward: 5.324, backward: 2.839, update: 5.903
[proc 0][Train](10000/10000) average pos_loss: 0.7055368921160698
[proc 0][Train](10000/10000) average neg_loss: 0.6587662636041641
[proc 0][Train](10000/10000) average loss: 0.682151577949524
[proc 0][Train](10000/10000) average regularization: 6.449081102800847e-06
[proc 0] 10000 steps, total: 16.497, sample: 2.259, forward: 5.693, backward: 2.743, update: 5.794
proc 0 takes 206.682 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.7058709394931794
[proc 1][Train](10000/10000) average neg_loss: 0.6591507942080498
[proc 1][Train](10000/10000) average loss: 0.6825108659267426
[proc 1][Train](10000/10000) average regularization: 6.447571744956804e-06
[proc 1] 10000 steps, total: 16.497, sample: 2.192, forward: 5.169, backward: 2.764, update: 5.811
proc 1 takes 206.175 seconds
Successfully xmh. training takes 214.88584542274475 seconds
