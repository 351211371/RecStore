Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 2 parts
part 0 has 152363825 edges
part 1 has 152363825 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_Freebase_2', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 738.931 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.6646767787039279
[proc 0][Train](1000/10000) average neg_loss: 0.6947906853556634
[proc 0][Train](1000/10000) average loss: 0.6797337318658829
[proc 0][Train](1000/10000) average regularization: 7.3252820054676704e-06
[proc 0][Train] 1000 steps take 54.656 seconds
[proc 0] 1000 steps, sample: 32.562, forward: 13.101, backward: 2.612, update: 6.374
[proc 1][Train](1000/10000) average pos_loss: 0.6776282791793347
[proc 1][Train](1000/10000) average neg_loss: 0.6991592746227979
[proc 1][Train](1000/10000) average loss: 0.6883937776088714
[proc 1][Train](1000/10000) average regularization: 7.189872542539888e-06
[proc 1][Train] 1000 steps take 54.128 seconds
[proc 1] 1000 steps, sample: 29.307, forward: 13.165, backward: 2.640, update: 6.138
[proc 0][Train](2000/10000) average pos_loss: 0.6721386362910271
[proc 0][Train](2000/10000) average neg_loss: 0.6867090491652489
[proc 0][Train](2000/10000) average loss: 0.6794238424897194
[proc 0][Train](2000/10000) average regularization: 7.692890720591094e-06
[proc 0][Train] 1000 steps take 18.737 seconds
[proc 0] 2000 steps, sample: 2.539, forward: 7.191, backward: 2.556, update: 6.443
[proc 1][Train](2000/10000) average pos_loss: 0.67167940056324
[proc 1][Train](2000/10000) average neg_loss: 0.6855952609181404
[proc 1][Train](2000/10000) average loss: 0.6786373307704926
[proc 1][Train](2000/10000) average regularization: 7.70355467693662e-06
[proc 1][Train] 1000 steps take 18.736 seconds
[proc 1] 2000 steps, sample: 2.365, forward: 7.275, backward: 2.739, update: 6.050
[proc 0][Train](3000/10000) average pos_loss: 0.6809967386126519
[proc 0][Train](3000/10000) average neg_loss: 0.6835562922954559
[proc 0][Train](3000/10000) average loss: 0.6822765156626701
[proc 0][Train](3000/10000) average regularization: 7.355269069194037e-06
[proc 0][Train] 1000 steps take 17.286 seconds
[proc 0] 3000 steps, sample: 2.481, forward: 5.975, backward: 2.615, update: 6.209
[proc 1][Train](3000/10000) average pos_loss: 0.6807132791876793
[proc 1][Train](3000/10000) average neg_loss: 0.6836751958727837
[proc 1][Train](3000/10000) average loss: 0.6821942372322083
[proc 1][Train](3000/10000) average regularization: 7.356177196470526e-06
[proc 1][Train] 1000 steps take 17.287 seconds
[proc 1] 3000 steps, sample: 2.368, forward: 6.132, backward: 2.681, update: 5.847
[proc 1][Train](4000/10000) average pos_loss: 0.6876319788098335
[proc 1][Train](4000/10000) average neg_loss: 0.680846452832222
[proc 1][Train](4000/10000) average loss: 0.6842392163276673
[proc 1][Train](4000/10000) average regularization: 6.844458627256245e-06
[proc 1][Train] 1000 steps take 16.819 seconds
[proc 1] 4000 steps, sample: 2.399, forward: 5.822, backward: 2.627, update: 5.964
[proc 0][Train](4000/10000) average pos_loss: 0.6875450240373612
[proc 0][Train](4000/10000) average neg_loss: 0.6812748147249221
[proc 0][Train](4000/10000) average loss: 0.6844099188446998
[proc 0][Train](4000/10000) average regularization: 6.853961790511675e-06
[proc 0][Train] 1000 steps take 16.820 seconds
[proc 0] 4000 steps, sample: 2.413, forward: 5.474, backward: 2.586, update: 6.173
[proc 0][Train](5000/10000) average pos_loss: 0.6917762088179589
[proc 0][Train](5000/10000) average neg_loss: 0.6784247832894326
[proc 0][Train](5000/10000) average loss: 0.6851004948019981
[proc 0][Train](5000/10000) average regularization: 6.4864373330237864e-06
[proc 0][Train] 1000 steps take 16.920 seconds
[proc 0] 5000 steps, sample: 2.718, forward: 5.341, backward: 2.618, update: 6.236
[proc 1][Train](5000/10000) average pos_loss: 0.692792368710041
[proc 1][Train](5000/10000) average neg_loss: 0.6782841236591339
[proc 1][Train](5000/10000) average loss: 0.6855382460951805
[proc 1][Train](5000/10000) average regularization: 6.489926844096772e-06
[proc 1][Train] 1000 steps take 16.922 seconds
[proc 1] 5000 steps, sample: 2.561, forward: 5.535, backward: 2.637, update: 5.904
[proc 0][Train](6000/10000) average pos_loss: 0.6955526864528656
[proc 0][Train](6000/10000) average neg_loss: 0.6745061800479889
[proc 0][Train](6000/10000) average loss: 0.685029432117939
[proc 0][Train](6000/10000) average regularization: 6.35740010511654e-06
[proc 0][Train] 1000 steps take 16.442 seconds
[proc 0] 6000 steps, sample: 2.415, forward: 5.325, backward: 2.634, update: 6.061
[proc 1][Train](6000/10000) average pos_loss: 0.695721418440342
[proc 1][Train](6000/10000) average neg_loss: 0.6744140877127648
[proc 1][Train](6000/10000) average loss: 0.685067752957344
[proc 1][Train](6000/10000) average regularization: 6.358118895605002e-06
[proc 1][Train] 1000 steps take 16.441 seconds
[proc 1] 6000 steps, sample: 2.414, forward: 5.482, backward: 2.644, update: 5.890
[proc 1][Train](7000/10000) average pos_loss: 0.6988377487659454
[proc 1][Train](7000/10000) average neg_loss: 0.6706899401545524
[proc 1][Train](7000/10000) average loss: 0.6847638435959816
[proc 1][Train](7000/10000) average regularization: 6.3612598410145434e-06
[proc 1][Train] 1000 steps take 16.604 seconds
[proc 1] 7000 steps, sample: 2.431, forward: 5.628, backward: 2.640, update: 5.898
[proc 0][Train](7000/10000) average pos_loss: 0.6991429342627525
[proc 0][Train](7000/10000) average neg_loss: 0.6708385844826699
[proc 0][Train](7000/10000) average loss: 0.684990759074688
[proc 0][Train](7000/10000) average regularization: 6.361910092437029e-06
[proc 0][Train] 1000 steps take 16.605 seconds
[proc 0] 7000 steps, sample: 2.359, forward: 5.122, backward: 2.606, update: 5.983
[proc 1][Train](8000/10000) average pos_loss: 0.7015940686464309
[proc 1][Train](8000/10000) average neg_loss: 0.667216422021389
[proc 1][Train](8000/10000) average loss: 0.6844052456021309
[proc 1][Train](8000/10000) average regularization: 6.391779500063422e-06
[proc 1][Train] 1000 steps take 16.626 seconds
[proc 1] 8000 steps, sample: 2.491, forward: 5.636, backward: 2.650, update: 5.842
[proc 0][Train](8000/10000) average pos_loss: 0.7026376375555992
[proc 0][Train](8000/10000) average neg_loss: 0.6673096688389778
[proc 0][Train](8000/10000) average loss: 0.6849736539125443
[proc 0][Train](8000/10000) average regularization: 6.390423374796228e-06
[proc 0][Train] 1000 steps take 16.625 seconds
[proc 0] 8000 steps, sample: 2.376, forward: 5.090, backward: 2.642, update: 5.958
[proc 1][Train](9000/10000) average pos_loss: 0.7041872175335884
[proc 1][Train](9000/10000) average neg_loss: 0.6631738845109939
[proc 1][Train](9000/10000) average loss: 0.6836805503368377
[proc 1][Train](9000/10000) average regularization: 6.435784021505242e-06
[proc 1][Train] 1000 steps take 16.374 seconds
[proc 1] 9000 steps, sample: 2.512, forward: 5.544, backward: 2.618, update: 5.693
[proc 0][Train](9000/10000) average pos_loss: 0.7046093743443489
[proc 0][Train](9000/10000) average neg_loss: 0.663831181883812
[proc 0][Train](9000/10000) average loss: 0.6842202781438828
[proc 0][Train](9000/10000) average regularization: 6.433634257518861e-06
[proc 0][Train] 1000 steps take 16.374 seconds
[proc 0] 9000 steps, sample: 2.501, forward: 5.108, backward: 2.605, update: 5.874
[proc 0][Train](10000/10000) average pos_loss: 0.7061055094003678
[proc 0][Train](10000/10000) average neg_loss: 0.6599084967374802
[proc 0][Train](10000/10000) average loss: 0.6830070028305054
[proc 0][Train](10000/10000) average regularization: 6.486630249582958e-06
[proc 0][Train] 1000 steps take 16.335 seconds
[proc 0] 10000 steps, sample: 2.436, forward: 5.253, backward: 2.642, update: 5.997
proc 0 takes 206.801 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.7057192184329033
[proc 1][Train](10000/10000) average neg_loss: 0.6590930632352829
[proc 1][Train](10000/10000) average loss: 0.6824061408042907
[proc 1][Train](10000/10000) average regularization: 6.488193488621619e-06
[proc 1][Train] 1000 steps take 16.336 seconds
[proc 1] 10000 steps, sample: 2.383, forward: 5.461, backward: 2.677, update: 5.679
proc 1 takes 206.272 seconds
Successfully xmh. training takes 214.911785364151 seconds
