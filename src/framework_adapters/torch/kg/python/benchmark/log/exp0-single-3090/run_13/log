Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 4 parts
part 0 has 76181913 edges
part 1 has 76181913 edges
part 2 has 76181913 edges
part 3 has 76181911 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2, 3], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=4, num_proc=4, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_Freebase_4', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 721.118 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 2][Train](1000/10000) average pos_loss: 0.6695392284989357
[proc 2][Train](1000/10000) average neg_loss: 0.6910266488194465
[proc 2][Train](1000/10000) average loss: 0.6802829396128655
[proc 2][Train](1000/10000) average regularization: 7.4747446119545205e-06
[proc 2][Train] 1000 steps take 39.762 seconds
[proc 2] 1000 steps, sample: 17.714, forward: 13.047, backward: 2.591, update: 6.402
[proc 0][Train](1000/10000) average pos_loss: 0.6689101869165898
[proc 0][Train](1000/10000) average neg_loss: 0.6972571567296982
[proc 0][Train](1000/10000) average loss: 0.6830836724638939
[proc 0][Train](1000/10000) average regularization: 7.330909947086184e-06
[proc 0][Train] 1000 steps take 40.763 seconds
[proc 0] 1000 steps, sample: 16.177, forward: 13.070, backward: 2.624, update: 6.313
[proc 3][Train](1000/10000) average pos_loss: 0.6700008283853531
[proc 3][Train](1000/10000) average neg_loss: 0.6897362662553788
[proc 3][Train](1000/10000) average loss: 0.6798685472607613
[proc 3][Train](1000/10000) average regularization: 7.467614354027319e-06
[proc 3][Train] 1000 steps take 39.275 seconds
[proc 3] 1000 steps, sample: 16.921, forward: 13.008, backward: 2.655, update: 6.325
[proc 1][Train](1000/10000) average pos_loss: 0.673541415989399
[proc 1][Train](1000/10000) average neg_loss: 0.6904413183331489
[proc 1][Train](1000/10000) average loss: 0.6819913665056229
[proc 1][Train](1000/10000) average regularization: 7.444025442055136e-06
[proc 1][Train] 1000 steps take 40.275 seconds
[proc 1] 1000 steps, sample: 16.879, forward: 13.084, backward: 2.694, update: 6.446
[proc 2][Train](2000/10000) average pos_loss: 0.6854632506370545
[proc 2][Train](2000/10000) average neg_loss: 0.683207679450512
[proc 2][Train](2000/10000) average loss: 0.684335464477539
[proc 2][Train](2000/10000) average regularization: 7.123830244836427e-06
[proc 2][Train] 1000 steps take 18.952 seconds
[proc 2] 2000 steps, sample: 2.594, forward: 7.528, backward: 2.580, update: 6.241
[proc 1][Train](2000/10000) average pos_loss: 0.6839938604235649
[proc 1][Train](2000/10000) average neg_loss: 0.6830173404216766
[proc 1][Train](2000/10000) average loss: 0.683505600810051
[proc 1][Train](2000/10000) average regularization: 7.1248837957682554e-06
[proc 1][Train] 1000 steps take 18.951 seconds
[proc 1] 2000 steps, sample: 2.583, forward: 7.344, backward: 2.672, update: 6.256
[proc 0][Train](2000/10000) average pos_loss: 0.6846534518003464
[proc 0][Train](2000/10000) average neg_loss: 0.683039908528328
[proc 0][Train](2000/10000) average loss: 0.6838466802835464
[proc 0][Train](2000/10000) average regularization: 7.136459271805507e-06
[proc 0][Train] 1000 steps take 18.951 seconds
[proc 0] 2000 steps, sample: 2.486, forward: 7.382, backward: 2.605, update: 6.142
[proc 3][Train](2000/10000) average pos_loss: 0.6850753625631333
[proc 3][Train](2000/10000) average neg_loss: 0.682842923283577
[proc 3][Train](2000/10000) average loss: 0.6839591421484947
[proc 3][Train](2000/10000) average regularization: 7.13064941464836e-06
[proc 3][Train] 1000 steps take 18.952 seconds
[proc 3] 2000 steps, sample: 2.456, forward: 7.556, backward: 2.619, update: 6.207
[proc 0][Train](3000/10000) average pos_loss: 0.6958562185764313
[proc 0][Train](3000/10000) average neg_loss: 0.6770903503894806
[proc 0][Train](3000/10000) average loss: 0.6864732849001884
[proc 0][Train](3000/10000) average regularization: 6.464770085585769e-06
[proc 0][Train] 1000 steps take 17.831 seconds
[proc 0] 3000 steps, sample: 2.579, forward: 6.350, backward: 2.647, update: 6.247
[proc 1][Train](3000/10000) average pos_loss: 0.6936130342483521
[proc 1][Train](3000/10000) average neg_loss: 0.6772866123914718
[proc 1][Train](3000/10000) average loss: 0.6854498234391212
[proc 1][Train](3000/10000) average regularization: 6.470537967288692e-06
[proc 1][Train] 1000 steps take 17.832 seconds
[proc 1] 3000 steps, sample: 2.514, forward: 6.044, backward: 2.705, update: 6.373
[proc 3][Train](3000/10000) average pos_loss: 0.6942369619011879
[proc 3][Train](3000/10000) average neg_loss: 0.676621091067791
[proc 3][Train](3000/10000) average loss: 0.6854290266036988
[proc 3][Train](3000/10000) average regularization: 6.4687133872212145e-06
[proc 3][Train] 1000 steps take 17.832 seconds
[proc 3] 3000 steps, sample: 2.521, forward: 6.336, backward: 2.589, update: 6.083
[proc 2][Train](3000/10000) average pos_loss: 0.6941617031693459
[proc 2][Train](3000/10000) average neg_loss: 0.6762677543163299
[proc 2][Train](3000/10000) average loss: 0.6852147282958031
[proc 2][Train](3000/10000) average regularization: 6.466750746767502e-06
[proc 2][Train] 1000 steps take 17.833 seconds
[proc 2] 3000 steps, sample: 2.527, forward: 6.231, backward: 2.581, update: 6.338
[proc 1][Train](4000/10000) average pos_loss: 0.7008998023867608
[proc 1][Train](4000/10000) average neg_loss: 0.6698677271008492
[proc 1][Train](4000/10000) average loss: 0.6853837652802467
[proc 1][Train](4000/10000) average regularization: 6.379281485806132e-06
[proc 1][Train] 1000 steps take 17.151 seconds
[proc 1] 4000 steps, sample: 2.508, forward: 5.710, backward: 2.606, update: 6.318
[proc 2][Train](4000/10000) average pos_loss: 0.7012278896570205
[proc 2][Train](4000/10000) average neg_loss: 0.6692576974630355
[proc 2][Train](4000/10000) average loss: 0.6852427929639816
[proc 2][Train](4000/10000) average regularization: 6.3775585313123885e-06
[proc 2][Train] 1000 steps take 17.150 seconds
[proc 2] 4000 steps, sample: 2.421, forward: 5.737, backward: 2.586, update: 6.308
[proc 3][Train](4000/10000) average pos_loss: 0.7016991160511971
[proc 3][Train](4000/10000) average neg_loss: 0.6699621276855469
[proc 3][Train](4000/10000) average loss: 0.6858306219577789
[proc 3][Train](4000/10000) average regularization: 6.378164879606629e-06
[proc 3][Train] 1000 steps take 17.151 seconds
[proc 3] 4000 steps, sample: 2.381, forward: 5.867, backward: 2.583, update: 6.096
[proc 0][Train](4000/10000) average pos_loss: 0.7006037948727608
[proc 0][Train](4000/10000) average neg_loss: 0.6701001511216164
[proc 0][Train](4000/10000) average loss: 0.6853519743084907
[proc 0][Train](4000/10000) average regularization: 6.3802187050896465e-06
[proc 0][Train] 1000 steps take 17.152 seconds
[proc 0] 4000 steps, sample: 2.376, forward: 5.852, backward: 2.604, update: 6.032
[proc 3][Train](5000/10000) average pos_loss: 0.7038429173231124
[proc 3][Train](5000/10000) average neg_loss: 0.661512428700924
[proc 3][Train](5000/10000) average loss: 0.6826776726841927
[proc 3][Train](5000/10000) average regularization: 6.471388377121912e-06
[proc 3][Train] 1000 steps take 17.170 seconds
[proc 3] 5000 steps, sample: 2.713, forward: 5.722, backward: 2.574, update: 6.152
[proc 2][Train](5000/10000) average pos_loss: 0.7041809945106506
[proc 2][Train](5000/10000) average neg_loss: 0.6628163605332374
[proc 2][Train](5000/10000) average loss: 0.6834986770153045
[proc 2][Train](5000/10000) average regularization: 6.466848988566198e-06
[proc 2][Train] 1000 steps take 17.171 seconds
[proc 2] 5000 steps, sample: 2.542, forward: 5.543, backward: 2.553, update: 6.230
[proc 0][Train](5000/10000) average pos_loss: 0.7052559005618095
[proc 0][Train](5000/10000) average neg_loss: 0.6616972715258599
[proc 0][Train](5000/10000) average loss: 0.6834765852689743
[proc 0][Train](5000/10000) average regularization: 6.469030426615063e-06
[proc 0][Train] 1000 steps take 17.170 seconds
[proc 0] 5000 steps, sample: 2.644, forward: 5.716, backward: 2.594, update: 6.057
[proc 1][Train](5000/10000) average pos_loss: 0.7053267694115639
[proc 1][Train](5000/10000) average neg_loss: 0.661381874024868
[proc 1][Train](5000/10000) average loss: 0.6833543216586113
[proc 1][Train](5000/10000) average regularization: 6.469422716691043e-06
[proc 1][Train] 1000 steps take 17.171 seconds
[proc 1] 5000 steps, sample: 2.703, forward: 5.417, backward: 2.690, update: 6.268
[proc 3][Train](6000/10000) average pos_loss: 0.7077434083223343
[proc 3][Train](6000/10000) average neg_loss: 0.655604033946991
[proc 3][Train](6000/10000) average loss: 0.6816737215518951
[proc 3][Train](6000/10000) average regularization: 6.5856464243552185e-06
[proc 3][Train] 1000 steps take 16.944 seconds
[proc 3] 6000 steps, sample: 2.427, forward: 5.757, backward: 2.675, update: 6.076
[proc 2][Train](6000/10000) average pos_loss: 0.7081394701600074
[proc 2][Train](6000/10000) average neg_loss: 0.6549173642396927
[proc 2][Train](6000/10000) average loss: 0.681528416633606
[proc 2][Train](6000/10000) average regularization: 6.585250131138309e-06
[proc 2][Train] 1000 steps take 16.944 seconds
[proc 2] 6000 steps, sample: 2.394, forward: 5.590, backward: 2.618, update: 6.147
[proc 1][Train](6000/10000) average pos_loss: 0.7077776324748993
[proc 1][Train](6000/10000) average neg_loss: 0.6536559917330742
[proc 1][Train](6000/10000) average loss: 0.6807168120741844
[proc 1][Train](6000/10000) average regularization: 6.585905085557897e-06
[proc 1][Train] 1000 steps take 16.944 seconds
[proc 1] 6000 steps, sample: 2.434, forward: 5.283, backward: 2.614, update: 6.146
[proc 0][Train](6000/10000) average pos_loss: 0.7083825137019157
[proc 0][Train](6000/10000) average neg_loss: 0.6532071726322174
[proc 0][Train](6000/10000) average loss: 0.6807948439121246
[proc 0][Train](6000/10000) average regularization: 6.583532143395132e-06
[proc 0][Train] 1000 steps take 16.944 seconds
[proc 0] 6000 steps, sample: 2.410, forward: 5.597, backward: 2.638, update: 5.966
[proc 0][Train](7000/10000) average pos_loss: 0.7094490819573402
[proc 0][Train](7000/10000) average neg_loss: 0.6463162259459495
[proc 0][Train](7000/10000) average loss: 0.6778826542496681
[proc 0][Train](7000/10000) average regularization: 6.7063844412587055e-06
[proc 0][Train] 1000 steps take 17.026 seconds
[proc 0] 7000 steps, sample: 2.630, forward: 5.680, backward: 2.635, update: 6.050
[proc 3][Train](7000/10000) average pos_loss: 0.7098949046730996
[proc 3][Train](7000/10000) average neg_loss: 0.6468206887543202
[proc 3][Train](7000/10000) average loss: 0.6783577966690063
[proc 3][Train](7000/10000) average regularization: 6.701033825265768e-06
[proc 3][Train] 1000 steps take 17.028 seconds
[proc 3] 7000 steps, sample: 2.395, forward: 5.649, backward: 2.633, update: 5.913
[proc 1][Train](7000/10000) average pos_loss: 0.7091656667590142
[proc 1][Train](7000/10000) average neg_loss: 0.64699100202322
[proc 1][Train](7000/10000) average loss: 0.6780783343911171
[proc 1][Train](7000/10000) average regularization: 6.702220576244145e-06
[proc 1][Train] 1000 steps take 17.027 seconds
[proc 1] 7000 steps, sample: 2.453, forward: 5.242, backward: 2.762, update: 6.073
[proc 2][Train](7000/10000) average pos_loss: 0.7091554954648018
[proc 2][Train](7000/10000) average neg_loss: 0.6462265417873859
[proc 2][Train](7000/10000) average loss: 0.677691019654274
[proc 2][Train](7000/10000) average regularization: 6.701822549985082e-06
[proc 2][Train] 1000 steps take 17.028 seconds
[proc 2] 7000 steps, sample: 2.429, forward: 5.545, backward: 2.695, update: 6.062
[proc 3][Train](8000/10000) average pos_loss: 0.710574535369873
[proc 3][Train](8000/10000) average neg_loss: 0.6387709306180477
[proc 3][Train](8000/10000) average loss: 0.6746727335453033
[proc 3][Train](8000/10000) average regularization: 6.8305534841783814e-06
[proc 3][Train] 1000 steps take 16.667 seconds
[proc 3] 8000 steps, sample: 2.421, forward: 5.712, backward: 2.648, update: 5.878
[proc 2][Train](8000/10000) average pos_loss: 0.7092506251931191
[proc 2][Train](8000/10000) average neg_loss: 0.638418262064457
[proc 2][Train](8000/10000) average loss: 0.6738344433903695
[proc 2][Train](8000/10000) average regularization: 6.82832830807456e-06
[proc 2][Train] 1000 steps take 16.668 seconds
[proc 2] 8000 steps, sample: 2.399, forward: 5.653, backward: 2.585, update: 5.978
[proc 0][Train](8000/10000) average pos_loss: 0.7101557772755623
[proc 0][Train](8000/10000) average neg_loss: 0.6388666682243347
[proc 0][Train](8000/10000) average loss: 0.6745112229585648
[proc 0][Train](8000/10000) average regularization: 6.82203555606975e-06
[proc 0][Train] 1000 steps take 16.669 seconds
[proc 0] 8000 steps, sample: 2.359, forward: 5.569, backward: 2.634, update: 5.805
[proc 1][Train](8000/10000) average pos_loss: 0.7102263469696045
[proc 1][Train](8000/10000) average neg_loss: 0.6394067273139954
[proc 1][Train](8000/10000) average loss: 0.6748165360689163
[proc 1][Train](8000/10000) average regularization: 6.822415686656314e-06
[proc 1][Train] 1000 steps take 16.668 seconds
[proc 1] 8000 steps, sample: 2.362, forward: 5.236, backward: 2.596, update: 5.924
[proc 3][Train](9000/10000) average pos_loss: 0.7093631981611251
[proc 3][Train](9000/10000) average neg_loss: 0.6314680669605732
[proc 3][Train](9000/10000) average loss: 0.6704156323075294
[proc 3][Train](9000/10000) average regularization: 6.941716831079247e-06
[proc 3][Train] 1000 steps take 16.729 seconds
[proc 3] 9000 steps, sample: 2.645, forward: 5.594, backward: 2.628, update: 5.847
[proc 2][Train](9000/10000) average pos_loss: 0.709347943007946
[proc 2][Train](9000/10000) average neg_loss: 0.6309818432629108
[proc 2][Train](9000/10000) average loss: 0.6701648933291435
[proc 2][Train](9000/10000) average regularization: 6.948081444534182e-06
[proc 2][Train] 1000 steps take 16.728 seconds
[proc 2] 9000 steps, sample: 2.633, forward: 5.693, backward: 2.445, update: 5.949
[proc 0][Train](9000/10000) average pos_loss: 0.7097897356152535
[proc 0][Train](9000/10000) average neg_loss: 0.6304694139659405
[proc 0][Train](9000/10000) average loss: 0.6701295752525329
[proc 0][Train](9000/10000) average regularization: 6.9516087637566674e-06
[proc 0][Train] 1000 steps take 16.729 seconds
[proc 0] 9000 steps, sample: 2.589, forward: 5.564, backward: 2.651, update: 5.788
[proc 1][Train](9000/10000) average pos_loss: 0.7095644720792771
[proc 1][Train](9000/10000) average neg_loss: 0.630767008304596
[proc 1][Train](9000/10000) average loss: 0.6701657402515412
[proc 1][Train](9000/10000) average regularization: 6.945164664102776e-06
[proc 1][Train] 1000 steps take 16.729 seconds
[proc 1] 9000 steps, sample: 2.476, forward: 5.118, backward: 2.624, update: 5.996
[proc 3][Train](10000/10000) average pos_loss: 0.7081581899523735
[proc 3][Train](10000/10000) average neg_loss: 0.6231536654233932
[proc 3][Train](10000/10000) average loss: 0.6656559269428253
[proc 3][Train](10000/10000) average regularization: 7.06612358953862e-06
[proc 3][Train] 1000 steps take 16.654 seconds
[proc 3] 10000 steps, sample: 2.403, forward: 5.650, backward: 2.677, update: 5.917
proc 3 takes 194.402 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.707164488196373
[proc 1][Train](10000/10000) average neg_loss: 0.6228982264995575
[proc 1][Train](10000/10000) average loss: 0.6650313575863838
[proc 1][Train](10000/10000) average regularization: 7.062857255277777e-06
[proc 1][Train] 1000 steps take 16.654 seconds
[proc 1] 10000 steps, sample: 2.426, forward: 5.379, backward: 2.639, update: 5.976
proc 1 takes 195.403 seconds
[proc 2][Train](10000/10000) average pos_loss: 0.7092933457493782
[proc 2][Train](10000/10000) average neg_loss: 0.6235761921405792
[proc 2][Train](10000/10000) average loss: 0.666434769153595
[proc 2][Train](10000/10000) average regularization: 7.059379158363299e-06
[proc 2][Train] 1000 steps take 16.655 seconds
[proc 2] 10000 steps, sample: 2.442, forward: 5.696, backward: 2.559, update: 5.916
proc 2 takes 194.891 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.709386082470417
[proc 0][Train](10000/10000) average neg_loss: 0.6233682073354722
[proc 0][Train](10000/10000) average loss: 0.666377144753933
[proc 0][Train](10000/10000) average regularization: 7.060846896820294e-06
[proc 0][Train] 1000 steps take 16.654 seconds
[proc 0] 10000 steps, sample: 2.337, forward: 5.592, backward: 2.584, update: 5.778
proc 0 takes 195.892 seconds
Successfully xmh. training takes 204.77340364456177 seconds
