Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 3 parts
part 0 has 161048 edges
part 1 has 161048 edges
part 2 has 161046 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=3, num_proc=3, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_FB15k_19', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 1.081 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 1][Train](1000/10000) average pos_loss: 0.17438718281686305
[proc 1][Train](1000/10000) average neg_loss: 0.19404585584253073
[proc 1][Train](1000/10000) average loss: 0.1842165195122361
[proc 1][Train](1000/10000) average regularization: 1.1997309966773173e-05
[proc 1] 1000 steps, total: 16.567, sample: 1.764, forward: 7.039, backward: 2.761, update: 4.996
[proc 2][Train](1000/10000) average pos_loss: 0.17346221496909855
[proc 2][Train](1000/10000) average neg_loss: 0.19294790668785572
[proc 2][Train](1000/10000) average loss: 0.18320506067574024
[proc 2][Train](1000/10000) average regularization: 1.1916614350411691e-05
[proc 2] 1000 steps, total: 16.568, sample: 1.694, forward: 6.826, backward: 2.731, update: 4.858
[proc 0][Train](1000/10000) average pos_loss: 0.17708712377399205
[proc 0][Train](1000/10000) average neg_loss: 0.2041091973334551
[proc 0][Train](1000/10000) average loss: 0.19059816092252732
[proc 0][Train](1000/10000) average regularization: 1.1686878684940894e-05
[proc 0] 1000 steps, total: 16.609, sample: 1.666, forward: 6.318, backward: 2.626, update: 4.776
[proc 2][Train](2000/10000) average pos_loss: 0.06667205416411161
[proc 2][Train](2000/10000) average neg_loss: 0.09597835264354944
[proc 2][Train](2000/10000) average loss: 0.08132520342990757
[proc 2][Train](2000/10000) average regularization: 1.662687956741138e-05
[proc 2] 2000 steps, total: 14.609, sample: 1.752, forward: 5.051, backward: 2.756, update: 5.039
[proc 1][Train](2000/10000) average pos_loss: 0.06639025989174843
[proc 1][Train](2000/10000) average neg_loss: 0.09637984081357717
[proc 1][Train](2000/10000) average loss: 0.08138505044579505
[proc 1][Train](2000/10000) average regularization: 1.6584036711719818e-05
[proc 1] 2000 steps, total: 14.610, sample: 1.661, forward: 4.779, backward: 2.738, update: 4.850
[proc 0][Train](2000/10000) average pos_loss: 0.06657619127258659
[proc 0][Train](2000/10000) average neg_loss: 0.09692675524204969
[proc 0][Train](2000/10000) average loss: 0.08175147330015897
[proc 0][Train](2000/10000) average regularization: 1.6502687692081963e-05
[proc 0] 2000 steps, total: 14.609, sample: 1.610, forward: 4.272, backward: 2.633, update: 4.760
[proc 1][Train](3000/10000) average pos_loss: 0.05665486735478044
[proc 1][Train](3000/10000) average neg_loss: 0.08433856211975217
[proc 1][Train](3000/10000) average loss: 0.07049671468511223
[proc 1][Train](3000/10000) average regularization: 1.8465267208739534e-05
[proc 1] 3000 steps, total: 14.157, sample: 1.655, forward: 4.866, backward: 2.750, update: 4.879
[proc 2][Train](3000/10000) average pos_loss: 0.05622714412212372
[proc 2][Train](3000/10000) average neg_loss: 0.08408025366812945
[proc 2][Train](3000/10000) average loss: 0.0701536988131702
[proc 2][Train](3000/10000) average regularization: 1.8460823235727732e-05
[proc 2] 3000 steps, total: 14.159, sample: 1.661, forward: 4.833, backward: 2.746, update: 4.889
[proc 0][Train](3000/10000) average pos_loss: 0.05647834714874625
[proc 0][Train](3000/10000) average neg_loss: 0.08464789348840714
[proc 0][Train](3000/10000) average loss: 0.07056312035769224
[proc 0][Train](3000/10000) average regularization: 1.839435262081679e-05
[proc 0] 3000 steps, total: 14.158, sample: 1.588, forward: 4.272, backward: 2.547, update: 4.774
[proc 2][Train](4000/10000) average pos_loss: 0.05171012635156512
[proc 2][Train](4000/10000) average neg_loss: 0.07829229146242142
[proc 2][Train](4000/10000) average loss: 0.0650012089908123
[proc 2][Train](4000/10000) average regularization: 1.9665240968606667e-05
[proc 2] 4000 steps, total: 14.350, sample: 1.889, forward: 4.824, backward: 2.738, update: 4.893
[proc 0][Train](4000/10000) average pos_loss: 0.0517443172596395
[proc 0][Train](4000/10000) average neg_loss: 0.0788644645921886
[proc 0][Train](4000/10000) average loss: 0.06530439091846346
[proc 0][Train](4000/10000) average regularization: 1.9595276891777757e-05
[proc 0] 4000 steps, total: 14.350, sample: 1.714, forward: 4.240, backward: 2.595, update: 4.727
[proc 1][Train](4000/10000) average pos_loss: 0.05177888584509492
[proc 1][Train](4000/10000) average neg_loss: 0.07822613072767853
[proc 1][Train](4000/10000) average loss: 0.0650025083720684
[proc 1][Train](4000/10000) average regularization: 1.9652306313219016e-05
[proc 1] 4000 steps, total: 14.352, sample: 1.772, forward: 4.805, backward: 2.679, update: 4.867
[proc 1][Train](5000/10000) average pos_loss: 0.04904410802572966
[proc 1][Train](5000/10000) average neg_loss: 0.07487880004569888
[proc 1][Train](5000/10000) average loss: 0.061961454015225174
[proc 1][Train](5000/10000) average regularization: 2.0535393257887337e-05
[proc 1] 5000 steps, total: 14.218, sample: 1.686, forward: 4.902, backward: 2.730, update: 4.892
[proc 2][Train](5000/10000) average pos_loss: 0.04870562718436122
[proc 2][Train](5000/10000) average neg_loss: 0.07482301780208946
[proc 2][Train](5000/10000) average loss: 0.06176432248950005
[proc 2][Train](5000/10000) average regularization: 2.0522358403468387e-05
[proc 2] 5000 steps, total: 14.219, sample: 1.653, forward: 4.747, backward: 2.740, update: 4.836
[proc 0][Train](5000/10000) average pos_loss: 0.04892832525074482
[proc 0][Train](5000/10000) average neg_loss: 0.07501777586340905
[proc 0][Train](5000/10000) average loss: 0.06197305053472519
[proc 0][Train](5000/10000) average regularization: 2.047639465126849e-05
[proc 0] 5000 steps, total: 14.218, sample: 1.598, forward: 4.229, backward: 2.620, update: 4.712
[proc 1][Train](6000/10000) average pos_loss: 0.04693988578021526
[proc 1][Train](6000/10000) average neg_loss: 0.07225998384505511
[proc 1][Train](6000/10000) average loss: 0.05959993489831686
[proc 1][Train](6000/10000) average regularization: 2.1222727846179622e-05
[proc 1] 6000 steps, total: 14.188, sample: 1.657, forward: 4.886, backward: 2.723, update: 4.915
[proc 2][Train](6000/10000) average pos_loss: 0.04694205005839467
[proc 2][Train](6000/10000) average neg_loss: 0.07245514836162328
[proc 2][Train](6000/10000) average loss: 0.05969859913364053
[proc 2][Train](6000/10000) average regularization: 2.1222537483481575e-05
[proc 2] 6000 steps, total: 14.188, sample: 1.652, forward: 4.873, backward: 2.742, update: 4.909
[proc 0][Train](6000/10000) average pos_loss: 0.04698509129881859
[proc 0][Train](6000/10000) average neg_loss: 0.07270171619206667
[proc 0][Train](6000/10000) average loss: 0.059843403674662114
[proc 0][Train](6000/10000) average regularization: 2.116673703494598e-05
[proc 0] 6000 steps, total: 14.189, sample: 1.553, forward: 4.179, backward: 2.638, update: 4.662
[proc 2][Train](7000/10000) average pos_loss: 0.0453608682230115
[proc 2][Train](7000/10000) average neg_loss: 0.0704058243483305
[proc 2][Train](7000/10000) average loss: 0.0578833463974297
[proc 2][Train](7000/10000) average regularization: 2.1790675729789655e-05
[proc 2] 7000 steps, total: 14.135, sample: 1.673, forward: 4.829, backward: 2.721, update: 4.906
[proc 1][Train](7000/10000) average pos_loss: 0.04544696453213692
[proc 1][Train](7000/10000) average neg_loss: 0.0703993979729712
[proc 1][Train](7000/10000) average loss: 0.05792318113520741
[proc 1][Train](7000/10000) average regularization: 2.1792473382447496e-05
[proc 1] 7000 steps, total: 14.135, sample: 1.678, forward: 4.864, backward: 2.663, update: 4.912
[proc 0][Train](7000/10000) average pos_loss: 0.045496304925531146
[proc 0][Train](7000/10000) average neg_loss: 0.07066114853695035
[proc 0][Train](7000/10000) average loss: 0.058078726697713134
[proc 0][Train](7000/10000) average regularization: 2.1744578563811955e-05
[proc 0] 7000 steps, total: 14.135, sample: 1.575, forward: 4.208, backward: 2.634, update: 4.683
[proc 2][Train](8000/10000) average pos_loss: 0.04419952799007296
[proc 2][Train](8000/10000) average neg_loss: 0.06906701124832035
[proc 2][Train](8000/10000) average loss: 0.05663326968252659
[proc 2][Train](8000/10000) average regularization: 2.2285433988145088e-05
[proc 2] 8000 steps, total: 14.103, sample: 1.648, forward: 4.833, backward: 2.697, update: 4.899
[proc 1][Train](8000/10000) average pos_loss: 0.04433534014597535
[proc 1][Train](8000/10000) average neg_loss: 0.06907338116690516
[proc 1][Train](8000/10000) average loss: 0.056704360678792
[proc 1][Train](8000/10000) average regularization: 2.2283184227489983e-05
[proc 1] 8000 steps, total: 14.103, sample: 1.623, forward: 4.852, backward: 2.715, update: 4.904
[proc 0][Train](8000/10000) average pos_loss: 0.04444424816220999
[proc 0][Train](8000/10000) average neg_loss: 0.06943807535246015
[proc 0][Train](8000/10000) average loss: 0.05694116169586778
[proc 0][Train](8000/10000) average regularization: 2.224305646814173e-05
[proc 0] 8000 steps, total: 14.103, sample: 1.571, forward: 4.204, backward: 2.600, update: 4.699
[proc 1][Train](9000/10000) average pos_loss: 0.043496235255151984
[proc 1][Train](9000/10000) average neg_loss: 0.06795666163787245
[proc 1][Train](9000/10000) average loss: 0.05572644847631454
[proc 1][Train](9000/10000) average regularization: 2.2712839960149722e-05
[proc 1] 9000 steps, total: 14.355, sample: 1.834, forward: 4.874, backward: 2.714, update: 4.926
[proc 2][Train](9000/10000) average pos_loss: 0.04336373265087604
[proc 2][Train](9000/10000) average neg_loss: 0.0680221642665565
[proc 2][Train](9000/10000) average loss: 0.05569294848293066
[proc 2][Train](9000/10000) average regularization: 2.2707672749675112e-05
[proc 2] 9000 steps, total: 14.355, sample: 1.816, forward: 4.854, backward: 2.739, update: 4.902
[proc 0][Train](9000/10000) average pos_loss: 0.043527465712279084
[proc 0][Train](9000/10000) average neg_loss: 0.06824778471887112
[proc 0][Train](9000/10000) average loss: 0.055887625224888327
[proc 0][Train](9000/10000) average regularization: 2.2660533144517104e-05
[proc 0] 9000 steps, total: 14.355, sample: 1.717, forward: 4.224, backward: 2.616, update: 4.696
[proc 2][Train](10000/10000) average pos_loss: 0.04259186699613929
[proc 2][Train](10000/10000) average neg_loss: 0.06709614568576217
[proc 2][Train](10000/10000) average loss: 0.054844006337225436
[proc 2][Train](10000/10000) average regularization: 2.308224235275702e-05
[proc 2] 10000 steps, total: 14.181, sample: 1.660, forward: 4.851, backward: 2.760, update: 4.903
proc 2 takes 144.866 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.04267038840800524
[proc 1][Train](10000/10000) average neg_loss: 0.06700614698976279
[proc 1][Train](10000/10000) average loss: 0.05483826773241162
[proc 1][Train](10000/10000) average regularization: 2.3080055509126395e-05
[proc 1] 10000 steps, total: 14.182, sample: 1.660, forward: 4.867, backward: 2.720, update: 4.915
proc 1 takes 144.867 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.04281745195016265
[proc 0][Train](10000/10000) average neg_loss: 0.06730386304855347
[proc 0][Train](10000/10000) average loss: 0.055060657512396576
[proc 0][Train](10000/10000) average regularization: 2.3039963067276403e-05
[proc 0] 10000 steps, total: 14.182, sample: 1.564, forward: 4.247, backward: 2.634, update: 4.692
proc 0 takes 144.908 seconds
Successfully xmh. training takes 145.39371275901794 seconds
