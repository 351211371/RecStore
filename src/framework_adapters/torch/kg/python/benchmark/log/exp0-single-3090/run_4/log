Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 4 parts
part 0 has 120786 edges
part 1 has 120786 edges
part 2 has 120786 edges
part 3 has 120784 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2, 3], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=4, num_proc=4, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_FB15k_20', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 1.029 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.147208709474653
[proc 0][Train](1000/10000) average neg_loss: 0.172871142745018
[proc 0][Train](1000/10000) average loss: 0.16003992632776498
[proc 0][Train](1000/10000) average regularization: 1.3194554788469758e-05
[proc 0] 1000 steps, total: 16.824, sample: 1.898, forward: 7.221, backward: 2.741, update: 4.897
[proc 2][Train](1000/10000) average pos_loss: 0.14311551282554866
[proc 2][Train](1000/10000) average neg_loss: 0.16993759658932686
[proc 2][Train](1000/10000) average loss: 0.15652655466645957
[proc 2][Train](1000/10000) average regularization: 1.318520924405675e-05
[proc 2] 1000 steps, total: 16.793, sample: 1.804, forward: 6.866, backward: 2.764, update: 5.107
[proc 1][Train](1000/10000) average pos_loss: 0.14051076034456492
[proc 1][Train](1000/10000) average neg_loss: 0.16571543370187283
[proc 1][Train](1000/10000) average loss: 0.15311309738457202
[proc 1][Train](1000/10000) average regularization: 1.3248554547317327e-05
[proc 1] 1000 steps, total: 16.788, sample: 1.856, forward: 7.136, backward: 2.427, update: 5.298
[proc 3][Train](1000/10000) average pos_loss: 0.14124137772992254
[proc 3][Train](1000/10000) average neg_loss: 0.16642607465386391
[proc 3][Train](1000/10000) average loss: 0.15383372620493174
[proc 3][Train](1000/10000) average regularization: 1.3275006468575158e-05
[proc 3] 1000 steps, total: 16.788, sample: 1.838, forward: 7.234, backward: 2.743, update: 4.965
[proc 3][Train](2000/10000) average pos_loss: 0.05989316376671195
[proc 3][Train](2000/10000) average neg_loss: 0.08825091924145818
[proc 3][Train](2000/10000) average loss: 0.07407204156368971
[proc 3][Train](2000/10000) average regularization: 1.800595116401382e-05
[proc 3] 2000 steps, total: 14.811, sample: 1.875, forward: 5.198, backward: 2.734, update: 4.995
[proc 2][Train](2000/10000) average pos_loss: 0.0598668433688581
[proc 2][Train](2000/10000) average neg_loss: 0.08868936945870519
[proc 2][Train](2000/10000) average loss: 0.07427810643240809
[proc 2][Train](2000/10000) average regularization: 1.7973886051549926e-05
[proc 2] 2000 steps, total: 14.812, sample: 1.741, forward: 4.650, backward: 2.855, update: 4.996
[proc 0][Train](2000/10000) average pos_loss: 0.059047749362885954
[proc 0][Train](2000/10000) average neg_loss: 0.08832265400886535
[proc 0][Train](2000/10000) average loss: 0.07368520167842507
[proc 0][Train](2000/10000) average regularization: 1.797856938355835e-05
[proc 0] 2000 steps, total: 14.812, sample: 1.738, forward: 5.022, backward: 2.717, update: 4.784
[proc 1][Train](2000/10000) average pos_loss: 0.059950026761740445
[proc 1][Train](2000/10000) average neg_loss: 0.08866935226321221
[proc 1][Train](2000/10000) average loss: 0.07430968956276775
[proc 1][Train](2000/10000) average regularization: 1.7977394127228762e-05
[proc 1] 2000 steps, total: 14.812, sample: 1.766, forward: 4.778, backward: 2.796, update: 5.058
[proc 3][Train](3000/10000) average pos_loss: 0.05184697802737355
[proc 3][Train](3000/10000) average neg_loss: 0.07868595200404525
[proc 3][Train](3000/10000) average loss: 0.0652664650157094
[proc 3][Train](3000/10000) average regularization: 1.982731381212943e-05
[proc 3] 3000 steps, total: 14.615, sample: 1.797, forward: 5.115, backward: 2.732, update: 4.963
[proc 0][Train](3000/10000) average pos_loss: 0.0515158813521266
[proc 0][Train](3000/10000) average neg_loss: 0.07849354841932654
[proc 0][Train](3000/10000) average loss: 0.06500471486523747
[proc 0][Train](3000/10000) average regularization: 1.9828984201012644e-05
[proc 0] 3000 steps, total: 14.615, sample: 1.806, forward: 5.028, backward: 2.738, update: 4.925
[proc 2][Train](3000/10000) average pos_loss: 0.05202790350094438
[proc 2][Train](3000/10000) average neg_loss: 0.0789487802349031
[proc 2][Train](3000/10000) average loss: 0.06548834182694555
[proc 2][Train](3000/10000) average regularization: 1.980592918152979e-05
[proc 2] 3000 steps, total: 14.615, sample: 1.774, forward: 4.608, backward: 2.822, update: 4.958
[proc 1][Train](3000/10000) average pos_loss: 0.05205149818211794
[proc 1][Train](3000/10000) average neg_loss: 0.07894394994154573
[proc 1][Train](3000/10000) average loss: 0.06549772415310144
[proc 1][Train](3000/10000) average regularization: 1.981193715437257e-05
[proc 1] 3000 steps, total: 14.615, sample: 1.782, forward: 4.752, backward: 2.783, update: 5.096
[proc 3][Train](4000/10000) average pos_loss: 0.04803074676916003
[proc 3][Train](4000/10000) average neg_loss: 0.0736785106100142
[proc 3][Train](4000/10000) average loss: 0.06085462871938944
[proc 3][Train](4000/10000) average regularization: 2.099315167833993e-05
[proc 3] 4000 steps, total: 14.498, sample: 1.735, forward: 5.126, backward: 2.741, update: 4.888
[proc 1][Train](4000/10000) average pos_loss: 0.04828267529979348
[proc 1][Train](4000/10000) average neg_loss: 0.07411245388910175
[proc 1][Train](4000/10000) average loss: 0.061197564512491226
[proc 1][Train](4000/10000) average regularization: 2.09874243264494e-05
[proc 1] 4000 steps, total: 14.498, sample: 1.715, forward: 4.744, backward: 2.783, update: 5.087
[proc 2][Train](4000/10000) average pos_loss: 0.04823672960326075
[proc 2][Train](4000/10000) average neg_loss: 0.07424306829273701
[proc 2][Train](4000/10000) average loss: 0.061239899050444364
[proc 2][Train](4000/10000) average regularization: 2.0977338645025158e-05
[proc 2] 4000 steps, total: 14.498, sample: 1.709, forward: 4.620, backward: 2.782, update: 4.995
[proc 0][Train](4000/10000) average pos_loss: 0.047745308708399534
[proc 0][Train](4000/10000) average neg_loss: 0.07369012718275189
[proc 0][Train](4000/10000) average loss: 0.06071771790832281
[proc 0][Train](4000/10000) average regularization: 2.1009167980082567e-05
[proc 0] 4000 steps, total: 14.498, sample: 1.759, forward: 4.996, backward: 2.687, update: 5.024
[proc 3][Train](5000/10000) average pos_loss: 0.04581986614316702
[proc 3][Train](5000/10000) average neg_loss: 0.07089238352701067
[proc 3][Train](5000/10000) average loss: 0.058356124859303235
[proc 3][Train](5000/10000) average regularization: 2.185088181977335e-05
[proc 3] 5000 steps, total: 14.853, sample: 2.007, forward: 5.142, backward: 2.724, update: 4.973
[proc 0][Train](5000/10000) average pos_loss: 0.04538791938126087
[proc 0][Train](5000/10000) average neg_loss: 0.0707430496737361
[proc 0][Train](5000/10000) average loss: 0.058065484531223774
[proc 0][Train](5000/10000) average regularization: 2.185681852824928e-05
[proc 0] 5000 steps, total: 14.853, sample: 1.985, forward: 4.787, backward: 2.798, update: 4.981
[proc 1][Train](5000/10000) average pos_loss: 0.045880953092128036
[proc 1][Train](5000/10000) average neg_loss: 0.0713093346580863
[proc 1][Train](5000/10000) average loss: 0.05859514389932156
[proc 1][Train](5000/10000) average regularization: 2.183831842012296e-05
[proc 1] 5000 steps, total: 14.853, sample: 2.001, forward: 4.676, backward: 2.746, update: 5.064
[proc 2][Train](5000/10000) average pos_loss: 0.04608970557525754
[proc 2][Train](5000/10000) average neg_loss: 0.07129045167565345
[proc 2][Train](5000/10000) average loss: 0.05869007868692279
[proc 2][Train](5000/10000) average regularization: 2.185028649728338e-05
[proc 2] 5000 steps, total: 14.853, sample: 1.984, forward: 4.647, backward: 2.875, update: 5.015
[proc 3][Train](6000/10000) average pos_loss: 0.04412946152687073
[proc 3][Train](6000/10000) average neg_loss: 0.06883273657038808
[proc 3][Train](6000/10000) average loss: 0.056481099005788564
[proc 3][Train](6000/10000) average regularization: 2.253387912969629e-05
[proc 3] 6000 steps, total: 14.545, sample: 1.736, forward: 5.079, backward: 2.718, update: 5.004
[proc 1][Train](6000/10000) average pos_loss: 0.04438374324142933
[proc 1][Train](6000/10000) average neg_loss: 0.06921743524447084
[proc 1][Train](6000/10000) average loss: 0.05680058917403221
[proc 1][Train](6000/10000) average regularization: 2.252974745715619e-05
[proc 1] 6000 steps, total: 14.545, sample: 1.762, forward: 4.780, backward: 2.719, update: 5.135
[proc 2][Train](6000/10000) average pos_loss: 0.04433201602101326
[proc 2][Train](6000/10000) average neg_loss: 0.06911697437614203
[proc 2][Train](6000/10000) average loss: 0.05672449520602822
[proc 2][Train](6000/10000) average regularization: 2.2519029185787077e-05
[proc 2] 6000 steps, total: 14.545, sample: 1.727, forward: 4.615, backward: 2.671, update: 5.066
[proc 0][Train](6000/10000) average pos_loss: 0.04392763498425484
[proc 0][Train](6000/10000) average neg_loss: 0.06885051257535815
[proc 0][Train](6000/10000) average loss: 0.05638907376676798
[proc 0][Train](6000/10000) average regularization: 2.2548495089722564e-05
[proc 0] 6000 steps, total: 14.546, sample: 1.742, forward: 4.938, backward: 2.704, update: 5.003
[proc 0][Train](7000/10000) average pos_loss: 0.04273450642079115
[proc 0][Train](7000/10000) average neg_loss: 0.0671842798665166
[proc 0][Train](7000/10000) average loss: 0.05495939302071929
[proc 0][Train](7000/10000) average regularization: 2.311593439844728e-05
[proc 0] 7000 steps, total: 14.466, sample: 1.795, forward: 5.008, backward: 2.871, update: 4.785
[proc 1][Train](7000/10000) average pos_loss: 0.04314544815570116
[proc 1][Train](7000/10000) average neg_loss: 0.06774335976317525
[proc 1][Train](7000/10000) average loss: 0.05544440393894911
[proc 1][Train](7000/10000) average regularization: 2.3097309793229216e-05
[proc 1] 7000 steps, total: 14.467, sample: 1.793, forward: 4.789, backward: 2.798, update: 5.070
[proc 3][Train](7000/10000) average pos_loss: 0.04288487723097205
[proc 3][Train](7000/10000) average neg_loss: 0.06734460744634271
[proc 3][Train](7000/10000) average loss: 0.05511474229767919
[proc 3][Train](7000/10000) average regularization: 2.3092720304703106e-05
[proc 3] 7000 steps, total: 14.468, sample: 1.759, forward: 5.055, backward: 2.677, update: 4.850
[proc 2][Train](7000/10000) average pos_loss: 0.04309588061273098
[proc 2][Train](7000/10000) average neg_loss: 0.06784631434082986
[proc 2][Train](7000/10000) average loss: 0.055471097435802225
[proc 2][Train](7000/10000) average regularization: 2.307889018084097e-05
[proc 2] 7000 steps, total: 14.468, sample: 1.783, forward: 4.639, backward: 2.317, update: 5.151
[proc 3][Train](8000/10000) average pos_loss: 0.042053275372833016
[proc 3][Train](8000/10000) average neg_loss: 0.06610927672311663
[proc 3][Train](8000/10000) average loss: 0.054081276029348375
[proc 3][Train](8000/10000) average regularization: 2.3574774158987565e-05
[proc 3] 8000 steps, total: 14.515, sample: 1.725, forward: 5.058, backward: 2.707, update: 5.018
[proc 1][Train](8000/10000) average pos_loss: 0.042200291108340025
[proc 1][Train](8000/10000) average neg_loss: 0.0665601851567626
[proc 1][Train](8000/10000) average loss: 0.054380238067358734
[proc 1][Train](8000/10000) average regularization: 2.3568238921143346e-05
[proc 1] 8000 steps, total: 14.516, sample: 1.739, forward: 4.830, backward: 2.704, update: 5.141
[proc 0][Train](8000/10000) average pos_loss: 0.041666956886649134
[proc 0][Train](8000/10000) average neg_loss: 0.06628539663180709
[proc 0][Train](8000/10000) average loss: 0.053976176761090754
[proc 0][Train](8000/10000) average regularization: 2.358429904234072e-05
[proc 0] 8000 steps, total: 14.516, sample: 1.731, forward: 5.014, backward: 2.689, update: 4.860
[proc 2][Train](8000/10000) average pos_loss: 0.04240714015439153
[proc 2][Train](8000/10000) average neg_loss: 0.06662645395100117
[proc 2][Train](8000/10000) average loss: 0.05451679706573486
[proc 2][Train](8000/10000) average regularization: 2.35703185753664e-05
[proc 2] 8000 steps, total: 14.516, sample: 1.718, forward: 4.711, backward: 2.868, update: 5.003
[proc 0][Train](9000/10000) average pos_loss: 0.04113485049083829
[proc 0][Train](9000/10000) average neg_loss: 0.06526154260337352
[proc 0][Train](9000/10000) average loss: 0.053198196552693845
[proc 0][Train](9000/10000) average regularization: 2.4003646705750726e-05
[proc 0] 9000 steps, total: 14.631, sample: 1.765, forward: 5.035, backward: 3.307, update: 4.516
[proc 1][Train](9000/10000) average pos_loss: 0.04143870078772306
[proc 1][Train](9000/10000) average neg_loss: 0.0656778456903994
[proc 1][Train](9000/10000) average loss: 0.053558273162692786
[proc 1][Train](9000/10000) average regularization: 2.3976991025847383e-05
[proc 1] 9000 steps, total: 14.632, sample: 1.770, forward: 4.748, backward: 2.886, update: 4.997
[proc 3][Train](9000/10000) average pos_loss: 0.04126196275278926
[proc 3][Train](9000/10000) average neg_loss: 0.06535939829424024
[proc 3][Train](9000/10000) average loss: 0.05331068057566881
[proc 3][Train](9000/10000) average regularization: 2.397942625248106e-05
[proc 3] 9000 steps, total: 14.633, sample: 1.727, forward: 5.095, backward: 2.638, update: 4.896
[proc 2][Train](9000/10000) average pos_loss: 0.04170692887157202
[proc 2][Train](9000/10000) average neg_loss: 0.06577981223165989
[proc 2][Train](9000/10000) average loss: 0.05374337046965957
[proc 2][Train](9000/10000) average regularization: 2.3981116122740787e-05
[proc 2] 9000 steps, total: 14.632, sample: 1.813, forward: 4.797, backward: 2.961, update: 4.901
[proc 0][Train](10000/10000) average pos_loss: 0.04053392538055778
[proc 0][Train](10000/10000) average neg_loss: 0.06445238530635834
[proc 0][Train](10000/10000) average loss: 0.052493155352771284
[proc 0][Train](10000/10000) average regularization: 2.4366571864447906e-05
[proc 0] 10000 steps, total: 14.736, sample: 1.903, forward: 5.032, backward: 3.359, update: 4.434
proc 0 takes 148.498 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.040844355762004854
[proc 1][Train](10000/10000) average neg_loss: 0.06497277282550931
[proc 1][Train](10000/10000) average loss: 0.052908564306795594
[proc 1][Train](10000/10000) average regularization: 2.4345641777472337e-05
[proc 1] 10000 steps, total: 14.736, sample: 1.864, forward: 4.647, backward: 2.662, update: 4.981
[proc 2][Train](10000/10000) average pos_loss: 0.04104106710478663
[proc 2][Train](10000/10000) average neg_loss: 0.06493132803589105
[proc 2][Train](10000/10000) average loss: 0.0529861975684762
[proc 2][Train](10000/10000) average regularization: 2.4343792994841352e-05
[proc 2] 10000 steps, total: 14.736, sample: 1.953, forward: 4.717, backward: 2.674, update: 4.956
proc 1 takes 148.463 seconds
proc 2 takes 148.467 seconds
[proc 3][Train](10000/10000) average pos_loss: 0.04076868604123592
[proc 3][Train](10000/10000) average neg_loss: 0.06469102764874697
[proc 3][Train](10000/10000) average loss: 0.05272985680773854
[proc 3][Train](10000/10000) average regularization: 2.43390964496939e-05
[proc 3] 10000 steps, total: 14.736, sample: 1.859, forward: 5.123, backward: 2.761, update: 4.769
proc 3 takes 148.463 seconds
Successfully xmh. training takes 148.9778184890747 seconds
