Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 2 parts
part 0 has 241571 edges
part 1 has 241571 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_FB15k_1', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 0.807 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.21545773608237506
[proc 0][Train](1000/10000) average neg_loss: 0.22912026926130055
[proc 0][Train](1000/10000) average loss: 0.2222890024855733
[proc 0][Train](1000/10000) average regularization: 1.0883940376288592e-05
[proc 0] 1000 steps, total: 12.950, sample: 1.454, forward: 5.054, backward: 2.554, update: 3.880
[proc 1][Train](1000/10000) average pos_loss: 0.2215623543858528
[proc 1][Train](1000/10000) average neg_loss: 0.236869822435081
[proc 1][Train](1000/10000) average loss: 0.22921608868986368
[proc 1][Train](1000/10000) average regularization: 1.066653335465162e-05
[proc 1] 1000 steps, total: 12.948, sample: 1.372, forward: 4.850, backward: 2.632, update: 3.486
[proc 0][Train](2000/10000) average pos_loss: 0.07672715444117785
[proc 0][Train](2000/10000) average neg_loss: 0.10795543736964464
[proc 0][Train](2000/10000) average loss: 0.0923412958830595
[proc 0][Train](2000/10000) average regularization: 1.5349331050856563e-05
[proc 0] 2000 steps, total: 11.609, sample: 1.346, forward: 3.966, backward: 2.546, update: 3.745
[proc 1][Train](2000/10000) average pos_loss: 0.07673582902923226
[proc 1][Train](2000/10000) average neg_loss: 0.1085404031649232
[proc 1][Train](2000/10000) average loss: 0.09263811614364385
[proc 1][Train](2000/10000) average regularization: 1.526482131521334e-05
[proc 1] 2000 steps, total: 11.609, sample: 1.330, forward: 3.925, backward: 1.917, update: 3.574
[proc 0][Train](3000/10000) average pos_loss: 0.06309627458453178
[proc 0][Train](3000/10000) average neg_loss: 0.0925050683915615
[proc 0][Train](3000/10000) average loss: 0.07780067150294781
[proc 0][Train](3000/10000) average regularization: 1.7226455705895204e-05
[proc 0] 3000 steps, total: 11.609, sample: 1.356, forward: 3.985, backward: 2.493, update: 3.767
[proc 1][Train](3000/10000) average pos_loss: 0.06332971031963826
[proc 1][Train](3000/10000) average neg_loss: 0.0927177899479866
[proc 1][Train](3000/10000) average loss: 0.07802375017106533
[proc 1][Train](3000/10000) average regularization: 1.7195362872371332e-05
[proc 1] 3000 steps, total: 11.609, sample: 1.328, forward: 3.865, backward: 2.643, update: 3.339
[proc 0][Train](4000/10000) average pos_loss: 0.057069446850568056
[proc 0][Train](4000/10000) average neg_loss: 0.08515002075582742
[proc 0][Train](4000/10000) average loss: 0.07110973390564322
[proc 0][Train](4000/10000) average regularization: 1.843703087615722e-05
[proc 0] 4000 steps, total: 11.736, sample: 1.453, forward: 3.997, backward: 2.548, update: 3.731
[proc 1][Train](4000/10000) average pos_loss: 0.057125647749751804
[proc 1][Train](4000/10000) average neg_loss: 0.08520549133419991
[proc 1][Train](4000/10000) average loss: 0.07116556949913502
[proc 1][Train](4000/10000) average regularization: 1.8412425622955197e-05
[proc 1] 4000 steps, total: 11.736, sample: 1.404, forward: 3.857, backward: 2.634, update: 3.327
[proc 0][Train](5000/10000) average pos_loss: 0.05335547249391675
[proc 0][Train](5000/10000) average neg_loss: 0.0804694791585207
[proc 0][Train](5000/10000) average loss: 0.06691247576475143
[proc 0][Train](5000/10000) average regularization: 1.9328995053001562e-05
[proc 0] 5000 steps, total: 11.385, sample: 1.337, forward: 3.961, backward: 2.193, update: 3.888
[proc 1][Train](5000/10000) average pos_loss: 0.05337117406353355
[proc 1][Train](5000/10000) average neg_loss: 0.08056445771083236
[proc 1][Train](5000/10000) average loss: 0.06696781588345765
[proc 1][Train](5000/10000) average regularization: 1.9306923206386272e-05
[proc 1] 5000 steps, total: 11.385, sample: 1.321, forward: 3.856, backward: 2.604, update: 3.333
[proc 0][Train](6000/10000) average pos_loss: 0.05081833109632134
[proc 0][Train](6000/10000) average neg_loss: 0.07750079142674804
[proc 0][Train](6000/10000) average loss: 0.06415956146270037
[proc 0][Train](6000/10000) average regularization: 2.001814626601117e-05
[proc 0] 6000 steps, total: 11.235, sample: 1.274, forward: 3.899, backward: 2.160, update: 3.895
[proc 1][Train](6000/10000) average pos_loss: 0.05097495027258992
[proc 1][Train](6000/10000) average neg_loss: 0.07735868138074875
[proc 1][Train](6000/10000) average loss: 0.06416681585833431
[proc 1][Train](6000/10000) average regularization: 2.002209410602518e-05
[proc 1] 6000 steps, total: 11.235, sample: 1.311, forward: 3.884, backward: 2.566, update: 3.361
[proc 1][Train](7000/10000) average pos_loss: 0.04902778398990631
[proc 1][Train](7000/10000) average neg_loss: 0.07504315825551748
[proc 1][Train](7000/10000) average loss: 0.062035471081733705
[proc 1][Train](7000/10000) average regularization: 2.059506373370823e-05
[proc 1] 7000 steps, total: 11.272, sample: 1.348, forward: 3.932, backward: 2.607, update: 3.377
[proc 0][Train](7000/10000) average pos_loss: 0.048972489338368175
[proc 0][Train](7000/10000) average neg_loss: 0.07506600525602698
[proc 0][Train](7000/10000) average loss: 0.062019247453659776
[proc 0][Train](7000/10000) average regularization: 2.0604700806870825e-05
[proc 0] 7000 steps, total: 11.272, sample: 1.268, forward: 3.895, backward: 1.929, update: 4.021
[proc 0][Train](8000/10000) average pos_loss: 0.047749313417822126
[proc 0][Train](8000/10000) average neg_loss: 0.07320375751703978
[proc 0][Train](8000/10000) average loss: 0.060476535469293595
[proc 0][Train](8000/10000) average regularization: 2.1107297783601098e-05
[proc 0] 8000 steps, total: 12.001, sample: 1.483, forward: 4.052, backward: 2.594, update: 3.864
[proc 1][Train](8000/10000) average pos_loss: 0.047452934592962265
[proc 1][Train](8000/10000) average neg_loss: 0.07320705498754979
[proc 1][Train](8000/10000) average loss: 0.06032999486476183
[proc 1][Train](8000/10000) average regularization: 2.1086958060550386e-05
[proc 1] 8000 steps, total: 12.002, sample: 1.351, forward: 3.833, backward: 2.357, update: 3.421
[proc 0][Train](9000/10000) average pos_loss: 0.04642775602266192
[proc 0][Train](9000/10000) average neg_loss: 0.07173530194535852
[proc 0][Train](9000/10000) average loss: 0.05908152898028493
[proc 0][Train](9000/10000) average regularization: 2.153660730436968e-05
[proc 0] 9000 steps, total: 11.387, sample: 1.287, forward: 3.915, backward: 2.308, update: 3.871
[proc 1][Train](9000/10000) average pos_loss: 0.046430646784603596
[proc 1][Train](9000/10000) average neg_loss: 0.07182803141325712
[proc 1][Train](9000/10000) average loss: 0.05912933911010623
[proc 1][Train](9000/10000) average regularization: 2.1510587625016343e-05
[proc 1] 9000 steps, total: 11.387, sample: 1.297, forward: 3.807, backward: 2.014, update: 3.353
[proc 0][Train](10000/10000) average pos_loss: 0.0455336517393589
[proc 0][Train](10000/10000) average neg_loss: 0.07050682378187775
[proc 0][Train](10000/10000) average loss: 0.05802023772150278
[proc 0][Train](10000/10000) average regularization: 2.192433087657264e-05
[proc 0] 10000 steps, total: 11.532, sample: 1.369, forward: 4.003, backward: 2.304, update: 3.850
proc 0 takes 116.718 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.04532243374362588
[proc 1][Train](10000/10000) average neg_loss: 0.07052813602611423
[proc 1][Train](10000/10000) average loss: 0.057925284888595344
[proc 1][Train](10000/10000) average regularization: 2.1889477440709015e-05
[proc 1] 10000 steps, total: 11.533, sample: 1.263, forward: 3.790, backward: 1.737, update: 3.384
proc 1 takes 116.717 seconds
Successfully xmh. training takes 116.97583055496216 seconds
-------------- Test result --------------
Test average MRR : 0.5389730704020346
Test average MR : 44.414611230553064
Test average HITS@1 : 0.4001286587327115
Test average HITS@3 : 0.6346345922703188
Test average HITS@10 : 0.7672969815984154
-----------------------------------------
testing takes 165.830 seconds
