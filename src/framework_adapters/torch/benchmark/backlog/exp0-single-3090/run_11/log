Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 4 parts
part 0 has 76181913 edges
part 1 has 76181913 edges
part 2 has 76181913 edges
part 3 has 76181911 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2, 3], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=4, num_proc=4, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_Freebase_3', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 725.345 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 3][Train](1000/10000) average pos_loss: 0.6701079326868057
[proc 3][Train](1000/10000) average neg_loss: 0.6891592440009117
[proc 3][Train](1000/10000) average loss: 0.6796335879564285
[proc 3][Train](1000/10000) average regularization: 7.782708413287764e-06
[proc 3] 1000 steps, total: 38.710, sample: 16.425, forward: 13.087, backward: 2.828, update: 6.362
[proc 1][Train](1000/10000) average pos_loss: 0.6705638350248336
[proc 1][Train](1000/10000) average neg_loss: 0.6913954992294311
[proc 1][Train](1000/10000) average loss: 0.6809796680212021
[proc 1][Train](1000/10000) average regularization: 7.788483972490213e-06
[proc 1] 1000 steps, total: 39.937, sample: 17.418, forward: 12.674, backward: 2.842, update: 6.348
[proc 0][Train](1000/10000) average pos_loss: 0.6695971379578114
[proc 0][Train](1000/10000) average neg_loss: 0.695891061604023
[proc 0][Train](1000/10000) average loss: 0.682744099855423
[proc 0][Train](1000/10000) average regularization: 7.694477952099987e-06
[proc 0] 1000 steps, total: 40.530, sample: 16.557, forward: 12.637, backward: 2.853, update: 6.468
[proc 2][Train](1000/10000) average pos_loss: 0.6743815788030625
[proc 2][Train](1000/10000) average neg_loss: 0.6921966571509838
[proc 2][Train](1000/10000) average loss: 0.6832891175746918
[proc 2][Train](1000/10000) average regularization: 7.745840104689705e-06
[proc 2] 1000 steps, total: 39.346, sample: 16.265, forward: 12.748, backward: 2.911, update: 6.378
[proc 3][Train](2000/10000) average pos_loss: 0.6857295050024986
[proc 3][Train](2000/10000) average neg_loss: 0.6825494593381882
[proc 3][Train](2000/10000) average loss: 0.6841394825577736
[proc 3][Train](2000/10000) average regularization: 7.1317859524242525e-06
[proc 3] 2000 steps, total: 19.776, sample: 2.533, forward: 7.831, backward: 2.869, update: 6.535
[proc 1][Train](2000/10000) average pos_loss: 0.6850841290354729
[proc 1][Train](2000/10000) average neg_loss: 0.6829061893820763
[proc 1][Train](2000/10000) average loss: 0.6839951592683792
[proc 1][Train](2000/10000) average regularization: 7.169503860495752e-06
[proc 1] 2000 steps, total: 19.776, sample: 2.216, forward: 7.381, backward: 2.837, update: 6.184
[proc 2][Train](2000/10000) average pos_loss: 0.6858937845826149
[proc 2][Train](2000/10000) average neg_loss: 0.6836959101557731
[proc 2][Train](2000/10000) average loss: 0.6847948476076126
[proc 2][Train](2000/10000) average regularization: 7.168725103838369e-06
[proc 2] 2000 steps, total: 19.776, sample: 2.323, forward: 7.397, backward: 2.794, update: 6.238
[proc 0][Train](2000/10000) average pos_loss: 0.6853939763903618
[proc 0][Train](2000/10000) average neg_loss: 0.6817912225127221
[proc 0][Train](2000/10000) average loss: 0.6835925983786583
[proc 0][Train](2000/10000) average regularization: 7.166464240981441e-06
[proc 0] 2000 steps, total: 19.776, sample: 2.324, forward: 7.157, backward: 2.894, update: 6.360
[proc 3][Train](3000/10000) average pos_loss: 0.6941376351118088
[proc 3][Train](3000/10000) average neg_loss: 0.676277921795845
[proc 3][Train](3000/10000) average loss: 0.6852077784538269
[proc 3][Train](3000/10000) average regularization: 6.450554843468126e-06
[proc 3] 3000 steps, total: 18.284, sample: 2.484, forward: 6.477, backward: 2.781, update: 6.535
[proc 1][Train](3000/10000) average pos_loss: 0.6945399518013
[proc 1][Train](3000/10000) average neg_loss: 0.676289499938488
[proc 1][Train](3000/10000) average loss: 0.6854147270917893
[proc 1][Train](3000/10000) average regularization: 6.456571562466707e-06
[proc 1] 3000 steps, total: 18.284, sample: 2.234, forward: 6.394, backward: 2.853, update: 6.090
[proc 2][Train](3000/10000) average pos_loss: 0.6942124079465866
[proc 2][Train](3000/10000) average neg_loss: 0.6764057422280312
[proc 2][Train](3000/10000) average loss: 0.6853090748786926
[proc 2][Train](3000/10000) average regularization: 6.451300563639961e-06
[proc 2] 3000 steps, total: 18.284, sample: 2.382, forward: 6.335, backward: 2.838, update: 6.147
[proc 0][Train](3000/10000) average pos_loss: 0.6945742459893227
[proc 0][Train](3000/10000) average neg_loss: 0.6777285019159317
[proc 0][Train](3000/10000) average loss: 0.6861513738632202
[proc 0][Train](3000/10000) average regularization: 6.453564123603428e-06
[proc 0] 3000 steps, total: 18.284, sample: 2.424, forward: 6.197, backward: 2.838, update: 6.385
[proc 3][Train](4000/10000) average pos_loss: 0.701224541425705
[proc 3][Train](4000/10000) average neg_loss: 0.6696694975495339
[proc 3][Train](4000/10000) average loss: 0.6854470195770264
[proc 3][Train](4000/10000) average regularization: 6.39170176918924e-06
[proc 3] 4000 steps, total: 17.867, sample: 2.443, forward: 5.950, backward: 2.835, update: 6.630
[proc 2][Train](4000/10000) average pos_loss: 0.7002133898139
[proc 2][Train](4000/10000) average neg_loss: 0.6709132335782051
[proc 2][Train](4000/10000) average loss: 0.6855633115172386
[proc 2][Train](4000/10000) average regularization: 6.387141551840614e-06
[proc 2] 4000 steps, total: 17.866, sample: 2.345, forward: 5.932, backward: 2.856, update: 6.056
[proc 1][Train](4000/10000) average pos_loss: 0.7020968895554542
[proc 1][Train](4000/10000) average neg_loss: 0.6698555201292038
[proc 1][Train](4000/10000) average loss: 0.6859762043356895
[proc 1][Train](4000/10000) average regularization: 6.3914470702002295e-06
[proc 1] 4000 steps, total: 17.866, sample: 2.192, forward: 5.839, backward: 2.813, update: 6.040
[proc 0][Train](4000/10000) average pos_loss: 0.7007041423916817
[proc 0][Train](4000/10000) average neg_loss: 0.6689781834483146
[proc 0][Train](4000/10000) average loss: 0.6848411631584167
[proc 0][Train](4000/10000) average regularization: 6.391858076767676e-06
[proc 0] 4000 steps, total: 17.866, sample: 2.372, forward: 5.792, backward: 2.848, update: 6.339
[proc 3][Train](5000/10000) average pos_loss: 0.7045712321996689
[proc 3][Train](5000/10000) average neg_loss: 0.6630074518918991
[proc 3][Train](5000/10000) average loss: 0.6837893428802491
[proc 3][Train](5000/10000) average regularization: 6.47324814735839e-06
[proc 3] 5000 steps, total: 17.505, sample: 2.560, forward: 5.689, backward: 2.843, update: 6.406
[proc 1][Train](5000/10000) average pos_loss: 0.7065969601273536
[proc 1][Train](5000/10000) average neg_loss: 0.6616250836253166
[proc 1][Train](5000/10000) average loss: 0.6841110226511955
[proc 1][Train](5000/10000) average regularization: 6.474117517882405e-06
[proc 1] 5000 steps, total: 17.504, sample: 2.464, forward: 5.716, backward: 2.907, update: 6.005
[proc 2][Train](5000/10000) average pos_loss: 0.7050407046079635
[proc 2][Train](5000/10000) average neg_loss: 0.6611614432930947
[proc 2][Train](5000/10000) average loss: 0.6831010735630989
[proc 2][Train](5000/10000) average regularization: 6.476158923305775e-06
[proc 2] 5000 steps, total: 17.505, sample: 2.537, forward: 5.795, backward: 2.890, update: 6.007
[proc 0][Train](5000/10000) average pos_loss: 0.7051013056635856
[proc 0][Train](5000/10000) average neg_loss: 0.6626263484954834
[proc 0][Train](5000/10000) average loss: 0.6838638260364532
[proc 0][Train](5000/10000) average regularization: 6.474204715686938e-06
[proc 0] 5000 steps, total: 17.505, sample: 2.598, forward: 5.614, backward: 2.864, update: 6.221
[proc 3][Train](6000/10000) average pos_loss: 0.7076641694903374
[proc 3][Train](6000/10000) average neg_loss: 0.6546846093535423
[proc 3][Train](6000/10000) average loss: 0.6811743898391723
[proc 3][Train](6000/10000) average regularization: 6.583626537121745e-06
[proc 3] 6000 steps, total: 17.452, sample: 2.441, forward: 5.739, backward: 2.841, update: 6.423
[proc 1][Train](6000/10000) average pos_loss: 0.7068192631602287
[proc 1][Train](6000/10000) average neg_loss: 0.6542517571151256
[proc 1][Train](6000/10000) average loss: 0.6805355097651482
[proc 1][Train](6000/10000) average regularization: 6.584732764167711e-06
[proc 1] 6000 steps, total: 17.452, sample: 2.242, forward: 5.685, backward: 2.805, update: 5.989
[proc 2][Train](6000/10000) average pos_loss: 0.7082576643824577
[proc 2][Train](6000/10000) average neg_loss: 0.6554849743843079
[proc 2][Train](6000/10000) average loss: 0.6818713200688362
[proc 2][Train](6000/10000) average regularization: 6.578341065960558e-06
[proc 2] 6000 steps, total: 17.452, sample: 2.278, forward: 5.695, backward: 2.870, update: 5.954
[proc 0][Train](6000/10000) average pos_loss: 0.7097685477137565
[proc 0][Train](6000/10000) average neg_loss: 0.65412096580863
[proc 0][Train](6000/10000) average loss: 0.6819447568655014
[proc 0][Train](6000/10000) average regularization: 6.578992932190886e-06
[proc 0] 6000 steps, total: 17.452, sample: 2.361, forward: 5.336, backward: 2.844, update: 6.163
[proc 3][Train](7000/10000) average pos_loss: 0.7098027489185333
[proc 3][Train](7000/10000) average neg_loss: 0.6467530962228775
[proc 3][Train](7000/10000) average loss: 0.6782779222130776
[proc 3][Train](7000/10000) average regularization: 6.6984307477468975e-06
[proc 3] 7000 steps, total: 17.475, sample: 2.431, forward: 5.778, backward: 2.861, update: 6.397
[proc 0][Train](7000/10000) average pos_loss: 0.7109147093892098
[proc 0][Train](7000/10000) average neg_loss: 0.6475045183300971
[proc 0][Train](7000/10000) average loss: 0.6792096130847931
[proc 0][Train](7000/10000) average regularization: 6.697998564959562e-06
[proc 0] 7000 steps, total: 17.474, sample: 2.307, forward: 5.315, backward: 2.816, update: 6.115
[proc 2][Train](7000/10000) average pos_loss: 0.709969713807106
[proc 2][Train](7000/10000) average neg_loss: 0.6479772279858589
[proc 2][Train](7000/10000) average loss: 0.6789734715819359
[proc 2][Train](7000/10000) average regularization: 6.6952975371350475e-06
[proc 2] 7000 steps, total: 17.475, sample: 2.434, forward: 5.735, backward: 2.894, update: 5.903
[proc 1][Train](7000/10000) average pos_loss: 0.7101918925642967
[proc 1][Train](7000/10000) average neg_loss: 0.6478857874274254
[proc 1][Train](7000/10000) average loss: 0.679038840174675
[proc 1][Train](7000/10000) average regularization: 6.700505021854042e-06
[proc 1] 7000 steps, total: 17.475, sample: 2.295, forward: 5.694, backward: 2.847, update: 5.878
[proc 3][Train](8000/10000) average pos_loss: 0.7101193682551384
[proc 3][Train](8000/10000) average neg_loss: 0.639084591448307
[proc 3][Train](8000/10000) average loss: 0.6746019798517228
[proc 3][Train](8000/10000) average regularization: 6.810951305851631e-06
[proc 3] 8000 steps, total: 17.071, sample: 2.312, forward: 5.570, backward: 2.872, update: 6.309
[proc 2][Train](8000/10000) average pos_loss: 0.7103626549243927
[proc 2][Train](8000/10000) average neg_loss: 0.6393268160820007
[proc 2][Train](8000/10000) average loss: 0.6748447355628013
[proc 2][Train](8000/10000) average regularization: 6.813928568590199e-06
[proc 2] 8000 steps, total: 17.071, sample: 2.361, forward: 5.690, backward: 2.848, update: 5.949
[proc 1][Train](8000/10000) average pos_loss: 0.7108574815988541
[proc 1][Train](8000/10000) average neg_loss: 0.6398668407797813
[proc 1][Train](8000/10000) average loss: 0.6753621618747712
[proc 1][Train](8000/10000) average regularization: 6.811993571318453e-06
[proc 1] 8000 steps, total: 17.071, sample: 2.186, forward: 5.742, backward: 2.811, update: 5.923
[proc 0][Train](8000/10000) average pos_loss: 0.7103291700482368
[proc 0][Train](8000/10000) average neg_loss: 0.6406614787578583
[proc 0][Train](8000/10000) average loss: 0.6754953239560127
[proc 0][Train](8000/10000) average regularization: 6.816633903326874e-06
[proc 0] 8000 steps, total: 17.071, sample: 2.302, forward: 5.420, backward: 2.859, update: 6.049
[proc 1][Train](9000/10000) average pos_loss: 0.7100021095871926
[proc 1][Train](9000/10000) average neg_loss: 0.6327461265325546
[proc 1][Train](9000/10000) average loss: 0.6713741192221642
[proc 1][Train](9000/10000) average regularization: 6.925052927726938e-06
[proc 1] 9000 steps, total: 17.146, sample: 2.440, forward: 5.842, backward: 2.865, update: 5.991
[proc 3][Train](9000/10000) average pos_loss: 0.711630597293377
[proc 3][Train](9000/10000) average neg_loss: 0.6314709280133247
[proc 3][Train](9000/10000) average loss: 0.6715507615208626
[proc 3][Train](9000/10000) average regularization: 6.92872987337978e-06
[proc 3] 9000 steps, total: 17.147, sample: 2.516, forward: 5.550, backward: 2.837, update: 6.215
[proc 2][Train](9000/10000) average pos_loss: 0.7101344954967499
[proc 2][Train](9000/10000) average neg_loss: 0.6324161849021912
[proc 2][Train](9000/10000) average loss: 0.6712753410339356
[proc 2][Train](9000/10000) average regularization: 6.928140466243349e-06
[proc 2] 9000 steps, total: 17.147, sample: 2.519, forward: 5.612, backward: 2.817, update: 5.932
[proc 0][Train](9000/10000) average pos_loss: 0.710434771001339
[proc 0][Train](9000/10000) average neg_loss: 0.6317527583837509
[proc 0][Train](9000/10000) average loss: 0.6710937651991844
[proc 0][Train](9000/10000) average regularization: 6.926981791821163e-06
[proc 0] 9000 steps, total: 17.147, sample: 2.452, forward: 5.301, backward: 2.848, update: 6.008
[proc 0][Train](10000/10000) average pos_loss: 0.7071517261266709
[proc 0][Train](10000/10000) average neg_loss: 0.6238252190351486
[proc 0][Train](10000/10000) average loss: 0.6654884731173515
[proc 0][Train](10000/10000) average regularization: 7.041182275315805e-06
[proc 0] 10000 steps, total: 17.084, sample: 2.499, forward: 5.555, backward: 2.871, update: 6.151
proc 0 takes 200.191 seconds
[proc 3][Train](10000/10000) average pos_loss: 0.709760449051857
[proc 3][Train](10000/10000) average neg_loss: 0.6232287583649159
[proc 3][Train](10000/10000) average loss: 0.6664946045279503
[proc 3][Train](10000/10000) average regularization: 7.042685328087828e-06
[proc 3] 10000 steps, total: 17.086, sample: 2.321, forward: 5.462, backward: 2.888, update: 6.187
[proc 2][Train](10000/10000) average pos_loss: 0.7077389823198319
[proc 2][Train](10000/10000) average neg_loss: 0.623991851568222
[proc 2][Train](10000/10000) average loss: 0.6658654177188873
[proc 2][Train](10000/10000) average regularization: 7.037562106233963e-06
[proc 2] 10000 steps, total: 17.085, sample: 2.350, forward: 5.664, backward: 2.824, update: 5.917
proc 3 takes 198.372 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.7087085680365562
[proc 1][Train](10000/10000) average neg_loss: 0.6245357709228992
[proc 1][Train](10000/10000) average loss: 0.6666221700310707
[proc 1][Train](10000/10000) average regularization: 7.041215584649763e-06
[proc 1] 10000 steps, total: 17.086, sample: 2.215, forward: 5.698, backward: 2.728, update: 5.844
proc 2 takes 199.008 seconds
proc 1 takes 199.598 seconds
Successfully xmh. training takes 209.02625608444214 seconds
