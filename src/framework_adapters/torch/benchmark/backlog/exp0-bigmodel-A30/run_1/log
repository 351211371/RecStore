Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 2 parts
part 0 has 152363825 edges
part 1 has 152363825 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=100, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_Freebase_13', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 386.248 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 1][Train](1000/10000) average pos_loss: 0.7157522986829281
[proc 1][Train](1000/10000) average neg_loss: 0.7951814600229263
[proc 1][Train](1000/10000) average loss: 0.7554668790698051
[proc 1][Train](1000/10000) average regularization: 8.453632036253112e-05
[proc 1] 1000 steps, total: 23.764, sample: 13.122, forward: 5.746, backward: 2.470, update: 2.421
[proc 0][Train](1000/10000) average pos_loss: 0.7155382053852082
[proc 0][Train](1000/10000) average neg_loss: 0.7961753679513931
[proc 0][Train](1000/10000) average loss: 0.7558567870855332
[proc 0][Train](1000/10000) average regularization: 8.429671010526363e-05
[proc 0] 1000 steps, total: 23.947, sample: 13.129, forward: 5.846, backward: 2.322, update: 2.474
[proc 1][Train](2000/10000) average pos_loss: 0.7030553123354912
[proc 1][Train](2000/10000) average neg_loss: 0.7703415835499764
[proc 1][Train](2000/10000) average loss: 0.7366984487771988
[proc 1][Train](2000/10000) average regularization: 9.560173872159794e-05
[proc 1] 2000 steps, total: 9.027, sample: 1.365, forward: 3.054, backward: 2.359, update: 2.245
[proc 0][Train](2000/10000) average pos_loss: 0.7036563431024552
[proc 0][Train](2000/10000) average neg_loss: 0.770460897743702
[proc 0][Train](2000/10000) average loss: 0.7370586213469505
[proc 0][Train](2000/10000) average regularization: 9.55795470654266e-05
[proc 0] 2000 steps, total: 9.027, sample: 1.365, forward: 3.055, backward: 2.295, update: 2.279
[proc 1][Train](3000/10000) average pos_loss: 0.6960476557016373
[proc 1][Train](3000/10000) average neg_loss: 0.7586801744103432
[proc 1][Train](3000/10000) average loss: 0.7273639150261879
[proc 1][Train](3000/10000) average regularization: 0.00010403199537540786
[proc 1] 3000 steps, total: 8.842, sample: 1.354, forward: 3.013, backward: 2.300, update: 2.171
[proc 0][Train](3000/10000) average pos_loss: 0.6967074707150459
[proc 0][Train](3000/10000) average neg_loss: 0.7610892767906189
[proc 0][Train](3000/10000) average loss: 0.728898374736309
[proc 0][Train](3000/10000) average regularization: 0.00010398878528940259
[proc 0] 3000 steps, total: 8.842, sample: 1.347, forward: 3.011, backward: 2.287, update: 2.181
[proc 0][Train](4000/10000) average pos_loss: 0.692260303735733
[proc 0][Train](4000/10000) average neg_loss: 0.7526135621666908
[proc 0][Train](4000/10000) average loss: 0.7224369317293167
[proc 0][Train](4000/10000) average regularization: 0.00011086392330616945
[proc 0] 4000 steps, total: 8.834, sample: 1.348, forward: 3.040, backward: 2.303, update: 2.138
[proc 1][Train](4000/10000) average pos_loss: 0.6902919135093689
[proc 1][Train](4000/10000) average neg_loss: 0.7529811556339264
[proc 1][Train](4000/10000) average loss: 0.7216365355849266
[proc 1][Train](4000/10000) average regularization: 0.00011088514104631031
[proc 1] 4000 steps, total: 8.834, sample: 1.325, forward: 3.001, backward: 1.973, update: 2.168
[proc 0][Train](5000/10000) average pos_loss: 0.687839452624321
[proc 0][Train](5000/10000) average neg_loss: 0.7470078665018082
[proc 0][Train](5000/10000) average loss: 0.717423658490181
[proc 0][Train](5000/10000) average regularization: 0.00011657028800254921
[proc 0] 5000 steps, total: 8.822, sample: 1.434, forward: 3.023, backward: 2.278, update: 2.083
[proc 1][Train](5000/10000) average pos_loss: 0.6874392354488372
[proc 1][Train](5000/10000) average neg_loss: 0.7472971134781837
[proc 1][Train](5000/10000) average loss: 0.71736817497015
[proc 1][Train](5000/10000) average regularization: 0.00011634749866789207
[proc 1] 5000 steps, total: 8.823, sample: 1.424, forward: 2.971, backward: 1.504, update: 2.170
[proc 0][Train](6000/10000) average pos_loss: 0.6837947135567665
[proc 0][Train](6000/10000) average neg_loss: 0.7420138458609581
[proc 0][Train](6000/10000) average loss: 0.7129042790532112
[proc 0][Train](6000/10000) average regularization: 0.00012101620953035308
[proc 0] 6000 steps, total: 8.691, sample: 1.338, forward: 3.028, backward: 2.283, update: 2.037
[proc 1][Train](6000/10000) average pos_loss: 0.6849329743981362
[proc 1][Train](6000/10000) average neg_loss: 0.7420022544264794
[proc 1][Train](6000/10000) average loss: 0.7134676151275635
[proc 1][Train](6000/10000) average regularization: 0.00012079503464337904
[proc 1] 6000 steps, total: 8.691, sample: 1.324, forward: 2.988, backward: 1.502, update: 2.139
[proc 0][Train](7000/10000) average pos_loss: 0.6823141739368439
[proc 0][Train](7000/10000) average neg_loss: 0.7381791967749596
[proc 0][Train](7000/10000) average loss: 0.7102466849684715
[proc 0][Train](7000/10000) average regularization: 0.00012447862239787355
[proc 0] 7000 steps, total: 8.652, sample: 1.346, forward: 3.020, backward: 2.269, update: 2.013
[proc 1][Train](7000/10000) average pos_loss: 0.681684402525425
[proc 1][Train](7000/10000) average neg_loss: 0.7379017078876495
[proc 1][Train](7000/10000) average loss: 0.7097930549383163
[proc 1][Train](7000/10000) average regularization: 0.00012439248180453434
[proc 1] 7000 steps, total: 8.652, sample: 1.330, forward: 2.971, backward: 1.517, update: 2.098
[proc 0][Train](8000/10000) average pos_loss: 0.6794074013829231
[proc 0][Train](8000/10000) average neg_loss: 0.7336476621627808
[proc 0][Train](8000/10000) average loss: 0.7065275324583054
[proc 0][Train](8000/10000) average regularization: 0.00012737317134451588
[proc 0] 8000 steps, total: 8.646, sample: 1.339, forward: 3.031, backward: 2.271, update: 2.000
[proc 1][Train](8000/10000) average pos_loss: 0.6784803512096405
[proc 1][Train](8000/10000) average neg_loss: 0.7341333184242248
[proc 1][Train](8000/10000) average loss: 0.7063068340420723
[proc 1][Train](8000/10000) average regularization: 0.00012726411713811104
[proc 1] 8000 steps, total: 8.646, sample: 1.351, forward: 3.020, backward: 2.214, update: 1.994
[proc 0][Train](9000/10000) average pos_loss: 0.6765934287309646
[proc 0][Train](9000/10000) average neg_loss: 0.7305292289853096
[proc 0][Train](9000/10000) average loss: 0.7035613293647767
[proc 0][Train](9000/10000) average regularization: 0.00012984103968483396
[proc 0] 9000 steps, total: 8.724, sample: 1.420, forward: 3.033, backward: 2.279, update: 1.987
[proc 1][Train](9000/10000) average pos_loss: 0.6767999286651611
[proc 1][Train](9000/10000) average neg_loss: 0.7314721182584762
[proc 1][Train](9000/10000) average loss: 0.7041360229849816
[proc 1][Train](9000/10000) average regularization: 0.00012982827157247812
[proc 1] 9000 steps, total: 8.724, sample: 1.426, forward: 3.029, backward: 2.277, update: 1.974
[proc 1][Train](10000/10000) average pos_loss: 0.674873432636261
[proc 1][Train](10000/10000) average neg_loss: 0.7274722442626953
[proc 1][Train](10000/10000) average loss: 0.7011728390455246
[proc 1][Train](10000/10000) average regularization: 0.00013194739952450619
[proc 1] 10000 steps, total: 8.723, sample: 1.352, forward: 3.046, backward: 2.384, update: 1.936
[proc 0][Train](10000/10000) average pos_loss: 0.6742028201818466
[proc 0][Train](10000/10000) average neg_loss: 0.7281021990180016
[proc 0][Train](10000/10000) average loss: 0.7011525096297264
[proc 0][Train](10000/10000) average regularization: 0.00013206228210765403
[proc 0] 10000 steps, total: 8.723, sample: 1.348, forward: 3.045, backward: 2.328, update: 1.969
proc 1 takes 102.727 seconds
proc 0 takes 102.909 seconds
Successfully xmh. training takes 106.42717790603638 seconds
