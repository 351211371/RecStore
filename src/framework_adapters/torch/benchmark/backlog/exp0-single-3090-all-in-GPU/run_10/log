Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=-1, format='built_in', gamma=16.0, gpu=[0], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=False, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=1, num_proc=1, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_Freebase_10', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Traceback (most recent call last):
  File "main.py", line 395, in <module>
    main()
  File "main.py", line 302, in main
    model = load_model(args, n_entities, n_relations)
  File "/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-ke/python/dglke/train_pytorch.py", line 98, in load_model
    model = KEModel(args, args.model_name, n_entities, n_relations,
  File "/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-ke/python/dglke/models/general_models.py", line 230, in __init__
    self.entity_emb = ExternalEmbedding(args, n_entities, entity_dim,
  File "/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-ke/python/dglke/models/pytorch/tensor_models.py", line 231, in __init__
    self.emb = th.empty(num, dim, dtype=th.float32, device=device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.23 GiB (GPU 0; 23.70 GiB total capacity; 0 bytes already allocated; 23.06 GiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
