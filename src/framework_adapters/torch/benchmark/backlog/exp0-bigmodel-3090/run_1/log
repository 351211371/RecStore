Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 2 parts
part 0 has 152363825 edges
part 1 has 152363825 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=100, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_Freebase_11', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 539.130 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.7165689877867699
[proc 0][Train](1000/10000) average neg_loss: 0.7931125761270523
[proc 0][Train](1000/10000) average loss: 0.7548407817482948
[proc 0][Train](1000/10000) average regularization: 8.457474246824859e-05
[proc 0] 1000 steps, total: 44.134, sample: 31.919, forward: 6.613, backward: 2.644, update: 2.951
[proc 1][Train](1000/10000) average pos_loss: 0.7157914886474609
[proc 1][Train](1000/10000) average neg_loss: 0.798117702305317
[proc 1][Train](1000/10000) average loss: 0.7569545955657959
[proc 1][Train](1000/10000) average regularization: 8.404981519561261e-05
[proc 1] 1000 steps, total: 43.547, sample: 31.181, forward: 6.461, backward: 2.734, update: 2.849
[proc 0][Train](2000/10000) average pos_loss: 0.7028054951429367
[proc 0][Train](2000/10000) average neg_loss: 0.7704098669886589
[proc 0][Train](2000/10000) average loss: 0.7366076819896697
[proc 0][Train](2000/10000) average regularization: 9.657648043503287e-05
[proc 0] 2000 steps, total: 11.137, sample: 2.223, forward: 3.436, backward: 2.667, update: 2.806
[proc 1][Train](2000/10000) average pos_loss: 0.7032565302252769
[proc 1][Train](2000/10000) average neg_loss: 0.7703278748393059
[proc 1][Train](2000/10000) average loss: 0.7367922022342682
[proc 1][Train](2000/10000) average regularization: 9.639450933173065e-05
[proc 1] 2000 steps, total: 11.137, sample: 2.167, forward: 3.088, backward: 2.712, update: 2.619
[proc 1][Train](3000/10000) average pos_loss: 0.6962253822684288
[proc 1][Train](3000/10000) average neg_loss: 0.7596465228796005
[proc 1][Train](3000/10000) average loss: 0.727935953438282
[proc 1][Train](3000/10000) average regularization: 0.00010524123976938427
[proc 1] 3000 steps, total: 10.687, sample: 2.109, forward: 3.094, backward: 2.703, update: 2.510
[proc 0][Train](3000/10000) average pos_loss: 0.6966661791205406
[proc 0][Train](3000/10000) average neg_loss: 0.7606295295953751
[proc 0][Train](3000/10000) average loss: 0.7286478545665741
[proc 0][Train](3000/10000) average regularization: 0.00010534365660714684
[proc 0] 3000 steps, total: 10.688, sample: 2.094, forward: 3.306, backward: 2.687, update: 2.593
[proc 0][Train](4000/10000) average pos_loss: 0.6924778078794479
[proc 0][Train](4000/10000) average neg_loss: 0.7538061279654503
[proc 0][Train](4000/10000) average loss: 0.7231419683098793
[proc 0][Train](4000/10000) average regularization: 0.0001122755895848968
[proc 0] 4000 steps, total: 11.055, sample: 2.184, forward: 3.468, backward: 2.684, update: 2.712
[proc 1][Train](4000/10000) average pos_loss: 0.6919340686202049
[proc 1][Train](4000/10000) average neg_loss: 0.7534736957550049
[proc 1][Train](4000/10000) average loss: 0.7227038806676864
[proc 1][Train](4000/10000) average regularization: 0.00011222083937173011
[proc 1] 4000 steps, total: 11.056, sample: 2.150, forward: 3.196, backward: 2.706, update: 2.537
[proc 0][Train](5000/10000) average pos_loss: 0.6885556041002273
[proc 0][Train](5000/10000) average neg_loss: 0.7474130774140358
[proc 0][Train](5000/10000) average loss: 0.7179843410849571
[proc 0][Train](5000/10000) average regularization: 0.00011802328204066726
[proc 0] 5000 steps, total: 11.153, sample: 2.341, forward: 3.458, backward: 2.657, update: 2.691
[proc 1][Train](5000/10000) average pos_loss: 0.6870714113712311
[proc 1][Train](5000/10000) average neg_loss: 0.7479335765838623
[proc 1][Train](5000/10000) average loss: 0.7175024943351745
[proc 1][Train](5000/10000) average regularization: 0.00011790272498910781
[proc 1] 5000 steps, total: 11.154, sample: 2.443, forward: 3.099, backward: 2.718, update: 2.484
[proc 0][Train](6000/10000) average pos_loss: 0.6843540472388268
[proc 0][Train](6000/10000) average neg_loss: 0.7425769235491753
[proc 0][Train](6000/10000) average loss: 0.7134654857516288
[proc 0][Train](6000/10000) average regularization: 0.00012261711110477335
[proc 0] 6000 steps, total: 10.829, sample: 2.171, forward: 3.456, backward: 2.666, update: 2.530
[proc 1][Train](6000/10000) average pos_loss: 0.6849518207907677
[proc 1][Train](6000/10000) average neg_loss: 0.7427936482429505
[proc 1][Train](6000/10000) average loss: 0.7138727330565453
[proc 1][Train](6000/10000) average regularization: 0.0001224755299917888
[proc 1] 6000 steps, total: 10.829, sample: 1.939, forward: 3.068, backward: 2.671, update: 2.327
[proc 0][Train](7000/10000) average pos_loss: 0.6818869336247444
[proc 0][Train](7000/10000) average neg_loss: 0.7379432857036591
[proc 0][Train](7000/10000) average loss: 0.7099151100516319
[proc 0][Train](7000/10000) average regularization: 0.00012658487826411145
[proc 0] 7000 steps, total: 10.563, sample: 2.124, forward: 3.250, backward: 2.675, update: 2.508
[proc 1][Train](7000/10000) average pos_loss: 0.6813992539048195
[proc 1][Train](7000/10000) average neg_loss: 0.7390186771154403
[proc 1][Train](7000/10000) average loss: 0.7102089668512345
[proc 1][Train](7000/10000) average regularization: 0.0001264546236998285
[proc 1] 7000 steps, total: 10.562, sample: 2.080, forward: 3.086, backward: 2.686, update: 2.331
[proc 0][Train](8000/10000) average pos_loss: 0.679442073404789
[proc 0][Train](8000/10000) average neg_loss: 0.7343720423579216
[proc 0][Train](8000/10000) average loss: 0.7069070585966111
[proc 0][Train](8000/10000) average regularization: 0.00012974420399405062
[proc 0] 8000 steps, total: 10.472, sample: 2.130, forward: 3.231, backward: 2.691, update: 2.414
[proc 1][Train](8000/10000) average pos_loss: 0.6789119166135787
[proc 1][Train](8000/10000) average neg_loss: 0.7345654885172844
[proc 1][Train](8000/10000) average loss: 0.7067387026548385
[proc 1][Train](8000/10000) average regularization: 0.0001296928881929489
[proc 1] 8000 steps, total: 10.472, sample: 2.080, forward: 3.063, backward: 2.702, update: 2.335
[proc 0][Train](9000/10000) average pos_loss: 0.6766594744324684
[proc 0][Train](9000/10000) average neg_loss: 0.7313038600683213
[proc 0][Train](9000/10000) average loss: 0.7039816675186157
[proc 0][Train](9000/10000) average regularization: 0.000132454478967702
[proc 0] 9000 steps, total: 10.289, sample: 2.064, forward: 3.178, backward: 2.660, update: 2.382
[proc 1][Train](9000/10000) average pos_loss: 0.6769268431663513
[proc 1][Train](9000/10000) average neg_loss: 0.7316775149703025
[proc 1][Train](9000/10000) average loss: 0.704302178800106
[proc 1][Train](9000/10000) average regularization: 0.00013246326852822676
[proc 1] 9000 steps, total: 10.289, sample: 2.180, forward: 3.071, backward: 2.661, update: 2.309
[proc 0][Train](10000/10000) average pos_loss: 0.6737950301766396
[proc 0][Train](10000/10000) average neg_loss: 0.7288254590034485
[proc 0][Train](10000/10000) average loss: 0.701310243844986
[proc 0][Train](10000/10000) average regularization: 0.000134824747001403
[proc 0] 10000 steps, total: 10.299, sample: 2.044, forward: 3.174, backward: 2.666, update: 2.406
proc 0 takes 140.620 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.6738635442256927
[proc 1][Train](10000/10000) average neg_loss: 0.7277167665362358
[proc 1][Train](10000/10000) average loss: 0.7007901545166969
[proc 1][Train](10000/10000) average regularization: 0.00013477320368110668
[proc 1] 10000 steps, total: 10.299, sample: 2.031, forward: 3.160, backward: 2.686, update: 2.337
proc 1 takes 140.032 seconds
Successfully xmh. training takes 143.93593001365662 seconds
