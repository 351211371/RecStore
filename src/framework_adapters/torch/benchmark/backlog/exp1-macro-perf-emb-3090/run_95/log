perf_emb.py:126: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("Before init DistEmbedding")
WARNING [perf_emb.py:126] Before init DistEmbedding
perf_emb.py:129: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("After init DistEmbedding")
WARNING [perf_emb.py:129] After init DistEmbedding
========== Running Perf with routine <function routine_local_cache_helper at 0x7f71008e8ee0>==========
Worker 0 pid=15984
Worker 1 pid=15985
Worker 2 pid=15986
Worker 3 pid=15987
Worker 4 pid=15994
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 5
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 4
INFO [distributed_c10d.py:466] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
Step99:rank1, time: 26.710, per_step: 0.267100
Step99:rank5, time: 26.683, per_step: 0.266834
Step99:rank2, time: 26.899, per_step: 0.268992
Step99:rank3, time: 26.701, per_step: 0.267012
Step99:rank4, time: 26.703, per_step: 0.267032
Step99:rank0, time: 26.856, per_step: 0.268559
Step199:rank1, time: 24.559, per_step: 0.243159
Step199:rank2, time: 24.547, per_step: 0.243041
Step199:rank3, time: 24.545, per_step: 0.243017
Step199:rank5, time: 24.566, per_step: 0.243231
Step199:rank4, time: 24.572, per_step: 0.243286
Step199:rank0, time: 24.572, per_step: 0.243291
Step299:rank2, time: 25.450, per_step: 0.251976
Step299:rank3, time: 25.468, per_step: 0.252157
Step299:rank1, time: 25.480, per_step: 0.252276
Step299:rank5, time: 25.464, per_step: 0.252120
Step299:rank4, time: 25.456, per_step: 0.252042
Step299:rank0, time: 25.475, per_step: 0.252228
Step399:rank5, time: 25.776, per_step: 0.255208
Step399:rank2, time: 25.812, per_step: 0.255563
Step399:rank3, time: 25.791, per_step: 0.255361
Step399:rank1, time: 25.792, per_step: 0.255367
Step399:rank4, time: 25.780, per_step: 0.255247
Step399:rank0, time: 25.791, per_step: 0.255360
Step499:rank1, time: 24.899, per_step: 0.246526
Step499:rank4, time: 24.902, per_step: 0.246550
Step499:rank3, time: 24.907, per_step: 0.246603
Step499:rank2, time: 24.919, per_step: 0.246724
Step499:rank5, time: 24.947, per_step: 0.246998
Step499:rank0, time: 24.878, per_step: 0.246318
Worker 5 pid=15995
Successfully xmh
