perf_emb.py:126: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("Before init DistEmbedding")
WARNING [perf_emb.py:126] Before init DistEmbedding
perf_emb.py:129: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("After init DistEmbedding")
WARNING [perf_emb.py:129] After init DistEmbedding
========== Running Perf with routine <function routine_local_cache_helper at 0x7f8791499ee0>==========
Worker 0 pid=44790
Worker 1 pid=44791
Worker 2 pid=44792
Worker 3 pid=44793
Worker 4 pid=44794
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 5
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 4
INFO [distributed_c10d.py:466] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
Step99:rank5, time: 17.423, per_step: 0.174228
Step99:rank2, time: 17.452, per_step: 0.174525
Step99:rank1, time: 17.227, per_step: 0.172274
Step99:rank4, time: 19.282, per_step: 0.192818
Step99:rank3, time: 17.405, per_step: 0.174053
Step99:rank0, time: 17.259, per_step: 0.172591
Step199:rank2, time: 16.101, per_step: 0.159416
Step199:rank1, time: 16.102, per_step: 0.159426
Step199:rank5, time: 16.119, per_step: 0.159590
Step199:rank3, time: 16.107, per_step: 0.159471
Step199:rank4, time: 16.131, per_step: 0.159709
Step199:rank0, time: 16.104, per_step: 0.159448
Step299:rank2, time: 15.712, per_step: 0.155561
Step299:rank1, time: 15.722, per_step: 0.155667
Step299:rank3, time: 15.709, per_step: 0.155534
Step299:rank4, time: 15.696, per_step: 0.155404
Step299:rank5, time: 15.729, per_step: 0.155732
Step299:rank0, time: 15.687, per_step: 0.155320
Step399:rank1, time: 15.561, per_step: 0.154066
Step399:rank5, time: 15.555, per_step: 0.154012
Step399:rank2, time: 15.589, per_step: 0.154351
Step399:rank4, time: 15.568, per_step: 0.154135
Step399:rank3, time: 15.574, per_step: 0.154202
Step399:rank0, time: 15.558, per_step: 0.154043
Step499:rank3, time: 16.089, per_step: 0.159294
Step499:rank5, time: 16.107, per_step: 0.159474
Step499:rank2, time: 16.098, per_step: 0.159385
Step499:rank1, time: 16.121, per_step: 0.159615
Step499:rank4, time: 16.105, per_step: 0.159451
Step499:rank0, time: 16.142, per_step: 0.159826
Worker 5 pid=44795
Successfully xmh
