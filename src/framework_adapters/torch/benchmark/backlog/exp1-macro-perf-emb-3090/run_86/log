perf_emb.py:126: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("Before init DistEmbedding")
WARNING [perf_emb.py:126] Before init DistEmbedding
perf_emb.py:129: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("After init DistEmbedding")
WARNING [perf_emb.py:129] After init DistEmbedding
========== Running Perf with routine <function routine_local_cache_helper at 0x7f1640506ee0>==========
Worker 0 pid=35775
Worker 1 pid=35776
Worker 2 pid=35777
Worker 3 pid=35778
Worker 4 pid=35785
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 4
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 5
INFO [distributed_c10d.py:466] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
Step99:rank2, time: 17.057, per_step: 0.170565
Step99:rank3, time: 17.565, per_step: 0.175654
Step99:rank4, time: 17.140, per_step: 0.171397
Step99:rank1, time: 17.070, per_step: 0.170704
Step99:rank5, time: 17.078, per_step: 0.170779
Step99:rank0, time: 17.082, per_step: 0.170824
Step199:rank2, time: 15.749, per_step: 0.155926
Step199:rank1, time: 15.756, per_step: 0.156003
Step199:rank3, time: 15.767, per_step: 0.156105
Step199:rank5, time: 15.762, per_step: 0.156061
Step199:rank4, time: 15.795, per_step: 0.156384
Step199:rank0, time: 15.818, per_step: 0.156611
Step299:rank4, time: 16.085, per_step: 0.159254
Step299:rank5, time: 16.110, per_step: 0.159506
Step299:rank3, time: 16.125, per_step: 0.159649
Step299:rank1, time: 16.135, per_step: 0.159748
Step299:rank2, time: 16.163, per_step: 0.160025
Step299:rank0, time: 16.104, per_step: 0.159444
Step399:rank2, time: 16.465, per_step: 0.163021
Step399:rank4, time: 16.493, per_step: 0.163296
Step399:rank5, time: 16.493, per_step: 0.163302
Step399:rank1, time: 16.490, per_step: 0.163262
Step399:rank3, time: 16.501, per_step: 0.163378
Step399:rank0, time: 16.500, per_step: 0.163364
Step499:rank4, time: 16.167, per_step: 0.160068
Step499:rank3, time: 16.160, per_step: 0.160000
Step499:rank1, time: 16.166, per_step: 0.160063
Step499:rank5, time: 16.177, per_step: 0.160171
Step499:rank2, time: 16.187, per_step: 0.160267
Step499:rank0, time: 16.172, per_step: 0.160118
Worker 5 pid=35786
Successfully xmh
