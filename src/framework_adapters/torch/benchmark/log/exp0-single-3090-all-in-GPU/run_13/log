Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 4 parts
part 0 has 76181913 edges
part 1 has 76181913 edges
part 2 has 76181913 edges
part 3 has 76181911 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2, 3], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=4, num_proc=4, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_Freebase_13', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 725.442 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 3][Train](1000/10000) average pos_loss: 0.6696652408242225
[proc 3][Train](1000/10000) average neg_loss: 0.6894007480144501
[proc 3][Train](1000/10000) average loss: 0.6795329940915108
[proc 3][Train](1000/10000) average regularization: 7.994026539108745e-06
[proc 3] 1000 steps, total: 38.384, sample: 16.710, forward: 12.669, backward: 2.851, update: 6.146
[proc 0][Train](1000/10000) average pos_loss: 0.6703860315084458
[proc 0][Train](1000/10000) average neg_loss: 0.693259803056717
[proc 0][Train](1000/10000) average loss: 0.6818229186534882
[proc 0][Train](1000/10000) average regularization: 7.947216647153254e-06
[proc 0] 1000 steps, total: 40.093, sample: 17.386, forward: 12.443, backward: 2.750, update: 6.444
[proc 1][Train](1000/10000) average pos_loss: 0.6753204309940338
[proc 1][Train](1000/10000) average neg_loss: 0.6933927516043186
[proc 1][Train](1000/10000) average loss: 0.6843565913438797
[proc 1][Train](1000/10000) average regularization: 7.928706761049398e-06
[proc 1] 1000 steps, total: 39.509, sample: 16.670, forward: 13.206, backward: 2.932, update: 6.460
[proc 2][Train](1000/10000) average pos_loss: 0.6685988880097866
[proc 2][Train](1000/10000) average neg_loss: 0.6909131347537041
[proc 2][Train](1000/10000) average loss: 0.679756011068821
[proc 2][Train](1000/10000) average regularization: 7.961950586377498e-06
[proc 2] 1000 steps, total: 38.972, sample: 16.544, forward: 12.863, backward: 2.758, update: 6.339
[proc 2][Train](2000/10000) average pos_loss: 0.6857475605607033
[proc 2][Train](2000/10000) average neg_loss: 0.6815907539129257
[proc 2][Train](2000/10000) average loss: 0.6836691560745239
[proc 2][Train](2000/10000) average regularization: 7.279365604972554e-06
[proc 2] 2000 steps, total: 19.726, sample: 2.595, forward: 7.739, backward: 2.813, update: 6.571
[proc 0][Train](2000/10000) average pos_loss: 0.6858247417807579
[proc 0][Train](2000/10000) average neg_loss: 0.6827821699380875
[proc 0][Train](2000/10000) average loss: 0.6843034570217132
[proc 0][Train](2000/10000) average regularization: 7.304837584797497e-06
[proc 0] 2000 steps, total: 19.727, sample: 2.632, forward: 7.011, backward: 2.904, update: 6.295
[proc 3][Train](2000/10000) average pos_loss: 0.68551624751091
[proc 3][Train](2000/10000) average neg_loss: 0.6826938416957855
[proc 3][Train](2000/10000) average loss: 0.6841050437092782
[proc 3][Train](2000/10000) average regularization: 7.303395481358166e-06
[proc 3] 2000 steps, total: 19.728, sample: 2.636, forward: 7.536, backward: 2.760, update: 6.168
[proc 1][Train](2000/10000) average pos_loss: 0.6854552783370018
[proc 1][Train](2000/10000) average neg_loss: 0.6834854966998101
[proc 1][Train](2000/10000) average loss: 0.6844703878164291
[proc 1][Train](2000/10000) average regularization: 7.291843479379168e-06
[proc 1] 2000 steps, total: 19.727, sample: 2.426, forward: 7.691, backward: 2.808, update: 6.525
[proc 1][Train](3000/10000) average pos_loss: 0.6941019951105117
[proc 1][Train](3000/10000) average neg_loss: 0.6758520176410675
[proc 1][Train](3000/10000) average loss: 0.6849770067930222
[proc 1][Train](3000/10000) average regularization: 6.435844698444271e-06
[proc 1] 3000 steps, total: 18.202, sample: 2.436, forward: 6.399, backward: 2.881, update: 6.475
[proc 2][Train](3000/10000) average pos_loss: 0.6944231885075569
[proc 2][Train](3000/10000) average neg_loss: 0.6761240387558937
[proc 2][Train](3000/10000) average loss: 0.685273613512516
[proc 2][Train](3000/10000) average regularization: 6.4368639582426115e-06
[proc 2] 3000 steps, total: 18.204, sample: 2.396, forward: 6.269, backward: 2.758, update: 6.672
[proc 0][Train](3000/10000) average pos_loss: 0.6938557714819908
[proc 0][Train](3000/10000) average neg_loss: 0.676873797416687
[proc 0][Train](3000/10000) average loss: 0.6853647851347924
[proc 0][Train](3000/10000) average regularization: 6.441446418648411e-06
[proc 0] 3000 steps, total: 18.203, sample: 2.428, forward: 5.895, backward: 2.767, update: 6.320
[proc 3][Train](3000/10000) average pos_loss: 0.6948628404736519
[proc 3][Train](3000/10000) average neg_loss: 0.677379534304142
[proc 3][Train](3000/10000) average loss: 0.6861211872696876
[proc 3][Train](3000/10000) average regularization: 6.4381164688711576e-06
[proc 3] 3000 steps, total: 18.203, sample: 2.504, forward: 6.457, backward: 2.728, update: 6.087
[proc 2][Train](4000/10000) average pos_loss: 0.701330560028553
[proc 2][Train](4000/10000) average neg_loss: 0.6689359105229378
[proc 2][Train](4000/10000) average loss: 0.6851332340836525
[proc 2][Train](4000/10000) average regularization: 6.339186427339882e-06
[proc 2] 4000 steps, total: 17.608, sample: 2.432, forward: 5.869, backward: 2.766, update: 6.532
[proc 0][Train](4000/10000) average pos_loss: 0.7005627849102021
[proc 0][Train](4000/10000) average neg_loss: 0.6700296899676323
[proc 0][Train](4000/10000) average loss: 0.6852962382435799
[proc 0][Train](4000/10000) average regularization: 6.334466844236886e-06
[proc 0] 4000 steps, total: 17.608, sample: 2.398, forward: 5.495, backward: 2.799, update: 6.219
[proc 3][Train](4000/10000) average pos_loss: 0.7002274756431579
[proc 3][Train](4000/10000) average neg_loss: 0.6695406854748726
[proc 3][Train](4000/10000) average loss: 0.6848840804696084
[proc 3][Train](4000/10000) average regularization: 6.340616005218181e-06
[proc 3] 4000 steps, total: 17.608, sample: 2.380, forward: 6.025, backward: 2.892, update: 5.973
[proc 1][Train](4000/10000) average pos_loss: 0.7012048460841179
[proc 1][Train](4000/10000) average neg_loss: 0.6704396802186966
[proc 1][Train](4000/10000) average loss: 0.6858222630023957
[proc 1][Train](4000/10000) average regularization: 6.337724792501831e-06
[proc 1] 4000 steps, total: 17.609, sample: 2.417, forward: 5.984, backward: 2.740, update: 6.419
[proc 2][Train](5000/10000) average pos_loss: 0.7060344062447548
[proc 2][Train](5000/10000) average neg_loss: 0.6621796096563339
[proc 2][Train](5000/10000) average loss: 0.6841070078611374
[proc 2][Train](5000/10000) average regularization: 6.431876081478549e-06
[proc 2] 5000 steps, total: 17.599, sample: 2.657, forward: 5.685, backward: 2.778, update: 6.472
[proc 3][Train](5000/10000) average pos_loss: 0.7044821516871452
[proc 3][Train](5000/10000) average neg_loss: 0.662129200398922
[proc 3][Train](5000/10000) average loss: 0.6833056768774987
[proc 3][Train](5000/10000) average regularization: 6.433182769796985e-06
[proc 3] 5000 steps, total: 17.599, sample: 2.527, forward: 5.825, backward: 2.760, update: 5.926
[proc 1][Train](5000/10000) average pos_loss: 0.7056680911183357
[proc 1][Train](5000/10000) average neg_loss: 0.6614546473026276
[proc 1][Train](5000/10000) average loss: 0.6835613686442376
[proc 1][Train](5000/10000) average regularization: 6.436273854433239e-06
[proc 1] 5000 steps, total: 17.599, sample: 2.560, forward: 5.835, backward: 2.746, update: 6.418
[proc 0][Train](5000/10000) average pos_loss: 0.7054729816913605
[proc 0][Train](5000/10000) average neg_loss: 0.6617745348215103
[proc 0][Train](5000/10000) average loss: 0.683623758494854
[proc 0][Train](5000/10000) average regularization: 6.430628848647757e-06
[proc 0] 5000 steps, total: 17.600, sample: 2.614, forward: 5.319, backward: 2.770, update: 6.178
[proc 2][Train](6000/10000) average pos_loss: 0.707710634291172
[proc 2][Train](6000/10000) average neg_loss: 0.6547082736492157
[proc 2][Train](6000/10000) average loss: 0.681209453523159
[proc 2][Train](6000/10000) average regularization: 6.548555881181528e-06
[proc 2] 6000 steps, total: 17.239, sample: 2.366, forward: 5.573, backward: 2.762, update: 6.531
[proc 0][Train](6000/10000) average pos_loss: 0.7088807212114334
[proc 0][Train](6000/10000) average neg_loss: 0.6553046455979348
[proc 0][Train](6000/10000) average loss: 0.6820926831960679
[proc 0][Train](6000/10000) average regularization: 6.543802239320939e-06
[proc 0] 6000 steps, total: 17.239, sample: 2.292, forward: 5.229, backward: 2.915, update: 6.079
[proc 3][Train](6000/10000) average pos_loss: 0.7085883826613426
[proc 3][Train](6000/10000) average neg_loss: 0.6543820263147354
[proc 3][Train](6000/10000) average loss: 0.6814852049350738
[proc 3][Train](6000/10000) average regularization: 6.5451789523649496e-06
[proc 3] 6000 steps, total: 17.240, sample: 2.404, forward: 5.792, backward: 2.779, update: 5.847
[proc 1][Train](6000/10000) average pos_loss: 0.7088797174096108
[proc 1][Train](6000/10000) average neg_loss: 0.6541237290501595
[proc 1][Train](6000/10000) average loss: 0.6815017226934433
[proc 1][Train](6000/10000) average regularization: 6.548649202613888e-06
[proc 1] 6000 steps, total: 17.240, sample: 2.351, forward: 5.695, backward: 2.727, update: 6.388
[proc 1][Train](7000/10000) average pos_loss: 0.711228895187378
[proc 1][Train](7000/10000) average neg_loss: 0.6467824897766113
[proc 1][Train](7000/10000) average loss: 0.6790056928992272
[proc 1][Train](7000/10000) average regularization: 6.665295181392139e-06
[proc 1] 7000 steps, total: 17.242, sample: 2.400, forward: 5.660, backward: 2.846, update: 6.326
[proc 2][Train](7000/10000) average pos_loss: 0.7105054785013198
[proc 2][Train](7000/10000) average neg_loss: 0.6466388034820557
[proc 2][Train](7000/10000) average loss: 0.6785721417069435
[proc 2][Train](7000/10000) average regularization: 6.670145717635024e-06
[proc 2] 7000 steps, total: 17.243, sample: 2.410, forward: 5.553, backward: 2.759, update: 6.427
[proc 0][Train](7000/10000) average pos_loss: 0.7096979457736016
[proc 0][Train](7000/10000) average neg_loss: 0.6477141098380089
[proc 0][Train](7000/10000) average loss: 0.6787060278058052
[proc 0][Train](7000/10000) average regularization: 6.666787611266045e-06
[proc 0] 7000 steps, total: 17.243, sample: 2.319, forward: 5.273, backward: 2.848, update: 6.123
[proc 3][Train](7000/10000) average pos_loss: 0.7093043330907821
[proc 3][Train](7000/10000) average neg_loss: 0.6465174486041069
[proc 3][Train](7000/10000) average loss: 0.6779108912348747
[proc 3][Train](7000/10000) average regularization: 6.669070645784814e-06
[proc 3] 7000 steps, total: 17.243, sample: 2.459, forward: 5.782, backward: 2.752, update: 5.877
[proc 2][Train](8000/10000) average pos_loss: 0.7113735044598579
[proc 2][Train](8000/10000) average neg_loss: 0.6382505466938019
[proc 2][Train](8000/10000) average loss: 0.6748120268583297
[proc 2][Train](8000/10000) average regularization: 6.7934645098830515e-06
[proc 2] 8000 steps, total: 17.200, sample: 2.381, forward: 5.575, backward: 2.767, update: 6.469
[proc 0][Train](8000/10000) average pos_loss: 0.7096923019886017
[proc 0][Train](8000/10000) average neg_loss: 0.639367943584919
[proc 0][Train](8000/10000) average loss: 0.6745301245450973
[proc 0][Train](8000/10000) average regularization: 6.787121424622455e-06
[proc 0] 8000 steps, total: 17.201, sample: 2.221, forward: 5.222, backward: 2.757, update: 5.966
[proc 3][Train](8000/10000) average pos_loss: 0.7104134244322777
[proc 3][Train](8000/10000) average neg_loss: 0.6391875744462013
[proc 3][Train](8000/10000) average loss: 0.6748004993796348
[proc 3][Train](8000/10000) average regularization: 6.785810876408505e-06
[proc 3] 8000 steps, total: 17.201, sample: 2.356, forward: 5.700, backward: 2.811, update: 5.932
[proc 1][Train](8000/10000) average pos_loss: 0.7095453664064407
[proc 1][Train](8000/10000) average neg_loss: 0.6393165173530578
[proc 1][Train](8000/10000) average loss: 0.6744309415817261
[proc 1][Train](8000/10000) average regularization: 6.787180087485467e-06
[proc 1] 8000 steps, total: 17.202, sample: 2.304, forward: 5.615, backward: 2.674, update: 6.363
[proc 1][Train](9000/10000) average pos_loss: 0.7108040878176689
[proc 1][Train](9000/10000) average neg_loss: 0.6321899571418762
[proc 1][Train](9000/10000) average loss: 0.6714970222711563
[proc 1][Train](9000/10000) average regularization: 6.90568056097618e-06
[proc 1] 9000 steps, total: 17.158, sample: 2.540, forward: 5.631, backward: 2.733, update: 6.244
[proc 2][Train](9000/10000) average pos_loss: 0.7101913309693336
[proc 2][Train](9000/10000) average neg_loss: 0.6310173993110657
[proc 2][Train](9000/10000) average loss: 0.6706043661236764
[proc 2][Train](9000/10000) average regularization: 6.908590585226193e-06
[proc 2] 9000 steps, total: 17.159, sample: 2.494, forward: 5.551, backward: 2.745, update: 6.313
[proc 0][Train](9000/10000) average pos_loss: 0.7105137837529183
[proc 0][Train](9000/10000) average neg_loss: 0.631181509912014
[proc 0][Train](9000/10000) average loss: 0.6708476467132568
[proc 0][Train](9000/10000) average regularization: 6.910676955612871e-06
[proc 0] 9000 steps, total: 17.158, sample: 2.428, forward: 5.266, backward: 2.841, update: 6.013
[proc 3][Train](9000/10000) average pos_loss: 0.7110725863575935
[proc 3][Train](9000/10000) average neg_loss: 0.6320041499733925
[proc 3][Train](9000/10000) average loss: 0.6715383679866791
[proc 3][Train](9000/10000) average regularization: 6.90578285320953e-06
[proc 3] 9000 steps, total: 17.159, sample: 2.494, forward: 5.715, backward: 2.753, update: 5.832
[proc 2][Train](10000/10000) average pos_loss: 0.7087897918820382
[proc 2][Train](10000/10000) average neg_loss: 0.6236334393024444
[proc 2][Train](10000/10000) average loss: 0.6662116162180901
[proc 2][Train](10000/10000) average regularization: 7.027802101674751e-06
[proc 2] 10000 steps, total: 17.214, sample: 2.522, forward: 5.591, backward: 2.753, update: 6.340
proc 2 takes 198.166 seconds
[proc 3][Train](10000/10000) average pos_loss: 0.7083728604316711
[proc 3][Train](10000/10000) average neg_loss: 0.6234255807101726
[proc 3][Train](10000/10000) average loss: 0.6658992203474045
[proc 3][Train](10000/10000) average regularization: 7.02390168362399e-06
[proc 3] 10000 steps, total: 17.214, sample: 2.382, forward: 5.712, backward: 2.778, update: 5.810
proc 3 takes 197.579 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.7088884575366974
[proc 1][Train](10000/10000) average neg_loss: 0.6235501969754695
[proc 1][Train](10000/10000) average loss: 0.6662193285226822
[proc 1][Train](10000/10000) average regularization: 7.0221438145381395e-06
[proc 1] 10000 steps, total: 17.215, sample: 2.324, forward: 5.569, backward: 2.755, update: 6.306
proc 1 takes 198.703 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.7084781278371811
[proc 0][Train](10000/10000) average neg_loss: 0.6234724529087543
[proc 0][Train](10000/10000) average loss: 0.6659752911925316
[proc 0][Train](10000/10000) average regularization: 7.0227611035988954e-06
[proc 0] 10000 steps, total: 17.215, sample: 2.301, forward: 5.298, backward: 2.905, update: 5.917
proc 0 takes 199.287 seconds
Successfully xmh. training takes 208.06733798980713 seconds
