WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240202 13:53:05.126662  6088 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_53', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [6088 sampler.py:454] Start PreSampling
WARNING [6088 sampler.py:532] Before construct renumbering_dict
WARNING [6088 sampler.py:555] PreSampling done
W20240202 13:53:10.536586  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240202 13:53:10.536834  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240202 13:53:10.536890  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240202 13:53:10.536938  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240202 13:53:10.536985  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240202 13:53:10.537034  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240202 13:53:10.537070  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240202 13:53:10.537118  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240202 13:53:10.537168  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240202 13:53:10.537205  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240202 13:53:10.537257  6088 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240202 13:53:10.537297  6088 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240202 13:53:10.537333  6088 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240202 13:53:10.537492  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240202 13:53:10.537550  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240202 13:53:10.537587  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240202 13:53:10.537636  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240202 13:53:10.537683  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240202 13:53:10.537724  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240202 13:53:10.537789  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240202 13:53:10.537837  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240202 13:53:10.537876  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240202 13:53:10.537922  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240202 13:53:10.537963  6088 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240202 13:53:10.537997  6088 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240202 13:53:10.538033  6088 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240202 13:53:10.538110  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240202 13:53:10.538149  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240202 13:53:10.538184  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240202 13:53:10.538234  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240202 13:53:10.538275  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240202 13:53:10.538311  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240202 13:53:10.538357  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240202 13:53:10.538395  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240202 13:53:10.538445  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240202 13:53:10.538501  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240202 13:53:10.538547  6088 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240202 13:53:10.538580  6088 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240202 13:53:10.538622  6088 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240202 13:53:10.538694  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240202 13:53:10.538733  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240202 13:53:10.538784  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240202 13:53:10.538823  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240202 13:53:10.538869  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240202 13:53:10.538921  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240202 13:53:10.538972  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240202 13:53:10.539009  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240202 13:53:10.539057  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240202 13:53:10.539095  6088 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240202 13:53:10.539131  6088 IPCTensor.h:369] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240202 13:53:10.539161  6088 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240202 13:53:10.539196  6088 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240202 13:53:10.827395  6088 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240202 13:53:10.926828  6088 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=9703, num_edges=161860,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11374, num_edges=168961,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=10715, num_edges=190828,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=11184, num_edges=240046,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9703 N 161860 E
MertisPartition: part 1 has 11374 N 168961 E
MertisPartition: part 2 has 10715 N 190828 E
MertisPartition: part 3 has 11184 N 240046 E
Rank0: cached key size 186
Rank1: cached key size 186
Rank2: cached key size 186
Rank3: cached key size 186
Before renumbering graph:  {'_ID': tensor([   6,   10,   11,  ..., 5824, 6189, 2559]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 2])}
After renumbering graph:  {'_ID': tensor([ 954, 1106, 1144,  ..., 4947, 4877, 9073]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 2])}
part_g: DGLGraph(num_nodes=9703, num_edges=161860,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9703, num_edges=161860,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 5.910 seconds
[Rank1] pid = 6512
[Rank2] pid = 6547
INFO [6088 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [6547 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [6641 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [6512 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [6547 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [6641 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [6512 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [6088 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240202 13:53:12.965137  6643 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_3 [747, 400]; dev=3; size=1.14 MB
W20240202 13:53:12.965189  6513 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240202 13:53:12.965909  6577 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [747, 400]; dev=2; size=1.14 MB
W20240202 13:53:12.966012  6642 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240202 13:53:12.993372  6513 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x100014878000 7.629 MB
W20240202 13:53:12.993396  6643 IPCTensor.h:369] NewIPCTensor: input_keys_3 [1000000]0x10001501b000 7.629 MB
W20240202 13:53:12.993604  6643 IPCTensor.h:369] NewIPCTensor: input_keys_neg_3 [1000000]0x1000157be000 7.629 MB
W20240202 13:53:12.993619  6513 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x100015f61000 7.629 MB
W20240202 13:53:12.993688  6513 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x100016704000 1.49 GB
W20240202 13:53:12.993697  6643 IPCTensor.h:369] NewIPCTensor: backward_grads_3 [1000000, 400]0x100075ce7000 1.49 GB
W20240202 13:53:12.993772  6643 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1000d52ca000 1.49 GB
W20240202 13:53:12.993779  6513 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1001348ad000 1.49 GB
W20240202 13:53:12.993850  6643 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240202 13:53:12.993861  6513 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240202 13:53:12.997525  6643 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240202 13:53:12.997570  6513 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240202 13:53:13.001185  6642 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x100193e9c000 7.629 MB
W20240202 13:53:13.001235  6577 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x10019463f000 7.629 MB
W20240202 13:53:13.001380  6642 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x100194de2000 7.629 MB
W20240202 13:53:13.001401  6577 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x100195585000 7.629 MB
W20240202 13:53:13.001456  6642 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x100195d28000 1.49 GB
W20240202 13:53:13.001482  6577 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x1001f530b000 1.49 GB
W20240202 13:53:13.001510  6642 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1002548ee000 1.49 GB
W20240202 13:53:13.001552  6577 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1002b3ed1000 1.49 GB
W20240202 13:53:13.001565  6642 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240202 13:53:13.001628  6577 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240202 13:53:13.006529  6642 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240202 13:53:13.006570  6577 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [6641 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [6547 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [6512 DistTensor.py:59] The tensor name already exists in the kvstore
[Rank3] pid = 6641
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494), (1494, 2241), (2241, 2988)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [6088 DistTensor.py:59] The tensor name already exists in the kvstore
I20240202 13:53:15.028491  6642 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240202 13:53:15.028858  6513 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240202 13:53:15.029163  6577 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240202 13:53:15.029278  6643 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240202 13:53:15.030944  6642 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 0.01,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240202 13:53:15.031064  6642 grad_base.h:184] Init GradProcessingBase done
I20240202 13:53:15.035348  6642 grad_async_v2.h:42] Use main thread to update emb.
W20240202 13:53:15.035384  6642 kg_controller.h:78] after init GradAsyncProcessingV2
I20240202 13:53:15.035392  6642 kg_controller.h:84] Construct KGCacheController done
E20240202 13:53:15.464641  6513 recstore.cc:66] init folly done
E20240202 13:53:15.464672  6643 recstore.cc:66] init folly done
E20240202 13:53:15.464818  6642 recstore.cc:66] init folly done
E20240202 13:53:15.464818  6577 recstore.cc:66] init folly done
I20240202 13:53:15.465802  6642 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240202 13:53:15.803882  7347 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
E20240202 13:53:15.804275  7347 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
I20240202 13:53:15.844440  6642 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240202 13:53:15.854537  6577 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240202 13:53:15.857789  6513 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240202 13:53:15.862974  6643 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240202 13:53:17.270501  6642 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
W20240202 13:53:17.298677  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=1, pq.top=1
W20240202 13:53:17.305163  7347 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
E20240202 13:53:17.330544  6642 grad_async_v2.h:404] Stalled in ProcessBackward: rank=2, step_no=1, sample_step_cpp_seen_[rank]=0
E20240202 13:53:18.270072  7360 parallel_pq_v2.h:79] insert failed, size(hashtable)=7229
W20240202 13:53:18.312124  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=24, pq.top=24
W20240202 13:53:18.313654  7347 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
E20240202 13:53:19.270054  7368 parallel_pq_v2.h:79] insert failed, size(hashtable)=13034
W20240202 13:53:19.313719  7347 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
W20240202 13:53:19.326954  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=50, pq.top=50
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.289 ms                  | 22.929 ms                 |
| Forward                   | 4.903 ms                  | 10.315 ms                 |
| Backward                  | 4.241 ms                  | 10.541 ms                 |
| Optimize                  | 2.088 ms                  | 3.495 ms                  |
| BarrierTimeBeforeRank0    | 347.141 us                | 11.931 ms                 |
| AfterBackward             | 22.351 ms                 | 39.620 ms                 |
| BlockToStepN              | 418.889 us                | 3.062 ms                  |
| OneStep                   | 38.623 ms                 | 68.235 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240202 13:53:20.270061  7358 parallel_pq_v2.h:79] insert failed, size(hashtable)=5545
W20240202 13:53:20.313890  7347 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
W20240202 13:53:20.338281  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=75, pq.top=75
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 302.740 us                | 2.949 ms                  |
| ProcessBack:Shuffle       | 2.593 ms                  | 3.793 ms                  |
| ProcessBack:UpdateCache   | 2.773 ms                  | 5.210 ms                  |
| ProcessBack:UpsertPq      | 15.137 ms                 | 21.410 ms                 |
| ProcessOneStep            | 22.360 ms                 | 39.591 ms                 |
| BlockToStepN              | 394.431 us                | 2.441 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240202 13:53:21.272115  7347 parallel_pq_v2.h:79] insert failed, size(hashtable)=43
W20240202 13:53:21.321647  7347 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
W20240202 13:53:21.338052  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=99, pq.top=99
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 5.522, sample: 0.321, forward: 1.036, backward: 0.663, update: 0.159
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 5.514, sample: 0.373, forward: 1.100, backward: 0.672, update: 0.172
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 5.519, sample: 0.318, forward: 1.058, backward: 0.682, update: 0.163
train_sampler.Prefill()
-------Step 0-------
tensor([ 4126,  9225, 13145,  5632,    11,  3624,  6427,    57,   108,  7092]) tensor([ 1144, 10292,  3001,  8848,  3684, 10273,  4083,  4114,  4702, 14421])
-------Step 1-------
tensor([ 4126,  9225, 13145,  5632,    11,  3624,  6427,    57,   108,  7092]) tensor([ 4675, 10568,  7078,  9203,  8309, 12693, 12157,  2836,  6669,  6333])
-------Step 2-------
tensor([ 9025, 11906, 10785,  5567,   110,  2055,    21,  5357,  4755,  2176]) tensor([ 7119,  2325,  4705, 10372, 11293,    66, 13231, 10060, 11884,  7828])
-------Step 3-------
tensor([ 9025, 11906, 10785,  5567,   110,  2055,    21,  5357,  4755,  2176]) tensor([ 6646,  1277,  9448,  3214,  5573,  2327, 13266,  2580,  8781, 12166])
-------Step 4-------
tensor([13782,  5059,  7738,  2892,  8287,  7409, 10111,  9449,    59, 12077]) tensor([  569,  7023,  8015, 10483,  2885,    33,  2012,  4439, 12556,  5019])
-------Step 5-------
tensor([13782,  5059,  7738,  2892,  8287,  7409, 10111,  9449,    59, 12077]) tensor([ 7740,  4348,  4056, 14018, 12301, 11719,  7693,  7519,  2866, 13648])
-------Step 6-------
tensor([ 1506,  2960,  3173, 14398,   111, 11421, 13481,  5501,   154,  3259]) tensor([ 3916, 14897, 14048,  2793,  6886, 13570,  2892,  4554, 14775, 10999])
-------Step 7-------
tensor([ 1506,  2960,  3173, 14398,   111, 11421, 13481,  5501,   154,  3259]) tensor([12267,  7240, 11692,  4624,  1463,   900,  2465,  2460,  6107,  3375])
-------Step 8-------
tensor([    4,  6690,   140,  5948,  6365, 11671, 13319,  7491,    81,  3342]) tensor([ 8111,  3438,  1528, 10657, 10612, 14111,  1746,  8890, 10275,  8945])
-------Step 9-------
tensor([    4,  6690,   140,  5948,  6365, 11671, 13319,  7491,    81,  3342]) tensor([ 6788,  8282,  5944,  2193, 13465,  2749, 14479,  2836,  3268,  5748])
before start barrier
start train
[proc 0] 100 steps, total: 5.533, sample: 0.393, forward: 1.072, backward: 0.674, update: 0.214
E20240202 13:53:22.272058  7372 parallel_pq_v2.h:79] insert failed, size(hashtable)=8947
W20240202 13:53:22.328240  7347 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end4
W20240202 13:53:22.364812  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=124, pq.top=124
E20240202 13:53:23.272085  7363 parallel_pq_v2.h:79] insert failed, size(hashtable)=2996
W20240202 13:53:23.332229  7347 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
W20240202 13:53:23.386749  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=149, pq.top=149
E20240202 13:53:24.272032  7359 parallel_pq_v2.h:79] insert failed, size(hashtable)=6189
W20240202 13:53:24.336141  7347 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
W20240202 13:53:24.386240  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=173, pq.top=173
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.502 ms                  | 22.929 ms                 |
| Forward                   | 4.841 ms                  | 9.087 ms                  |
| Backward                  | 4.275 ms                  | 10.201 ms                 |
| Optimize                  | 2.088 ms                  | 4.046 ms                  |
| BarrierTimeBeforeRank0    | 32.811 us                 | 11.042 ms                 |
| AfterBackward             | 23.036 ms                 | 30.623 ms                 |
| BlockToStepN              | 928.573 us                | 4.703 ms                  |
| OneStep                   | 38.800 ms                 | 63.181 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240202 13:53:25.272019  7353 parallel_pq_v2.h:79] insert failed, size(hashtable)=8924
W20240202 13:53:25.337317  7347 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end7
W20240202 13:53:25.386214  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=198, pq.top=198
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 387.642 us                | 3.848 ms                  |
| ProcessBack:Shuffle       | 2.596 ms                  | 3.793 ms                  |
| ProcessBack:UpdateCache   | 2.684 ms                  | 4.093 ms                  |
| ProcessBack:UpsertPq      | 15.921 ms                 | 22.139 ms                 |
| ProcessOneStep            | 23.114 ms                 | 30.594 ms                 |
| BlockToStepN              | 945.483 us                | 4.654 ms                  |
+---------------------------+---------------------------+---------------------------+
[proc 3] 200 steps, total: 4.120, sample: 0.342, forward: 0.464, backward: 0.447, update: 0.157
[proc 2] 200 steps, total: 4.120, sample: 0.344, forward: 0.461, backward: 0.449, update: 0.160
[proc 0] 200 steps, total: 4.120, sample: 0.439, forward: 0.463, backward: 0.422, update: 0.195
[proc 1] 200 steps, total: 4.120, sample: 0.354, forward: 0.460, backward: 0.467, update: 0.156
E20240202 13:53:26.272022  6642 parallel_pq_v2.h:79] insert failed, size(hashtable)=643
W20240202 13:53:26.343415  7347 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
W20240202 13:53:26.391517  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=222, pq.top=222
E20240202 13:53:27.272194  7048 parallel_pq_v2.h:79] insert failed, size(hashtable)=856
W20240202 13:53:27.348769  7347 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
W20240202 13:53:27.406644  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=247, pq.top=247
E20240202 13:53:28.272020  7369 parallel_pq_v2.h:79] insert failed, size(hashtable)=6443
W20240202 13:53:28.371234  7347 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end0
W20240202 13:53:28.466921  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=271, pq.top=271
E20240202 13:53:29.272068  7347 parallel_pq_v2.h:79] insert failed, size(hashtable)=138
W20240202 13:53:29.376262  7347 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end1
W20240202 13:53:29.484376  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=293, pq.top=293
[proc 3] 300 steps, total: 4.295, sample: 0.303, forward: 0.431, backward: 0.439, update: 0.150
[proc 2] 300 steps, total: 4.295, sample: 0.304, forward: 0.432, backward: 0.426, update: 0.155
[proc 0] 300 steps, total: 4.295, sample: 0.428, forward: 0.437, backward: 0.389, update: 0.197
[proc 1] 300 steps, total: 4.295, sample: 0.319, forward: 0.403, backward: 0.420, update: 0.159
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.781 ms                  | 23.335 ms                 |
| Forward                   | 4.629 ms                  | 7.543 ms                  |
| Backward                  | 4.163 ms                  | 9.038 ms                  |
| Optimize                  | 2.070 ms                  | 4.026 ms                  |
| BarrierTimeBeforeRank0    | 29.198 us                 | 14.027 ms                 |
| AfterBackward             | 23.110 ms                 | 30.623 ms                 |
| BlockToStepN              | 1.505 ms                  | 5.910 ms                  |
| OneStep                   | 39.259 ms                 | 63.503 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240202 13:53:30.272007  6642 parallel_pq_v2.h:79] insert failed, size(hashtable)=2065
W20240202 13:53:30.395843  7347 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end3
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 471.437 us                | 5.920 ms                  |
| ProcessBack:Shuffle       | 2.593 ms                  | 3.558 ms                  |
| ProcessBack:UpdateCache   | 2.550 ms                  | 3.964 ms                  |
| ProcessBack:UpsertPq      | 16.257 ms                 | 22.787 ms                 |
| ProcessOneStep            | 23.122 ms                 | 30.594 ms                 |
| BlockToStepN              | 1.474 ms                  | 6.344 ms                  |
+---------------------------+---------------------------+---------------------------+
W20240202 13:53:30.501977  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=315, pq.top=315
E20240202 13:53:31.272033  6642 parallel_pq_v2.h:79] insert failed, size(hashtable)=44
W20240202 13:53:31.398317  7347 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end4
W20240202 13:53:31.514997  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=336, pq.top=336
E20240202 13:53:32.273669  7370 parallel_pq_v2.h:79] insert failed, size(hashtable)=6
W20240202 13:53:32.406284  7347 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
W20240202 13:53:32.533023  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=357, pq.top=357
E20240202 13:53:33.273036  7347 parallel_pq_v2.h:79] insert failed, size(hashtable)=15
W20240202 13:53:33.428906  7347 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
W20240202 13:53:33.564229  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=378, pq.top=378
E20240202 13:53:34.273129  7347 parallel_pq_v2.h:79] insert failed, size(hashtable)=3
W20240202 13:53:34.433372  7347 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
W20240202 13:53:34.568697  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=398, pq.top=398
[proc 3] 400 steps, total: 4.889, sample: 0.317, forward: 0.433, backward: 0.457, update: 0.153
[proc 2] 400 steps, total: 4.889, sample: 0.317, forward: 0.421, backward: 0.435, update: 0.149
[proc 0] 400 steps, total: 4.889, sample: 0.455, forward: 0.437, backward: 0.384, update: 0.179
[proc 1] 400 steps, total: 4.889, sample: 0.330, forward: 0.419, backward: 0.416, update: 0.150
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.985 ms                  | 22.929 ms                 |
| Forward                   | 4.579 ms                  | 7.543 ms                  |
| Backward                  | 4.098 ms                  | 8.834 ms                  |
| Optimize                  | 2.044 ms                  | 3.989 ms                  |
| BarrierTimeBeforeRank0    | 29.348 us                 | 21.978 ms                 |
| AfterBackward             | 23.206 ms                 | 30.623 ms                 |
| BlockToStepN              | 2.254 ms                  | 8.993 ms                  |
| OneStep                   | 40.567 ms                 | 64.164 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240202 13:53:35.273188  7347 parallel_pq_v2.h:79] insert failed, size(hashtable)=23
W20240202 13:53:35.460235  7347 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end7
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 580.779 us                | 6.801 ms                  |
| ProcessBack:Shuffle       | 2.581 ms                  | 3.558 ms                  |
| ProcessBack:UpdateCache   | 2.420 ms                  | 3.964 ms                  |
| ProcessBack:UpsertPq      | 16.415 ms                 | 23.534 ms                 |
| ProcessOneStep            | 23.174 ms                 | 30.594 ms                 |
| BlockToStepN              | 2.292 ms                  | 8.918 ms                  |
+---------------------------+---------------------------+---------------------------+
W20240202 13:53:35.597635  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=419, pq.top=419
E20240202 13:53:36.273162  7351 parallel_pq_v2.h:79] insert failed, size(hashtable)=4054
W20240202 13:53:36.478412  7347 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end7
W20240202 13:53:36.635263  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=439, pq.top=439
E20240202 13:53:37.273006  6642 parallel_pq_v2.h:79] insert failed, size(hashtable)=402
W20240202 13:53:37.479596  7347 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
W20240202 13:53:37.639020  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=459, pq.top=459
E20240202 13:53:38.273146  7355 parallel_pq_v2.h:79] insert failed, size(hashtable)=4479
W20240202 13:53:38.480993  7347 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
W20240202 13:53:38.640246  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=479, pq.top=479
E20240202 13:53:39.273084  7366 parallel_pq_v2.h:79] insert failed, size(hashtable)=4417
W20240202 13:53:39.488092  7347 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end6
W20240202 13:53:39.690289  6642 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=499, pq.top=499
[proc 2] 500 steps, total: 5.075, sample: 0.302, forward: 0.415, backward: 0.444, update: 0.158
[proc 3] 500 steps, total: 5.075, sample: 0.307, forward: 0.432, backward: 0.427, update: 0.159
[proc 1] 500 steps, total: 5.075, sample: 0.303, forward: 0.410, backward: 0.427, update: 0.156
[proc 0] 500 steps, total: 5.075, sample: 0.504, forward: 0.440, backward: 0.403, update: 0.187
Successfully xmh. training takes 23.9119393825531 seconds
before call kg_cache_controller.StopThreads()
W20240202 13:53:39.756456  6642 grad_async_v2.h:84] call StopThreads. PID = 6088
W20240202 13:53:39.756486  6642 grad_base.h:212] before processOneStepNegThread_.join();
W20240202 13:53:39.756824  6642 grad_base.h:214] after processOneStepNegThread_.join();
W20240202 13:53:39.756839  6642 grad_async_v2.h:86] call GradProcessingBase::StopThreads.
W20240202 13:53:39.760836  6642 grad_async_v2.h:105] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f5cf00bc9d0>
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 2.033 ms                  | 23.335 ms                 |
| Forward                   | 4.538 ms                  | 6.580 ms                  |
| Backward                  | 4.085 ms                  | 8.834 ms                  |
| Optimize                  | 2.031 ms                  | 3.585 ms                  |
| BarrierTimeBeforeRank0    | 29.371 us                 | 19.745 ms                 |
| AfterBackward             | 23.317 ms                 | 30.552 ms                 |
| BlockToStepN              | 3.011 ms                  | 9.229 ms                  |
| OneStep                   | 42.051 ms                 | 65.661 ms                 |
+---------------------------+---------------------------+---------------------------+
