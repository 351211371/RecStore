WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240205 19:57:36.952693 34211 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_141', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=3, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=3, gpu=[0, 1, 2], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [34211 sampler.py:454] Start PreSampling
WARNING [34211 sampler.py:532] Before construct renumbering_dict
WARNING [34211 sampler.py:555] PreSampling done
W20240205 19:57:42.203867 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240205 19:57:42.204109 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240205 19:57:42.204149 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240205 19:57:42.204185 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240205 19:57:42.204219 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240205 19:57:42.204252 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240205 19:57:42.204294 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240205 19:57:42.204336 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240205 19:57:42.204371 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240205 19:57:42.204402 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240205 19:57:42.204444 34211 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240205 19:57:42.204478 34211 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240205 19:57:42.204516 34211 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240205 19:57:42.204654 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240205 19:57:42.204694 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240205 19:57:42.204725 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240205 19:57:42.204769 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240205 19:57:42.204810 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240205 19:57:42.204842 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240205 19:57:42.204881 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240205 19:57:42.204926 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240205 19:57:42.204963 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240205 19:57:42.205004 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240205 19:57:42.205042 34211 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240205 19:57:42.205070 34211 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240205 19:57:42.205097 34211 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240205 19:57:42.205164 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240205 19:57:42.205196 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240205 19:57:42.205235 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240205 19:57:42.205281 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240205 19:57:42.205319 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240205 19:57:42.205358 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240205 19:57:42.205401 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240205 19:57:42.205446 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240205 19:57:42.205489 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240205 19:57:42.205526 34211 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240205 19:57:42.205559 34211 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240205 19:57:42.205583 34211 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240205 19:57:42.205608 34211 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
{0: Graph(num_nodes=11088, num_edges=209563,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12469, num_edges=203028,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11122, num_edges=307147,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 11088 N 209563 E
MertisPartition: part 1 has 12469 N 203028 E
MertisPartition: part 2 has 11122 N 307147 E
Rank0: cached key size 249
Rank1: cached key size 249
Rank2: cached key size 249
Before renumbering graph:  {'_ID': tensor([   7,   10,   16,  ..., 9100, 2559, 8058]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([ 988, 1080, 1276,  ..., 8581, 8485, 4606]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=11088, num_edges=209563,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=11088, num_edges=209563,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 5.660 seconds
[Rank1] pid = 34446
INFO [34211 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [34211 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [34474 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [34446 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [34446 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [34474 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
E20240205 19:57:44.381215 34575 recstore.cc:66] init folly done
E20240205 19:57:44.381592 34447 recstore.cc:66] init folly done
E20240205 19:57:44.381594 34512 recstore.cc:66] init folly done
I20240205 19:57:44.476491 34447 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 3
I20240205 19:57:44.480324 34512 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
I20240205 19:57:44.482148 34575 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
[Rank2] pid = 34474
train_sampler.Prefill()
-------Step 0-------
tensor([   56, 12677, 12122,  5124,    88,  7685,  6425,  5714,  5315, 11976]) tensor([ 1276,  3720, 12021,  6376,  8753,  9924,   272,  5778,  4121, 14889])
-------Step 1-------
tensor([   56, 12677, 12122,  5124,    88,  7685,  6425,  5714,  5315, 11976]) tensor([ 6520,  7590,  8667, 14927,  5174,  6434,  1358, 13226,  4188,  2646])
-------Step 2-------
tensor([ 6304,  1807,  9546,    16,  7087,  2477,   205,  2775, 12132,  9695]) tensor([ 4404,  7507, 12681,  9025,  6360, 14262,  8953,  1072,  2262,  7276])
-------Step 3-------
tensor([ 6304,  1807,  9546,    16,  7087,  2477,   205,  2775, 12132,  9695]) tensor([ 7879,   317,  8284,  1837,  7002,  1878,  4417,  3863,   989, 14804])
-------Step 4-------
tensor([12634, 14510,   151,  7354,  8553,  2368,   211,   203,   142,  6626]) tensor([ 2268,  4894,  9970,  5213, 12098,  8721, 12705,   710,   363,  3280])
-------Step 5-------
tensor([12634, 14510,   151,  7354,  8553,  2368,   211,   203,   142,  6626]) tensor([ 4003, 12010,  8113,  7690, 12624, 13912, 12244, 11264, 13899,  2110])
-------Step 6-------
tensor([14387,  3782, 11044,     0, 14344,  3048, 14829, 12761,  9199,   749]) tensor([ 2783,  8480, 11585,  6076, 14902,  5482,  3965,  7367,  2535, 12181])
-------Step 7-------
tensor([14387,  3782, 11044,     0, 14344,  3048, 14829, 12761,  9199,   749]) tensor([13353,  8494,  7362,   570, 10828, 10872,  1603,  3432,  9818,   956])
-------Step 8-------
tensor([ 4453,   206,  7842,  1337, 10554,   928,   237,  8422,  2022,  9354]) tensor([ 4854,  7925,    79, 10660,  8624,  2960,  6626,  6095,  7511, 13824])
-------Step 9-------
tensor([ 4453,   206,  7842,  1337, 10554,   928,   237,  8422,  2022,  9354]) tensor([11601,  4953,  7980,   369,  3103,  9015,  1371,  4708,  7651,  5663])
before start barrier
start train
[proc 0] 100 steps, total: 3.731, sample: 0.427, forward: 1.424, backward: 0.775, update: 0.846
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 3.729, sample: 0.438, forward: 1.385, backward: 0.765, update: 0.836
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.735, sample: 0.437, forward: 1.345, backward: 0.734, update: 0.858
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.246 ms                  | 28.664 ms                 |
| Forward                   | 8.155 ms                  | 24.854 ms                 |
| Backward                  | 6.061 ms                  | 10.584 ms                 |
| Optimize                  | 7.915 ms                  | 14.950 ms                 |
| OneStep                   | 26.834 ms                 | 63.423 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 2] 200 steps, total: 3.164, sample: 0.556, forward: 0.841, backward: 0.603, update: 0.825
[proc 1] 200 steps, total: 3.164, sample: 0.536, forward: 0.781, backward: 0.608, update: 0.850
[proc 0] 200 steps, total: 3.164, sample: 0.487, forward: 0.896, backward: 0.585, update: 0.829
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.205 ms                  | 33.350 ms                 |
| Forward                   | 8.113 ms                  | 19.782 ms                 |
| Backward                  | 6.025 ms                  | 6.902 ms                  |
| Optimize                  | 7.790 ms                  | 14.366 ms                 |
| OneStep                   | 27.211 ms                 | 63.423 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 300 steps, total: 3.177, sample: 0.422, forward: 0.759, backward: 0.600, update: 0.828
[proc 2] 300 steps, total: 3.177, sample: 0.490, forward: 0.823, backward: 0.601, update: 0.801
[proc 0] 300 steps, total: 3.177, sample: 0.431, forward: 0.917, backward: 0.256, update: 0.758
[proc 2] 400 steps, total: 3.524, sample: 0.510, forward: 0.860, backward: 0.603, update: 0.835
[proc 1] 400 steps, total: 3.524, sample: 0.505, forward: 0.805, backward: 0.596, update: 0.862
[proc 0] 400 steps, total: 3.524, sample: 0.449, forward: 0.957, backward: 0.474, update: 0.792
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.220 ms                  | 33.919 ms                 |
| Forward                   | 8.155 ms                  | 19.782 ms                 |
| Backward                  | 6.025 ms                  | 6.902 ms                  |
| Optimize                  | 7.795 ms                  | 14.366 ms                 |
| OneStep                   | 27.944 ms                 | 63.780 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 500 steps, total: 3.457, sample: 0.500, forward: 0.770, backward: 0.609, update: 0.851
[proc 2] 500 steps, total: 3.457, sample: 0.502, forward: 0.818, backward: 0.601, update: 0.811
[proc 0] 500 steps, total: 3.457, sample: 0.431, forward: 0.921, backward: 0.608, update: 0.826
Successfully xmh. training takes 17.053767204284668 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
