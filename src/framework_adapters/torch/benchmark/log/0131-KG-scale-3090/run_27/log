WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240202 14:40:50.675011 23554 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_80', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [23554 sampler.py:454] Start PreSampling
WARNING [23554 sampler.py:532] Before construct renumbering_dict
WARNING [23554 sampler.py:555] PreSampling done
W20240202 14:40:55.815923 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240202 14:40:55.816164 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240202 14:40:55.816237 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240202 14:40:55.816278 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240202 14:40:55.816323 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240202 14:40:55.816386 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240202 14:40:55.816442 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240202 14:40:55.816491 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240202 14:40:55.816541 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240202 14:40:55.816597 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240202 14:40:55.816646 23554 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240202 14:40:55.816684 23554 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240202 14:40:55.816730 23554 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240202 14:40:55.816882 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240202 14:40:55.816934 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240202 14:40:55.816977 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240202 14:40:55.817035 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240202 14:40:55.817086 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240202 14:40:55.817134 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240202 14:40:55.817190 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240202 14:40:55.817245 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240202 14:40:55.817286 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240202 14:40:55.817327 23554 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240202 14:40:55.817368 23554 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240202 14:40:55.817402 23554 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240202 14:40:55.817437 23554 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13804, num_edges=289155,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12626, num_edges=379866,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13804 N 289155 E
MertisPartition: part 1 has 12626 N 379866 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  752,   825,   968,  ...,  9981, 10730, 10373]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 5.496 seconds
INFO [23977 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [23554 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [23554 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [23977 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240202 14:40:57.761269 24041 recstore.cc:66] init folly done
E20240202 14:40:57.761489 23978 recstore.cc:66] init folly done
I20240202 14:40:57.860776 23978 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240202 14:40:57.867796 24041 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.543, sample: 0.431, forward: 1.327, backward: 0.755, update: 0.807
[Rank1] pid = 23977
train_sampler.Prefill()
-------Step 0-------
tensor([  114,  5956,  8886,  8672,  2516, 14555,  3496,  6438,  6502,  7593]) tensor([ 1006,  8761, 10685, 13974, 12912,  7795,  5733,   560,  6667, 10119])
-------Step 1-------
tensor([  114,  5956,  8886,  8672,  2516, 14555,  3496,  6438,  6502,  7593]) tensor([10404,  2857,   485,   384, 10338,  8267, 11987, 11622,  1874,  4200])
-------Step 2-------
tensor([ 4623,  6824,    14,  3081,  9693,  3734,  9621,   634,  1588, 10024]) tensor([ 3598,   455,  1297,  1760,  4906,  7932, 13444, 14900, 11146,  7048])
-------Step 3-------
tensor([ 4623,  6824,    14,  3081,  9693,  3734,  9621,   634,  1588, 10024]) tensor([ 2616,   472, 10073, 10778,  2771,   576, 12415, 10931,  2764,  5920])
-------Step 4-------
tensor([ 9699, 12655,   176,   134,  3011, 14583,  7360,  4303,  5813, 11117]) tensor([11033,  3964,  4507,  7882,  7033,  3871,  6879, 12543,   793,  8779])
-------Step 5-------
tensor([ 9699, 12655,   176,   134,  3011, 14583,  7360,  4303,  5813, 11117]) tensor([ 9231, 13677, 11060, 11623,  1932,  7960, 10013, 10838,  6569, 10807])
-------Step 6-------
tensor([  318,  9937,   327,   302,   783,  6453,  7372,  6284,    57, 14133]) tensor([10283,  3689,  3313,  3781,  8014,  8598,  8858, 12426, 11010,  3746])
-------Step 7-------
tensor([  318,  9937,   327,   302,   783,  6453,  7372,  6284,    57, 14133]) tensor([ 7508,     2,  3226, 11105,   962,  8212,  1019, 11858,  7502,  8327])
-------Step 8-------
tensor([14256,  7870,   337,    62,  4276,  4076,  6698,  5553,  1481, 13737]) tensor([  252,  3999,   190,  1931, 10628,  8258,  4951,  2641, 12958, 14760])
-------Step 9-------
tensor([14256,  7870,   337,    62,  4276,  4076,  6698,  5553,  1481, 13737]) tensor([11227, 13747,  4605,  4138,  2832, 12083,  6556,  7141,  4731, 14099])
before start barrier
start train
[proc 0] 100 steps, total: 3.550, sample: 0.408, forward: 1.338, backward: 0.796, update: 0.812
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.129 ms                  | 32.094 ms                 |
| Forward                   | 7.594 ms                  | 16.215 ms                 |
| Backward                  | 6.120 ms                  | 15.774 ms                 |
| Optimize                  | 7.608 ms                  | 14.767 ms                 |
| OneStep                   | 24.162 ms                 | 58.469 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 200 steps, total: 2.920, sample: 0.492, forward: 0.820, backward: 0.624, update: 0.828
[proc 1] 200 steps, total: 2.920, sample: 0.477, forward: 0.784, backward: 0.594, update: 0.784
[proc 1] 300 steps, total: 2.984, sample: 0.482, forward: 0.804, backward: 0.603, update: 0.808
[proc 0] 300 steps, total: 2.984, sample: 0.447, forward: 0.819, backward: 0.638, update: 0.822
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.149 ms                  | 35.635 ms                 |
| Forward                   | 7.665 ms                  | 14.452 ms                 |
| Backward                  | 6.194 ms                  | 11.971 ms                 |
| Optimize                  | 7.683 ms                  | 14.503 ms                 |
| OneStep                   | 25.004 ms                 | 64.201 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 3.171, sample: 0.489, forward: 0.859, backward: 0.608, update: 0.834
[proc 0] 400 steps, total: 3.171, sample: 0.453, forward: 0.865, backward: 0.700, update: 0.824
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.179 ms                  | 35.528 ms                 |
| Forward                   | 7.753 ms                  | 15.794 ms                 |
| Backward                  | 6.875 ms                  | 11.879 ms                 |
| Optimize                  | 7.706 ms                  | 14.767 ms                 |
| OneStep                   | 26.052 ms                 | 63.385 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 500 steps, total: 3.365, sample: 0.493, forward: 0.886, backward: 0.602, update: 0.859
[proc 0] 500 steps, total: 3.365, sample: 0.454, forward: 0.907, backward: 0.693, update: 0.857
Successfully xmh. training takes 15.991060495376587 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
