WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240205 21:14:36.042184 56547 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='SimplE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/SimplE_FB15k_27', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [56547 sampler.py:454] Start PreSampling
WARNING [56547 sampler.py:532] Before construct renumbering_dict
WARNING [56547 sampler.py:555] PreSampling done
W20240205 21:14:40.889732 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240205 21:14:40.889940 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240205 21:14:40.889977 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240205 21:14:40.890004 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240205 21:14:40.890046 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240205 21:14:40.890075 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240205 21:14:40.890111 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240205 21:14:40.890151 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240205 21:14:40.890177 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240205 21:14:40.890200 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240205 21:14:40.890233 56547 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240205 21:14:40.890262 56547 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240205 21:14:40.890285 56547 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240205 21:14:40.890395 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240205 21:14:40.890429 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240205 21:14:40.890463 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240205 21:14:40.890502 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240205 21:14:40.890548 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240205 21:14:40.890583 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240205 21:14:40.890607 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240205 21:14:40.890645 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240205 21:14:40.890686 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240205 21:14:40.890722 56547 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240205 21:14:40.890755 56547 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240205 21:14:40.890777 56547 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240205 21:14:40.890797 56547 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13804, num_edges=289155,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12626, num_edges=379866,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13804 N 289155 E
MertisPartition: part 1 has 12626 N 379866 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  774,   822,   941,  ...,  9154,  9929, 12996]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 5.146 seconds
INFO [56751 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [56547 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [56751 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [56547 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240205 21:14:42.745597 56815 recstore.cc:66] init folly done
E20240205 21:14:42.745621 56752 recstore.cc:66] init folly done
I20240205 21:14:42.846566 56752 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240205 21:14:42.855739 56815 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.520, sample: 0.455, forward: 1.178, backward: 0.724, update: 0.850
[Rank1] pid = 56751
train_sampler.Prefill()
-------Step 0-------
tensor([  274,  4610,  8260,  9076,  3068, 12135,  3322,  7971,  6014,  7889]) tensor([  987,  7961,  9938, 11098, 14390,  8766,  7280,   546,  6212, 10662])
-------Step 1-------
tensor([  274,  4610,  8260,  9076,  3068, 12135,  3322,  7971,  6014,  7889]) tensor([13010,  2312,   494,   400,  8074, 10528, 13941,  8913,  2174,  3518])
-------Step 2-------
tensor([ 4289,  8746,   150,  2896, 12441,  3087,  8820,   557,  1725,  9184]) tensor([ 3837,   449,  1509,  2038,  3779,  8236, 12476, 14929, 10262,  7590])
-------Step 3-------
tensor([ 4289,  8746,   150,  2896, 12441,  3087,  8820,   557,  1725,  9184]) tensor([ 2609,   450, 10914, 13260,  3533,   577, 11458, 10132,  2268,  4588])
-------Step 4-------
tensor([ 8842, 14320,   104,   100,  2395, 14808,  8358,  4372,  7068, 11613]) tensor([11509,  4929,  4679,  7398,  8726,  3632,  8808, 13024,   785,  6688])
-------Step 5-------
tensor([ 8842, 14320,   104,   100,  2395, 14808,  8358,  4372,  7068, 11613]) tensor([ 9079, 13378,  8769, 13721,  2401, 10255, 12617, 13280,  8349, 12457])
-------Step 6-------
tensor([  253, 12544,   271,   242,   780,  8183,  9262,  7927,   167, 13974]) tensor([10759,  4662,  4147,  4748,  7512,  8986, 10943, 11540,  9996,  3801])
-------Step 7-------
tensor([  253, 12544,   271,   242,   780,  8183,  9262,  7927,   167, 13974]) tensor([ 9347,    50,  3010, 13449,   914,  6476,   966, 10991,  9297, 10428])
-------Step 8-------
tensor([11626,  6036,   365,    44,  4005,  3331,  6993,  6892,  1746, 10478]) tensor([  348,  4106,   305,  2254, 11212,  8631,  5700,  2095, 14486, 14684])
-------Step 9-------
tensor([11626,  6036,   365,    44,  4005,  3331,  6993,  6892,  1746, 10478]) tensor([12148, 13427,  5908,  5073,  2287,  9516,  8093,  9053,  5823, 13942])
before start barrier
start train
[proc 0] 100 steps, total: 3.530, sample: 0.448, forward: 1.141, backward: 0.867, update: 0.854
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.255 ms                  | 31.997 ms                 |
| Forward                   | 7.177 ms                  | 18.102 ms                 |
| Backward                  | 6.897 ms                  | 18.462 ms                 |
| Optimize                  | 7.493 ms                  | 18.428 ms                 |
| OneStep                   | 24.697 ms                 | 69.865 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 200 steps, total: 2.793, sample: 0.448, forward: 0.761, backward: 0.665, update: 0.771
[proc 1] 200 steps, total: 2.793, sample: 0.477, forward: 0.822, backward: 0.268, update: 0.760
[proc 0] 300 steps, total: 2.882, sample: 0.454, forward: 0.769, backward: 0.685, update: 0.788
[proc 1] 300 steps, total: 2.882, sample: 0.461, forward: 0.817, backward: 0.348, update: 0.752
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.247 ms                  | 31.997 ms                 |
| Forward                   | 7.132 ms                  | 15.299 ms                 |
| Backward                  | 6.863 ms                  | 13.604 ms                 |
| Optimize                  | 7.446 ms                  | 14.640 ms                 |
| OneStep                   | 24.220 ms                 | 65.431 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 2.846, sample: 0.413, forward: 0.821, backward: 0.273, update: 0.741
[proc 0] 400 steps, total: 2.846, sample: 0.413, forward: 0.748, backward: 0.686, update: 0.797
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.265 ms                  | 32.075 ms                 |
| Forward                   | 7.123 ms                  | 15.217 ms                 |
| Backward                  | 6.863 ms                  | 12.662 ms                 |
| Optimize                  | 7.475 ms                  | 14.800 ms                 |
| OneStep                   | 24.697 ms                 | 62.845 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 500 steps, total: 3.229, sample: 0.492, forward: 0.849, backward: 0.377, update: 0.765
[proc 0] 500 steps, total: 3.229, sample: 0.471, forward: 0.808, backward: 0.684, update: 0.882
Successfully xmh. training takes 15.280042886734009 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
