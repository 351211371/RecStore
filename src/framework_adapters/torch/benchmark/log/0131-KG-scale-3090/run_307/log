WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240212 21:10:45.193688 62001 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_250', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=1, update_pq_use_omp=2, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [62001 sampler.py:454] Start PreSampling
WARNING [62001 sampler.py:532] Before construct renumbering_dict
WARNING [62001 sampler.py:555] PreSampling done
W20240212 21:10:50.036216 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240212 21:10:50.036401 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240212 21:10:50.036444 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240212 21:10:50.036501 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240212 21:10:50.036541 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240212 21:10:50.036576 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240212 21:10:50.036613 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240212 21:10:50.036655 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240212 21:10:50.036695 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240212 21:10:50.036736 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240212 21:10:50.036778 62001 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240212 21:10:50.036813 62001 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240212 21:10:50.036849 62001 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240212 21:10:50.036976 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240212 21:10:50.037021 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240212 21:10:50.037060 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240212 21:10:50.037104 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240212 21:10:50.037143 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240212 21:10:50.037180 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240212 21:10:50.037218 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240212 21:10:50.037266 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240212 21:10:50.037307 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240212 21:10:50.037351 62001 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240212 21:10:50.037393 62001 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240212 21:10:50.037422 62001 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240212 21:10:50.037451 62001 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13804, num_edges=289155,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12626, num_edges=379866,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13804 N 289155 E
MertisPartition: part 1 has 12626 N 379866 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  763,   842,   943,  ...,  9652, 10680, 13318]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 5.219 seconds
INFO [62001 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [62001 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [62204 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [62204 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240212 21:10:52.034780 62268 recstore.cc:66] init folly done
E20240212 21:10:52.034883 62205 recstore.cc:66] init folly done
I20240212 21:10:52.121779 62205 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240212 21:10:52.130045 62268 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
[Rank1] pid = 62204
train_sampler.Prefill()
-------Step 0-------
tensor([  212,  4977,  8870,  9410,  2716, 12497,  3635,  6396,  6614,  7674]) tensor([  962,  8662, 10580, 11579, 12665,  6437,  7071,   384,  5741, 10485])
-------Step 1-------
tensor([  212,  4977,  8870,  9410,  2716, 12497,  3635,  6396,  6614,  7674]) tensor([13949,  1566,  1936,  4922,  9399,  9822,  9437,  9205, 13221,  4478])
-------Step 2-------
tensor([12497,     4,   179,   275,  7045,  7947,  1504, 13809,  7746, 13002]) tensor([ 2104,  2168, 14939, 10377,  6014,  7110, 12162,  1900,  5985,  5513])
-------Step 3-------
tensor([12497,     4,   179,   275,  7045,  7947,  1504, 13809,  7746, 13002]) tensor([12933,  2123,   350,  5069,  6629,  9428,  3244,   825, 14900, 11889])
-------Step 4-------
tensor([2655, 1986,   92, 1655, 7944, 7478, 8971, 7776,   33, 6876]) tensor([ 6510, 14583,  8268,  7933, 13524,  5633,  7481,  8126,  5246,  9195])
-------Step 5-------
tensor([2655, 1986,   92, 1655, 7944, 7478, 8971, 7776,   33, 6876]) tensor([ 7316,  3356, 10702,  6223,  3923,  9270,   156,   794,  5025,  8481])
-------Step 6-------
tensor([ 7153,  3521,  8504,   141,  1316,   249, 12497,  7311,   327,   322]) tensor([11896, 14535,  8888,  9536,   870,  5899,  4685, 14396, 14318,  8502])
-------Step 7-------
tensor([ 7153,  3521,  8504,   141,  1316,   249, 12497,  7311,   327,   322]) tensor([ 7130,  1706, 12924, 13932, 14746,  9961,  1951,   566,    96,  6897])
-------Step 8-------
tensor([ 4332,  8913,  5564,  2100,  4977,  5049,  7045,  2655, 14053, 11066]) tensor([14125,  7899, 14238,  6333,  5755,  8143,  2414,  8538,  9937, 13858])
-------Step 9-------
tensor([ 4332,  8913,  5564,  2100,  4977,  5049,  7045,  2655, 14053, 11066]) tensor([ 4626, 11251, 12678, 12871, 14533,  3849,  2233,  9205, 11211,  3034])
before start barrier
start train
[proc 0] 100 steps, total: 3.158, sample: 0.375, forward: 1.197, backward: 0.847, update: 0.590
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.150, sample: 0.382, forward: 1.126, backward: 0.824, update: 0.581
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.188 ms                  | 25.319 ms                 |
| Forward                   | 5.955 ms                  | 12.729 ms                 |
| Backward                  | 6.014 ms                  | 7.065 ms                  |
| Optimize                  | 5.650 ms                  | 11.481 ms                 |
| OneStep                   | 20.233 ms                 | 52.478 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 200 steps, total: 2.342, sample: 0.388, forward: 0.569, backward: 0.597, update: 0.570
[proc 0] 200 steps, total: 2.342, sample: 0.376, forward: 0.623, backward: 0.604, update: 0.594
[proc 1] 300 steps, total: 2.260, sample: 0.355, forward: 0.556, backward: 0.595, update: 0.567
[proc 0] 300 steps, total: 2.260, sample: 0.354, forward: 0.590, backward: 0.606, update: 0.566
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.168 ms                  | 26.609 ms                 |
| Forward                   | 5.886 ms                  | 12.729 ms                 |
| Backward                  | 6.014 ms                  | 13.117 ms                 |
| Optimize                  | 5.633 ms                  | 11.481 ms                 |
| OneStep                   | 20.219 ms                 | 51.251 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 2.323, sample: 0.357, forward: 0.570, backward: 0.589, update: 0.578
[proc 0] 400 steps, total: 2.323, sample: 0.353, forward: 0.641, backward: 0.600, update: 0.595
[proc 1] 500 steps, total: 2.470, sample: 0.383, forward: 0.638, backward: 0.597, update: 0.632
[proc 0] 500 steps, total: 2.470, sample: 0.377, forward: 0.674, backward: 0.610, update: 0.606
Successfully xmh. training takes 12.553767442703247 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
