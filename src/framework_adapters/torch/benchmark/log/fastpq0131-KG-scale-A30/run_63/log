WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240201 01:07:57.108526 3377982 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_265', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [3377982 sampler.py:454] Start PreSampling
WARNING [3377982 sampler.py:532] Before construct renumbering_dict
WARNING [3377982 sampler.py:555] PreSampling done
W20240201 01:07:59.165730 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240201 01:07:59.165927 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240201 01:07:59.165954 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240201 01:07:59.165978 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240201 01:07:59.166002 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240201 01:07:59.166026 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240201 01:07:59.166049 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240201 01:07:59.166079 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240201 01:07:59.166096 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240201 01:07:59.166112 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240201 01:07:59.166141 3377982 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240201 01:07:59.166159 3377982 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240201 01:07:59.166173 3377982 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240201 01:07:59.166306 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240201 01:07:59.166333 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240201 01:07:59.166348 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240201 01:07:59.166379 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240201 01:07:59.166399 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240201 01:07:59.166420 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240201 01:07:59.166445 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240201 01:07:59.166465 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240201 01:07:59.166483 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240201 01:07:59.166499 3377982 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240201 01:07:59.166522 3377982 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240201 01:07:59.166535 3377982 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240201 01:07:59.166553 3377982 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13458, num_edges=276636,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12796, num_edges=383671,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13458 N 276636 E
MertisPartition: part 1 has 12796 N 383671 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  746,   832,   957,  ..., 10410, 10753, 11126]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13458, num_edges=276636,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13458, num_edges=276636,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.260 seconds
INFO [3378196 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [3377982 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [3378196 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [3377982 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240201 01:08:01.007119 3378223 recstore.cc:66] init folly done
E20240201 01:08:01.007196 3378197 recstore.cc:66] init folly done
I20240201 01:08:01.045100 3378223 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240201 01:08:01.067077 3378197 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
[Rank1] pid = 3378196
train_sampler.Prefill()
-------Step 0-------
tensor([12756, 14572, 13288, 14164,  1779,  1479,  1971,  8996,  2111,  5513]) tensor([  987,  4886,  6795,  6010, 12851,  6365, 13578, 14130,  4511, 13584])
-------Step 1-------
tensor([12756, 14572, 13288, 14164,  1779,  1479,  1971,  8996,  2111,  5513]) tensor([11624,  6614, 14208,  4983, 14511,  1585,  5929,  2686,  1300,  9245])
-------Step 2-------
tensor([  53, 2477, 9683,   77, 6673, 7313, 1899,   20,    0,  107]) tensor([  250,  4775,   596, 10850, 12144, 14003,  7501,  5743,  3094,  3174])
-------Step 3-------
tensor([  53, 2477, 9683,   77, 6673, 7313, 1899,   20,    0,  107]) tensor([ 2015,   469,  4254,  5863,  8279, 14298,  5425,  3011, 10539,  3655])
-------Step 4-------
tensor([ 8580,  5083,  7176, 10267, 14918,  5339,  9268, 12357,   318,  5598]) tensor([ 2895, 14335,  5686,  9459,  6411, 14436,  1743, 12833,  8570, 12151])
-------Step 5-------
tensor([ 8580,  5083,  7176, 10267, 14918,  5339,  9268, 12357,   318,  5598]) tensor([ 5604,  3242,   996,  9782, 12691,  3167,  4278,  3928, 14449,  4676])
-------Step 6-------
tensor([12889,   209,  8963, 10544,  4307,  9938, 14575,   256, 11146,   204]) tensor([ 7611, 11193,  9912, 14070, 13430,  2050, 14750, 14184, 13778,  6656])
-------Step 7-------
tensor([12889,   209,  8963, 10544,  4307,  9938, 14575,   256, 11146,   204]) tensor([ 2176,  5422, 10890, 13764,  4459, 12598, 14893, 13991, 12307,  7791])
-------Step 8-------
tensor([ 4604, 13936, 10861,     4, 14164,  5230,  3728,   452,  7708, 13113]) tensor([ 1845,  8023,  2702, 11415,  4843,   785,  4360,  6107, 11540,  8214])
-------Step 9-------
tensor([ 4604, 13936, 10861,     4, 14164,  5230,  3728,   452,  7708, 13113]) tensor([ 6437, 11167, 12208, 12561,   712,  2230, 14537, 13749,  7890,  6644])
before start barrier
start train
[proc 0] 100 steps, total: 3.163, sample: 0.218, forward: 1.228, backward: 1.123, update: 0.418
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.185, sample: 0.260, forward: 1.234, backward: 1.087, update: 0.445
[proc 1] 200 steps, total: 1.531, sample: 0.266, forward: 0.478, backward: 0.300, update: 0.425
[proc 0] 200 steps, total: 1.531, sample: 0.205, forward: 0.473, backward: 0.300, update: 0.378
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 728.370 us                | 11.688 ms                 |
| Forward                   | 4.847 ms                  | 12.787 ms                 |
| Backward                  | 3.069 ms                  | 3.265 ms                  |
| Optimize                  | 3.839 ms                  | 8.366 ms                  |
| OneStep                   | 13.361 ms                 | 40.657 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 300 steps, total: 1.541, sample: 0.209, forward: 0.469, backward: 0.302, update: 0.376
[proc 1] 300 steps, total: 1.541, sample: 0.221, forward: 0.480, backward: 0.301, update: 0.413
[proc 1] 400 steps, total: 1.769, sample: 0.251, forward: 0.511, backward: 0.307, update: 0.446
[proc 0] 400 steps, total: 1.769, sample: 0.240, forward: 0.518, backward: 0.307, update: 0.418
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 806.506 us                | 14.776 ms                 |
| Forward                   | 4.909 ms                  | 8.481 ms                  |
| Backward                  | 3.121 ms                  | 3.480 ms                  |
| Optimize                  | 3.890 ms                  | 8.231 ms                  |
| OneStep                   | 13.913 ms                 | 33.257 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 500 steps, total: 1.980, sample: 0.254, forward: 0.587, backward: 0.327, update: 0.531
[proc 0] 500 steps, total: 1.980, sample: 0.259, forward: 0.595, backward: 0.320, update: 0.489
Successfully xmh. training takes 9.984877586364746 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
