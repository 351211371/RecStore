WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240207 22:41:08.122170 495949 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='SimplE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/SimplE_FB15k_151', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [495949 sampler.py:454] Start PreSampling
WARNING [495949 sampler.py:532] Before construct renumbering_dict
WARNING [495949 sampler.py:555] PreSampling done
W20240207 22:41:10.115943 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240207 22:41:10.116056 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240207 22:41:10.116078 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240207 22:41:10.116096 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240207 22:41:10.116114 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240207 22:41:10.116137 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240207 22:41:10.116155 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240207 22:41:10.116175 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240207 22:41:10.116189 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240207 22:41:10.116206 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240207 22:41:10.116225 495949 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240207 22:41:10.116240 495949 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240207 22:41:10.116254 495949 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240207 22:41:10.116335 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240207 22:41:10.116358 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240207 22:41:10.116371 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240207 22:41:10.116402 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240207 22:41:10.116420 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240207 22:41:10.116434 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240207 22:41:10.116457 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240207 22:41:10.116475 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240207 22:41:10.116497 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240207 22:41:10.116511 495949 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240207 22:41:10.116528 495949 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240207 22:41:10.116540 495949 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240207 22:41:10.116555 495949 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13458, num_edges=276636,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12796, num_edges=383671,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13458 N 276636 E
MertisPartition: part 1 has 12796 N 383671 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  764,   818,   927,  ..., 11310, 12530, 11212]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13458, num_edges=276636,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13458, num_edges=276636,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.153 seconds
INFO [495949 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [496160 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [495949 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [496160 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240207 22:41:11.854120 496204 recstore.cc:66] init folly done
E20240207 22:41:11.854156 496161 recstore.cc:66] init folly done
I20240207 22:41:11.901124 496204 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240207 22:41:11.907783 496161 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.109, sample: 0.252, forward: 1.478, backward: 0.779, update: 0.525
[Rank1] pid = 496160
train_sampler.Prefill()
-------Step 0-------
tensor([12828, 11869, 13175, 14092,  1724,  1562,  2113,  9069,  1900,  5936]) tensor([  953,  4019,  6575,  6105, 12246,  6673, 10154, 14050,  4452, 14439])
-------Step 1-------
tensor([12828, 11869, 13175, 14092,  1724,  1562,  2113,  9069,  1900,  5936]) tensor([11764,  6533, 14452,  5329, 14425,  1554,  6402,  2760,  1344,  9939])
-------Step 2-------
tensor([  293,  2484, 10511,   177,  6587,  7386,  1878,     7,     0,    18]) tensor([  159,  5227,   621, 11522, 12998, 13809,  8097,  5810,  3177,  3346])
-------Step 3-------
tensor([  293,  2484, 10511,   177,  6587,  7386,  1878,     7,     0,    18]) tensor([ 1972,   453,  4145,  5948,  8997, 14904,  5427,  3104,  9851,  3662])
-------Step 4-------
tensor([ 8541,  5294,  7601, 11513, 13934,  5170,  9727, 12959,   332,  5965]) tensor([ 2901, 14489,  4645,  9412,  6201, 12001,  1754, 13017,  9168, 12150])
-------Step 5-------
tensor([ 8541,  5294,  7601, 11513, 13934,  5170,  9727, 12959,   332,  5965]) tensor([ 5465,  3201,   973, 10383, 12904,  3198,  4468,  4267, 11078,  5145])
-------Step 6-------
tensor([14798,   115,  8456, 10551,  4250, 10570, 12370,   239, 11058,   101]) tensor([ 8499,  8389, 10547, 13873, 14207,  2049, 12545, 14105, 14262,  7141])
-------Step 7-------
tensor([14798,   115,  8456, 10551,  4250, 10570, 12370,   239, 11058,   101]) tensor([ 2082,  5694, 11041, 13545,  4833, 11876, 14658, 14764, 12094,  7499])
-------Step 8-------
tensor([ 4801, 10773,  8471,     1, 14092,  5639,  3058,   449,  8053, 13291]) tensor([ 1843,  9295,  2900, 12429,  4959,   795,  4566,  6755, 11435,  8473])
-------Step 9-------
tensor([ 4801, 10773,  8471,     1, 14092,  5639,  3058,   449,  8053, 13291]) tensor([ 7191, 11279,  9115, 13249,   664,  2241, 11298, 14572,  7819,  6532])
before start barrier
start train
[proc 0] 100 steps, total: 3.103, sample: 0.200, forward: 1.088, backward: 0.771, update: 0.453
[proc 1] 200 steps, total: 1.528, sample: 0.212, forward: 0.486, backward: 0.240, update: 0.397
[proc 0] 200 steps, total: 1.528, sample: 0.202, forward: 0.501, backward: 0.350, update: 0.390
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 692.147 us                | 11.955 ms                 |
| Forward                   | 5.073 ms                  | 9.328 ms                  |
| Backward                  | 3.610 ms                  | 7.215 ms                  |
| Optimize                  | 4.029 ms                  | 6.393 ms                  |
| OneStep                   | 14.144 ms                 | 38.399 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 300 steps, total: 1.550, sample: 0.202, forward: 0.496, backward: 0.349, update: 0.387
[proc 1] 300 steps, total: 1.550, sample: 0.187, forward: 0.480, backward: 0.223, update: 0.387
[proc 0] 400 steps, total: 1.642, sample: 0.211, forward: 0.502, backward: 0.347, update: 0.388
[proc 1] 400 steps, total: 1.642, sample: 0.204, forward: 0.484, backward: 0.239, update: 0.397
[proc 1] 500 steps, total: 1.640, sample: 0.198, forward: 0.481, backward: 0.258, update: 0.400
[proc 0] 500 steps, total: 1.640, sample: 0.203, forward: 0.500, backward: 0.351, update: 0.393
Successfully xmh. training takes 9.46383023262024 seconds
before call kg_cache_controller.StopThreads()
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 693.879 us                | 12.982 ms                 |
| Forward                   | 5.075 ms                  | 7.191 ms                  |
| Backward                  | 3.617 ms                  | 4.910 ms                  |
| Optimize                  | 4.003 ms                  | 5.474 ms                  |
| OneStep                   | 14.073 ms                 | 27.831 ms                 |
+---------------------------+---------------------------+---------------------------+
KGCacheControllerWrapperDummy.StopThreads
