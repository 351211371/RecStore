WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240201 00:02:50.874295 3260968 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_202', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [3260968 sampler.py:454] Start PreSampling
WARNING [3260968 sampler.py:532] Before construct renumbering_dict
WARNING [3260968 sampler.py:555] PreSampling done
W20240201 00:02:54.022998 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240201 00:02:54.023142 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240201 00:02:54.023169 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240201 00:02:54.023188 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240201 00:02:54.023213 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240201 00:02:54.023233 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240201 00:02:54.023253 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240201 00:02:54.023283 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240201 00:02:54.023306 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240201 00:02:54.023324 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240201 00:02:54.023351 3260968 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240201 00:02:54.023373 3260968 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240201 00:02:54.023391 3260968 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240201 00:02:54.023487 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240201 00:02:54.023511 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240201 00:02:54.023533 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240201 00:02:54.023573 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240201 00:02:54.023594 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240201 00:02:54.023614 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240201 00:02:54.023631 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240201 00:02:54.023654 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240201 00:02:54.023674 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240201 00:02:54.023690 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240201 00:02:54.023708 3260968 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240201 00:02:54.023723 3260968 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240201 00:02:54.023741 3260968 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240201 00:02:54.023788 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240201 00:02:54.023821 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240201 00:02:54.023839 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240201 00:02:54.023859 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240201 00:02:54.023877 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240201 00:02:54.023895 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240201 00:02:54.023912 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240201 00:02:54.023929 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240201 00:02:54.023953 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240201 00:02:54.023977 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240201 00:02:54.023995 3260968 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240201 00:02:54.024010 3260968 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240201 00:02:54.024027 3260968 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240201 00:02:54.024063 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240201 00:02:54.024086 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240201 00:02:54.024108 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240201 00:02:54.024127 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240201 00:02:54.024147 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240201 00:02:54.024173 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240201 00:02:54.024190 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240201 00:02:54.024212 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240201 00:02:54.024231 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240201 00:02:54.024255 3260968 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240201 00:02:54.024271 3260968 IPCTensor.h:369] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240201 00:02:54.024286 3260968 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240201 00:02:54.024308 3260968 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240201 00:02:54.157817 3260968 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240201 00:02:54.186178 3260968 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 186
Rank1: cached key size 186
Rank2: cached key size 186
Rank3: cached key size 186
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([ 839, 1036, 1114,  ..., 1660, 5778, 7012]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.333 seconds
[Rank1] pid = 3261181
[Rank2] pid = 3261246
INFO [3260968 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [3261181 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [3261310 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [3261246 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [3261246 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240201 00:02:57.686645 3261247 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [747, 400]; dev=2; size=1.14 MB
INFO [3260968 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240201 00:02:57.687638 3261247 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x100014876000 7.629 MB
INFO [3261310 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240201 00:02:57.688009 3261247 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x100015019000 7.629 MB
INFO [3261181 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240201 00:02:57.688192 3261247 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x1000157bc000 1.49 GB
W20240201 00:02:57.688315 3261247 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x100074d9f000 1.49 GB
W20240201 00:02:57.688396 3261247 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240201 00:02:57.688750 3261311 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240201 00:02:57.690412 3261182 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240201 00:02:57.690414 3261312 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_3 [747, 400]; dev=3; size=1.14 MB
W20240201 00:02:57.693951 3261247 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240201 00:02:57.694257 3261311 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x1000d4386000 7.629 MB
W20240201 00:02:57.694505 3261311 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x1000d4b2b000 7.629 MB
W20240201 00:02:57.694612 3261311 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000d52ce000 1.49 GB
W20240201 00:02:57.694671 3261311 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1001348b1000 1.49 GB
W20240201 00:02:57.694746 3261311 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240201 00:02:57.694747 3261312 IPCTensor.h:369] NewIPCTensor: input_keys_3 [1000000]0x100193e94000 7.629 MB
W20240201 00:02:57.695057 3261312 IPCTensor.h:369] NewIPCTensor: input_keys_neg_3 [1000000]0x100194639000 7.629 MB
W20240201 00:02:57.695183 3261312 IPCTensor.h:369] NewIPCTensor: backward_grads_3 [1000000, 400]0x10019557f000 1.49 GB
W20240201 00:02:57.695180 3261182 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x100194ddc000 7.629 MB
W20240201 00:02:57.695273 3261312 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1001f4b62000 1.49 GB
W20240201 00:02:57.695351 3261312 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240201 00:02:57.695462 3261182 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x100254145000 7.629 MB
W20240201 00:02:57.695569 3261182 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x1002548e8000 1.49 GB
W20240201 00:02:57.695650 3261182 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1002b3ecb000 1.49 GB
W20240201 00:02:57.695734 3261182 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240201 00:02:57.713882 3261182 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240201 00:02:57.714385 3261311 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240201 00:02:57.724133 3261312 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [3261181 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [3261246 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [3261310 DistTensor.py:59] The tensor name already exists in the kvstore
[Rank3] pid = 3261310
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494), (1494, 2241), (2241, 2988)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [3260968 DistTensor.py:59] The tensor name already exists in the kvstore
I20240201 00:02:58.846940 3261311 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240201 00:02:58.847049 3261312 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240201 00:02:58.847288 3261182 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240201 00:02:58.847427 3261247 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240201 00:02:58.848841 3261311 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 0.01,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240201 00:02:58.848969 3261311 grad_base.h:184] Init GradProcessingBase done
I20240201 00:02:58.853261 3261311 grad_async_v2.h:42] Use main thread to update emb.
W20240201 00:02:58.853292 3261311 kg_controller.h:78] after init GradAsyncProcessingV2
I20240201 00:02:58.853298 3261311 kg_controller.h:84] Construct KGCacheController done
E20240201 00:03:00.175789 3261311 recstore.cc:66] init folly done
E20240201 00:03:00.175851 3261312 recstore.cc:66] init folly done
E20240201 00:03:00.175858 3261247 recstore.cc:66] init folly done
E20240201 00:03:00.175961 3261182 recstore.cc:66] init folly done
I20240201 00:03:00.176987 3261311 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240201 00:03:00.847864 3261692 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
E20240201 00:03:00.848178 3261692 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
I20240201 00:03:00.872315 3261311 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240201 00:03:00.905483 3261247 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240201 00:03:00.908183 3261182 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240201 00:03:00.919353 3261312 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240201 00:03:03.344372 3261311 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
W20240201 00:03:03.365713 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=1, pq.top=0
W20240201 00:03:03.391405 3261692 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
E20240201 00:03:03.404240 3261498 grad_async_v2.h:404] Stalled in ProcessBackward: rank=1, step_no=1, sample_step_cpp_seen_[rank]=0
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 983.711 us                | 10.788 ms                 |
| Forward                   | 3.206 ms                  | 923.448 ms                |
| Backward                  | 2.407 ms                  | 237.216 ms                |
| Optimize                  | 959.837 us                | 1.591 ms                  |
| BarrierTimeBeforeRank0    | 24.310 us                 | 63.251 ms                 |
| AfterBackward             | 10.791 ms                 | 1.219 s                   |
| BlockToStepN              | 197.764 us                | 23.759 ms                 |
| OneStep                   | 19.728 ms                 | 2.471 s                   |
+---------------------------+---------------------------+---------------------------+
E20240201 00:03:04.344007 3261498 parallel_pq_v2.h:79] insert failed, size(hashtable)=12
W20240201 00:03:04.375214 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=46, pq.top=46
W20240201 00:03:04.401427 3261692 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 260.459 us                | 2.799 ms                  |
| ProcessBack:Shuffle       | 2.085 ms                  | 4.184 ms                  |
| ProcessBack:UpdateCache   | 1.788 ms                  | 4.069 ms                  |
| ProcessBack:UpsertPq      | 6.144 ms                  | 10.477 ms                 |
| ProcessOneStep            | 12.173 ms                 | 17.266 ms                 |
| BlockToStepN              | 403.378 us                | 1.905 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240201 00:03:05.344013 3261311 parallel_pq_v2.h:79] insert failed, size(hashtable)=102
W20240201 00:03:05.387753 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=91, pq.top=91
W20240201 00:03:05.410044 3261692 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.670, sample: 0.156, forward: 1.187, backward: 0.477, update: 0.070
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.673, sample: 0.157, forward: 1.160, backward: 0.549, update: 0.067
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.659, sample: 0.167, forward: 1.172, backward: 0.518, update: 0.072
train_sampler.Prefill()
-------Step 0-------
tensor([ 7532,  3550,  8920,  7357,  7971,  3941,   697,  4716, 11914,  9812]) tensor([ 1114,  7860,  8991,  3498,  7380,  7145, 13379,  7427,  7630,  7265])
-------Step 1-------
tensor([ 7532,  3550,  8920,  7357,  7971,  3941,   697,  4716, 11914,  9812]) tensor([  406, 11084, 13345,  1023, 11073, 10496,  1650,  9158,  9928,  8318])
-------Step 2-------
tensor([ 5269, 13214,  8172,  4467,  5002, 11942, 11976, 10185, 11486,   122]) tensor([9461, 3859, 1669, 6580, 5533,  730, 7488, 5479, 6539, 6967])
-------Step 3-------
tensor([ 5269, 13214,  8172,  4467,  5002, 11942, 11976, 10185, 11486,   122]) tensor([ 5619, 12672,  8013, 10541,  6459,  1477,  9392, 13034, 11894, 11605])
-------Step 4-------
tensor([ 8575,  2125,  3252,   158,  9161,  9271,  4478, 12589, 11670,  9365]) tensor([10178,  3638,  3215, 12130,  1623,  2028, 11220,  5118, 11707,  6193])
-------Step 5-------
tensor([ 8575,  2125,  3252,   158,  9161,  9271,  4478, 12589, 11670,  9365]) tensor([ 5586, 10917,  5381,  9133,  9043,  6526,  5254,  2994,  7633, 13949])
-------Step 6-------
tensor([10631,  6840,  5914,  6603,  1328,  6112,  7659,  2405, 13555,    81]) tensor([ 7413,  6544,  2977, 13704,  6776,   598,  3692, 11652, 14663,  3252])
-------Step 7-------
tensor([10631,  6840,  5914,  6603,  1328,  6112,  7659,  2405, 13555,    81]) tensor([ 5813, 10357,  8201, 11246,   535,   173, 13833, 10564,  4363, 14516])
-------Step 8-------
tensor([   58, 13643, 12597, 10721,  4993,  5914, 12973,  8593,  4551,  1403]) tensor([14437,  5094, 10653, 10451,  3618,  8857,  5537,   412, 11417, 12600])
-------Step 9-------
tensor([   58, 13643, 12597, 10721,  4993,  5914, 12973,  8593,  4551,  1403]) tensor([ 9487, 11824, 12869,   530, 12779,  9805,  5517,  1758,  6525,  9562])
before start barrier
start train
[proc 0] 100 steps, total: 4.706, sample: 0.218, forward: 1.230, backward: 0.473, update: 0.100
E20240201 00:03:06.344199 3261704 parallel_pq_v2.h:79] insert failed, size(hashtable)=4991
W20240201 00:03:06.400293 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=135, pq.top=135
W20240201 00:03:06.412572 3261692 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
E20240201 00:03:07.344043 3261692 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
W20240201 00:03:07.412968 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=178, pq.top=178
W20240201 00:03:07.414216 3261692 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
[proc 0] 200 steps, total: 2.372, sample: 0.253, forward: 0.308, backward: 0.209, update: 0.091
[proc 1] 200 steps, total: 2.372, sample: 0.171, forward: 0.253, backward: 0.214, update: 0.064
[proc 2] 200 steps, total: 2.372, sample: 0.162, forward: 0.221, backward: 0.196, update: 0.064
[proc 3] 200 steps, total: 2.372, sample: 0.159, forward: 0.221, backward: 0.210, update: 0.063
E20240201 00:03:08.344023 3261693 parallel_pq_v2.h:79] insert failed, size(hashtable)=4165
W20240201 00:03:08.414261 3261692 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
W20240201 00:03:08.430370 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=220, pq.top=220
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.147 ms                  | 11.208 ms                 |
| Forward                   | 3.208 ms                  | 3.832 ms                  |
| Backward                  | 2.211 ms                  | 4.188 ms                  |
| Optimize                  | 1.011 ms                  | 1.676 ms                  |
| BarrierTimeBeforeRank0    | 23.736 us                 | 760.092 us                |
| AfterBackward             | 13.004 ms                 | 16.587 ms                 |
| BlockToStepN              | 921.554 us                | 2.648 ms                  |
| OneStep                   | 22.433 ms                 | 34.420 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240201 00:03:09.344007 3261498 parallel_pq_v2.h:79] insert failed, size(hashtable)=203
W20240201 00:03:09.417189 3261692 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
W20240201 00:03:09.450944 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=261, pq.top=261
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 397.190 us                | 2.823 ms                  |
| ProcessBack:Shuffle       | 2.015 ms                  | 2.444 ms                  |
| ProcessBack:UpdateCache   | 1.617 ms                  | 3.254 ms                  |
| ProcessBack:UpsertPq      | 7.192 ms                  | 11.754 ms                 |
| ProcessOneStep            | 13.287 ms                 | 15.974 ms                 |
| BlockToStepN              | 983.030 us                | 2.753 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240201 00:03:10.344066 3261715 parallel_pq_v2.h:79] insert failed, size(hashtable)=7486
W20240201 00:03:10.421727 3261692 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
W20240201 00:03:10.472184 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=300, pq.top=300
[proc 3] 300 steps, total: 2.523, sample: 0.144, forward: 0.218, backward: 0.211, update: 0.062
[proc 0] 300 steps, total: 2.523, sample: 0.255, forward: 0.328, backward: 0.206, update: 0.091
[proc 2] 300 steps, total: 2.523, sample: 0.142, forward: 0.214, backward: 0.188, update: 0.064
[proc 1] 300 steps, total: 2.523, sample: 0.164, forward: 0.259, backward: 0.218, update: 0.065
E20240201 00:03:11.344007 3261498 parallel_pq_v2.h:79] insert failed, size(hashtable)=146
W20240201 00:03:11.422441 3261692 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
W20240201 00:03:11.493204 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=340, pq.top=340
E20240201 00:03:12.344094 3261692 parallel_pq_v2.h:79] insert failed, size(hashtable)=8
W20240201 00:03:12.425231 3261692 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
W20240201 00:03:12.502661 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=381, pq.top=381
[proc 2] 400 steps, total: 2.533, sample: 0.141, forward: 0.215, backward: 0.188, update: 0.063
[proc 3] 400 steps, total: 2.533, sample: 0.143, forward: 0.219, backward: 0.212, update: 0.061
[proc 1] 400 steps, total: 2.533, sample: 0.210, forward: 0.330, backward: 0.221, update: 0.082
[proc 0] 400 steps, total: 2.533, sample: 0.219, forward: 0.284, backward: 0.223, update: 0.078
E20240201 00:03:13.344020 3261311 parallel_pq_v2.h:79] insert failed, size(hashtable)=75
W20240201 00:03:13.438835 3261692 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
W20240201 00:03:13.548724 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=419, pq.top=419
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.242 ms                  | 11.467 ms                 |
| Forward                   | 3.183 ms                  | 4.269 ms                  |
| Backward                  | 2.255 ms                  | 2.784 ms                  |
| Optimize                  | 975.445 us                | 1.591 ms                  |
| BarrierTimeBeforeRank0    | 24.911 us                 | 4.280 ms                  |
| AfterBackward             | 13.672 ms                 | 18.272 ms                 |
| BlockToStepN              | 1.382 ms                  | 4.067 ms                  |
| OneStep                   | 23.575 ms                 | 35.681 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240201 00:03:14.344007 3261498 parallel_pq_v2.h:79] insert failed, size(hashtable)=122
W20240201 00:03:14.448064 3261692 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end4
W20240201 00:03:14.560935 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=457, pq.top=457
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 465.237 us                | 3.210 ms                  |
| ProcessBack:Shuffle       | 1.954 ms                  | 2.318 ms                  |
| ProcessBack:UpdateCache   | 1.668 ms                  | 2.648 ms                  |
| ProcessBack:UpsertPq      | 8.123 ms                  | 13.151 ms                 |
| ProcessOneStep            | 13.625 ms                 | 17.981 ms                 |
| BlockToStepN              | 1.454 ms                  | 4.863 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240201 00:03:15.344025 3261692 parallel_pq_v2.h:79] insert failed, size(hashtable)=226
W20240201 00:03:15.449366 3261692 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
W20240201 00:03:15.570515 3261311 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=495, pq.top=495
[proc 3] 500 steps, total: 2.702, sample: 0.123, forward: 0.226, backward: 0.225, update: 0.059
[proc 0] 500 steps, total: 2.702, sample: 0.232, forward: 0.276, backward: 0.227, update: 0.085
[proc 2] 500 steps, total: 2.702, sample: 0.170, forward: 0.237, backward: 0.199, update: 0.063
[proc 1] 500 steps, total: 2.702, sample: 0.209, forward: 0.347, backward: 0.221, update: 0.087
Successfully xmh. training takes 14.83686637878418 seconds
before call kg_cache_controller.StopThreads()
W20240201 00:03:15.709317 3261311 grad_async_v2.h:84] call StopThreads. PID = 3260968
W20240201 00:03:15.709347 3261311 grad_base.h:212] before processOneStepNegThread_.join();
W20240201 00:03:15.709753 3261311 grad_base.h:214] after processOneStepNegThread_.join();
W20240201 00:03:15.709764 3261311 grad_async_v2.h:86] call GradProcessingBase::StopThreads.
W20240201 00:03:15.710100 3261311 grad_async_v2.h:105] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
