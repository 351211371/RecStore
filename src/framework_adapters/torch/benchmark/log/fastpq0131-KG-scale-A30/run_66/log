WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240201 01:10:37.133991 3382290 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_268', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=3, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=3, gpu=[0, 1, 2], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [3382290 sampler.py:454] Start PreSampling
WARNING [3382290 sampler.py:532] Before construct renumbering_dict
WARNING [3382290 sampler.py:555] PreSampling done
W20240201 01:10:39.246682 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240201 01:10:39.246837 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240201 01:10:39.246860 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240201 01:10:39.246882 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240201 01:10:39.246899 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240201 01:10:39.246922 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240201 01:10:39.246943 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240201 01:10:39.246966 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240201 01:10:39.246987 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240201 01:10:39.247009 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240201 01:10:39.247033 3382290 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240201 01:10:39.247056 3382290 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240201 01:10:39.247076 3382290 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240201 01:10:39.247185 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240201 01:10:39.247216 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240201 01:10:39.247236 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240201 01:10:39.247264 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240201 01:10:39.247292 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240201 01:10:39.247313 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240201 01:10:39.247328 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240201 01:10:39.247350 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240201 01:10:39.247376 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240201 01:10:39.247398 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240201 01:10:39.247422 3382290 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240201 01:10:39.247437 3382290 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240201 01:10:39.247449 3382290 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240201 01:10:39.247488 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240201 01:10:39.247509 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240201 01:10:39.247525 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240201 01:10:39.247541 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240201 01:10:39.247560 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240201 01:10:39.247578 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240201 01:10:39.247601 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240201 01:10:39.247619 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240201 01:10:39.247638 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240201 01:10:39.247658 3382290 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240201 01:10:39.247675 3382290 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240201 01:10:39.247689 3382290 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240201 01:10:39.247701 3382290 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240201 01:10:39.385145 3382290 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x10000e52e000 22.81 MB
W20240201 01:10:39.412191 3382290 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x10000fc00000 58.4 kB
{0: Graph(num_nodes=11296, num_edges=176344,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12898, num_edges=253277,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=12169, num_edges=314310,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 11296 N 176344 E
MertisPartition: part 1 has 12898 N 253277 E
MertisPartition: part 2 has 12169 N 314310 E
Rank0: cached key size 249
Rank1: cached key size 249
Rank2: cached key size 249
Before renumbering graph:  {'_ID': tensor([    0,     2,    10,  ...,  8580,   176, 12835]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 2, 2])}
After renumbering graph:  {'_ID': tensor([ 768,  837, 1115,  ..., 5597, 6279, 7317]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 2, 2])}
part_g: DGLGraph(num_nodes=11296, num_edges=176344,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=11296, num_edges=176344,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.299 seconds
[Rank1] pid = 3382504
INFO [3382290 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [3382504 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [3382290 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [3382504 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
W20240201 01:10:42.210529 3382570 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240201 01:10:42.210827 3382505 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240201 01:10:42.211398 3382570 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x10000fc14000 7.629 MB
W20240201 01:10:42.211447 3382505 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x1000103b7000 7.629 MB
W20240201 01:10:42.211599 3382505 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x100010b5a000 7.629 MB
W20240201 01:10:42.211613 3382570 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x1000112fd000 7.629 MB
W20240201 01:10:42.211676 3382505 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x100011aa0000 1.49 GB
W20240201 01:10:42.211711 3382505 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x100071083000 1.49 GB
W20240201 01:10:42.211723 3382570 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000d0666000 1.49 GB
W20240201 01:10:42.211773 3382505 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240201 01:10:42.212033 3382570 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x10012fc49000 1.49 GB
W20240201 01:10:42.212118 3382570 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
INFO [3382569 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [3382569 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
W20240201 01:10:42.215167 3382579 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [747, 400]; dev=2; size=1.14 MB
W20240201 01:10:42.218330 3382505 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240201 01:10:42.218452 3382570 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240201 01:10:42.220069 3382579 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x10018f232000 7.629 MB
W20240201 01:10:42.220278 3382579 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x10018f9d5000 7.629 MB
W20240201 01:10:42.220355 3382579 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x100190178000 1.49 GB
W20240201 01:10:42.220417 3382579 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1001ef75b000 1.49 GB
W20240201 01:10:42.220482 3382579 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240201 01:10:42.227679 3382579 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
[Rank2] pid = 3382569
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494), (1494, 2241)]
cudaHostRegister 0x10000e52e000
0: KnownLocalCachedEmbedding init done
WARNING [3382290 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x10000e52e000
1: KnownLocalCachedEmbedding init done
WARNING [3382504 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x10000e52e000
2: KnownLocalCachedEmbedding init done
WARNING [3382569 DistTensor.py:59] The tensor name already exists in the kvstore
I20240201 01:10:43.060990 3382579 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 3
I20240201 01:10:43.061028 3382570 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 3
I20240201 01:10:43.061087 3382505 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 3
W20240201 01:10:43.061765 3382570 grad_base.h:55] KGCacheController, config={
        "num_gpus": 3,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 0.01,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240201 01:10:43.061916 3382570 grad_base.h:184] Init GradProcessingBase done
I20240201 01:10:43.065133 3382570 grad_async_v2.h:42] Use main thread to update emb.
W20240201 01:10:43.065163 3382570 kg_controller.h:78] after init GradAsyncProcessingV2
I20240201 01:10:43.065167 3382570 kg_controller.h:84] Construct KGCacheController done
E20240201 01:10:43.310269 3382570 recstore.cc:66] init folly done
E20240201 01:10:43.310307 3382579 recstore.cc:66] init folly done
E20240201 01:10:43.310387 3382505 recstore.cc:66] init folly done
I20240201 01:10:43.310972 3382570 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240201 01:10:43.795629 3382890 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
E20240201 01:10:43.795960 3382890 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
I20240201 01:10:43.824615 3382570 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 3
I20240201 01:10:43.867056 3382505 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
I20240201 01:10:43.875135 3382579 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
E20240201 01:10:45.674525 3382747 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
W20240201 01:10:45.692966 3382890 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
E20240201 01:10:45.709715 3382747 grad_async_v2.h:404] Stalled in ProcessBackward: rank=0, step_no=1, sample_step_cpp_seen_[rank]=0
W20240201 01:10:45.743191 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=2, pq.top=2
E20240201 01:10:46.674015 3382914 parallel_pq_v2.h:79] insert failed, size(hashtable)=12596
W20240201 01:10:46.719838 3382890 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end5
W20240201 01:10:46.780270 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=37, pq.top=37
E20240201 01:10:47.674013 3382570 parallel_pq_v2.h:79] insert failed, size(hashtable)=348
W20240201 01:10:47.820386 3382890 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
W20240201 01:10:47.844229 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=69, pq.top=69
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 892.617 us                | 20.816 ms                 |
| Forward                   | 3.609 ms                  | 8.424 ms                  |
| Backward                  | 2.997 ms                  | 5.636 ms                  |
| Optimize                  | 1.653 ms                  | 3.482 ms                  |
| BarrierTimeBeforeRank0    | 25.149 us                 | 8.403 ms                  |
| AfterBackward             | 11.960 ms                 | 170.963 ms                |
| BlockToStepN              | 277.013 us                | 1.369 ms                  |
| OneStep                   | 22.956 ms                 | 183.675 ms                |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 228.750 us                | 3.154 ms                  |
| ProcessBack:Shuffle       | 1.235 ms                  | 1.536 ms                  |
| ProcessBack:UpdateCache   | 770.386 us                | 1.416 ms                  |
| ProcessBack:UpsertPq      | 8.563 ms                  | 14.008 ms                 |
| ProcessOneStep            | 11.941 ms                 | 170.921 ms                |
| BlockToStepN              | 256.797 us                | 4.888 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240201 01:10:48.674007 3382890 parallel_pq_v2.h:79] insert failed, size(hashtable)=313
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.868, sample: 0.228, forward: 1.045, backward: 0.541, update: 0.135
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.860, sample: 0.260, forward: 1.325, backward: 0.553, update: 0.146
train_sampler.Prefill()
-------Step 0-------
tensor([   89, 13870,   242, 10321,  9920,  1899, 11329, 14384, 13333,   585]) tensor([ 1115,  7807,  6282,  9917, 10525,  8431,  5290,  4302,  5501,  8606])
-------Step 1-------
tensor([   89, 13870,   242, 10321,  9920,  1899, 11329, 14384, 13333,   585]) tensor([ 1986,  6807,  8535,  2788,  9845,  9283,  8837, 14442, 14648, 13931])
-------Step 2-------
tensor([ 9231,  7731, 13774,   132, 13815,  4925,  6395,  5524,  8576,  1675]) tensor([6566, 6545,  706, 7594, 4367, 2990, 1611, 1089, 5812, 3980])
-------Step 3-------
tensor([ 9231,  7731, 13774,   132, 13815,  4925,  6395,  5524,  8576,  1675]) tensor([ 7637,  8312,  8880, 10818,  5972,  8218, 14032,  5669,  6937,  4826])
-------Step 4-------
tensor([13457,  6755,  8181,   225,  8260,  1181, 13778, 11144,   188,  4634]) tensor([12003,  5297,  2725,  5456,  6558,  2031, 10390,  1833,  5084,  9972])
-------Step 5-------
tensor([13457,  6755,  8181,   225,  8260,  1181, 13778, 11144,   188,  4634]) tensor([12674,  9681, 12550, 11346,  7506,  8246,  2919,  4757,  8751,  9482])
-------Step 6-------
tensor([ 6171,  8966,  1899,  2443, 12803,  7099,  2574,   199,   182,  7330]) tensor([12181,   560, 10026,  1613,  8035,  3923,  9794,  9510, 12742, 12791])
-------Step 7-------
tensor([ 6171,  8966,  1899,  2443, 12803,  7099,  2574,   199,   182,  7330]) tensor([14103,  7604,   117, 12279, 14523,  9613, 13854,  7791, 10900,  9778])
-------Step 8-------
tensor([ 1280,  8140,  5367, 11539,  5704,  1194,  1932, 13475,  8868,  7646]) tensor([ 7101,  9307,  7415,  4118,  2163, 12744,  8385,  5282,  7403,   613])
-------Step 9-------
tensor([ 1280,  8140,  5367, 11539,  5704,  1194,  1932, 13475,  8868,  7646]) tensor([ 6445,  2063,  1703, 13845,  7204,  8051, 12178,  4364,  7281, 12799])
before start barrier
start train
[proc 0] 100 steps, total: 4.910, sample: 0.287, forward: 1.460, backward: 0.563, update: 0.172
W20240201 01:10:48.847926 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=104, pq.top=104
W20240201 01:10:48.949208 3382890 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end7
E20240201 01:10:49.674019 3382892 parallel_pq_v2.h:79] insert failed, size(hashtable)=8666
W20240201 01:10:49.857066 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=141, pq.top=141
W20240201 01:10:50.028622 3382890 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
E20240201 01:10:50.674029 3382890 parallel_pq_v2.h:79] insert failed, size(hashtable)=14
W20240201 01:10:50.858240 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=177, pq.top=177
E20240201 01:10:50.885375 3382747 grad_async_v2.h:404] Stalled in ProcessBackward: rank=2, step_no=178, sample_step_cpp_seen_[rank]=177
W20240201 01:10:51.100859 3382890 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end3
[proc 2] 200 steps, total: 2.858, sample: 0.281, forward: 0.294, backward: 0.290, update: 0.123
[proc 1] 200 steps, total: 2.858, sample: 0.244, forward: 0.304, backward: 0.255, update: 0.142
[proc 0] 200 steps, total: 2.858, sample: 0.302, forward: 0.334, backward: 0.309, update: 0.162
E20240201 01:10:51.674645 3382890 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
W20240201 01:10:51.887015 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=210, pq.top=210
W20240201 01:10:52.227636 3382890 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end3
E20240201 01:10:52.674017 3382570 parallel_pq_v2.h:79] insert failed, size(hashtable)=12096
W20240201 01:10:52.905849 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=242, pq.top=242
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 898.987 us                | 19.814 ms                 |
| Forward                   | 3.428 ms                  | 5.106 ms                  |
| Backward                  | 2.910 ms                  | 5.822 ms                  |
| Optimize                  | 1.563 ms                  | 3.537 ms                  |
| BarrierTimeBeforeRank0    | 19.446 us                 | 8.525 ms                  |
| AfterBackward             | 10.803 ms                 | 170.963 ms                |
| BlockToStepN              | 496.566 us                | 6.101 ms                  |
| OneStep                   | 22.049 ms                 | 183.675 ms                |
+---------------------------+---------------------------+---------------------------+
W20240201 01:10:53.235703 3382890 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 258.388 us                | 4.634 ms                  |
| ProcessBack:Shuffle       | 1.206 ms                  | 1.643 ms                  |
| ProcessBack:UpdateCache   | 746.350 us                | 1.312 ms                  |
| ProcessBack:UpsertPq      | 7.515 ms                  | 14.648 ms                 |
| ProcessOneStep            | 11.031 ms                 | 126.863 ms                |
| BlockToStepN              | 476.377 us                | 5.348 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240201 01:10:53.674007 3382747 parallel_pq_v2.h:79] insert failed, size(hashtable)=840
W20240201 01:10:53.961422 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=275, pq.top=275
W20240201 01:10:54.238337 3382890 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end4
E20240201 01:10:54.674013 3382570 parallel_pq_v2.h:79] insert failed, size(hashtable)=144
[proc 1] 300 steps, total: 3.208, sample: 0.243, forward: 0.306, backward: 0.253, update: 0.154
[proc 0] 300 steps, total: 3.208, sample: 0.321, forward: 0.366, backward: 0.283, update: 0.188
[proc 2] 300 steps, total: 3.208, sample: 0.190, forward: 0.266, backward: 0.418, update: 0.119
W20240201 01:10:54.964437 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=305, pq.top=305
W20240201 01:10:55.240238 3382890 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
E20240201 01:10:55.674008 3382570 parallel_pq_v2.h:79] insert failed, size(hashtable)=1394
W20240201 01:10:55.976737 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=334, pq.top=334
W20240201 01:10:56.240968 3382890 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
E20240201 01:10:56.674031 3382915 parallel_pq_v2.h:79] insert failed, size(hashtable)=11956
W20240201 01:10:56.985970 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=363, pq.top=363
W20240201 01:10:57.256798 3382890 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
E20240201 01:10:57.674022 3382895 parallel_pq_v2.h:79] insert failed, size(hashtable)=10984
W20240201 01:10:58.047716 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=393, pq.top=393
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.145 ms                  | 22.412 ms                 |
| Forward                   | 3.634 ms                  | 5.409 ms                  |
| Backward                  | 2.918 ms                  | 5.643 ms                  |
| Optimize                  | 1.663 ms                  | 3.723 ms                  |
| BarrierTimeBeforeRank0    | 20.730 us                 | 13.218 ms                 |
| AfterBackward             | 13.791 ms                 | 126.545 ms                |
| BlockToStepN              | 721.069 us                | 4.933 ms                  |
| OneStep                   | 28.023 ms                 | 135.413 ms                |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 3.461, sample: 0.279, forward: 0.317, backward: 0.244, update: 0.136
[proc 2] 400 steps, total: 3.461, sample: 0.205, forward: 0.269, backward: 0.415, update: 0.116
[proc 0] 400 steps, total: 3.461, sample: 0.397, forward: 0.382, backward: 0.285, update: 0.175
W20240201 01:10:58.262372 3382890 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 321.528 us                | 3.004 ms                  |
| ProcessBack:Shuffle       | 1.270 ms                  | 1.983 ms                  |
| ProcessBack:UpdateCache   | 747.144 us                | 1.087 ms                  |
| ProcessBack:UpsertPq      | 9.723 ms                  | 16.345 ms                 |
| ProcessOneStep            | 14.009 ms                 | 126.507 ms                |
| BlockToStepN              | 723.085 us                | 5.348 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240201 01:10:58.674015 3382570 parallel_pq_v2.h:79] insert failed, size(hashtable)=819
W20240201 01:10:59.056224 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=424, pq.top=424
W20240201 01:10:59.262022 3382890 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
E20240201 01:10:59.674055 3382910 parallel_pq_v2.h:79] insert failed, size(hashtable)=5090
W20240201 01:11:00.079866 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=456, pq.top=456
W20240201 01:11:00.271603 3382890 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end4
E20240201 01:11:00.674007 3382570 parallel_pq_v2.h:79] insert failed, size(hashtable)=895
W20240201 01:11:01.109570 3382570 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=488, pq.top=488
W20240201 01:11:01.278028 3382890 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
[proc 0] 500 steps, total: 3.243, sample: 0.303, forward: 0.335, backward: 0.291, update: 0.155
[proc 1] 500 steps, total: 3.243, sample: 0.310, forward: 0.323, backward: 0.249, update: 0.152
[proc 2] 500 steps, total: 3.243, sample: 0.300, forward: 0.301, backward: 0.259, update: 0.131
Successfully xmh. training takes 17.680285215377808 seconds
before call kg_cache_controller.StopThreads()
W20240201 01:11:01.505386 3382570 grad_async_v2.h:84] call StopThreads. PID = 3382290
W20240201 01:11:01.505412 3382570 grad_base.h:212] before processOneStepNegThread_.join();
W20240201 01:11:01.505671 3382570 grad_base.h:214] after processOneStepNegThread_.join();
W20240201 01:11:01.505678 3382570 grad_async_v2.h:86] call GradProcessingBase::StopThreads.
W20240201 01:11:01.507417 3382570 grad_async_v2.h:105] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7efc11fb4810>
