WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240207 21:36:14.291888 372669 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='SimplE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/SimplE_FB15k_88', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, nr_background_threads=32, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [372669 sampler.py:454] Start PreSampling
WARNING [372669 sampler.py:532] Before construct renumbering_dict
WARNING [372669 sampler.py:555] PreSampling done
W20240207 21:36:17.221244 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240207 21:36:17.221366 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240207 21:36:17.221390 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240207 21:36:17.221408 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240207 21:36:17.221422 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240207 21:36:17.221438 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240207 21:36:17.221453 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240207 21:36:17.221473 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240207 21:36:17.221496 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240207 21:36:17.221511 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240207 21:36:17.221530 372669 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240207 21:36:17.221546 372669 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240207 21:36:17.221560 372669 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240207 21:36:17.221642 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240207 21:36:17.221663 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240207 21:36:17.221678 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240207 21:36:17.221705 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240207 21:36:17.221722 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240207 21:36:17.221737 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240207 21:36:17.221758 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240207 21:36:17.221776 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240207 21:36:17.221794 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240207 21:36:17.221815 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240207 21:36:17.221833 372669 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240207 21:36:17.221846 372669 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240207 21:36:17.221861 372669 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240207 21:36:17.221894 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240207 21:36:17.221915 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240207 21:36:17.221930 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240207 21:36:17.221946 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240207 21:36:17.221959 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240207 21:36:17.221974 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240207 21:36:17.221992 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240207 21:36:17.222005 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240207 21:36:17.222023 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240207 21:36:17.222036 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240207 21:36:17.222050 372669 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240207 21:36:17.222062 372669 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240207 21:36:17.222077 372669 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240207 21:36:17.222106 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240207 21:36:17.222126 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240207 21:36:17.222138 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240207 21:36:17.222154 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240207 21:36:17.222168 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240207 21:36:17.222182 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240207 21:36:17.222196 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240207 21:36:17.222213 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240207 21:36:17.222229 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240207 21:36:17.222244 372669 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240207 21:36:17.222259 372669 IPCTensor.h:369] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240207 21:36:17.222270 372669 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240207 21:36:17.222282 372669 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240207 21:36:17.337181 372669 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240207 21:36:17.364076 372669 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 186
Rank1: cached key size 186
Rank2: cached key size 186
Rank3: cached key size 186
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([ 889, 1070, 1104,  ..., 1953, 6764, 6270]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.101 seconds
[Rank1] pid = 372882
[Rank2] pid = 372947
INFO [372669 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [372882 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [373011 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [372947 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [373011 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [372947 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [372882 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240207 21:36:20.516240 373013 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_3 [747, 400]; dev=3; size=1.14 MB
W20240207 21:36:20.516743 372948 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [747, 400]; dev=2; size=1.14 MB
W20240207 21:36:20.517158 373013 IPCTensor.h:369] NewIPCTensor: input_keys_3 [1000000]0x100014876000 7.629 MB
W20240207 21:36:20.517257 372883 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240207 21:36:20.517498 373013 IPCTensor.h:369] NewIPCTensor: input_keys_neg_3 [1000000]0x100015019000 7.629 MB
W20240207 21:36:20.517624 373013 IPCTensor.h:369] NewIPCTensor: backward_grads_3 [1000000, 400]0x1000157bc000 1.49 GB
W20240207 21:36:20.517670 373013 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x100074d9f000 1.49 GB
W20240207 21:36:20.517722 373013 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240207 21:36:20.517853 372883 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x1000d4386000 7.629 MB
W20240207 21:36:20.518003 372883 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x1000d4b29000 7.629 MB
W20240207 21:36:20.518062 372883 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x1000d5a6f000 1.49 GB
W20240207 21:36:20.518062 372948 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x1000d52cc000 7.629 MB
W20240207 21:36:20.518103 372883 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x100135052000 1.49 GB
W20240207 21:36:20.518160 372883 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240207 21:36:20.518395 372948 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x100194635000 7.629 MB
W20240207 21:36:20.518563 372948 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x100194dd8000 1.49 GB
W20240207 21:36:20.518679 372948 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1001f43bb000 1.49 GB
INFO [372669 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240207 21:36:20.518776 372948 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240207 21:36:20.519829 373012 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240207 21:36:20.526993 372883 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240207 21:36:20.527048 372948 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240207 21:36:20.527117 373012 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x1002539a6000 7.629 MB
W20240207 21:36:20.527132 373013 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240207 21:36:20.527320 373012 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x100254149000 7.629 MB
W20240207 21:36:20.527415 373012 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x1002548ec000 1.49 GB
W20240207 21:36:20.527505 373012 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1002b3ecf000 1.49 GB
W20240207 21:36:20.527562 373012 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240207 21:36:20.541254 373012 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [372947 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [373011 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [372882 DistTensor.py:59] The tensor name already exists in the kvstore
[Rank3] pid = 373011
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494), (1494, 2241), (2241, 2988)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [372669 DistTensor.py:59] The tensor name already exists in the kvstore
I20240207 21:36:22.147472 373012 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240207 21:36:22.147717 372948 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240207 21:36:22.147833 373013 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240207 21:36:22.147977 372883 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240207 21:36:22.149438 373012 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 0.01,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240207 21:36:22.149581 373012 grad_base.h:184] Init GradProcessingBase done
I20240207 21:36:22.154299 373012 grad_async_v2.h:42] Use main thread to update emb.
W20240207 21:36:22.154345 373012 kg_controller.h:78] after init GradAsyncProcessingV2
I20240207 21:36:22.154350 373012 kg_controller.h:84] Construct KGCacheController done
E20240207 21:36:23.563614 372883 recstore.cc:66] init folly done
E20240207 21:36:23.563673 373013 recstore.cc:66] init folly done
E20240207 21:36:23.563916 372948 recstore.cc:66] init folly done
E20240207 21:36:23.564078 373012 recstore.cc:66] init folly done
I20240207 21:36:23.565316 373012 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240207 21:36:24.278807 373502 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
E20240207 21:36:24.279199 373502 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
I20240207 21:36:24.296553 372948 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240207 21:36:24.301645 372883 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240207 21:36:24.304132 373013 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240207 21:36:24.312839 373012 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240207 21:36:26.561363 373308 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
W20240207 21:36:26.569756 373502 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
W20240207 21:36:26.586618 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=2, pq.top=0
E20240207 21:36:26.988101 373012 grad_async_v2.h:404] Stalled in ProcessBackward: rank=2, step_no=23, sample_step_cpp_seen_[rank]=22
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 917.713 us                | 10.512 ms                 |
| Forward                   | 2.945 ms                  | 799.237 ms                |
| Backward                  | 2.523 ms                  | 305.065 ms                |
| Optimize                  | 845.792 us                | 57.320 ms                 |
| BarrierTimeBeforeRank0    | 499.933 us                | 50.589 ms                 |
| AfterBackward             | 8.364 ms                  | 1.041 s                   |
| BlockToStepN              | 307.237 us                | 2.663 ms                  |
| OneStep                   | 17.679 ms                 | 2.256 s                   |
+---------------------------+---------------------------+---------------------------+
E20240207 21:36:27.561046 373308 parallel_pq_v2.h:79] insert failed, size(hashtable)=289
W20240207 21:36:27.570099 373502 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
W20240207 21:36:27.603106 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=51, pq.top=51
E20240207 21:36:28.561067 373502 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 209.844 us                | 1.866 ms                  |
| ProcessBack:Shuffle       | 1.641 ms                  | 2.228 ms                  |
| ProcessBack:UpdateCache   | 1.424 ms                  | 3.140 ms                  |
| ProcessBack:UpsertPq      | 6.321 ms                  | 11.472 ms                 |
| ProcessOneStep            | 9.857 ms                  | 90.366 ms                 |
| BlockToStepN              | 687.742 us                | 2.635 ms                  |
+---------------------------+---------------------------+---------------------------+
W20240207 21:36:28.577661 373502 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
W20240207 21:36:28.622715 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=97, pq.top=97
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.392, sample: 0.171, forward: 1.015, backward: 0.638, update: 0.119
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.390, sample: 0.146, forward: 1.005, backward: 0.639, update: 0.106
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.398, sample: 0.155, forward: 1.061, backward: 0.632, update: 0.109
train_sampler.Prefill()
-------Step 0-------
tensor([ 9353,  4273,  9926,  7753,  6831,  4833,   667,  3920, 11347,  8330]) tensor([ 1104,  7390, 10016,  3132,  8785,  8834, 12471,  9203,  6830,  9018])
-------Step 1-------
tensor([ 9353,  4273,  9926,  7753,  6831,  4833,   667,  3920, 11347,  8330]) tensor([  414,  9343, 12326,  1288,  9075,  9290,  1526, 11501,  8222, 10428])
-------Step 2-------
tensor([ 6490, 14875,  5199,  5449,  4392,  9898, 10215, 10724, 14644,    36]) tensor([8468, 3339, 1939, 8282, 4663,  704, 6313, 3752, 8219, 4628])
-------Step 3-------
tensor([ 6490, 14875,  5199,  5449,  4392,  9898, 10215, 10724, 14644,    36]) tensor([ 6021, 14700, 10793,  9468,  7989,  1942,  8361, 13208, 12588, 10440])
-------Step 4-------
tensor([ 9395,  1924,  3985,   106,  8207, 12405,  6434,  8354, 11830,  7925]) tensor([13955,  3428,  4526, 10988,  1772,  2175, 13493,  6215,  9992,  7712])
-------Step 5-------
tensor([ 9395,  1924,  3985,   106,  8207, 12405,  6434,  8354, 11830,  7925]) tensor([ 6914,  8878,  4953, 12223, 11346,  5969,  5525,  3650,  9458, 12153])
-------Step 6-------
tensor([13675,  8655,  7904,  8175,  1446,  7569,  7040,  2162, 12606,    49]) tensor([ 8823,  4424,  2674, 11499,  6092,   603,  4299, 13013, 10685,  3985])
-------Step 7-------
tensor([13675,  8655,  7904,  8175,  1446,  7569,  7040,  2162, 12606,    49]) tensor([ 5586,  8558,  9078, 11344,   531,   168, 11479, 13144,  3972, 10167])
-------Step 8-------
tensor([  117, 14729, 10752,  9816,  4657,  7904, 12513,  5740,  3181,  1857]) tensor([12817,  4325, 13211, 14138,  3102,  8120,  5107,   421,  7552, 14433])
-------Step 9-------
tensor([  117, 14729, 10752,  9816,  4657,  7904, 12513,  5740,  3181,  1857]) tensor([12060, 10136, 14236,   495, 13517, 10323,  6819,  1705,  7995, 12068])
before start barrier
start train
[proc 0] 100 steps, total: 4.381, sample: 0.177, forward: 1.066, backward: 0.532, update: 0.138
E20240207 21:36:29.561035 373530 parallel_pq_v2.h:79] insert failed, size(hashtable)=4732
W20240207 21:36:29.580000 373502 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
W20240207 21:36:29.639483 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=140, pq.top=140
E20240207 21:36:30.561009 373502 parallel_pq_v2.h:79] insert failed, size(hashtable)=134
W20240207 21:36:30.583220 373502 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
W20240207 21:36:30.726258 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=184, pq.top=184
[proc 3] 200 steps, total: 2.451, sample: 0.153, forward: 0.236, backward: 0.310, update: 0.067
[proc 1] 200 steps, total: 2.451, sample: 0.188, forward: 0.255, backward: 0.309, update: 0.062
[proc 0] 200 steps, total: 2.451, sample: 0.238, forward: 0.277, backward: 0.278, update: 0.078
[proc 2] 200 steps, total: 2.451, sample: 0.161, forward: 0.238, backward: 0.245, update: 0.077
E20240207 21:36:31.561013 373308 parallel_pq_v2.h:79] insert failed, size(hashtable)=74
W20240207 21:36:31.592092 373502 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
W20240207 21:36:31.746783 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=225, pq.top=225
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.152 ms                  | 11.212 ms                 |
| Forward                   | 2.737 ms                  | 5.651 ms                  |
| Backward                  | 2.328 ms                  | 6.950 ms                  |
| Optimize                  | 835.526 us                | 1.350 ms                  |
| BarrierTimeBeforeRank0    | 422.753 us                | 5.713 ms                  |
| AfterBackward             | 12.424 ms                 | 19.405 ms                 |
| BlockToStepN              | 977.875 us                | 3.039 ms                  |
| OneStep                   | 22.394 ms                 | 37.841 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240207 21:36:32.561015 373502 parallel_pq_v2.h:79] insert failed, size(hashtable)=27
W20240207 21:36:32.592501 373502 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
W20240207 21:36:32.751897 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=268, pq.top=268
[proc 3] 300 steps, total: 2.358, sample: 0.158, forward: 0.252, backward: 0.224, update: 0.062
[proc 1] 300 steps, total: 2.358, sample: 0.167, forward: 0.265, backward: 0.262, update: 0.064
[proc 2] 300 steps, total: 2.358, sample: 0.159, forward: 0.255, backward: 0.238, update: 0.074
[proc 0] 300 steps, total: 2.358, sample: 0.221, forward: 0.276, backward: 0.243, update: 0.073
E20240207 21:36:33.561007 373502 parallel_pq_v2.h:79] insert failed, size(hashtable)=23
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 327.980 us                | 2.986 ms                  |
| ProcessBack:Shuffle       | 1.816 ms                  | 2.228 ms                  |
| ProcessBack:UpdateCache   | 1.543 ms                  | 3.140 ms                  |
| ProcessBack:UpsertPq      | 7.213 ms                  | 12.667 ms                 |
| ProcessOneStep            | 12.814 ms                 | 17.679 ms                 |
| BlockToStepN              | 986.510 us                | 2.908 ms                  |
+---------------------------+---------------------------+---------------------------+
W20240207 21:36:33.595263 373502 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
W20240207 21:36:33.760133 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=311, pq.top=311
E20240207 21:36:34.561110 373513 parallel_pq_v2.h:79] insert failed, size(hashtable)=5731
W20240207 21:36:34.599272 373502 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
W20240207 21:36:34.769673 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=351, pq.top=351
E20240207 21:36:35.561012 373520 parallel_pq_v2.h:79] insert failed, size(hashtable)=1649
W20240207 21:36:35.599537 373502 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end4
W20240207 21:36:35.853086 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=393, pq.top=393
[proc 3] 400 steps, total: 2.534, sample: 0.163, forward: 0.253, backward: 0.231, update: 0.061
[proc 2] 400 steps, total: 2.534, sample: 0.145, forward: 0.249, backward: 0.245, update: 0.069
[proc 0] 400 steps, total: 2.534, sample: 0.227, forward: 0.269, backward: 0.332, update: 0.073
[proc 1] 400 steps, total: 2.534, sample: 0.148, forward: 0.250, backward: 0.228, update: 0.069
E20240207 21:36:36.561010 373308 parallel_pq_v2.h:79] insert failed, size(hashtable)=717
W20240207 21:36:36.599886 373502 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
W20240207 21:36:36.875908 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=431, pq.top=431
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.257 ms                  | 11.122 ms                 |
| Forward                   | 2.785 ms                  | 4.521 ms                  |
| Backward                  | 2.500 ms                  | 6.747 ms                  |
| Optimize                  | 832.398 us                | 1.398 ms                  |
| BarrierTimeBeforeRank0    | 23.942 us                 | 4.467 ms                  |
| AfterBackward             | 13.366 ms                 | 17.588 ms                 |
| BlockToStepN              | 1.332 ms                  | 3.541 ms                  |
| OneStep                   | 23.487 ms                 | 35.700 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240207 21:36:37.563598 373012 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
W20240207 21:36:37.613471 373502 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end7
W20240207 21:36:37.887001 373012 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=468, pq.top=468
E20240207 21:36:38.563010 373517 parallel_pq_v2.h:79] insert failed, size(hashtable)=9316
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 416.663 us                | 2.922 ms                  |
| ProcessBack:Shuffle       | 1.859 ms                  | 2.187 ms                  |
| ProcessBack:UpdateCache   | 1.587 ms                  | 2.494 ms                  |
| ProcessBack:UpsertPq      | 7.884 ms                  | 12.642 ms                 |
| ProcessOneStep            | 13.402 ms                 | 17.502 ms                 |
| BlockToStepN              | 1.387 ms                  | 4.224 ms                  |
+---------------------------+---------------------------+---------------------------+
W20240207 21:36:38.617659 373502 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
[proc 1] 500 steps, total: 2.665, sample: 0.148, forward: 0.242, backward: 0.322, update: 0.065
[proc 3] 500 steps, total: 2.665, sample: 0.159, forward: 0.245, backward: 0.217, update: 0.063
[proc 2] 500 steps, total: 2.665, sample: 0.170, forward: 0.241, backward: 0.247, update: 0.064
[proc 0] 500 steps, total: 2.665, sample: 0.231, forward: 0.276, backward: 0.312, update: 0.080
Successfully xmh. training takes 14.389576196670532 seconds
before call kg_cache_controller.StopThreads()
W20240207 21:36:38.702456 373012 grad_async_v2.h:84] call StopThreads. PID = 372669
W20240207 21:36:38.702481 373012 grad_base.h:212] before processOneStepNegThread_.join();
W20240207 21:36:38.702710 373012 grad_base.h:214] after processOneStepNegThread_.join();
W20240207 21:36:38.702719 373012 grad_async_v2.h:86] call GradProcessingBase::StopThreads.
W20240207 21:36:38.703732 373012 grad_async_v2.h:105] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7ff2f967b2d0>
