WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240207 22:07:18.564455 431634 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='SimplE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/SimplE_FB15k_118', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='CppAsyncV2', L=10, nr_background_threads=32, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [431634 sampler.py:454] Start PreSampling
WARNING [431634 sampler.py:532] Before construct renumbering_dict
WARNING [431634 sampler.py:555] PreSampling done
W20240207 22:07:22.091289 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240207 22:07:22.091455 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240207 22:07:22.091481 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240207 22:07:22.091499 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240207 22:07:22.091516 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240207 22:07:22.091529 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240207 22:07:22.091545 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240207 22:07:22.091569 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240207 22:07:22.091585 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240207 22:07:22.091606 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240207 22:07:22.091626 431634 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240207 22:07:22.091643 431634 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240207 22:07:22.091658 431634 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240207 22:07:22.091751 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240207 22:07:22.092530 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240207 22:07:22.092562 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240207 22:07:22.092595 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240207 22:07:22.092622 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240207 22:07:22.092638 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240207 22:07:22.092660 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240207 22:07:22.092679 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240207 22:07:22.092696 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240207 22:07:22.092720 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240207 22:07:22.092741 431634 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240207 22:07:22.092761 431634 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240207 22:07:22.092773 431634 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240207 22:07:22.092849 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240207 22:07:22.092873 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240207 22:07:22.092892 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240207 22:07:22.092909 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240207 22:07:22.092927 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240207 22:07:22.092942 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240207 22:07:22.092963 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240207 22:07:22.092981 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240207 22:07:22.093001 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240207 22:07:22.093019 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240207 22:07:22.093036 431634 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240207 22:07:22.093050 431634 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240207 22:07:22.093060 431634 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240207 22:07:22.093098 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240207 22:07:22.093115 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240207 22:07:22.093132 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240207 22:07:22.093145 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240207 22:07:22.093163 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240207 22:07:22.093179 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240207 22:07:22.093196 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240207 22:07:22.093214 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240207 22:07:22.093230 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240207 22:07:22.093246 431634 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240207 22:07:22.093261 431634 IPCTensor.h:369] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240207 22:07:22.093274 431634 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240207 22:07:22.093288 431634 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240207 22:07:22.247545 431634 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240207 22:07:22.274539 431634 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1601, 1795, 1878,  ..., 2583, 6113, 8006]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.741 seconds
[Rank1] pid = 431849
[Rank2] pid = 431914
INFO [431634 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [431849 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [431978 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [431914 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [431914 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240207 22:07:24.654765 431915 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [1495, 400]; dev=2; size=2.281 MB
W20240207 22:07:24.655359 431915 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x100014876000 7.629 MB
W20240207 22:07:24.655522 431915 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x100015019000 7.629 MB
W20240207 22:07:24.655575 431915 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x1000157bc000 1.49 GB
W20240207 22:07:24.655613 431915 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x100074d9f000 1.49 GB
W20240207 22:07:24.655651 431915 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240207 22:07:24.657580 431915 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
INFO [431849 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240207 22:07:24.661070 431850 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [1495, 400]; dev=1; size=2.281 MB
INFO [431634 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [431978 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240207 22:07:24.661511 431850 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x1000d4388000 7.629 MB
W20240207 22:07:24.661633 431850 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x1000d4b2b000 7.629 MB
W20240207 22:07:24.661679 431850 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x1000d52ce000 1.49 GB
W20240207 22:07:24.661716 431850 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1001348b1000 1.49 GB
W20240207 22:07:24.661756 431850 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240207 22:07:24.662156 431979 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [1495, 400]; dev=0; size=2.281 MB
W20240207 22:07:24.662671 431980 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_3 [1495, 400]; dev=3; size=2.281 MB
W20240207 22:07:24.664556 431850 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240207 22:07:24.664597 431979 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x100193e98000 7.629 MB
W20240207 22:07:24.664711 431979 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x10019463d000 7.629 MB
W20240207 22:07:24.664752 431980 IPCTensor.h:369] NewIPCTensor: input_keys_3 [1000000]0x100194de0000 7.629 MB
W20240207 22:07:24.664769 431979 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x100195583000 1.49 GB
W20240207 22:07:24.664817 431979 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1001f4b66000 1.49 GB
W20240207 22:07:24.664860 431979 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240207 22:07:24.664901 431980 IPCTensor.h:369] NewIPCTensor: input_keys_neg_3 [1000000]0x100254149000 7.629 MB
W20240207 22:07:24.664954 431980 IPCTensor.h:369] NewIPCTensor: backward_grads_3 [1000000, 400]0x1002548ec000 1.49 GB
W20240207 22:07:24.664996 431980 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1002b3ecf000 1.49 GB
W20240207 22:07:24.665024 431980 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240207 22:07:24.670480 431979 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240207 22:07:24.670527 431980 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
[Rank3] pid = 431978
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1495), (1495, 2990), (2990, 4485), (4485, 5980)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [431634 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [431914 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [431978 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [431849 DistTensor.py:59] The tensor name already exists in the kvstore
I20240207 22:07:25.846562 431850 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240207 22:07:25.846616 431979 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240207 22:07:25.846777 431915 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240207 22:07:25.846947 431980 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240207 22:07:25.848136 431979 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 0.01,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.1,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240207 22:07:25.848423 431979 grad_base.h:184] Init GradProcessingBase done
I20240207 22:07:25.851785 431979 grad_async_v2.h:42] Use main thread to update emb.
W20240207 22:07:25.851814 431979 kg_controller.h:78] after init GradAsyncProcessingV2
I20240207 22:07:25.851819 431979 kg_controller.h:84] Construct KGCacheController done
E20240207 22:07:26.218793 431980 recstore.cc:66] init folly done
E20240207 22:07:26.218900 431850 recstore.cc:66] init folly done
E20240207 22:07:26.219178 431979 recstore.cc:66] init folly done
E20240207 22:07:26.219264 431915 recstore.cc:66] init folly done
I20240207 22:07:26.221983 431979 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240207 22:07:26.950018 432355 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
E20240207 22:07:26.950368 432355 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
I20240207 22:07:26.972493 431979 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240207 22:07:26.976846 431850 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240207 22:07:26.981971 431980 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240207 22:07:26.993896 431915 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240207 22:07:29.216466 431979 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
W20240207 22:07:29.225263 432355 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
W20240207 22:07:29.411532 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=11, pq.top=11
E20240207 22:07:30.216037 432377 parallel_pq_v2.h:79] insert failed, size(hashtable)=6037
W20240207 22:07:30.232182 432355 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
W20240207 22:07:30.426666 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=62, pq.top=62
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 836.867 us                | 10.910 ms                 |
| Forward                   | 2.533 ms                  | 4.788 ms                  |
| Backward                  | 2.833 ms                  | 6.439 ms                  |
| Optimize                  | 924.492 us                | 1.440 ms                  |
| BarrierTimeBeforeRank0    | 30.959 us                 | 2.599 ms                  |
| AfterBackward             | 9.949 ms                  | 15.755 ms                 |
| BlockToStepN              | 507.578 us                | 1.871 ms                  |
| OneStep                   | 19.876 ms                 | 30.860 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240207 22:07:31.216008 431979 parallel_pq_v2.h:79] insert failed, size(hashtable)=431
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 224.855 us                | 1.689 ms                  |
| ProcessBack:Shuffle       | 1.768 ms                  | 3.726 ms                  |
| ProcessBack:UpdateCache   | 1.523 ms                  | 2.486 ms                  |
| ProcessBack:UpsertPq      | 5.788 ms                  | 10.680 ms                 |
| ProcessOneStep            | 10.316 ms                 | 15.735 ms                 |
| BlockToStepN              | 471.979 us                | 1.834 ms                  |
+---------------------------+---------------------------+---------------------------+
W20240207 22:07:31.242041 432355 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.278, sample: 0.162, forward: 1.008, backward: 0.561, update: 0.128
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.283, sample: 0.175, forward: 1.043, backward: 0.496, update: 0.113
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.266, sample: 0.169, forward: 1.038, backward: 0.630, update: 0.110
train_sampler.Prefill()
-------Step 0-------
tensor([ 7834,  4102,  9433,  7237,  7742,  4491,  9583,  4909, 10514,   228]) tensor([ 1878,  7149,  9518,  1270,  7421,  7464, 12127,  7748,  8667,  1241])
-------Step 1-------
tensor([ 7834,  4102,  9433,  7237,  7742,  4491,  9583,  4909, 10514,   228]) tensor([ 6741, 11783, 14633,  1762, 12123, 11567,  2380, 11584,  9435, 10344])
-------Step 2-------
tensor([ 5772, 12990,  6972,  5350,  5804, 11258, 12845,  9717, 11478,   264]) tensor([10170,  4061,  2596, 10093,  6328,  1329,  8274,  5008, 10035,  6098])
-------Step 3-------
tensor([ 5772, 12990,  6972,  5350,  5804, 11258, 12845,  9717, 11478,   264]) tensor([ 7670, 13093,  8643, 13852,  6858,  2168, 10401, 11092, 11297, 12455])
-------Step 4-------
tensor([11503,  2676,  3682,    10,   706,   358,    53, 10229,  9947, 10161]) tensor([10325,  4160,  3737, 14674,  2255,  2734, 10567,  5961, 11125,  6673])
-------Step 5-------
tensor([11503,  2676,  3682,    10,   706,   358,    53, 10229,  9947, 10161]) tensor([ 6105, 10336,  5398,  9643,  9384,  9014,  5498,  3886,  7400, 13000])
-------Step 6-------
tensor([11142, 10466,  6578,  6971,  2029,  7938,  7215,  3122, 12264,    49]) tensor([ 7447,  4812,  3441, 12985,  7533,  1326,  4247, 11407, 10462,  3682])
-------Step 7-------
tensor([11142, 10466,  6578,  6971,  2029,  7938,  7215,  3122, 12264,    49]) tensor([ 6083,  9782,  8626,  9571,  1117,   360, 13115, 12817,  4532,   816])
-------Step 8-------
tensor([ 3146, 13786, 13421,  9823,  4858,  6578, 12686,  5929,  3681,  2107]) tensor([13143,   949, 12918, 10579,  3769,   690,  7781,  1081,  9242, 14571])
-------Step 9-------
tensor([ 3146, 13786, 13421,  9823,  4858,  6578, 12686,  5929,  3681,  2107]) tensor([13723, 10486, 12268,   933, 11725,  9361,  6039,  2411,  6400, 11771])
before start barrier
start train
[proc 0] 100 steps, total: 4.288, sample: 0.178, forward: 1.036, backward: 0.557, update: 0.125
W20240207 22:07:31.431576 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=108, pq.top=108
E20240207 22:07:32.216015 431979 parallel_pq_v2.h:79] insert failed, size(hashtable)=174
W20240207 22:07:32.245128 432355 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
W20240207 22:07:32.437739 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=156, pq.top=156
E20240207 22:07:33.216009 431979 parallel_pq_v2.h:79] insert failed, size(hashtable)=93
W20240207 22:07:33.245568 432355 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
[proc 1] 200 steps, total: 2.124, sample: 0.162, forward: 0.232, backward: 0.216, update: 0.065
[proc 3] 200 steps, total: 2.124, sample: 0.163, forward: 0.233, backward: 0.215, update: 0.069
[proc 2] 200 steps, total: 2.124, sample: 0.184, forward: 0.254, backward: 0.245, update: 0.066
[proc 0] 200 steps, total: 2.124, sample: 0.220, forward: 0.263, backward: 0.243, update: 0.079
W20240207 22:07:33.448021 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=203, pq.top=203
E20240207 22:07:34.216022 432363 parallel_pq_v2.h:79] insert failed, size(hashtable)=5209
W20240207 22:07:34.246296 432355 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
W20240207 22:07:34.461159 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=250, pq.top=250
E20240207 22:07:35.216015 432360 parallel_pq_v2.h:79] insert failed, size(hashtable)=3638
W20240207 22:07:35.253908 432355 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end7
W20240207 22:07:35.481561 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=296, pq.top=296
[proc 2] 300 steps, total: 2.183, sample: 0.164, forward: 0.257, backward: 0.235, update: 0.065
[proc 1] 300 steps, total: 2.183, sample: 0.163, forward: 0.241, backward: 0.219, update: 0.065
[proc 0] 300 steps, total: 2.183, sample: 0.209, forward: 0.267, backward: 0.235, update: 0.077
[proc 3] 300 steps, total: 2.183, sample: 0.147, forward: 0.226, backward: 0.211, update: 0.064
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.057 ms                  | 10.599 ms                 |
| Forward                   | 2.709 ms                  | 3.487 ms                  |
| Backward                  | 2.455 ms                  | 5.892 ms                  |
| Optimize                  | 878.872 us                | 1.379 ms                  |
| BarrierTimeBeforeRank0    | 18.077 us                 | 2.108 ms                  |
| AfterBackward             | 11.730 ms                 | 14.687 ms                 |
| BlockToStepN              | 915.364 us                | 2.203 ms                  |
| OneStep                   | 20.814 ms                 | 30.488 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240207 22:07:36.216023 432366 parallel_pq_v2.h:79] insert failed, size(hashtable)=5131
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 309.959 us                | 2.732 ms                  |
| ProcessBack:Shuffle       | 1.939 ms                  | 2.990 ms                  |
| ProcessBack:UpdateCache   | 1.610 ms                  | 1.943 ms                  |
| ProcessBack:UpsertPq      | 6.266 ms                  | 10.236 ms                 |
| ProcessOneStep            | 11.736 ms                 | 14.665 ms                 |
| BlockToStepN              | 896.417 us                | 2.149 ms                  |
+---------------------------+---------------------------+---------------------------+
W20240207 22:07:36.261669 432355 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
W20240207 22:07:36.528668 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=343, pq.top=343
E20240207 22:07:37.216174 432381 parallel_pq_v2.h:79] insert failed, size(hashtable)=12099
W20240207 22:07:37.265022 432355 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
W20240207 22:07:37.537324 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=386, pq.top=386
[proc 3] 400 steps, total: 2.304, sample: 0.133, forward: 0.213, backward: 0.211, update: 0.067
[proc 1] 400 steps, total: 2.304, sample: 0.162, forward: 0.237, backward: 0.218, update: 0.064
[proc 2] 400 steps, total: 2.304, sample: 0.165, forward: 0.261, backward: 0.244, update: 0.062
[proc 0] 400 steps, total: 2.304, sample: 0.218, forward: 0.267, backward: 0.235, update: 0.078
E20240207 22:07:38.216116 432355 parallel_pq_v2.h:79] insert failed, size(hashtable)=141
W20240207 22:07:38.265487 432355 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end7
W20240207 22:07:38.539508 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=428, pq.top=428
E20240207 22:07:39.216015 432371 parallel_pq_v2.h:79] insert failed, size(hashtable)=3230
W20240207 22:07:39.268445 432355 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
W20240207 22:07:39.549180 431979 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=470, pq.top=470
E20240207 22:07:40.216014 431979 parallel_pq_v2.h:79] insert failed, size(hashtable)=1799
W20240207 22:07:40.277098 432355 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
[proc 3] 500 steps, total: 2.439, sample: 0.143, forward: 0.220, backward: 0.209, update: 0.065
[proc 1] 500 steps, total: 2.439, sample: 0.161, forward: 0.236, backward: 0.216, update: 0.064
[proc 2] 500 steps, total: 2.439, sample: 0.185, forward: 0.265, backward: 0.226, update: 0.063
[proc 0] 500 steps, total: 2.439, sample: 0.229, forward: 0.273, backward: 0.238, update: 0.078
Successfully xmh. training takes 13.33780550956726 seconds
before call kg_cache_controller.StopThreads()
W20240207 22:07:40.310298 431979 grad_async_v2.h:84] call StopThreads. PID = 431634
W20240207 22:07:40.310325 431979 grad_base.h:212] before processOneStepNegThread_.join();
W20240207 22:07:40.310540 431979 grad_base.h:214] after processOneStepNegThread_.join();
W20240207 22:07:40.310547 431979 grad_async_v2.h:86] call GradProcessingBase::StopThreads.
W20240207 22:07:40.311179 431979 grad_async_v2.h:105] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.147 ms                  | 10.044 ms                 |
| Forward                   | 2.730 ms                  | 3.447 ms                  |
| Backward                  | 2.435 ms                  | 5.209 ms                  |
| Optimize                  | 864.961 us                | 1.397 ms                  |
| BarrierTimeBeforeRank0    | 18.259 us                 | 5.242 ms                  |
| AfterBackward             | 12.362 ms                 | 15.129 ms                 |
| BlockToStepN              | 1.244 ms                  | 3.970 ms                  |
| OneStep                   | 21.624 ms                 | 32.228 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 412.711 us                | 3.397 ms                  |
| ProcessBack:Shuffle       | 1.958 ms                  | 2.615 ms                  |
| ProcessBack:UpdateCache   | 1.621 ms                  | 1.941 ms                  |
| ProcessBack:UpsertPq      | 6.693 ms                  | 10.871 ms                 |
| ProcessOneStep            | 12.339 ms                 | 15.106 ms                 |
| BlockToStepN              | 1.188 ms                  | 3.914 ms                  |
+---------------------------+---------------------------+---------------------------+
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7fae9fe3c0d0>
