WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240201 01:13:37.658944 3387552 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_271', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=3, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=3, gpu=[0, 1, 2], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [3387552 sampler.py:454] Start PreSampling
WARNING [3387552 sampler.py:532] Before construct renumbering_dict
WARNING [3387552 sampler.py:555] PreSampling done
W20240201 01:13:40.554107 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240201 01:13:40.554352 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240201 01:13:40.554406 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240201 01:13:40.554430 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240201 01:13:40.554461 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240201 01:13:40.554495 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240201 01:13:40.554543 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240201 01:13:40.554585 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240201 01:13:40.554613 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240201 01:13:40.554641 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240201 01:13:40.554689 3387552 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240201 01:13:40.554711 3387552 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240201 01:13:40.554739 3387552 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240201 01:13:40.554836 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240201 01:13:40.554883 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240201 01:13:40.554909 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240201 01:13:40.554983 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240201 01:13:40.555011 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240201 01:13:40.555030 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240201 01:13:40.555068 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240201 01:13:40.555114 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240201 01:13:40.555148 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240201 01:13:40.555192 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240201 01:13:40.555212 3387552 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240201 01:13:40.555228 3387552 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240201 01:13:40.555243 3387552 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240201 01:13:40.555287 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240201 01:13:40.555310 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240201 01:13:40.555328 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240201 01:13:40.555366 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240201 01:13:40.555395 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240201 01:13:40.555415 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240201 01:13:40.555435 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240201 01:13:40.555464 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240201 01:13:40.555507 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240201 01:13:40.555532 3387552 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240201 01:13:40.555557 3387552 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240201 01:13:40.555574 3387552 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240201 01:13:40.555590 3387552 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
{0: Graph(num_nodes=11296, num_edges=176344,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12898, num_edges=253277,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=12169, num_edges=314310,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 11296 N 176344 E
MertisPartition: part 1 has 12898 N 253277 E
MertisPartition: part 2 has 12169 N 314310 E
Rank0: cached key size 249
Rank1: cached key size 249
Rank2: cached key size 249
Before renumbering graph:  {'_ID': tensor([    0,     2,    10,  ...,  8580,   176, 12835]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 2, 2])}
After renumbering graph:  {'_ID': tensor([ 758,  826, 1058,  ..., 6147, 6031, 7798]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 2, 2])}
part_g: DGLGraph(num_nodes=11296, num_edges=176344,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=11296, num_edges=176344,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.076 seconds
[Rank1] pid = 3387766
INFO [3387552 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [3387831 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [3387831 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [3387552 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [3387766 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [3387766 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
E20240201 01:13:42.593768 3387767 recstore.cc:66] init folly done
E20240201 01:13:42.593767 3387857 recstore.cc:66] init folly done
E20240201 01:13:42.593801 3387832 recstore.cc:66] init folly done
I20240201 01:13:42.634435 3387767 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 3
I20240201 01:13:42.642879 3387832 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
I20240201 01:13:42.647351 3387857 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
[Rank2] pid = 3387831
train_sampler.Prefill()
-------Step 0-------
tensor([  157, 14301,    33, 11172, 10425,  1862, 11652, 12300, 13454,   568]) tensor([ 1058,  7984,  5469, 10650, 11314,  8218,  5834,  3328,  5030,  9721])
-------Step 1-------
tensor([  157, 14301,    33, 11172, 10425,  1862, 11652, 12300, 13454,   568]) tensor([ 2010,  7015,  8924,  2874, 10668,  9574,  8513, 12344, 14716, 14694])
-------Step 2-------
tensor([ 6854,  7986, 14293,    80, 14478,  4878,  6669,  5913,  7835,  1682]) tensor([5122, 7147,  718, 8118, 3364, 3073, 1600, 1080, 5546, 4437])
-------Step 3-------
tensor([ 6854,  7986, 14293,    80, 14478,  4878,  6669,  5913,  7835,  1682]) tensor([ 7805,  8311,  9995, 10024,  6820,  8220, 14720,  6372,  7500,  5003])
-------Step 4-------
tensor([12427,  6695,  8535,    44,  8374,  1209, 13257,  8234,   230,  5335]) tensor([10897,  5412,  2806,  4989,  6763,  2160, 10759,  1999,  5448, 11190])
-------Step 5-------
tensor([12427,  6695,  8535,    44,  8374,  1209, 13257,  8234,   230,  5335]) tensor([12703, 10018, 12588, 12027,  7779,  8250,  3276,  4969,  9209,  8608])
-------Step 6-------
tensor([ 6273,  6651,  1862,  2512, 13568,  7449,  2679,   120,    39,  7120]) tensor([11019,   578,  7680,  1595,  7679,  4255, 10866,  9850, 13181, 13629])
-------Step 7-------
tensor([ 6273,  6651,  1862,  2512, 13568,  7449,  2679,   120,    39,  7120]) tensor([14837,  8421,   235, 13383, 14942,  8639, 14884,  5807, 10101, 10260])
-------Step 8-------
tensor([ 1247,  8362,  5551, 12212,  4948,  1237,  2053, 14274,  9127,  7900]) tensor([ 7222, 10347,  6878,  4085,  2352, 13754,  6461,  5084,  7702,   628])
-------Step 9-------
tensor([ 1247,  8362,  5551, 12212,  4948,  1237,  2053, 14274,  9127,  7900]) tensor([ 5946,  2141,  1789, 14572,  6666,  8322, 12782,  4475,  6937, 13809])
before start barrier
start train
[proc 0] 100 steps, total: 3.804, sample: 0.206, forward: 1.383, backward: 1.635, update: 0.437
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.812, sample: 0.216, forward: 1.348, backward: 1.451, update: 0.455
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 3.799, sample: 0.213, forward: 1.354, backward: 1.545, update: 0.439
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 705.836 us                | 17.461 ms                 |
| Forward                   | 5.644 ms                  | 15.390 ms                 |
| Backward                  | 2.793 ms                  | 3.401 ms                  |
| Optimize                  | 4.080 ms                  | 8.656 ms                  |
| OneStep                   | 14.192 ms                 | 44.670 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 200 steps, total: 1.599, sample: 0.215, forward: 0.552, backward: 0.274, update: 0.410
[proc 1] 200 steps, total: 1.599, sample: 0.206, forward: 0.550, backward: 0.295, update: 0.409
[proc 2] 200 steps, total: 1.599, sample: 0.239, forward: 0.553, backward: 0.282, update: 0.405
[proc 1] 300 steps, total: 1.681, sample: 0.199, forward: 0.538, backward: 0.299, update: 0.409
[proc 2] 300 steps, total: 1.681, sample: 0.227, forward: 0.556, backward: 0.289, update: 0.409
[proc 0] 300 steps, total: 1.681, sample: 0.197, forward: 0.559, backward: 0.289, update: 0.408
[proc 1] 400 steps, total: 2.192, sample: 0.285, forward: 0.590, backward: 0.310, update: 0.472
[proc 2] 400 steps, total: 2.192, sample: 0.285, forward: 0.599, backward: 0.302, update: 0.469
[proc 0] 400 steps, total: 2.192, sample: 0.288, forward: 0.607, backward: 0.306, update: 0.443
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 766.822 us                | 18.485 ms                 |
| Forward                   | 5.745 ms                  | 10.915 ms                 |
| Backward                  | 3.033 ms                  | 4.320 ms                  |
| Optimize                  | 4.222 ms                  | 7.671 ms                  |
| OneStep                   | 14.923 ms                 | 39.066 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 500 steps, total: 2.326, sample: 0.296, forward: 0.628, backward: 0.310, update: 0.471
[proc 2] 500 steps, total: 2.326, sample: 0.317, forward: 0.618, backward: 0.306, update: 0.482
Successfully xmh. training takes 11.602785348892212 seconds
before call kg_cache_controller.StopThreads()
[proc 1] 500 steps, total: 2.326, sample: 0.329, forward: 0.607, backward: 0.315, update: 0.486
KGCacheControllerWrapperDummy.StopThreads
