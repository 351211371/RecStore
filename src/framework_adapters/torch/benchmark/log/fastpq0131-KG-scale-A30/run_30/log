WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240201 00:34:10.754650 3316349 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_232', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [3316349 sampler.py:454] Start PreSampling
WARNING [3316349 sampler.py:532] Before construct renumbering_dict
WARNING [3316349 sampler.py:555] PreSampling done
W20240201 00:34:13.907778 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240201 00:34:13.907949 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240201 00:34:13.907979 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240201 00:34:13.908003 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240201 00:34:13.908025 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240201 00:34:13.908051 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240201 00:34:13.908068 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240201 00:34:13.908092 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240201 00:34:13.908115 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240201 00:34:13.908136 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240201 00:34:13.908161 3316349 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240201 00:34:13.908181 3316349 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240201 00:34:13.908198 3316349 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240201 00:34:13.908303 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240201 00:34:13.908331 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240201 00:34:13.908350 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240201 00:34:13.908386 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240201 00:34:13.908404 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240201 00:34:13.908427 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240201 00:34:13.908449 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240201 00:34:13.908471 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240201 00:34:13.908494 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240201 00:34:13.908516 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240201 00:34:13.908536 3316349 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240201 00:34:13.908552 3316349 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240201 00:34:13.908568 3316349 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240201 00:34:13.908605 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240201 00:34:13.908632 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240201 00:34:13.908651 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240201 00:34:13.908672 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240201 00:34:13.908689 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240201 00:34:13.908712 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240201 00:34:13.908730 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240201 00:34:13.908754 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240201 00:34:13.908777 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240201 00:34:13.908795 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240201 00:34:13.908812 3316349 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240201 00:34:13.908828 3316349 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240201 00:34:13.908843 3316349 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240201 00:34:13.908880 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240201 00:34:13.908900 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240201 00:34:13.908918 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240201 00:34:13.908937 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240201 00:34:13.908954 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240201 00:34:13.908972 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240201 00:34:13.908994 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240201 00:34:13.909015 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240201 00:34:13.909034 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240201 00:34:13.909050 3316349 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240201 00:34:13.909073 3316349 IPCTensor.h:369] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240201 00:34:13.909087 3316349 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240201 00:34:13.909107 3316349 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240201 00:34:14.054621 3316349 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240201 00:34:14.083108 3316349 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1584, 1777, 1835,  ..., 2392, 7464, 7761]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.350 seconds
[Rank1] pid = 3316561
[Rank2] pid = 3316626
INFO [3316349 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [3316561 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [3316626 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [3316626 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [3316690 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [3316349 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [3316690 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240201 00:34:17.384748 3316627 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [1495, 400]; dev=2; size=2.281 MB
W20240201 00:34:17.385345 3316627 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x100014876000 7.629 MB
W20240201 00:34:17.385499 3316627 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x100015019000 7.629 MB
W20240201 00:34:17.385546 3316627 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x1000157bc000 1.49 GB
W20240201 00:34:17.385592 3316627 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x100074d9f000 1.49 GB
W20240201 00:34:17.385648 3316627 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
INFO [3316561 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240201 00:34:17.385705 3316691 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [1495, 400]; dev=0; size=2.281 MB
W20240201 00:34:17.387225 3316692 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_3 [1495, 400]; dev=3; size=2.281 MB
W20240201 00:34:17.387717 3316627 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240201 00:34:17.387799 3316562 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [1495, 400]; dev=1; size=2.281 MB
W20240201 00:34:17.389575 3316691 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x1000d4388000 7.629 MB
W20240201 00:34:17.389772 3316691 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x1000d4b2d000 7.629 MB
W20240201 00:34:17.389838 3316692 IPCTensor.h:369] NewIPCTensor: input_keys_3 [1000000]0x1000d52d0000 7.629 MB
W20240201 00:34:17.389878 3316691 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000d5a75000 1.49 GB
W20240201 00:34:17.389963 3316691 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x100135058000 1.49 GB
W20240201 00:34:17.390051 3316691 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240201 00:34:17.390115 3316562 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x10019463b000 7.629 MB
W20240201 00:34:17.390136 3316692 IPCTensor.h:369] NewIPCTensor: input_keys_neg_3 [1000000]0x100194dde000 7.629 MB
W20240201 00:34:17.390257 3316692 IPCTensor.h:369] NewIPCTensor: backward_grads_3 [1000000, 400]0x100195581000 1.49 GB
W20240201 00:34:17.390364 3316692 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1001f4b64000 1.49 GB
W20240201 00:34:17.390376 3316562 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x100254147000 7.629 MB
W20240201 00:34:17.390465 3316692 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240201 00:34:17.390511 3316562 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x1002548ea000 1.49 GB
W20240201 00:34:17.390609 3316562 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1002b3ecd000 1.49 GB
W20240201 00:34:17.390682 3316562 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240201 00:34:17.405696 3316691 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240201 00:34:17.405855 3316562 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240201 00:34:17.405916 3316692 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [3316626 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [3316690 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [3316561 DistTensor.py:59] The tensor name already exists in the kvstore
[Rank3] pid = 3316690
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1495), (1495, 2990), (2990, 4485), (4485, 5980)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [3316349 DistTensor.py:59] The tensor name already exists in the kvstore
I20240201 00:34:18.727052 3316691 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240201 00:34:18.727149 3316627 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240201 00:34:18.727286 3316692 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240201 00:34:18.727447 3316562 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240201 00:34:18.728515 3316691 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 0.01,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.1,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240201 00:34:18.728655 3316691 grad_base.h:184] Init GradProcessingBase done
I20240201 00:34:18.733158 3316691 grad_async_v2.h:42] Use main thread to update emb.
W20240201 00:34:18.733191 3316691 kg_controller.h:78] after init GradAsyncProcessingV2
I20240201 00:34:18.733196 3316691 kg_controller.h:84] Construct KGCacheController done
E20240201 00:34:19.055439 3316691 recstore.cc:66] init folly done
E20240201 00:34:19.055507 3316627 recstore.cc:66] init folly done
E20240201 00:34:19.055617 3316692 recstore.cc:66] init folly done
E20240201 00:34:19.055666 3316562 recstore.cc:66] init folly done
I20240201 00:34:19.056335 3316691 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240201 00:34:19.714577 3317071 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
E20240201 00:34:19.714871 3317071 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
I20240201 00:34:19.737047 3316691 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240201 00:34:19.750818 3316627 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240201 00:34:19.764470 3316692 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240201 00:34:19.768021 3316562 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240201 00:34:22.233844 3316691 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
W20240201 00:34:22.245481 3317071 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
W20240201 00:34:22.438395 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=11, pq.top=11
E20240201 00:34:23.233013 3317090 parallel_pq_v2.h:79] insert failed, size(hashtable)=7165
W20240201 00:34:23.252419 3317071 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
W20240201 00:34:23.446991 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=64, pq.top=64
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 931.150 us                | 9.351 ms                  |
| Forward                   | 2.747 ms                  | 7.327 ms                  |
| Backward                  | 2.166 ms                  | 3.559 ms                  |
| Optimize                  | 926.137 us                | 1.581 ms                  |
| BarrierTimeBeforeRank0    | 20.477 us                 | 4.116 ms                  |
| AfterBackward             | 10.114 ms                 | 13.900 ms                 |
| BlockToStepN              | 517.386 us                | 1.596 ms                  |
| OneStep                   | 18.183 ms                 | 28.376 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 273.830 us                | 2.940 ms                  |
| ProcessBack:Shuffle       | 1.817 ms                  | 2.268 ms                  |
| ProcessBack:UpdateCache   | 1.628 ms                  | 2.114 ms                  |
| ProcessBack:UpsertPq      | 5.524 ms                  | 8.946 ms                  |
| ProcessOneStep            | 10.245 ms                 | 13.870 ms                 |
| BlockToStepN              | 508.030 us                | 3.346 ms                  |
+---------------------------+---------------------------+---------------------------+
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.412, sample: 0.160, forward: 1.180, backward: 0.542, update: 0.069
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.395, sample: 0.158, forward: 1.172, backward: 0.483, update: 0.072
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.398, sample: 0.147, forward: 1.168, backward: 0.510, update: 0.073
train_sampler.Prefill()
-------Step 0-------
tensor([ 7596,  4265,  9432,  6945,  9102,  4279, 10841,  4976, 12398,    51]) tensor([ 1835,  8427,  9509,  1185,  9287,  7230, 14157,  7495,  8394,  1239])
-------Step 1-------
tensor([ 7596,  4265,  9432,  6945,  9102,  4279, 10841,  4976, 12398,    51]) tensor([ 7850, 11517, 13390,  1766, 11799, 11249,  2408,  9880,  7672,  8484])
-------Step 2-------
tensor([ 5560, 14550,  7535,  6315,  5712,  9153, 11030,  9296, 12964,   295]) tensor([9877, 3531, 2425, 6692, 5576, 1305, 7219, 5343, 6653, 6516])
-------Step 3-------
tensor([ 5560, 14550,  7535,  6315,  5712,  9153, 11030,  9296, 12964,   295]) tensor([ 6239, 11845,  7785, 12130,  6621,  2276, 10180, 12834, 10677, 11874])
-------Step 4-------
tensor([ 9088,  2977,  3853,    22,   674,   302,   141, 11240, 11570,  8792]) tensor([11635,  4043,  4171, 13915,  2332,  2748, 11536,  7123, 12864,  6406])
-------Step 5-------
tensor([ 9088,  2977,  3853,    22,   674,   302,   141, 11240, 11570,  8792]) tensor([ 5857, 10358,  6222,  8752,  9471,  7934,  5257,  4544,  8119, 14727])
-------Step 6-------
tensor([10096,  6920,  5966,  6741,  2125,  6822,  8413,  3135, 14305,   108]) tensor([ 9312,  5523,  3957, 10604,  7404,  1313,  4058, 12441, 12318,  3853])
-------Step 7-------
tensor([10096,  6920,  5966,  6741,  2125,  6822,  8413,  3135, 14305,   108]) tensor([ 6008,  7956,  8695, 11173,  1101,   321, 12983, 10515,  5187,   838])
-------Step 8-------
tensor([ 3021, 13798, 11535, 11501,  5642,  5966, 12259,  6960,  4146,  2189]) tensor([14505,   964, 10613, 11895,  4215,   640,  6901,  1072, 10214, 13329])
-------Step 9-------
tensor([ 3021, 13798, 11535, 11501,  5642,  5966, 12259,  6960,  4146,  2189]) tensor([ 9331, 11794, 14808,   885, 12620,  8961,  5781,  2370,  7046,  9620])
before start barrier
start train
[proc 0] 100 steps, total: 4.426, sample: 0.184, forward: 1.129, backward: 0.407, update: 0.086
E20240201 00:34:24.233016 3317087 parallel_pq_v2.h:79] insert failed, size(hashtable)=7389
W20240201 00:34:24.253645 3317071 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
W20240201 00:34:24.446715 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=114, pq.top=114
E20240201 00:34:25.233006 3316691 parallel_pq_v2.h:79] insert failed, size(hashtable)=132
W20240201 00:34:25.253052 3317071 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
W20240201 00:34:25.453297 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=163, pq.top=163
E20240201 00:34:26.233043 3317094 parallel_pq_v2.h:79] insert failed, size(hashtable)=4937
W20240201 00:34:26.254731 3317071 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
[proc 2] 200 steps, total: 2.099, sample: 0.151, forward: 0.234, backward: 0.209, update: 0.060
[proc 1] 200 steps, total: 2.099, sample: 0.163, forward: 0.228, backward: 0.219, update: 0.062
[proc 0] 200 steps, total: 2.098, sample: 0.215, forward: 0.263, backward: 0.206, update: 0.075
[proc 3] 200 steps, total: 2.098, sample: 0.169, forward: 0.239, backward: 0.196, update: 0.065
W20240201 00:34:26.466197 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=210, pq.top=210
E20240201 00:34:27.233009 3317087 parallel_pq_v2.h:79] insert failed, size(hashtable)=1520
W20240201 00:34:27.266640 3317071 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
W20240201 00:34:27.467350 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=257, pq.top=257
E20240201 00:34:28.233145 3317071 parallel_pq_v2.h:79] insert failed, size(hashtable)=105
W20240201 00:34:28.273133 3317071 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
[proc 2] 300 steps, total: 2.140, sample: 0.135, forward: 0.236, backward: 0.212, update: 0.062
[proc 0] 300 steps, total: 2.139, sample: 0.205, forward: 0.259, backward: 0.210, update: 0.072
[proc 3] 300 steps, total: 2.139, sample: 0.158, forward: 0.233, backward: 0.194, update: 0.065
[proc 1] 300 steps, total: 2.140, sample: 0.148, forward: 0.226, backward: 0.199, update: 0.064
W20240201 00:34:28.482719 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=304, pq.top=304
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.083 ms                  | 10.018 ms                 |
| Forward                   | 2.713 ms                  | 5.238 ms                  |
| Backward                  | 2.146 ms                  | 3.464 ms                  |
| Optimize                  | 848.097 us                | 1.406 ms                  |
| BarrierTimeBeforeRank0    | 17.366 us                 | 1.892 ms                  |
| AfterBackward             | 11.478 ms                 | 13.900 ms                 |
| BlockToStepN              | 1.129 ms                  | 3.414 ms                  |
| OneStep                   | 20.223 ms                 | 29.108 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 387.003 us                | 2.982 ms                  |
| ProcessBack:Shuffle       | 1.829 ms                  | 2.167 ms                  |
| ProcessBack:UpdateCache   | 1.618 ms                  | 1.941 ms                  |
| ProcessBack:UpsertPq      | 6.351 ms                  | 9.685 ms                  |
| ProcessOneStep            | 11.469 ms                 | 13.870 ms                 |
| BlockToStepN              | 1.103 ms                  | 3.346 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240201 00:34:29.233008 3316691 parallel_pq_v2.h:79] insert failed, size(hashtable)=2450
W20240201 00:34:29.276558 3317071 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
W20240201 00:34:29.497079 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=349, pq.top=349
E20240201 00:34:30.233434 3316879 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
W20240201 00:34:30.277788 3317071 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end0
W20240201 00:34:30.515553 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=389, pq.top=389
[proc 0] 400 steps, total: 2.406, sample: 0.216, forward: 0.261, backward: 0.209, update: 0.072
[proc 2] 400 steps, total: 2.406, sample: 0.160, forward: 0.259, backward: 0.215, update: 0.060
[proc 1] 400 steps, total: 2.406, sample: 0.149, forward: 0.226, backward: 0.201, update: 0.063
[proc 3] 400 steps, total: 2.406, sample: 0.162, forward: 0.230, backward: 0.192, update: 0.065
E20240201 00:34:31.233058 3317071 parallel_pq_v2.h:79] insert failed, size(hashtable)=171
W20240201 00:34:31.280689 3317071 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
W20240201 00:34:31.535056 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=428, pq.top=428
E20240201 00:34:32.233016 3316691 parallel_pq_v2.h:79] insert failed, size(hashtable)=51
W20240201 00:34:32.282640 3317071 grad_async_v2.h:137] Detect new sample comes, old_end6, new_end7
W20240201 00:34:32.562949 3316691 grad_async_v2.h:270] Sleep in <BlockToStepN>, step_no=467, pq.top=467
E20240201 00:34:33.233323 3317079 parallel_pq_v2.h:79] insert failed, size(hashtable)=8938
W20240201 00:34:33.282269 3317071 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end4
[proc 1] 500 steps, total: 2.666, sample: 0.149, forward: 0.226, backward: 0.200, update: 0.063
[proc 2] 500 steps, total: 2.666, sample: 0.175, forward: 0.258, backward: 0.217, update: 0.059
[proc 0] 500 steps, total: 2.666, sample: 0.227, forward: 0.265, backward: 0.211, update: 0.071
[proc 3] 500 steps, total: 2.666, sample: 0.146, forward: 0.218, backward: 0.200, update: 0.062
Successfully xmh. training takes 13.73618745803833 seconds
before call kg_cache_controller.StopThreads()
W20240201 00:34:33.473299 3316691 grad_async_v2.h:84] call StopThreads. PID = 3316349
W20240201 00:34:33.473337 3316691 grad_base.h:212] before processOneStepNegThread_.join();
W20240201 00:34:33.473776 3316691 grad_base.h:214] after processOneStepNegThread_.join();
W20240201 00:34:33.473788 3316691 grad_async_v2.h:86] call GradProcessingBase::StopThreads.
W20240201 00:34:33.474023 3316691 grad_async_v2.h:105] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.186 ms                  | 9.660 ms                  |
| Forward                   | 2.713 ms                  | 3.839 ms                  |
| Backward                  | 2.152 ms                  | 2.715 ms                  |
| Optimize                  | 818.941 us                | 1.380 ms                  |
| BarrierTimeBeforeRank0    | 17.875 us                 | 5.330 ms                  |
| AfterBackward             | 12.210 ms                 | 17.337 ms                 |
| BlockToStepN              | 1.612 ms                  | 4.718 ms                  |
| OneStep                   | 21.443 ms                 | 32.941 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 382.111 us                | 3.398 ms                  |
| ProcessBack:Shuffle       | 1.876 ms                  | 2.268 ms                  |
| ProcessBack:UpdateCache   | 1.673 ms                  | 2.601 ms                  |
| ProcessBack:UpsertPq      | 7.653 ms                  | 12.451 ms                 |
| ProcessOneStep            | 12.188 ms                 | 17.310 ms                 |
| BlockToStepN              | 1.563 ms                  | 4.654 ms                  |
+---------------------------+---------------------------+---------------------------+
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f10163b43d0>
