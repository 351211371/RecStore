WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240212 00:59:26.130810 39923 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='SimplE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/SimplE_FB15k_100', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=1, update_pq_use_omp=2, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [39923 sampler.py:454] Start PreSampling
WARNING [39923 sampler.py:532] Before construct renumbering_dict
WARNING [39923 sampler.py:555] PreSampling done
W20240212 00:59:31.059886 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240212 00:59:31.060166 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240212 00:59:31.060226 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240212 00:59:31.060279 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240212 00:59:31.060317 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240212 00:59:31.060359 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240212 00:59:31.060405 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240212 00:59:31.060456 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240212 00:59:31.060505 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240212 00:59:31.060542 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240212 00:59:31.060592 39923 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240212 00:59:31.060628 39923 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240212 00:59:31.060669 39923 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240212 00:59:31.060830 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240212 00:59:31.060892 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240212 00:59:31.060933 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240212 00:59:31.061002 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240212 00:59:31.061061 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240212 00:59:31.061125 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240212 00:59:31.061172 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240212 00:59:31.061218 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240212 00:59:31.061255 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240212 00:59:31.061300 39923 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240212 00:59:31.061342 39923 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240212 00:59:31.061375 39923 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240212 00:59:31.061409 39923 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13804, num_edges=289155,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12626, num_edges=379866,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13804 N 289155 E
MertisPartition: part 1 has 12626 N 379866 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  760,   810,   894,  ..., 11982, 11021, 12254]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 5.304 seconds
INFO [39923 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [40128 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [39923 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [40128 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240212 00:59:33.013170 40191 recstore.cc:66] init folly done
E20240212 00:59:33.013459 40129 recstore.cc:66] init folly done
I20240212 00:59:33.103166 40191 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240212 00:59:33.118695 40129 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.015, sample: 0.365, forward: 1.001, backward: 0.851, update: 0.624
[Rank1] pid = 40128
train_sampler.Prefill()
-------Step 0-------
tensor([  346,  5572,  9120,  8679,  3004, 13462,  3723,  7737,  6705,  7471]) tensor([  922,  7996, 11083, 13479, 14623,  6165,  6874,   378,  6045,  9522])
-------Step 1-------
tensor([  346,  5572,  9120,  8679,  3004, 13462,  3723,  7737,  6705,  7471]) tensor([13661,  1587,  2323,  4719,  8853, 10305,  9401,  8764, 12154,  3064])
-------Step 2-------
tensor([13462,    24,   112,   269,  7544,  7244,  1671, 12806,  8217, 11954]) tensor([ 2228,  2255, 14835, 11127,  5827,  7147, 11972,  1997,  5932,  5593])
-------Step 3-------
tensor([13462,    24,   112,   269,  7544,  7244,  1671, 12806,  8217, 11954]) tensor([14174,  2039,   144,  4518,  7100, 11092,  3121,   859, 14475, 13224])
-------Step 4-------
tensor([ 2723,  2213,    99,  1823,  8415,  7546, 10859,  7538,    93,  5805]) tensor([ 5478, 14034,  8731,  6996, 12551,  5927,  6330,  9182,  5588,  9553])
-------Step 5-------
tensor([ 2723,  2213,    99,  1823,  8415,  7546, 10859,  7538,    93,  5805]) tensor([ 7723,  3367, 11922,  6141,  3942,  8248,   151,   776,  6094,  7093])
-------Step 6-------
tensor([ 7627,  3563,  8303,   273,  1190,   225, 13462,  7379,   190,   367]) tensor([12799, 13071,  7396,  8954,   882,  7403,  4323, 10381, 14948,  8341])
-------Step 7-------
tensor([ 7627,  3563,  8303,   273,  1190,   225, 13462,  7379,   190,   367]) tensor([ 8816,  1928, 14262, 13311, 14753,  8825,  1881,   532,    56,  8534])
-------Step 8-------
tensor([ 4041,  9093,  5896,  2434,  5572,  6082,  7544,  2723, 13877, 11704]) tensor([12249,  7832, 14938,  5823,  5790,  8630,  2700,  5654, 10598, 13963])
-------Step 9-------
tensor([ 4041,  9093,  5896,  2434,  5572,  6082,  7544,  2723, 13877, 11704]) tensor([ 4675, 10396, 11726, 12186, 14283,  3577,  2635,  8764, 13153,  3088])
before start barrier
start train
[proc 0] 100 steps, total: 2.999, sample: 0.369, forward: 0.990, backward: 0.858, update: 0.623
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.295 ms                  | 26.607 ms                 |
| Forward                   | 6.100 ms                  | 14.633 ms                 |
| Backward                  | 6.924 ms                  | 10.716 ms                 |
| Optimize                  | 5.520 ms                  | 10.628 ms                 |
| OneStep                   | 21.477 ms                 | 44.894 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 200 steps, total: 2.469, sample: 0.397, forward: 0.640, backward: 0.674, update: 0.562
[proc 1] 200 steps, total: 2.469, sample: 0.382, forward: 0.659, backward: 0.694, update: 0.581
[proc 0] 300 steps, total: 2.544, sample: 0.396, forward: 0.664, backward: 0.686, update: 0.598
[proc 1] 300 steps, total: 2.544, sample: 0.384, forward: 0.663, backward: 0.714, update: 0.598
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.351 ms                  | 26.694 ms                 |
| Forward                   | 6.210 ms                  | 12.009 ms                 |
| Backward                  | 6.935 ms                  | 10.716 ms                 |
| Optimize                  | 5.560 ms                  | 10.711 ms                 |
| OneStep                   | 22.285 ms                 | 49.025 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 400 steps, total: 2.535, sample: 0.383, forward: 0.632, backward: 0.691, update: 0.604
[proc 1] 400 steps, total: 2.535, sample: 0.376, forward: 0.672, backward: 0.719, update: 0.594
[proc 1] 500 steps, total: 2.401, sample: 0.369, forward: 0.644, backward: 0.680, update: 0.563
[proc 0] 500 steps, total: 2.401, sample: 0.388, forward: 0.615, backward: 0.687, update: 0.576
Successfully xmh. training takes 12.949295043945312 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
