WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240211 08:04:28.953537 54948 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_222', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=1, update_pq_use_omp=2, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [54948 sampler.py:454] Start PreSampling
WARNING [54948 sampler.py:532] Before construct renumbering_dict
WARNING [54948 sampler.py:555] PreSampling done
W20240211 08:04:33.627944 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240211 08:04:33.628203 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240211 08:04:33.628268 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240211 08:04:33.628319 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240211 08:04:33.628360 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240211 08:04:33.628451 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240211 08:04:33.628499 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240211 08:04:33.628557 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240211 08:04:33.628608 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240211 08:04:33.628644 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240211 08:04:33.628688 54948 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240211 08:04:33.628722 54948 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240211 08:04:33.628753 54948 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240211 08:04:33.628861 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240211 08:04:33.628913 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240211 08:04:33.628952 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240211 08:04:33.628998 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240211 08:04:33.629035 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240211 08:04:33.629079 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240211 08:04:33.629112 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240211 08:04:33.629151 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240211 08:04:33.629189 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240211 08:04:33.629223 54948 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240211 08:04:33.629263 54948 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240211 08:04:33.629292 54948 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240211 08:04:33.629328 54948 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13804, num_edges=289155,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12626, num_edges=379866,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13804 N 289155 E
MertisPartition: part 1 has 12626 N 379866 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  773,   815,   927,  ..., 10057, 10092,  9395]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 5.045 seconds
INFO [55156 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [55156 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [54948 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [54948 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240211 08:04:34.617722 55157 recstore.cc:66] init folly done
E20240211 08:04:34.618023 55158 recstore.cc:66] init folly done
I20240211 08:04:34.698822 55157 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240211 08:04:34.702219 55158 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 2.997, sample: 0.346, forward: 1.168, backward: 0.752, update: 0.555
[Rank1] pid = 55156
train_sampler.Prefill()
-------Step 0-------
tensor([  311,  6399, 11756,  6561,  3151, 11923,  3406,  5868,  6179,  5736]) tensor([  954, 11355, 13347, 14304, 11821,  6538,  5201,   396,  7575,  7790])
-------Step 1-------
tensor([  311,  6399, 11756,  6561,  3151, 11923,  3406,  5868,  6179,  5736]) tensor([14421,  1895,  1973,  3702,  6676, 12904, 12508,  6752,  9321,  4812])
-------Step 2-------
tensor([11923,     9,   195,   222,  5676,  5946,  1692,  9897,  7340,  9156]) tensor([ 2568,  2974, 12282, 13284,  4463,  9193, 13193,  2278,  8481,  7274])
-------Step 3-------
tensor([11923,     9,   195,   222,  5676,  5946,  1692,  9897,  7340,  9156]) tensor([14714,  2339,   326,  6483,  5372, 12928,  2533,   825, 12402, 13704])
-------Step 4-------
tensor([ 3657,  2368,   121,  1851, 10461,  5821,  8279, 10170,    38,  6562]) tensor([ 6187, 11743, 11056,  7354,  9631,  7432,  7135, 10738,  4307,  7259])
-------Step 5-------
tensor([ 3657,  2368,   121,  1851, 10461,  5821,  8279, 10170,    38,  6562]) tensor([ 6917,  3138, 12966,  4700,  3140,  8696,    80,   803,  4645,  8049])
-------Step 6-------
tensor([ 5743,  4967,  6319,   249,  1235,   148, 11923,  9353,   347,   361]) tensor([14136, 13697,  8419,  6756,   949,  6084,  3880, 14340, 12269, 11161])
-------Step 7-------
tensor([ 5743,  4967,  6319,   249,  1235,   148, 11923,  9353,   347,   361]) tensor([ 7365,  2220, 14894, 10249, 12224,  7236,  1598,   611,    51,  7126])
-------Step 8-------
tensor([ 5557,  8393,  7241,  1885,  6399,  6473,  5676,  3657, 10887, 13757]) tensor([13246,  7398, 12092,  4799,  7418, 10740,  2790,  8947, 12969, 10820])
-------Step 9-------
tensor([ 5557,  8393,  7241,  1885,  6399,  6473,  5676,  3657, 10887, 13757]) tensor([ 3690,  7907, 12709, 14618, 11264,  4925,  2065,  6752, 14120,  3823])
before start barrier
start train
[proc 0] 100 steps, total: 2.993, sample: 0.340, forward: 1.188, backward: 0.778, update: 0.544
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.159 ms                  | 23.488 ms                 |
| Forward                   | 6.216 ms                  | 11.455 ms                 |
| Backward                  | 6.142 ms                  | 12.465 ms                 |
| Optimize                  | 5.134 ms                  | 11.243 ms                 |
| OneStep                   | 19.773 ms                 | 48.187 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 200 steps, total: 2.299, sample: 0.374, forward: 0.636, backward: 0.614, update: 0.538
[proc 1] 200 steps, total: 2.299, sample: 0.399, forward: 0.601, backward: 0.458, update: 0.542
[proc 1] 300 steps, total: 2.295, sample: 0.337, forward: 0.622, backward: 0.589, update: 0.567
[proc 0] 300 steps, total: 2.295, sample: 0.349, forward: 0.646, backward: 0.607, update: 0.534
[proc 1] 400 steps, total: 2.263, sample: 0.349, forward: 0.633, backward: 0.589, update: 0.559
[proc 0] 400 steps, total: 2.263, sample: 0.291, forward: 0.639, backward: 0.612, update: 0.502
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.132 ms                  | 23.843 ms                 |
| Forward                   | 6.216 ms                  | 11.455 ms                 |
| Backward                  | 6.128 ms                  | 7.181 ms                  |
| Optimize                  | 5.090 ms                  | 11.545 ms                 |
| OneStep                   | 19.864 ms                 | 49.079 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 500 steps, total: 2.270, sample: 0.338, forward: 0.640, backward: 0.593, update: 0.562
[proc 0] 500 steps, total: 2.270, sample: 0.300, forward: 0.650, backward: 0.611, update: 0.498
Successfully xmh. training takes 12.1196448802948 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
