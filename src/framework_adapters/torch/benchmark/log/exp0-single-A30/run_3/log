Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 3 parts
part 0 has 161048 edges
part 1 has 161048 edges
part 2 has 161046 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=3, num_proc=3, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_FB15k_12', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 1.163 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 1][Train](1000/10000) average pos_loss: 0.17648270764946938
[proc 1][Train](1000/10000) average neg_loss: 0.20297241848707198
[proc 1][Train](1000/10000) average loss: 0.18972756341844796
[proc 1][Train](1000/10000) average regularization: 1.1614921940235945e-05
[proc 1] 1000 steps, total: 15.966, sample: 1.671, forward: 5.736, backward: 2.174, update: 4.657
[proc 0][Train](1000/10000) average pos_loss: 0.17546328608691691
[proc 0][Train](1000/10000) average neg_loss: 0.1920795883461833
[proc 0][Train](1000/10000) average loss: 0.18377143759280443
[proc 0][Train](1000/10000) average regularization: 1.2033584349410375e-05
[proc 0] 1000 steps, total: 16.016, sample: 1.982, forward: 6.254, backward: 1.963, update: 5.808
[proc 2][Train](1000/10000) average pos_loss: 0.1771335427388549
[proc 2][Train](1000/10000) average neg_loss: 0.1961128859370947
[proc 2][Train](1000/10000) average loss: 0.1866232146397233
[proc 2][Train](1000/10000) average regularization: 1.1819571578143951e-05
[proc 2] 1000 steps, total: 15.953, sample: 1.845, forward: 5.982, backward: 2.064, update: 5.023
[proc 1][Train](2000/10000) average pos_loss: 0.0668866260163486
[proc 1][Train](2000/10000) average neg_loss: 0.09664722344279289
[proc 1][Train](2000/10000) average loss: 0.08176692470163106
[proc 1][Train](2000/10000) average regularization: 1.646541449099459e-05
[proc 1] 2000 steps, total: 14.222, sample: 1.952, forward: 4.735, backward: 2.297, update: 4.676
[proc 0][Train](2000/10000) average pos_loss: 0.06619807146117092
[proc 0][Train](2000/10000) average neg_loss: 0.09596460016816855
[proc 0][Train](2000/10000) average loss: 0.08108133592456579
[proc 0][Train](2000/10000) average regularization: 1.650423360752029e-05
[proc 0] 2000 steps, total: 14.221, sample: 1.689, forward: 4.923, backward: 1.991, update: 5.610
[proc 2][Train](2000/10000) average pos_loss: 0.06661869065091014
[proc 2][Train](2000/10000) average neg_loss: 0.09662093352526427
[proc 2][Train](2000/10000) average loss: 0.08161981211602688
[proc 2][Train](2000/10000) average regularization: 1.647517027322465e-05
[proc 2] 2000 steps, total: 14.222, sample: 1.818, forward: 4.903, backward: 2.160, update: 4.920
[proc 1][Train](3000/10000) average pos_loss: 0.056382450349628924
[proc 1][Train](3000/10000) average neg_loss: 0.08465365570038558
[proc 1][Train](3000/10000) average loss: 0.07051805293187499
[proc 1][Train](3000/10000) average regularization: 1.831865308668057e-05
[proc 1] 3000 steps, total: 14.887, sample: 1.741, forward: 4.701, backward: 2.171, update: 4.649
[proc 0][Train](3000/10000) average pos_loss: 0.056652134340256455
[proc 0][Train](3000/10000) average neg_loss: 0.08386319833993912
[proc 0][Train](3000/10000) average loss: 0.07025766628980637
[proc 0][Train](3000/10000) average regularization: 1.8395608427454136e-05
[proc 0] 3000 steps, total: 14.887, sample: 2.073, forward: 4.998, backward: 2.118, update: 5.689
[proc 2][Train](3000/10000) average pos_loss: 0.05651407029852271
[proc 2][Train](3000/10000) average neg_loss: 0.08454415062442422
[proc 2][Train](3000/10000) average loss: 0.07052911049127579
[proc 2][Train](3000/10000) average regularization: 1.834412236348726e-05
[proc 2] 3000 steps, total: 14.887, sample: 1.968, forward: 4.858, backward: 2.100, update: 4.917
[proc 0][Train](4000/10000) average pos_loss: 0.05170876861736178
[proc 0][Train](4000/10000) average neg_loss: 0.07821011230349541
[proc 0][Train](4000/10000) average loss: 0.06495944040641188
[proc 0][Train](4000/10000) average regularization: 1.9585632886446548e-05
[proc 0] 4000 steps, total: 14.649, sample: 1.921, forward: 4.941, backward: 2.103, update: 5.675
[proc 1][Train](4000/10000) average pos_loss: 0.0517744776122272
[proc 1][Train](4000/10000) average neg_loss: 0.07882989805564285
[proc 1][Train](4000/10000) average loss: 0.06530218784883618
[proc 1][Train](4000/10000) average regularization: 1.952944407821633e-05
[proc 1] 4000 steps, total: 14.649, sample: 1.843, forward: 4.638, backward: 2.103, update: 4.687
[proc 2][Train](4000/10000) average pos_loss: 0.05185469983145594
[proc 2][Train](4000/10000) average neg_loss: 0.07852079992368817
[proc 2][Train](4000/10000) average loss: 0.06518774984776973
[proc 2][Train](4000/10000) average regularization: 1.95508760989469e-05
[proc 2] 4000 steps, total: 14.649, sample: 1.881, forward: 4.740, backward: 2.121, update: 4.849
[proc 2][Train](5000/10000) average pos_loss: 0.04895619209855795
[proc 2][Train](5000/10000) average neg_loss: 0.0746741446442902
[proc 2][Train](5000/10000) average loss: 0.06181516845524311
[proc 2][Train](5000/10000) average regularization: 2.043201126070926e-05
[proc 2] 5000 steps, total: 14.562, sample: 1.708, forward: 4.877, backward: 1.829, update: 5.050
[proc 0][Train](5000/10000) average pos_loss: 0.04875949965417385
[proc 0][Train](5000/10000) average neg_loss: 0.07477214653044939
[proc 0][Train](5000/10000) average loss: 0.061765823014080526
[proc 0][Train](5000/10000) average regularization: 2.045472939244064e-05
[proc 0] 5000 steps, total: 14.562, sample: 1.861, forward: 5.001, backward: 1.975, update: 5.717
[proc 1][Train](5000/10000) average pos_loss: 0.048978653896600007
[proc 1][Train](5000/10000) average neg_loss: 0.07502313608303667
[proc 1][Train](5000/10000) average loss: 0.06200089505687356
[proc 1][Train](5000/10000) average regularization: 2.0415586508534034e-05
[proc 1] 5000 steps, total: 14.562, sample: 1.871, forward: 4.771, backward: 1.969, update: 4.682
[proc 0][Train](6000/10000) average pos_loss: 0.046751042935997245
[proc 0][Train](6000/10000) average neg_loss: 0.07240716505423188
[proc 0][Train](6000/10000) average loss: 0.05957910402491689
[proc 0][Train](6000/10000) average regularization: 2.1137959191037227e-05
[proc 0] 6000 steps, total: 14.486, sample: 1.811, forward: 4.931, backward: 2.010, update: 5.726
[proc 2][Train](6000/10000) average pos_loss: 0.047067084562033415
[proc 2][Train](6000/10000) average neg_loss: 0.07239091712981463
[proc 2][Train](6000/10000) average loss: 0.05972900081425905
[proc 2][Train](6000/10000) average regularization: 2.112926340305421e-05
[proc 2] 6000 steps, total: 14.486, sample: 1.888, forward: 5.006, backward: 2.142, update: 5.077
[proc 1][Train](6000/10000) average pos_loss: 0.04713263237476349
[proc 1][Train](6000/10000) average neg_loss: 0.07259278805553913
[proc 1][Train](6000/10000) average loss: 0.05986271026730537
[proc 1][Train](6000/10000) average regularization: 2.1124307251739082e-05
[proc 1] 6000 steps, total: 14.486, sample: 1.938, forward: 4.858, backward: 2.108, update: 4.862
[proc 0][Train](7000/10000) average pos_loss: 0.04548002532497048
[proc 0][Train](7000/10000) average neg_loss: 0.07048633835837245
[proc 0][Train](7000/10000) average loss: 0.057983181815594434
[proc 0][Train](7000/10000) average regularization: 2.1717931058446994e-05
[proc 0] 7000 steps, total: 14.274, sample: 1.684, forward: 4.844, backward: 2.035, update: 5.703
[proc 1][Train](7000/10000) average pos_loss: 0.045437675304710864
[proc 1][Train](7000/10000) average neg_loss: 0.0708363796211779
[proc 1][Train](7000/10000) average loss: 0.058137027464807034
[proc 1][Train](7000/10000) average regularization: 2.1690023146220482e-05
[proc 1] 7000 steps, total: 14.273, sample: 1.608, forward: 4.695, backward: 1.946, update: 4.581
[proc 2][Train](7000/10000) average pos_loss: 0.045643109057098626
[proc 2][Train](7000/10000) average neg_loss: 0.0704769282862544
[proc 2][Train](7000/10000) average loss: 0.05806001874059439
[proc 2][Train](7000/10000) average regularization: 2.1709823913624858e-05
[proc 2] 7000 steps, total: 14.274, sample: 1.755, forward: 5.013, backward: 2.073, update: 5.065
[proc 0][Train](8000/10000) average pos_loss: 0.04411948905140162
[proc 0][Train](8000/10000) average neg_loss: 0.06911175322160125
[proc 0][Train](8000/10000) average loss: 0.05661562106758356
[proc 0][Train](8000/10000) average regularization: 2.2202529788046378e-05
[proc 0] 8000 steps, total: 14.526, sample: 1.678, forward: 4.919, backward: 2.062, update: 5.706
[proc 1][Train](8000/10000) average pos_loss: 0.04458092079311609
[proc 1][Train](8000/10000) average neg_loss: 0.06936324508115649
[proc 1][Train](8000/10000) average loss: 0.05697208296880126
[proc 1][Train](8000/10000) average regularization: 2.2191388172359437e-05
[proc 1] 8000 steps, total: 14.525, sample: 1.901, forward: 5.003, backward: 2.090, update: 4.964
[proc 2][Train](8000/10000) average pos_loss: 0.04444144334644079
[proc 2][Train](8000/10000) average neg_loss: 0.06908099354803562
[proc 2][Train](8000/10000) average loss: 0.05676121836155653
[proc 2][Train](8000/10000) average regularization: 2.2194580949872035e-05
[proc 2] 8000 steps, total: 14.525, sample: 1.950, forward: 5.212, backward: 2.155, update: 5.199
[proc 1][Train](9000/10000) average pos_loss: 0.04356431237235665
[proc 1][Train](9000/10000) average neg_loss: 0.06825331046059728
[proc 1][Train](9000/10000) average loss: 0.0559088113643229
[proc 1][Train](9000/10000) average regularization: 2.2616630518314197e-05
[proc 1] 9000 steps, total: 14.540, sample: 1.850, forward: 4.733, backward: 2.176, update: 4.761
[proc 2][Train](9000/10000) average pos_loss: 0.04348200955241919
[proc 2][Train](9000/10000) average neg_loss: 0.06798477276042104
[proc 2][Train](9000/10000) average loss: 0.055733391191810366
[proc 2][Train](9000/10000) average regularization: 2.261755616564187e-05
[proc 2] 9000 steps, total: 14.540, sample: 1.893, forward: 4.789, backward: 2.278, update: 4.824
[proc 0][Train](9000/10000) average pos_loss: 0.04340006325766444
[proc 0][Train](9000/10000) average neg_loss: 0.0679111138060689
[proc 0][Train](9000/10000) average loss: 0.05565558850765228
[proc 0][Train](9000/10000) average regularization: 2.262668164803472e-05
[proc 0] 9000 steps, total: 14.541, sample: 1.869, forward: 4.878, backward: 1.983, update: 5.802
[proc 0][Train](10000/10000) average pos_loss: 0.04283599726855755
[proc 0][Train](10000/10000) average neg_loss: 0.0670170830860734
[proc 0][Train](10000/10000) average loss: 0.05492654021456838
[proc 0][Train](10000/10000) average regularization: 2.3013684856778128e-05
[proc 0] 10000 steps, total: 14.261, sample: 1.608, forward: 5.015, backward: 2.019, update: 5.610
[proc 1][Train](10000/10000) average pos_loss: 0.04294023009762168
[proc 1][Train](10000/10000) average neg_loss: 0.06735774135217071
[proc 1][Train](10000/10000) average loss: 0.05514898570626974
[proc 1][Train](10000/10000) average regularization: 2.2998652231763118e-05
[proc 1] 10000 steps, total: 14.261, sample: 1.481, forward: 4.398, backward: 2.519, update: 4.262
proc 0 takes 146.423 seconds
proc 1 takes 146.373 seconds
[proc 2][Train](10000/10000) average pos_loss: 0.04242147342115641
[proc 2][Train](10000/10000) average neg_loss: 0.06711694030091167
[proc 2][Train](10000/10000) average loss: 0.054769206818193195
[proc 2][Train](10000/10000) average regularization: 2.2980440335231833e-05
[proc 2] 10000 steps, total: 14.261, sample: 1.422, forward: 4.151, backward: 1.967, update: 4.172
proc 2 takes 146.360 seconds
Successfully xmh. training takes 146.8329999446869 seconds
-------------- Test result --------------
Test average MRR : 0.5499117565333214
Test average MR : 41.50353811514957
Test average HITS@1 : 0.41272367151394085
Test average HITS@3 : 0.6434714157539232
Test average HITS@10 : 0.7799935670633644
-----------------------------------------
testing takes 116.753 seconds
