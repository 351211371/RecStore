Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 3 parts
part 0 has 161048 edges
part 1 has 161048 edges
part 2 has 161046 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=3, num_proc=3, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_FB15k_2', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 0.824 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.1648611605912447
[proc 0][Train](1000/10000) average neg_loss: 0.18468927846103905
[proc 0][Train](1000/10000) average loss: 0.1747752194404602
[proc 0][Train](1000/10000) average regularization: 1.2303042241455841e-05
[proc 0] 1000 steps, total: 14.866, sample: 1.458, forward: 5.798, backward: 2.484, update: 5.118
[proc 1][Train](1000/10000) average pos_loss: 0.18099389690160753
[proc 1][Train](1000/10000) average neg_loss: 0.200235348880291
[proc 1][Train](1000/10000) average loss: 0.1906146229058504
[proc 1][Train](1000/10000) average regularization: 1.1902288512146698e-05
[proc 1] 1000 steps, total: 14.866, sample: 1.360, forward: 5.344, backward: 2.701, update: 4.504
[proc 2][Train](1000/10000) average pos_loss: 0.1787065615579486
[proc 2][Train](1000/10000) average neg_loss: 0.19877476079761983
[proc 2][Train](1000/10000) average loss: 0.18874066137522458
[proc 2][Train](1000/10000) average regularization: 1.1977638526332158e-05
[proc 2] 1000 steps, total: 14.844, sample: 1.524, forward: 5.436, backward: 2.411, update: 4.816
[proc 1][Train](2000/10000) average pos_loss: 0.0662684814222157
[proc 1][Train](2000/10000) average neg_loss: 0.0958159644678235
[proc 1][Train](2000/10000) average loss: 0.0810422229282558
[proc 1][Train](2000/10000) average regularization: 1.6799608078144955e-05
[proc 1] 2000 steps, total: 12.793, sample: 1.344, forward: 4.201, backward: 2.742, update: 4.499
[proc 0][Train](2000/10000) average pos_loss: 0.06599903765320778
[proc 0][Train](2000/10000) average neg_loss: 0.09594352423399687
[proc 0][Train](2000/10000) average loss: 0.08097128108143807
[proc 0][Train](2000/10000) average regularization: 1.678069966419571e-05
[proc 0] 2000 steps, total: 12.793, sample: 1.319, forward: 4.480, backward: 1.838, update: 5.112
[proc 2][Train](2000/10000) average pos_loss: 0.06597821611166
[proc 2][Train](2000/10000) average neg_loss: 0.09641178189218044
[proc 2][Train](2000/10000) average loss: 0.08119499895721674
[proc 2][Train](2000/10000) average regularization: 1.6763740942224102e-05
[proc 2] 2000 steps, total: 12.793, sample: 1.367, forward: 4.079, backward: 2.483, update: 4.590
[proc 1][Train](3000/10000) average pos_loss: 0.05610697949677706
[proc 1][Train](3000/10000) average neg_loss: 0.08405021969601512
[proc 1][Train](3000/10000) average loss: 0.07007859955728055
[proc 1][Train](3000/10000) average regularization: 1.8672818658160397e-05
[proc 1] 3000 steps, total: 12.807, sample: 1.375, forward: 4.195, backward: 2.708, update: 4.521
[proc 0][Train](3000/10000) average pos_loss: 0.05645437041670084
[proc 0][Train](3000/10000) average neg_loss: 0.08400253416225315
[proc 0][Train](3000/10000) average loss: 0.07022845227643848
[proc 0][Train](3000/10000) average regularization: 1.866267661534948e-05
[proc 0] 3000 steps, total: 12.807, sample: 1.332, forward: 4.486, backward: 1.812, update: 5.117
[proc 2][Train](3000/10000) average pos_loss: 0.05618613536655903
[proc 2][Train](3000/10000) average neg_loss: 0.08444558366760611
[proc 2][Train](3000/10000) average loss: 0.07031585950031877
[proc 2][Train](3000/10000) average regularization: 1.864334887068253e-05
[proc 2] 3000 steps, total: 12.808, sample: 1.496, forward: 4.161, backward: 2.358, update: 4.723
[proc 0][Train](4000/10000) average pos_loss: 0.05182795805484056
[proc 0][Train](4000/10000) average neg_loss: 0.07814290854334831
[proc 0][Train](4000/10000) average loss: 0.06498543332144618
[proc 0][Train](4000/10000) average regularization: 1.985769264501869e-05
[proc 0] 4000 steps, total: 13.889, sample: 1.505, forward: 4.630, backward: 2.641, update: 5.106
[proc 1][Train](4000/10000) average pos_loss: 0.05109622287005186
[proc 1][Train](4000/10000) average neg_loss: 0.0782546875551343
[proc 1][Train](4000/10000) average loss: 0.06467545529454946
[proc 1][Train](4000/10000) average regularization: 1.9832254860375543e-05
[proc 1] 4000 steps, total: 13.889, sample: 1.437, forward: 4.204, backward: 2.713, update: 4.535
[proc 2][Train](4000/10000) average pos_loss: 0.05175645699352026
[proc 2][Train](4000/10000) average neg_loss: 0.07844988777860999
[proc 2][Train](4000/10000) average loss: 0.06510317239165306
[proc 2][Train](4000/10000) average regularization: 1.9871284039254533e-05
[proc 2] 4000 steps, total: 13.889, sample: 1.767, forward: 4.451, backward: 2.408, update: 4.974
[proc 0][Train](5000/10000) average pos_loss: 0.04902621917799115
[proc 0][Train](5000/10000) average neg_loss: 0.07446592961251736
[proc 0][Train](5000/10000) average loss: 0.06174607441946864
[proc 0][Train](5000/10000) average regularization: 2.074552804879204e-05
[proc 0] 5000 steps, total: 13.777, sample: 1.408, forward: 4.635, backward: 2.742, update: 4.985
[proc 1][Train](5000/10000) average pos_loss: 0.048663629915565255
[proc 1][Train](5000/10000) average neg_loss: 0.07482801460102201
[proc 1][Train](5000/10000) average loss: 0.061745822317898276
[proc 1][Train](5000/10000) average regularization: 2.0724960459119758e-05
[proc 1] 5000 steps, total: 13.777, sample: 1.357, forward: 4.221, backward: 2.616, update: 4.522
[proc 2][Train](5000/10000) average pos_loss: 0.04854021256789565
[proc 2][Train](5000/10000) average neg_loss: 0.07494233077391982
[proc 2][Train](5000/10000) average loss: 0.0617412717230618
[proc 2][Train](5000/10000) average regularization: 2.072322850654018e-05
[proc 2] 5000 steps, total: 13.777, sample: 1.444, forward: 4.179, backward: 2.546, update: 4.651
[proc 0][Train](6000/10000) average pos_loss: 0.0468632135130465
[proc 0][Train](6000/10000) average neg_loss: 0.07204217426851392
[proc 0][Train](6000/10000) average loss: 0.059452693823724985
[proc 0][Train](6000/10000) average regularization: 2.1439455980726053e-05
[proc 0] 6000 steps, total: 13.678, sample: 1.432, forward: 4.655, backward: 2.591, update: 4.993
[proc 2][Train](6000/10000) average pos_loss: 0.04666227313131094
[proc 2][Train](6000/10000) average neg_loss: 0.07230116295814513
[proc 2][Train](6000/10000) average loss: 0.05948171804100275
[proc 2][Train](6000/10000) average regularization: 2.141665032286255e-05
[proc 2] 6000 steps, total: 13.678, sample: 1.324, forward: 4.121, backward: 2.619, update: 4.573
[proc 1][Train](6000/10000) average pos_loss: 0.04663982917368412
[proc 1][Train](6000/10000) average neg_loss: 0.07218250113725662
[proc 1][Train](6000/10000) average loss: 0.0594111651070416
[proc 1][Train](6000/10000) average regularization: 2.1421875291707692e-05
[proc 1] 6000 steps, total: 13.679, sample: 1.351, forward: 4.202, backward: 2.667, update: 4.539
[proc 0][Train](7000/10000) average pos_loss: 0.045358524445444345
[proc 0][Train](7000/10000) average neg_loss: 0.07030162815004587
[proc 0][Train](7000/10000) average loss: 0.05783007639274001
[proc 0][Train](7000/10000) average regularization: 2.2004064370776177e-05
[proc 0] 7000 steps, total: 13.690, sample: 1.459, forward: 4.663, backward: 2.312, update: 5.247
[proc 1][Train](7000/10000) average pos_loss: 0.045244785610586404
[proc 1][Train](7000/10000) average neg_loss: 0.07049321587383747
[proc 1][Train](7000/10000) average loss: 0.05786900071054697
[proc 1][Train](7000/10000) average regularization: 2.1989751508954214e-05
[proc 1] 7000 steps, total: 13.690, sample: 1.415, forward: 4.307, backward: 2.463, update: 4.659
[proc 2][Train](7000/10000) average pos_loss: 0.045394266922026874
[proc 2][Train](7000/10000) average neg_loss: 0.07047958655655384
[proc 2][Train](7000/10000) average loss: 0.057936926767230036
[proc 2][Train](7000/10000) average regularization: 2.1999218201017358e-05
[proc 2] 7000 steps, total: 13.690, sample: 1.463, forward: 4.274, backward: 2.522, update: 4.679
[proc 0][Train](8000/10000) average pos_loss: 0.04421327491104603
[proc 0][Train](8000/10000) average neg_loss: 0.06881769910082221
[proc 0][Train](8000/10000) average loss: 0.05651548697799444
[proc 0][Train](8000/10000) average regularization: 2.2488724025606642e-05
[proc 0] 8000 steps, total: 13.002, sample: 1.384, forward: 4.596, backward: 1.848, update: 5.166
[proc 1][Train](8000/10000) average pos_loss: 0.04425980981066823
[proc 1][Train](8000/10000) average neg_loss: 0.06896283388882875
[proc 1][Train](8000/10000) average loss: 0.056611321855336426
[proc 1][Train](8000/10000) average regularization: 2.248702265387692e-05
[proc 1] 8000 steps, total: 13.002, sample: 1.425, forward: 4.330, backward: 2.403, update: 4.767
[proc 2][Train](8000/10000) average pos_loss: 0.04416383635997772
[proc 2][Train](8000/10000) average neg_loss: 0.06924455957487226
[proc 2][Train](8000/10000) average loss: 0.05670419803634286
[proc 2][Train](8000/10000) average regularization: 2.2474838311609348e-05
[proc 2] 8000 steps, total: 13.002, sample: 1.427, forward: 4.214, backward: 2.420, update: 4.691
[proc 2][Train](9000/10000) average pos_loss: 0.04341712532564998
[proc 2][Train](9000/10000) average neg_loss: 0.06809195444360375
[proc 2][Train](9000/10000) average loss: 0.0557545399479568
[proc 2][Train](9000/10000) average regularization: 2.2912179741979344e-05
[proc 2] 9000 steps, total: 13.482, sample: 1.736, forward: 4.420, backward: 2.455, update: 4.863
[proc 0][Train](9000/10000) average pos_loss: 0.04322501643747091
[proc 0][Train](9000/10000) average neg_loss: 0.06774631027132273
[proc 0][Train](9000/10000) average loss: 0.05548566343635321
[proc 0][Train](9000/10000) average regularization: 2.290468335195328e-05
[proc 0] 9000 steps, total: 13.482, sample: 1.429, forward: 4.522, backward: 1.858, update: 5.156
[proc 1][Train](9000/10000) average pos_loss: 0.04327414879575372
[proc 1][Train](9000/10000) average neg_loss: 0.0677594566270709
[proc 1][Train](9000/10000) average loss: 0.055516802676022055
[proc 1][Train](9000/10000) average regularization: 2.2905830370291368e-05
[proc 1] 9000 steps, total: 13.482, sample: 1.584, forward: 4.373, backward: 2.362, update: 4.808
[proc 0][Train](10000/10000) average pos_loss: 0.04280868799611926
[proc 0][Train](10000/10000) average neg_loss: 0.06690660724043847
[proc 0][Train](10000/10000) average loss: 0.05485764756053686
[proc 0][Train](10000/10000) average regularization: 2.3285587834834586e-05
[proc 0] 10000 steps, total: 13.513, sample: 1.535, forward: 4.674, backward: 2.077, update: 5.218
proc 0 takes 135.498 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.042554677106440064
[proc 1][Train](10000/10000) average neg_loss: 0.06698288417980075
[proc 1][Train](10000/10000) average loss: 0.05476878063008189
[proc 1][Train](10000/10000) average regularization: 2.3283399186766474e-05
[proc 1] 10000 steps, total: 13.513, sample: 1.415, forward: 4.306, backward: 2.399, update: 4.750
proc 1 takes 135.498 seconds
[proc 2][Train](10000/10000) average pos_loss: 0.04232652991265058
[proc 2][Train](10000/10000) average neg_loss: 0.06703464801236987
[proc 2][Train](10000/10000) average loss: 0.05468058903515339
[proc 2][Train](10000/10000) average regularization: 2.328143395607185e-05
[proc 2] 10000 steps, total: 13.513, sample: 1.342, forward: 3.991, backward: 2.381, update: 4.531
proc 2 takes 135.477 seconds
Successfully xmh. training takes 135.86162161827087 seconds
-------------- Test result --------------
Test average MRR : 0.5509766888798057
Test average MR : 41.181256454097614
Test average HITS@1 : 0.413942543718576
Test average HITS@3 : 0.6444194274686394
Test average HITS@10 : 0.779087877300198
-----------------------------------------
testing takes 117.059 seconds
