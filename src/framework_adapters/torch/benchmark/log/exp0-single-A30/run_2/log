Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 2 parts
part 0 has 241571 edges
part 1 has 241571 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_FB15k_11', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 1.130 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.2049426779523492
[proc 0][Train](1000/10000) average neg_loss: 0.2259463578686118
[proc 0][Train](1000/10000) average loss: 0.2154445176795125
[proc 0][Train](1000/10000) average regularization: 1.1055657884298854e-05
[proc 0] 1000 steps, total: 13.445, sample: 1.675, forward: 5.507, backward: 2.010, update: 4.246
[proc 1][Train](1000/10000) average pos_loss: 0.209420593470335
[proc 1][Train](1000/10000) average neg_loss: 0.22915680857002735
[proc 1][Train](1000/10000) average loss: 0.21928870123624802
[proc 1][Train](1000/10000) average regularization: 1.1014193327355315e-05
[proc 1] 1000 steps, total: 13.445, sample: 1.787, forward: 5.300, backward: 2.114, update: 3.895
[proc 0][Train](2000/10000) average pos_loss: 0.07570058768615126
[proc 0][Train](2000/10000) average neg_loss: 0.10730040873587131
[proc 0][Train](2000/10000) average loss: 0.09150049822777509
[proc 0][Train](2000/10000) average regularization: 1.566060478853615e-05
[proc 0] 2000 steps, total: 11.929, sample: 1.475, forward: 4.271, backward: 2.186, update: 3.991
[proc 1][Train](2000/10000) average pos_loss: 0.07541288960352541
[proc 1][Train](2000/10000) average neg_loss: 0.10739807084947825
[proc 1][Train](2000/10000) average loss: 0.09140548028796912
[proc 1][Train](2000/10000) average regularization: 1.563901152167091e-05
[proc 1] 2000 steps, total: 11.930, sample: 1.650, forward: 4.063, backward: 2.179, update: 3.650
[proc 1][Train](3000/10000) average pos_loss: 0.062268268562853335
[proc 1][Train](3000/10000) average neg_loss: 0.09212435672432184
[proc 1][Train](3000/10000) average loss: 0.07719631262496114
[proc 1][Train](3000/10000) average regularization: 1.753256133997638e-05
[proc 1] 3000 steps, total: 12.203, sample: 1.590, forward: 4.119, backward: 2.001, update: 3.715
[proc 0][Train](3000/10000) average pos_loss: 0.06274582505971193
[proc 0][Train](3000/10000) average neg_loss: 0.09201826740801335
[proc 0][Train](3000/10000) average loss: 0.0773820462860167
[proc 0][Train](3000/10000) average regularization: 1.7576814245330753e-05
[proc 0] 3000 steps, total: 12.204, sample: 1.588, forward: 4.380, backward: 2.170, update: 4.058
[proc 1][Train](4000/10000) average pos_loss: 0.05661606871709227
[proc 1][Train](4000/10000) average neg_loss: 0.08453067760914564
[proc 1][Train](4000/10000) average loss: 0.0705733731649816
[proc 1][Train](4000/10000) average regularization: 1.877509341102268e-05
[proc 1] 4000 steps, total: 12.470, sample: 1.962, forward: 4.424, backward: 2.154, update: 3.922
[proc 0][Train](4000/10000) average pos_loss: 0.05649288788810372
[proc 0][Train](4000/10000) average neg_loss: 0.08491511688008904
[proc 0][Train](4000/10000) average loss: 0.07070400240272283
[proc 0][Train](4000/10000) average regularization: 1.876343537696812e-05
[proc 0] 4000 steps, total: 12.469, sample: 1.731, forward: 4.388, backward: 2.081, update: 4.081
[proc 0][Train](5000/10000) average pos_loss: 0.053241758152842523
[proc 0][Train](5000/10000) average neg_loss: 0.08013253152370453
[proc 0][Train](5000/10000) average loss: 0.06668714484944939
[proc 0][Train](5000/10000) average regularization: 1.9678097965879716e-05
[proc 0] 5000 steps, total: 12.525, sample: 1.774, forward: 4.449, backward: 2.165, update: 4.129
[proc 1][Train](5000/10000) average pos_loss: 0.05262266246974468
[proc 1][Train](5000/10000) average neg_loss: 0.08016985630616545
[proc 1][Train](5000/10000) average loss: 0.06639625944569708
[proc 1][Train](5000/10000) average regularization: 1.9642961990030017e-05
[proc 1] 5000 steps, total: 12.525, sample: 1.562, forward: 4.092, backward: 2.172, update: 3.668
[proc 1][Train](6000/10000) average pos_loss: 0.05036434322223067
[proc 1][Train](6000/10000) average neg_loss: 0.0771584812477231
[proc 1][Train](6000/10000) average loss: 0.0637614122927189
[proc 1][Train](6000/10000) average regularization: 2.0352908168206342e-05
[proc 1] 6000 steps, total: 12.622, sample: 1.553, forward: 4.087, backward: 2.239, update: 3.621
[proc 0][Train](6000/10000) average pos_loss: 0.050645422894507644
[proc 0][Train](6000/10000) average neg_loss: 0.07697220331057907
[proc 0][Train](6000/10000) average loss: 0.06380881301313639
[proc 0][Train](6000/10000) average regularization: 2.0375915530166823e-05
[proc 0] 6000 steps, total: 12.642, sample: 1.803, forward: 4.465, backward: 2.215, update: 4.132
[proc 0][Train](7000/10000) average pos_loss: 0.04875237887352705
[proc 0][Train](7000/10000) average neg_loss: 0.07484372632578015
[proc 0][Train](7000/10000) average loss: 0.06179805267229676
[proc 0][Train](7000/10000) average regularization: 2.0958327731932513e-05
[proc 0] 7000 steps, total: 12.485, sample: 1.718, forward: 4.474, backward: 2.168, update: 4.117
[proc 1][Train](7000/10000) average pos_loss: 0.0485525783225894
[proc 1][Train](7000/10000) average neg_loss: 0.07460907780751586
[proc 1][Train](7000/10000) average loss: 0.06158082811161876
[proc 1][Train](7000/10000) average regularization: 2.0933706975483802e-05
[proc 1] 7000 steps, total: 12.505, sample: 1.564, forward: 4.155, backward: 1.911, update: 3.785
[proc 0][Train](8000/10000) average pos_loss: 0.047262524221092464
[proc 0][Train](8000/10000) average neg_loss: 0.07298801102489233
[proc 0][Train](8000/10000) average loss: 0.06012526753544807
[proc 0][Train](8000/10000) average regularization: 2.1442660652610356e-05
[proc 0] 8000 steps, total: 12.310, sample: 1.648, forward: 4.399, backward: 2.180, update: 4.076
[proc 1][Train](8000/10000) average pos_loss: 0.04727119467034936
[proc 1][Train](8000/10000) average neg_loss: 0.07285440453886986
[proc 1][Train](8000/10000) average loss: 0.0600627996660769
[proc 1][Train](8000/10000) average regularization: 2.143371116289927e-05
[proc 1] 8000 steps, total: 12.310, sample: 1.690, forward: 4.235, backward: 2.152, update: 3.783
[proc 0][Train](9000/10000) average pos_loss: 0.046217167560011145
[proc 0][Train](9000/10000) average neg_loss: 0.07171395597979427
[proc 0][Train](9000/10000) average loss: 0.05896556174010038
[proc 0][Train](9000/10000) average regularization: 2.1872081371839158e-05
[proc 0] 9000 steps, total: 12.156, sample: 1.620, forward: 4.392, backward: 2.068, update: 4.070
[proc 1][Train](9000/10000) average pos_loss: 0.04607926919683814
[proc 1][Train](9000/10000) average neg_loss: 0.07144079630449414
[proc 1][Train](9000/10000) average loss: 0.058760032679885624
[proc 1][Train](9000/10000) average regularization: 2.1867750479941605e-05
[proc 1] 9000 steps, total: 12.156, sample: 1.555, forward: 4.197, backward: 2.063, update: 3.774
[proc 0][Train](10000/10000) average pos_loss: 0.04521771045029163
[proc 0][Train](10000/10000) average neg_loss: 0.07055604588985444
[proc 0][Train](10000/10000) average loss: 0.05788687821477652
[proc 0][Train](10000/10000) average regularization: 2.224110897805076e-05
[proc 0] 10000 steps, total: 12.188, sample: 1.608, forward: 4.366, backward: 2.159, update: 4.048
proc 0 takes 124.355 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.045270382210612296
[proc 1][Train](10000/10000) average neg_loss: 0.07017409480735659
[proc 1][Train](10000/10000) average loss: 0.05772223849967122
[proc 1][Train](10000/10000) average regularization: 2.2250244528549955e-05
[proc 1] 10000 steps, total: 12.188, sample: 1.708, forward: 4.340, backward: 2.221, update: 3.871
proc 1 takes 124.355 seconds
Successfully xmh. training takes 124.62185406684875 seconds
-------------- Test result --------------
Test average MRR : 0.5398690716434793
Test average MR : 44.06713107954834
Test average HITS@1 : 0.4017114997206751
Test average HITS@3 : 0.6355402820334851
Test average HITS@10 : 0.768414281119331
-----------------------------------------
testing takes 182.650 seconds
