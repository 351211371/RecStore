WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240218 06:40:59.541776 1681070 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='SimplE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/SimplE_FB15k_17', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=3, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=3, gpu=[0, 1, 2], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=1, update_pq_use_omp=2, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [1681070 sampler.py:454] Start PreSampling
WARNING [1681070 sampler.py:532] Before construct renumbering_dict
WARNING [1681070 sampler.py:555] PreSampling done
W20240218 06:41:01.732103 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240218 06:41:01.732244 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240218 06:41:01.732268 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240218 06:41:01.732287 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240218 06:41:01.732309 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240218 06:41:01.732328 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240218 06:41:01.732345 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240218 06:41:01.732367 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240218 06:41:01.732388 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240218 06:41:01.732412 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240218 06:41:01.732434 1681070 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240218 06:41:01.732450 1681070 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240218 06:41:01.732466 1681070 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240218 06:41:01.732553 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240218 06:41:01.732578 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240218 06:41:01.732600 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240218 06:41:01.732630 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240218 06:41:01.732645 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240218 06:41:01.732659 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240218 06:41:01.732673 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240218 06:41:01.732690 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240218 06:41:01.732707 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240218 06:41:01.732722 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240218 06:41:01.732738 1681070 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240218 06:41:01.732750 1681070 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240218 06:41:01.732762 1681070 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240218 06:41:01.732793 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240218 06:41:01.732815 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240218 06:41:01.732832 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240218 06:41:01.732846 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240218 06:41:01.732863 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240218 06:41:01.732882 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240218 06:41:01.732899 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240218 06:41:01.732916 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240218 06:41:01.732934 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240218 06:41:01.732949 1681070 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240218 06:41:01.732964 1681070 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240218 06:41:01.732976 1681070 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240218 06:41:01.732990 1681070 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
{0: Graph(num_nodes=11088, num_edges=209563,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12469, num_edges=203028,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11122, num_edges=307147,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 11088 N 209563 E
MertisPartition: part 1 has 12469 N 203028 E
MertisPartition: part 2 has 11122 N 307147 E
Rank0: cached key size 249
Rank1: cached key size 249
Rank2: cached key size 249
Before renumbering graph:  {'_ID': tensor([   7,   10,   16,  ..., 9100, 2559, 8058]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([ 972, 1069, 1279,  ..., 6649, 6166, 3819]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=11088, num_edges=209563,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=11088, num_edges=209563,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.362 seconds
[Rank1] pid = 1681295
INFO [1681070 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [1681359 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [1681295 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [1681359 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [1681070 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [1681295 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
E20240218 06:41:09.364367 1681296 recstore.cc:67] init folly done
E20240218 06:41:09.364384 1681361 recstore.cc:67] init folly done
E20240218 06:41:09.364598 1681360 recstore.cc:67] init folly done
I20240218 06:41:09.410866 1681296 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 3
I20240218 06:41:09.429412 1681361 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
I20240218 06:41:09.435482 1681360 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
[Rank2] pid = 1681359
train_sampler.Prefill()
-------Step 0-------
tensor([   12, 12502,  9068,    69,    48,  9607,  5044,  7701,  6446,  9291]) tensor([ 1279,  2977, 14671,  4753,  8427,  8843,   369,  6598,  5091, 12718])
-------Step 1-------
tensor([   12, 12502,  9068,    69,    48,  9607,  5044,  7701,  6446,  9291]) tensor([ 8325,  3618,  4191,  2167,   649,   286,     8, 14076,   457, 12056])
-------Step 2-------
tensor([   0, 2107, 7527, 3998, 3349,  173, 6399,  726,  213, 8600]) tensor([  598,  3411,  2725,  6204,  6409, 10172,  1546,   520, 13718,  8205])
-------Step 3-------
tensor([   0, 2107, 7527, 3998, 3349,  173, 6399,  726,  213, 8600]) tensor([ 8221, 11768,  8937, 11508, 14063,  7772,   736,  6158,  4020,  9422])
-------Step 4-------
tensor([10411,  8312,     4,    85,  9291,  5044,  4570, 14109,  1535,    18]) tensor([10816,  2763, 11501, 14054, 13384, 10967, 11646,  6429,  1943, 12338])
-------Step 5-------
tensor([10411,  8312,     4,    85,  9291,  5044,  4570, 14109,  1535,    18]) tensor([ 5538, 12574, 13899, 12411,  6027, 13489,  3748,  5669, 13365, 12588])
-------Step 6-------
tensor([12568,  6863, 12606, 11943, 12699,  7822,  8936, 13621,  4587, 12061]) tensor([ 9474,  6588, 12941,  1851,  4670,    85,  9734, 12566, 10513,    91])
-------Step 7-------
tensor([12568,  6863, 12606, 11943, 12699,  7822,  8936, 13621,  4587, 12061]) tensor([ 8914, 11971,  3212,  2637, 14486,   710,  2518, 12189,  2815, 11986])
-------Step 8-------
tensor([ 5267,    23,    62,  9468,   134, 11700,  8926,    66,    36, 13561]) tensor([ 4606,  9996, 13692,  8598,  5148,  3493, 11176,  3091,  8858, 11617])
-------Step 9-------
tensor([ 5267,    23,    62,  9468,   134, 11700,  8926,    66,    36, 13561]) tensor([  347,  6451, 14344,  8727,   936, 10727, 10122, 14076,  2399,  2735])
before start barrier
start train
[proc 0] 100 steps, total: 4.367, sample: 0.210, forward: 1.463, backward: 1.727, update: 0.649
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.392, sample: 0.232, forward: 1.466, backward: 1.753, update: 0.608
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.373, sample: 0.236, forward: 1.427, backward: 1.575, update: 0.595
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 826.603 us                | 15.405 ms                 |
| Forward                   | 5.625 ms                  | 14.034 ms                 |
| Backward                  | 5.074 ms                  | 243.506 ms                |
| Optimize                  | 6.226 ms                  | 17.077 ms                 |
| OneStep                   | 19.277 ms                 | 1.029 s                   |
+---------------------------+---------------------------+---------------------------+
[proc 1] 200 steps, total: 2.060, sample: 0.234, forward: 0.554, backward: 0.494, update: 0.570
[proc 2] 200 steps, total: 2.061, sample: 0.240, forward: 0.548, backward: 0.498, update: 0.572
[proc 0] 200 steps, total: 2.061, sample: 0.208, forward: 0.561, backward: 0.466, update: 0.627
[proc 0] 300 steps, total: 1.957, sample: 0.189, forward: 0.529, backward: 0.446, update: 0.589
[proc 1] 300 steps, total: 1.957, sample: 0.208, forward: 0.553, backward: 0.496, update: 0.538
[proc 2] 300 steps, total: 1.957, sample: 0.209, forward: 0.541, backward: 0.504, update: 0.535
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 826.603 us                | 12.664 ms                 |
| Forward                   | 5.639 ms                  | 9.320 ms                  |
| Backward                  | 4.994 ms                  | 5.583 ms                  |
| Optimize                  | 6.226 ms                  | 9.384 ms                  |
| OneStep                   | 19.124 ms                 | 36.391 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 400 steps, total: 2.327, sample: 0.219, forward: 0.580, backward: 0.484, update: 0.588
[proc 2] 400 steps, total: 2.327, sample: 0.262, forward: 0.582, backward: 0.497, update: 0.550
[proc 1] 400 steps, total: 2.327, sample: 0.274, forward: 0.592, backward: 0.495, update: 0.548
[proc 0] 500 steps, total: 2.607, sample: 0.274, forward: 0.646, backward: 0.494, update: 0.635
[proc 1] 500 steps, total: 2.607, sample: 0.306, forward: 0.647, backward: 0.502, update: 0.601
[proc 2] 500 steps, total: 2.607, sample: 0.297, forward: 0.645, backward: 0.500, update: 0.603
Successfully xmh. training takes 13.318918704986572 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
