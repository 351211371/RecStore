WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240218 00:14:18.611716 1307111 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_12', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=1, update_pq_use_omp=2, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [1307111 sampler.py:454] Start PreSampling
WARNING [1307111 sampler.py:532] Before construct renumbering_dict
WARNING [1307111 sampler.py:555] PreSampling done
W20240218 00:14:20.694290 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240218 00:14:20.694389 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240218 00:14:20.694408 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240218 00:14:20.694424 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240218 00:14:20.694440 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240218 00:14:20.694455 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240218 00:14:20.694470 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240218 00:14:20.694489 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240218 00:14:20.694506 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240218 00:14:20.694522 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240218 00:14:20.694540 1307111 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240218 00:14:20.694554 1307111 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240218 00:14:20.694571 1307111 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240218 00:14:20.694643 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240218 00:14:20.694664 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240218 00:14:20.694679 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240218 00:14:20.694706 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240218 00:14:20.694725 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240218 00:14:20.694738 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240218 00:14:20.694753 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240218 00:14:20.694768 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240218 00:14:20.694783 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240218 00:14:20.694798 1307111 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240218 00:14:20.694814 1307111 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240218 00:14:20.694828 1307111 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240218 00:14:20.694841 1307111 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13804, num_edges=289155,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12626, num_edges=379866,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13804 N 289155 E
MertisPartition: part 1 has 12626 N 379866 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  762,   828,   964,  ...,  9977, 12069, 12368]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.249 seconds
INFO [1307111 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [1307111 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [1307453 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [1307453 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240218 00:14:22.734822 1307454 recstore.cc:67] init folly done
E20240218 00:14:22.734831 1307485 recstore.cc:67] init folly done
I20240218 00:14:22.814105 1307454 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240218 00:14:22.830462 1307485 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
[Rank1] pid = 1307453
train_sampler.Prefill()
-------Step 0-------
tensor([  195,  5712, 10179,  7194,  2885, 13232,  4034,  7461,  7454,  8302]) tensor([  983,  9487, 12205, 12590, 14250,  7180,  6747,   384,  6917,  8642])
-------Step 1-------
tensor([  195,  5712, 10179,  7194,  2885, 13232,  4034,  7461,  7454,  8302]) tensor([13820,  1712,  1969,  4736,  8798, 11196, 11406,  9804, 12264,  5129])
-------Step 2-------
tensor([13232,     4,    87,   294,  6160,  6450,  1586, 10793,  7865, 12050]) tensor([ 2469,  2057, 13322, 12605,  4757,  8001, 13779,  2208,  5267,  5387])
-------Step 3-------
tensor([13232,     4,    87,   294,  6160,  6450,  1586, 10793,  7865, 12050]) tensor([14408,  2285,   215,  5531,  5825, 10055,  3550,   816, 13628, 12576])
-------Step 4-------
tensor([ 2439,  1994,    98,  1730,  9495,  6366, 10322,  9290,   124,  6680]) tensor([ 6302, 12957,  9968,  7990, 12733,  6758,  7294,  9286,  4694,  7923])
-------Step 5-------
tensor([ 2439,  1994,    98,  1730,  9495,  6366, 10322,  9290,   124,  6680]) tensor([ 7403,  2755, 11282,  5146,  3414,  9437,    57,   789,  5890,  8157])
-------Step 6-------
tensor([ 6219,  3181,  7047,   333,  1274,   113, 13232,  7127,   344,   293]) tensor([14158, 14462,  8519,  8906,   872,  5951,  3863, 14876, 13536, 10216])
-------Step 7-------
tensor([ 6219,  3181,  7047,   333,  1274,   113, 13232,  7127,   344,   293]) tensor([ 7147,  1758, 13883, 13593, 13761,  7970,  2056,   568,    84,  6946])
-------Step 8-------
tensor([ 5205, 10039,  6705,  1975,  5712,  5136,  6160,  2439, 12304, 12643]) tensor([13978,  6309, 13356,  5176,  6459,  9716,  2551,  9372, 11989, 12044])
-------Step 9-------
tensor([ 5205, 10039,  6705,  1975,  5712,  5136,  6160,  2439, 12304, 12643]) tensor([ 4018, 10507, 13452, 14060, 12237,  4576,  2529,  9804, 12161,  3425])
before start barrier
start train
[proc 0] 100 steps, total: 3.769, sample: 0.217, forward: 1.319, backward: 1.077, update: 0.632
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.752, sample: 0.225, forward: 1.654, backward: 1.081, update: 0.640
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 849.277 us                | 12.063 ms                 |
| Forward                   | 5.929 ms                  | 14.334 ms                 |
| Backward                  | 4.746 ms                  | 4.915 ms                  |
| Optimize                  | 6.202 ms                  | 10.660 ms                 |
| OneStep                   | 18.883 ms                 | 40.809 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 200 steps, total: 2.020, sample: 0.224, forward: 0.577, backward: 0.467, update: 0.618
[proc 0] 200 steps, total: 2.020, sample: 0.215, forward: 0.586, backward: 0.465, update: 0.609
[proc 1] 300 steps, total: 1.709, sample: 0.188, forward: 0.456, backward: 0.427, update: 0.480
[proc 0] 300 steps, total: 1.709, sample: 0.183, forward: 0.499, backward: 0.427, update: 0.489
[proc 0] 400 steps, total: 1.497, sample: 0.163, forward: 0.398, backward: 0.427, update: 0.398
[proc 1] 400 steps, total: 1.497, sample: 0.180, forward: 0.400, backward: 0.430, update: 0.410
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 832.477 us                | 10.286 ms                 |
| Forward                   | 5.663 ms                  | 8.624 ms                  |
| Backward                  | 4.679 ms                  | 4.899 ms                  |
| Optimize                  | 5.624 ms                  | 7.691 ms                  |
| OneStep                   | 18.341 ms                 | 29.976 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 500 steps, total: 1.766, sample: 0.199, forward: 0.497, backward: 0.450, update: 0.511
[proc 0] 500 steps, total: 1.766, sample: 0.188, forward: 0.462, backward: 0.441, update: 0.476
Successfully xmh. training takes 10.760444164276123 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
