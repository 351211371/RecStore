WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240218 01:18:11.742981 1365910 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_17', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=3, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=3, gpu=[0, 1, 2], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, nr_background_threads=32, update_cache_use_omp=1, update_pq_use_omp=2, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [1365910 sampler.py:454] Start PreSampling
WARNING [1365910 sampler.py:532] Before construct renumbering_dict
WARNING [1365910 sampler.py:555] PreSampling done
W20240218 01:18:13.926316 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240218 01:18:13.926438 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240218 01:18:13.926461 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240218 01:18:13.926482 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240218 01:18:13.926501 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240218 01:18:13.926517 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240218 01:18:13.926535 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240218 01:18:13.926555 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240218 01:18:13.926574 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240218 01:18:13.926589 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240218 01:18:13.926609 1365910 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240218 01:18:13.926626 1365910 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240218 01:18:13.926645 1365910 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240218 01:18:13.926719 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240218 01:18:13.926738 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240218 01:18:13.926755 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240218 01:18:13.926787 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240218 01:18:13.926808 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240218 01:18:13.926826 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240218 01:18:13.926844 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240218 01:18:13.926867 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240218 01:18:13.926885 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240218 01:18:13.926900 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240218 01:18:13.926918 1365910 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240218 01:18:13.926931 1365910 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240218 01:18:13.926944 1365910 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240218 01:18:13.926976 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240218 01:18:13.926995 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240218 01:18:13.927009 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240218 01:18:13.927023 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240218 01:18:13.927038 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240218 01:18:13.927055 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240218 01:18:13.927073 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240218 01:18:13.927091 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240218 01:18:13.927106 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240218 01:18:13.927124 1365910 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240218 01:18:13.927140 1365910 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240218 01:18:13.927152 1365910 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240218 01:18:13.927167 1365910 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
{0: Graph(num_nodes=11088, num_edges=209563,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12469, num_edges=203028,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11122, num_edges=307147,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 11088 N 209563 E
MertisPartition: part 1 has 12469 N 203028 E
MertisPartition: part 2 has 11122 N 307147 E
Rank0: cached key size 249
Rank1: cached key size 249
Rank2: cached key size 249
Before renumbering graph:  {'_ID': tensor([   7,   10,   16,  ..., 9100, 2559, 8058]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([ 952, 1034, 1224,  ..., 7505, 7328, 4111]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=11088, num_edges=209563,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=11088, num_edges=209563,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.350 seconds
[Rank1] pid = 1366244
INFO [1366244 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [1365910 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [1365910 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [1366308 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [1366308 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [1366244 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
E20240218 01:18:21.512113 1366245 recstore.cc:67] init folly done
E20240218 01:18:21.512228 1366310 recstore.cc:67] init folly done
E20240218 01:18:21.512534 1366309 recstore.cc:67] init folly done
I20240218 01:18:21.563797 1366245 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 3
I20240218 01:18:21.568023 1366310 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
I20240218 01:18:21.582320 1366309 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
[Rank2] pid = 1366308
train_sampler.Prefill()
-------Step 0-------
tensor([    1, 11459, 10223,   200,   176,  8657,  5613,  6611,  6039, 10088]) tensor([ 1224,  3326, 14033,  5557,  7683,  7792,   348,  7087,  4823, 14564])
-------Step 1-------
tensor([    1, 11459, 10223,   200,   176,  8657,  5613,  6611,  6039, 10088]) tensor([ 8145,  3789,  3898,  2244,   646,   288,     8, 14497,   407, 12312])
-------Step 2-------
tensor([   0, 2015, 8249, 4709, 3123,  141, 5940,  705,  230, 7976]) tensor([  635,  3177,  2535,  5663,  5896,  8823,  1504,   522, 13486,  9387])
-------Step 3-------
tensor([   0, 2015, 8249, 4709, 3123,  141, 5940,  705,  230, 7976]) tensor([ 7202, 10627,  8258, 10761, 14842,  9303,   730,  6437,  4568,  9908])
-------Step 4-------
tensor([10283,  7504,    94,   132, 10088,  5613,  4353, 13446,  1536,    36]) tensor([ 9708,  3019, 10501, 13443, 13588, 12645, 10607,  6077,  1893, 13510])
-------Step 5-------
tensor([10283,  7504,    94,   132, 10088,  5613,  4353, 13446,  1536,    36]) tensor([ 5087, 13245, 13194, 11309,  6604, 13053,  3901,  5272, 13540, 11595])
-------Step 6-------
tensor([11778,  7243, 10855, 11124, 11836,  8415,  9733, 12898,  4719, 10785]) tensor([ 8452,  5950, 11987,  1980,  5018,   132,  8870, 14071, 10383,     7])
-------Step 7-------
tensor([11778,  7243, 10855, 11124, 11836,  8415,  9733, 12898,  4719, 10785]) tensor([ 9652, 11018,  3026,  2824, 14349,   737,  2432, 13167,  2905, 11238])
-------Step 8-------
tensor([ 4998,   128,   157,  8538,    14, 10683,  9252,     5,     3, 12517]) tensor([ 4191, 10821, 12702,  8043,  4722,  3246, 10897,  3286,  9760, 10348])
-------Step 9-------
tensor([ 4998,   128,   157,  8538,    14, 10683,  9252,     5,     3, 12517]) tensor([  342,  6233, 14069,  9859,   934,  9843,  9974, 14497,  2536,  2569])
before start barrier
start train
[proc 0] 100 steps, total: 4.777, sample: 0.222, forward: 1.710, backward: 1.967, update: 0.617
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.795, sample: 0.224, forward: 1.727, backward: 1.789, update: 0.663
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.791, sample: 0.225, forward: 1.614, backward: 1.721, update: 0.719
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 917.517 us                | 16.398 ms                 |
| Forward                   | 6.037 ms                  | 36.869 ms                 |
| Backward                  | 4.836 ms                  | 397.791 ms                |
| Optimize                  | 5.722 ms                  | 18.124 ms                 |
| OneStep                   | 19.554 ms                 | 1.176 s                   |
+---------------------------+---------------------------+---------------------------+
[proc 1] 200 steps, total: 2.069, sample: 0.220, forward: 0.603, backward: 0.468, update: 0.608
[proc 2] 200 steps, total: 2.069, sample: 0.224, forward: 0.549, backward: 0.457, update: 0.659
[proc 0] 200 steps, total: 2.070, sample: 0.218, forward: 0.601, backward: 0.467, update: 0.576
[proc 0] 300 steps, total: 1.962, sample: 0.200, forward: 0.562, backward: 0.440, update: 0.522
[proc 2] 300 steps, total: 1.962, sample: 0.202, forward: 0.534, backward: 0.444, update: 0.606
[proc 1] 300 steps, total: 1.962, sample: 0.197, forward: 0.552, backward: 0.458, update: 0.547
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 916.665 us                | 10.622 ms                 |
| Forward                   | 6.001 ms                  | 10.558 ms                 |
| Backward                  | 4.740 ms                  | 5.070 ms                  |
| Optimize                  | 5.593 ms                  | 9.128 ms                  |
| OneStep                   | 19.112 ms                 | 38.536 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 400 steps, total: 2.291, sample: 0.216, forward: 0.660, backward: 0.456, update: 0.596
[proc 2] 400 steps, total: 2.291, sample: 0.219, forward: 0.557, backward: 0.456, update: 0.640
[proc 1] 400 steps, total: 2.291, sample: 0.241, forward: 0.600, backward: 0.471, update: 0.600
[proc 2] 500 steps, total: 2.389, sample: 0.221, forward: 0.585, backward: 0.461, update: 0.673
[proc 0] 500 steps, total: 2.390, sample: 0.235, forward: 0.652, backward: 0.460, update: 0.604
Successfully xmh. training takes 13.488898038864136 seconds
before call kg_cache_controller.StopThreads()
[proc 1] 500 steps, total: 2.389, sample: 0.247, forward: 0.599, backward: 0.469, update: 0.622
KGCacheControllerWrapperDummy.StopThreads
