WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 12:33:44.076601 83300 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_0', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.01, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [83300 sampler.py:454] Start PreSampling
WARNING [83300 sampler.py:532] Before construct renumbering_dict
WARNING [83300 sampler.py:555] PreSampling done
W20240128 12:33:47.575567 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 12:33:47.575690 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 12:33:47.575716 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 12:33:47.575740 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 12:33:47.575755 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 12:33:47.575778 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 12:33:47.575796 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 12:33:47.575822 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 12:33:47.575838 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 12:33:47.575857 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 12:33:47.575886 83300 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 12:33:47.575903 83300 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 12:33:47.575922 83300 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 12:33:47.576025 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 12:33:47.576051 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 12:33:47.576069 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 12:33:47.576098 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 12:33:47.576113 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 12:33:47.576130 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 12:33:47.576148 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 12:33:47.576161 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 12:33:47.576181 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 12:33:47.576198 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 12:33:47.576212 83300 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 12:33:47.576224 83300 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 12:33:47.576239 83300 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 12:33:47.576277 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 12:33:47.576296 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 12:33:47.576314 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 12:33:47.576333 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 12:33:47.576352 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 12:33:47.576372 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 12:33:47.576386 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 12:33:47.576401 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 12:33:47.576417 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 12:33:47.576434 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 12:33:47.576453 83300 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 12:33:47.576465 83300 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 12:33:47.576476 83300 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 12:33:47.576510 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 12:33:47.576530 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 12:33:47.576547 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 12:33:47.576561 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 12:33:47.576586 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 12:33:47.576604 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 12:33:47.576618 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 12:33:47.576637 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 12:33:47.576658 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 12:33:47.576673 83300 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 12:33:47.576691 83300 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 12:33:47.576711 83300 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 12:33:47.576723 83300 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 12:33:47.707384 83300 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 12:33:47.707506 83300 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 37
Rank1: cached key size 37
Rank2: cached key size 37
Rank3: cached key size 37
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([ 279,  498,  583,  ..., 1170, 5936, 6693]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.663 seconds
[Rank1] pid = 83514
[Rank2] pid = 83579
INFO [83300 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [83514 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [83579 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [83579 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [83643 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [83300 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [83643 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [83514 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 12:33:51.105005 83644 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_0 [149, 400]; dev=0; size=232.8 kB
W20240128 12:33:51.105123 83580 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_2 [149, 400]; dev=2; size=232.8 kB
W20240128 12:33:51.105389 83515 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_1 [149, 400]; dev=1; size=232.8 kB
W20240128 12:33:51.105787 83644 IPCTensor.h:368] NewIPCTensor: input_keys_0 [1000000]0x10001487a000 7.629 MB
W20240128 12:33:51.105805 83580 IPCTensor.h:368] NewIPCTensor: input_keys_2 [1000000]0x10001501d000 7.629 MB
W20240128 12:33:51.105830 83515 IPCTensor.h:368] NewIPCTensor: input_keys_1 [1000000]0x1000157c0000 7.629 MB
W20240128 12:33:51.105940 83515 IPCTensor.h:368] NewIPCTensor: input_keys_neg_1 [1000000]0x100015f63000 7.629 MB
W20240128 12:33:51.105964 83580 IPCTensor.h:368] NewIPCTensor: input_keys_neg_2 [1000000]0x100016ea9000 7.629 MB
W20240128 12:33:51.105960 83644 IPCTensor.h:368] NewIPCTensor: input_keys_neg_0 [1000000]0x100016706000 7.629 MB
W20240128 12:33:51.105996 83515 IPCTensor.h:368] NewIPCTensor: backward_grads_1 [1000000, 400]0x10001764c000 1.49 GB
W20240128 12:33:51.106030 83580 IPCTensor.h:368] NewIPCTensor: backward_grads_2 [1000000, 400]0x100076c2f000 1.49 GB
W20240128 12:33:51.106035 83515 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1000d6212000 1.49 GB
W20240128 12:33:51.106050 83644 IPCTensor.h:368] NewIPCTensor: backward_grads_0 [1000000, 400]0x1001357f5000 1.49 GB
W20240128 12:33:51.106079 83515 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 12:33:51.106089 83580 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x100194dd8000 1.49 GB
W20240128 12:33:51.106115 83644 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1001f43bb000 1.49 GB
W20240128 12:33:51.106149 83580 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 12:33:51.106169 83644 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 12:33:51.106213 83645 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_3 [149, 400]; dev=3; size=232.8 kB
W20240128 12:33:51.114881 83580 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 12:33:51.114897 83515 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 12:33:51.114951 83644 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 12:33:51.115097 83645 IPCTensor.h:368] NewIPCTensor: input_keys_3 [1000000]0x1002539a6000 7.629 MB
W20240128 12:33:51.115295 83645 IPCTensor.h:368] NewIPCTensor: input_keys_neg_3 [1000000]0x100254149000 7.629 MB
W20240128 12:33:51.115388 83645 IPCTensor.h:368] NewIPCTensor: backward_grads_3 [1000000, 400]0x1002548ec000 1.49 GB
W20240128 12:33:51.115460 83645 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1002b3ecf000 1.49 GB
W20240128 12:33:51.115520 83645 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 12:33:51.128190 83645 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
[Rank3] pid = 83643
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 149), (149, 298), (298, 447), (447, 596)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [83300 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [83514 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [83643 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [83579 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 12:33:52.451458 83580 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 12:33:52.451511 83645 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 12:33:52.451572 83515 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 12:33:52.451648 83644 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240128 12:33:52.453120 83644 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.01,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240128 12:33:52.453280 83644 grad_base.h:184] Init GradProcessingBase done
I20240128 12:33:52.457646 83644 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240128 12:33:52.457744 83644 kg_controller.h:78] after init GradAsyncProcessingV2
I20240128 12:33:52.457749 83644 kg_controller.h:84] Construct KGCacheController done
I20240128 12:33:52.813273 83644 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240128 12:33:53.468008 84167 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240128 12:33:53.468514 84167 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240128 12:33:53.489715 83515 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 12:33:53.501696 83644 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 12:33:53.508224 83580 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 12:33:53.509621 83645 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240128 12:33:55.765215 83941 parallel_pq_v2.h:76] insert failed, size(hashtable)=5
W20240128 12:33:55.775235 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=1, pq.top=0
W20240128 12:33:55.778148 84167 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
E20240128 12:33:56.765385 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=7817
W20240128 12:33:56.783936 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=45, pq.top=45
W20240128 12:33:56.788982 84167 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 913.041 us                | 10.125 ms                 |
| Forward                   | 2.392 ms                  | 7.263 ms                  |
| Backward                  | 1.838 ms                  | 3.745 ms                  |
| Optimize                  | 875.315 us                | 1.636 ms                  |
| BarrierTimeBeforeRank0    | 104.723 us                | 4.207 ms                  |
| AfterBackward             | 11.663 ms                 | 14.790 ms                 |
| BlockToStepN              | 2.769 ms                  | 9.032 ms                  |
| OneStep                   | 22.752 ms                 | 34.495 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 12:33:57.765012 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=7662
W20240128 12:33:57.794917 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=88, pq.top=88
W20240128 12:33:57.798527 84167 grad_async_v2.h:120] Detect new sample comes, old_end8, new_end9
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.678 ms                  | 3.439 ms                  |
| ProcessBack:UpdateCache   | 1.480 ms                  | 3.217 ms                  |
| ProcessBack:UpsertPq      | 7.762 ms                  | 10.703 ms                 |
| ProcessOneStep            | 11.558 ms                 | 14.769 ms                 |
| BlockToStepN              | 2.929 ms                  | 8.979 ms                  |
+---------------------------+---------------------------+---------------------------+
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.572, sample: 0.145, forward: 0.927, backward: 0.443, update: 0.108
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.590, sample: 0.154, forward: 1.404, backward: 0.428, update: 0.122
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.570, sample: 0.188, forward: 0.958, backward: 0.419, update: 0.120
train_sampler.Prefill()
-------Step 0-------
tensor([   11,  3694, 10619,  5843,  7110,  3934, 10666,     9, 11291,  9699]) tensor([  583,  7191, 10743,  3615,  7617,  7659, 13318,  8010,  7279,  8570])
-------Step 1-------
tensor([   11,  3694, 10619,  5843,  7110,  3934, 10666,     9, 11291,  9699]) tensor([ 5964, 11017, 13340,   426, 10453, 10131,  1093,  8392,  6997,  7799])
-------Step 2-------
tensor([ 5540, 12528,  6202,  5448,  4671,  8472,  9893,  8234, 10678,  2868]) tensor([11353,  2453,   998,  9561,  4135, 11313,  5963,  3959,  9493,  5167])
-------Step 3-------
tensor([ 5540, 12528,  6202,  5448,  4671,  8472,  9893,  8234, 10678,  2868]) tensor([ 5661, 11006,  6772, 10786,  6916,   837,  9028, 13125,  9888, 14076])
-------Step 4-------
tensor([ 9029,  1503,  3532,  2260, 10949,  7771,  3775,  9931, 11611,  7562]) tensor([ 9280,  2923,  2513, 12648,   981,  1734, 13611,  6346, 10935,  6622])
-------Step 5-------
tensor([ 9029,  1503,  3532,  2260, 10949,  7771,  3775,  9931, 11611,  7562]) tensor([ 5941,  9066,  4933,  7660, 10826,  6352,  4085,  3496,  9105, 13288])
-------Step 6-------
tensor([ 9078,  9920,  4912,  7088,   839,  5400,  7286,  1866, 13500,  7248]) tensor([ 7643,  4241,  2342,  9990,  7911,   141,  3641, 12657, 11836,  3532])
-------Step 7-------
tensor([ 9078,  9920,  4912,  7088,   839,  5400,  7286,  1866, 13500,  7248]) tensor([ 5053,  7285,  9650, 11090,  9229,  4118, 11838, 10220,  3853, 12187])
-------Step 8-------
tensor([ 2247, 14852, 10498,    35,  4361,  4912, 12208,  5823,  2835,   747]) tensor([14457,  4564, 10317,  9534,  3218,  8505,  5257,  4563,  8870, 11918])
-------Step 9-------
tensor([ 2247, 14852, 10498,    35,  4361,  4912, 12208,  5823,  2835,   747]) tensor([14011, 11808, 13820,  5506, 11738,  7907,  5848,  1147,  7538,  9189])
before start barrier
start train
[proc 0] 100 steps, total: 4.578, sample: 0.165, forward: 1.511, backward: 0.350, update: 0.119
E20240128 12:33:58.765024 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=7396
W20240128 12:33:58.794198 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=127, pq.top=127
W20240128 12:33:58.802520 84167 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
E20240128 12:33:59.765009 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=8624
W20240128 12:33:59.811475 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=164, pq.top=164
W20240128 12:33:59.817847 84167 grad_async_v2.h:120] Detect new sample comes, old_end4, new_end5
E20240128 12:34:00.765064 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=7807
W20240128 12:34:00.821065 84167 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 12:34:00.836552 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=200, pq.top=200
[proc 2] 200 steps, total: 2.764, sample: 0.179, forward: 0.215, backward: 0.192, update: 0.066
[proc 3] 200 steps, total: 2.764, sample: 0.151, forward: 0.203, backward: 0.209, update: 0.072
[proc 1] 200 steps, total: 2.764, sample: 0.167, forward: 0.225, backward: 0.181, update: 0.073
[proc 0] 200 steps, total: 2.764, sample: 0.170, forward: 0.207, backward: 0.171, update: 0.074
E20240128 12:34:01.765010 83644 parallel_pq_v2.h:76] insert failed, size(hashtable)=4
W20240128 12:34:01.821903 84167 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
W20240128 12:34:01.840101 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=236, pq.top=236
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.008 ms                  | 9.542 ms                  |
| Forward                   | 2.148 ms                  | 3.075 ms                  |
| Backward                  | 1.844 ms                  | 3.707 ms                  |
| Optimize                  | 822.973 us                | 1.601 ms                  |
| BarrierTimeBeforeRank0    | 92.395 us                 | 4.192 ms                  |
| AfterBackward             | 11.552 ms                 | 14.975 ms                 |
| BlockToStepN              | 5.824 ms                  | 18.210 ms                 |
| OneStep                   | 24.957 ms                 | 45.113 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 12:34:02.765039 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=8672
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.653 ms                  | 2.353 ms                  |
| ProcessBack:UpdateCache   | 1.336 ms                  | 2.794 ms                  |
| ProcessBack:UpsertPq      | 7.759 ms                  | 10.706 ms                 |
| ProcessOneStep            | 11.556 ms                 | 14.914 ms                 |
| BlockToStepN              | 5.835 ms                  | 18.150 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240128 12:34:02.823249 84167 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
W20240128 12:34:02.840463 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=273, pq.top=273
[proc 1] 300 steps, total: 2.790, sample: 0.180, forward: 0.255, backward: 0.197, update: 0.072
[proc 2] 300 steps, total: 2.790, sample: 0.158, forward: 0.205, backward: 0.161, update: 0.067
[proc 3] 300 steps, total: 2.790, sample: 0.160, forward: 0.206, backward: 0.173, update: 0.068
[proc 0] 300 steps, total: 2.790, sample: 0.213, forward: 0.250, backward: 0.181, update: 0.078
E20240128 12:34:03.765014 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=6492
W20240128 12:34:03.835999 84167 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
W20240128 12:34:03.855772 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=308, pq.top=308
E20240128 12:34:04.765012 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=9641
W20240128 12:34:04.848870 84167 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
W20240128 12:34:04.866827 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=343, pq.top=343
E20240128 12:34:05.765015 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=10553
W20240128 12:34:05.865572 84167 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
W20240128 12:34:05.884709 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=378, pq.top=378
[proc 2] 400 steps, total: 2.936, sample: 0.153, forward: 0.201, backward: 0.156, update: 0.067
[proc 3] 400 steps, total: 2.936, sample: 0.162, forward: 0.209, backward: 0.169, update: 0.067
[proc 0] 400 steps, total: 2.936, sample: 0.214, forward: 0.252, backward: 0.184, update: 0.077
[proc 1] 400 steps, total: 2.936, sample: 0.183, forward: 0.260, backward: 0.192, update: 0.073
E20240128 12:34:06.765013 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=10577
W20240128 12:34:06.867640 84167 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 12:34:06.884439 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=410, pq.top=410
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.066 ms                  | 9.630 ms                  |
| Forward                   | 2.548 ms                  | 3.065 ms                  |
| Backward                  | 1.879 ms                  | 3.662 ms                  |
| Optimize                  | 819.994 us                | 1.565 ms                  |
| BarrierTimeBeforeRank0    | 22.150 us                 | 4.182 ms                  |
| AfterBackward             | 11.742 ms                 | 14.790 ms                 |
| BlockToStepN              | 7.125 ms                  | 18.587 ms                 |
| OneStep                   | 26.292 ms                 | 45.113 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 12:34:07.765009 83941 parallel_pq_v2.h:76] insert failed, size(hashtable)=270
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.815 ms                  | 2.165 ms                  |
| ProcessBack:UpdateCache   | 1.454 ms                  | 2.497 ms                  |
| ProcessBack:UpsertPq      | 7.698 ms                  | 10.408 ms                 |
| ProcessOneStep            | 11.756 ms                 | 14.769 ms                 |
| BlockToStepN              | 7.130 ms                  | 18.548 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240128 12:34:07.877629 84167 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
W20240128 12:34:07.897379 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=443, pq.top=443
E20240128 12:34:08.765009 84166 parallel_pq_v2.h:76] insert failed, size(hashtable)=7945
W20240128 12:34:08.886354 84167 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240128 12:34:08.905113 83644 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=474, pq.top=474
[proc 1] 500 steps, total: 3.169, sample: 0.183, forward: 0.260, backward: 0.194, update: 0.071
[proc 3] 500 steps, total: 3.169, sample: 0.165, forward: 0.208, backward: 0.169, update: 0.067
[proc 2] 500 steps, total: 3.169, sample: 0.159, forward: 0.194, backward: 0.157, update: 0.063
[proc 0] 500 steps, total: 3.169, sample: 0.222, forward: 0.254, backward: 0.190, update: 0.076
Successfully xmh. training takes 16.237372875213623 seconds
before call kg_cache_controller.StopThreads()
W20240128 12:34:09.739058 83644 grad_async_v2.h:71] call StopThreads. PID = 83300
W20240128 12:34:09.739089 83644 grad_base.h:212] before processOneStepNegThread_.join();
W20240128 12:34:09.739290 83644 grad_base.h:214] after processOneStepNegThread_.join();
W20240128 12:34:09.739298 83644 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
W20240128 12:34:09.744100 83644 grad_async_v2.h:91] StopThreads done.
