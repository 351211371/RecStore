WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 17:34:08.324849 584331 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='SimplE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/SimplE_FB15k_5', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.01, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [584331 sampler.py:454] Start PreSampling
WARNING [584331 sampler.py:532] Before construct renumbering_dict
WARNING [584331 sampler.py:555] PreSampling done
W20240128 17:34:11.010376 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 17:34:11.010519 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 17:34:11.010551 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 17:34:11.010576 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 17:34:11.010594 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 17:34:11.010614 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 17:34:11.010637 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 17:34:11.010661 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 17:34:11.010684 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 17:34:11.010707 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 17:34:11.010730 584331 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 17:34:11.010751 584331 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 17:34:11.010766 584331 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 17:34:11.010874 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 17:34:11.010900 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 17:34:11.010919 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 17:34:11.010957 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 17:34:11.010983 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 17:34:11.011003 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 17:34:11.011023 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 17:34:11.011044 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 17:34:11.011065 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 17:34:11.011081 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 17:34:11.011102 584331 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 17:34:11.011117 584331 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 17:34:11.011132 584331 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 17:34:11.011174 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 17:34:11.011196 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 17:34:11.011217 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 17:34:11.011236 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 17:34:11.011257 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 17:34:11.011273 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 17:34:11.011294 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 17:34:11.011315 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 17:34:11.011337 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 17:34:11.011354 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 17:34:11.011374 584331 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 17:34:11.011389 584331 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 17:34:11.011404 584331 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 17:34:11.011442 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 17:34:11.011468 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 17:34:11.011487 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 17:34:11.011507 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 17:34:11.011523 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 17:34:11.011541 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 17:34:11.011562 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 17:34:11.011579 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 17:34:11.011600 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 17:34:11.011619 584331 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 17:34:11.011636 584331 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 17:34:11.011651 584331 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 17:34:11.011665 584331 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 17:34:11.141090 584331 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 17:34:11.141218 584331 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 37
Rank1: cached key size 37
Rank2: cached key size 37
Rank3: cached key size 37
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([ 264,  484,  553,  ..., 1037, 5457, 8138]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.846 seconds
[Rank1] pid = 584541
[Rank2] pid = 584606
INFO [584331 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [584541 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [584670 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [584606 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [584670 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [584606 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [584331 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [584541 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 17:34:14.528486 584672 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_3 [149, 400]; dev=3; size=232.8 kB
W20240128 17:34:14.528586 584607 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_2 [149, 400]; dev=2; size=232.8 kB
W20240128 17:34:14.528980 584671 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_0 [149, 400]; dev=0; size=232.8 kB
W20240128 17:34:14.529461 584607 IPCTensor.h:368] NewIPCTensor: input_keys_2 [1000000]0x10001487a000 7.629 MB
W20240128 17:34:14.529592 584671 IPCTensor.h:368] NewIPCTensor: input_keys_0 [1000000]0x10001501d000 7.629 MB
W20240128 17:34:14.529623 584607 IPCTensor.h:368] NewIPCTensor: input_keys_neg_2 [1000000]0x1000157c0000 7.629 MB
W20240128 17:34:14.529702 584607 IPCTensor.h:368] NewIPCTensor: backward_grads_2 [1000000, 400]0x100016706000 1.49 GB
W20240128 17:34:14.529680 584672 IPCTensor.h:368] NewIPCTensor: input_keys_3 [1000000]0x100015f63000 7.629 MB
W20240128 17:34:14.529738 584607 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x100075ce9000 1.49 GB
W20240128 17:34:14.529779 584607 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 17:34:14.529772 584671 IPCTensor.h:368] NewIPCTensor: input_keys_neg_0 [1000000]0x1000d52cc000 7.629 MB
W20240128 17:34:14.529774 584542 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_1 [149, 400]; dev=1; size=232.8 kB
W20240128 17:34:14.529865 584671 IPCTensor.h:368] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000d5a6f000 1.49 GB
W20240128 17:34:14.529924 584671 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x100135052000 1.49 GB
W20240128 17:34:14.529994 584671 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 17:34:14.530033 584672 IPCTensor.h:368] NewIPCTensor: input_keys_neg_3 [1000000]0x100194635000 7.629 MB
W20240128 17:34:14.530236 584672 IPCTensor.h:368] NewIPCTensor: backward_grads_3 [1000000, 400]0x100194dd8000 1.49 GB
W20240128 17:34:14.530328 584672 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1001f43bb000 1.49 GB
W20240128 17:34:14.530427 584672 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 17:34:14.540828 584607 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 17:34:14.540879 584671 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 17:34:14.540947 584672 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 17:34:14.541028 584542 IPCTensor.h:368] NewIPCTensor: input_keys_1 [1000000]0x1002539a6000 7.629 MB
W20240128 17:34:14.541247 584542 IPCTensor.h:368] NewIPCTensor: input_keys_neg_1 [1000000]0x100254149000 7.629 MB
W20240128 17:34:14.541332 584542 IPCTensor.h:368] NewIPCTensor: backward_grads_1 [1000000, 400]0x1002548ec000 1.49 GB
W20240128 17:34:14.541422 584542 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1002b3ecf000 1.49 GB
W20240128 17:34:14.541503 584542 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 17:34:14.556560 584542 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [584606 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [584541 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [584670 DistTensor.py:56] The tensor name already exists in the kvstore
[Rank3] pid = 584670
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 149), (149, 298), (298, 447), (447, 596)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [584331 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 17:34:15.590298 584671 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 17:34:15.590533 584542 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 17:34:15.590621 584607 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 17:34:15.590723 584672 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240128 17:34:15.591667 584671 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.01,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240128 17:34:15.592043 584671 grad_base.h:184] Init GradProcessingBase done
I20240128 17:34:15.596136 584671 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240128 17:34:15.596235 584671 kg_controller.h:78] after init GradAsyncProcessingV2
I20240128 17:34:15.596241 584671 kg_controller.h:84] Construct KGCacheController done
E20240128 17:34:16.978986 584671 recstore.cc:66] init folly done
E20240128 17:34:16.979128 584542 recstore.cc:66] init folly done
E20240128 17:34:16.979139 584672 recstore.cc:66] init folly done
E20240128 17:34:16.979202 584607 recstore.cc:66] init folly done
I20240128 17:34:16.979871 584671 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240128 17:34:17.666414 585085 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
E20240128 17:34:17.666746 585085 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240128 17:34:17.695793 584671 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 17:34:17.712190 584607 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 17:34:17.713022 584672 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 17:34:17.718843 584542 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240128 17:34:20.011693 584671 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
W20240128 17:34:20.023022 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=1, pq.top=0
W20240128 17:34:20.025954 585085 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 965.288 us                | 14.110 ms                 |
| Forward                   | 3.450 ms                  | 644.268 ms                |
| Backward                  | 2.834 ms                  | 324.953 ms                |
| Optimize                  | 1.171 ms                  | 49.047 ms                 |
| BarrierTimeBeforeRank0    | 376.148 us                | 579.274 ms                |
| AfterBackward             | 19.012 ms                 | 704.970 ms                |
| BlockToStepN              | 236.519 us                | 21.302 ms                 |
| OneStep                   | 31.410 ms                 | 2.306 s                   |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:21.011008 584671 parallel_pq_v2.h:76] insert failed, size(hashtable)=1155
W20240128 17:34:21.028676 585085 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 17:34:21.044131 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=32, pq.top=32
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.150 ms                  | 82.101 ms                 |
| ProcessBack:UpdateCache   | 2.393 ms                  | 197.602 ms                |
| ProcessBack:UpsertPq      | 14.322 ms                 | 20.357 ms                 |
| ProcessOneStep            | 20.423 ms                 | 27.163 ms                 |
| BlockToStepN              | 1.344 ms                  | 7.172 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:22.011094 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=6680
W20240128 17:34:22.034583 585085 grad_async_v2.h:121] Detect new sample comes, old_end9, new_end0
W20240128 17:34:22.069232 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=61, pq.top=61
E20240128 17:34:23.011026 585085 parallel_pq_v2.h:76] insert failed, size(hashtable)=204
W20240128 17:34:23.050570 585085 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
W20240128 17:34:23.085155 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=88, pq.top=88
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 5.867, sample: 0.164, forward: 1.436, backward: 0.706, update: 0.142
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 5.867, sample: 0.236, forward: 1.035, backward: 0.629, update: 0.165
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 5.861, sample: 0.233, forward: 1.062, backward: 0.682, update: 0.187
train_sampler.Prefill()
-------Step 0-------
tensor([   33,  3549, 10125,  7645,  9849,  3682, 10940,  4154, 12371,  9965]) tensor([  553,  7960, 10253,  2903,  7136,  7245, 11725,  7599,  8896,  6791])
-------Step 1-------
tensor([   33,  3549, 10125,  7645,  9849,  3682, 10940,  4154, 12371,  9965]) tensor([ 6276, 12548, 11788, 13666,  5891,  7797,  5051,   918,  1669,  7996])
-------Step 2-------
tensor([ 8873,  2007,  2746,  2460,  8586,  8311,  4438, 10089,  9805,  8132]) tensor([10927,  3134,  3008, 12767,   934,  1659, 10732,  4851, 14318,  6236])
-------Step 3-------
tensor([ 8873,  2007,  2746,  2460,  8586,  8311,  4438, 10089,  9805,  8132]) tensor([ 4053, 10143,  6040, 13558,  1893,  7427,  1051, 11120,  4820, 10879])
-------Step 4-------
tensor([ 2115, 14698, 11246,    32,  4777,  5186, 12862,  6794,  3385,   914]) tensor([14495,  4058,  9704, 11216,  3236,  9078,  5517,  5066,  8917, 13861])
-------Step 5-------
tensor([ 2115, 14698, 11246,    32,  4777,  5186, 12862,  6794,  3385,   914]) tensor([ 6644,  5817,  7210, 14454,  7461, 12621,  1454, 13155,  7684,  5862])
-------Step 6-------
tensor([10886,  4042,  8259,  1732, 10868, 12205, 14823, 11246,  8532,  5718]) tensor([ 2519,  8479,  6441, 11919,  8284, 13393,   753,  1566, 12843, 13534])
-------Step 7-------
tensor([10886,  4042,  8259,  1732, 10868, 12205, 14823, 11246,  8532,  5718]) tensor([ 4389, 14206,  9982,  7981,  4786, 12897,  4473,  7499, 11146, 12679])
-------Step 8-------
tensor([ 9080,  8897, 12770,  9848,  3791,  5920,   495,  5153,  3597, 11298]) tensor([ 8259, 11335, 13852,   501,  9218, 12519,  1157, 10013,  8330,  7484])
-------Step 9-------
tensor([ 9080,  8897, 12770,  9848,  3791,  5920,   495,  5153,  3597, 11298]) tensor([10702, 11963,   414,  2748,  1069, 11843,  6148,  2100,  1669, 13431])
before start barrier
start train
[proc 0] 100 steps, total: 5.884, sample: 0.261, forward: 0.969, backward: 0.597, update: 0.182
E20240128 17:34:24.011013 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=4893
W20240128 17:34:24.057055 585085 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 17:34:24.085026 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=112, pq.top=112
E20240128 17:34:25.011016 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=4779
W20240128 17:34:25.058800 585085 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
W20240128 17:34:25.085072 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=138, pq.top=138
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.091 ms                  | 15.378 ms                 |
| Forward                   | 3.242 ms                  | 5.076 ms                  |
| Backward                  | 2.755 ms                  | 5.634 ms                  |
| Optimize                  | 1.239 ms                  | 2.590 ms                  |
| BarrierTimeBeforeRank0    | 185.169 us                | 4.641 ms                  |
| AfterBackward             | 19.082 ms                 | 24.293 ms                 |
| BlockToStepN              | 6.064 ms                  | 18.123 ms                 |
| OneStep                   | 36.086 ms                 | 52.747 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:26.011014 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=5180
W20240128 17:34:26.063380 585085 grad_async_v2.h:121] Detect new sample comes, old_end2, new_end3
W20240128 17:34:26.085072 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=163, pq.top=163
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.068 ms                  | 2.280 ms                  |
| ProcessBack:UpdateCache   | 1.836 ms                  | 2.808 ms                  |
| ProcessBack:UpsertPq      | 13.424 ms                 | 19.174 ms                 |
| ProcessOneStep            | 18.581 ms                 | 24.146 ms                 |
| BlockToStepN              | 6.535 ms                  | 24.282 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:27.011940 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=4718
W20240128 17:34:27.067818 585085 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240128 17:34:27.093020 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=187, pq.top=187
[proc 1] 200 steps, total: 4.001, sample: 0.233, forward: 0.316, backward: 0.357, update: 0.121
[proc 2] 200 steps, total: 4.001, sample: 0.215, forward: 0.267, backward: 0.318, update: 0.109
[proc 3] 200 steps, total: 4.001, sample: 0.230, forward: 0.262, backward: 0.305, update: 0.109
[proc 0] 200 steps, total: 4.001, sample: 0.296, forward: 0.325, backward: 0.304, update: 0.120
E20240128 17:34:28.011547 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=4753
W20240128 17:34:28.070295 585085 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240128 17:34:28.123004 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=215, pq.top=215
E20240128 17:34:29.011014 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=6909
W20240128 17:34:29.079205 585085 grad_async_v2.h:121] Detect new sample comes, old_end9, new_end0
W20240128 17:34:29.138737 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=241, pq.top=241
E20240128 17:34:30.011011 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=4522
W20240128 17:34:30.084949 585085 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240128 17:34:30.138111 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=265, pq.top=265
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.135 ms                  | 15.378 ms                 |
| Forward                   | 3.313 ms                  | 5.005 ms                  |
| Backward                  | 2.796 ms                  | 5.632 ms                  |
| Optimize                  | 1.219 ms                  | 2.539 ms                  |
| BarrierTimeBeforeRank0    | 36.127 us                 | 11.687 ms                 |
| AfterBackward             | 17.322 ms                 | 24.213 ms                 |
| BlockToStepN              | 7.797 ms                  | 24.351 ms                 |
| OneStep                   | 37.807 ms                 | 52.747 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:31.011015 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=4284
W20240128 17:34:31.099668 585085 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
W20240128 17:34:31.138394 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=289, pq.top=289
[proc 3] 300 steps, total: 4.035, sample: 0.232, forward: 0.260, backward: 0.249, update: 0.104
[proc 0] 300 steps, total: 4.035, sample: 0.272, forward: 0.322, backward: 0.274, update: 0.116
[proc 1] 300 steps, total: 4.035, sample: 0.211, forward: 0.318, backward: 0.278, update: 0.112
[proc 2] 300 steps, total: 4.035, sample: 0.216, forward: 0.268, backward: 0.251, update: 0.113
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.062 ms                  | 2.479 ms                  |
| ProcessBack:UpdateCache   | 1.840 ms                  | 2.757 ms                  |
| ProcessBack:UpsertPq      | 12.707 ms                 | 19.174 ms                 |
| ProcessOneStep            | 17.168 ms                 | 24.146 ms                 |
| BlockToStepN              | 8.042 ms                  | 25.020 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:32.011771 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=7013
W20240128 17:34:32.104950 585085 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 17:34:32.138412 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=312, pq.top=312
E20240128 17:34:33.011013 584671 parallel_pq_v2.h:76] insert failed, size(hashtable)=1435
W20240128 17:34:33.109169 585085 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240128 17:34:33.138067 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=335, pq.top=335
E20240128 17:34:34.011016 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=3431
W20240128 17:34:34.118156 585085 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
W20240128 17:34:34.161233 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=358, pq.top=358
E20240128 17:34:35.011015 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=3330
W20240128 17:34:35.121635 585085 grad_async_v2.h:121] Detect new sample comes, old_end9, new_end0
W20240128 17:34:35.181613 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=381, pq.top=381
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.176 ms                  | 16.553 ms                 |
| Forward                   | 3.329 ms                  | 4.636 ms                  |
| Backward                  | 2.799 ms                  | 5.579 ms                  |
| Optimize                  | 1.204 ms                  | 2.539 ms                  |
| BarrierTimeBeforeRank0    | 25.608 us                 | 12.221 ms                 |
| AfterBackward             | 17.127 ms                 | 23.863 ms                 |
| BlockToStepN              | 9.624 ms                  | 26.450 ms                 |
| OneStep                   | 39.992 ms                 | 55.466 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:36.016249 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=4702
[proc 2] 400 steps, total: 4.505, sample: 0.210, forward: 0.263, backward: 0.249, update: 0.112
[proc 3] 400 steps, total: 4.505, sample: 0.224, forward: 0.268, backward: 0.243, update: 0.105
[proc 0] 400 steps, total: 4.505, sample: 0.296, forward: 0.331, backward: 0.275, update: 0.119
[proc 1] 400 steps, total: 4.505, sample: 0.261, forward: 0.322, backward: 0.278, update: 0.114
W20240128 17:34:36.122385 585085 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240128 17:34:36.181577 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=401, pq.top=401
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.084 ms                  | 2.480 ms                  |
| ProcessBack:UpdateCache   | 1.839 ms                  | 2.648 ms                  |
| ProcessBack:UpsertPq      | 12.604 ms                 | 18.739 ms                 |
| ProcessOneStep            | 17.088 ms                 | 23.838 ms                 |
| BlockToStepN              | 9.781 ms                  | 32.531 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:37.016012 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=6206
W20240128 17:34:37.129415 585085 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240128 17:34:37.192174 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=422, pq.top=422
E20240128 17:34:38.016008 584671 parallel_pq_v2.h:76] insert failed, size(hashtable)=2006
W20240128 17:34:38.137202 585085 grad_async_v2.h:121] Detect new sample comes, old_end2, new_end3
W20240128 17:34:38.205090 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=444, pq.top=444
E20240128 17:34:39.017695 585085 parallel_pq_v2.h:76] insert failed, size(hashtable)=45
W20240128 17:34:39.144835 585085 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240128 17:34:39.205420 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=466, pq.top=466
E20240128 17:34:40.017007 584671 parallel_pq_v2.h:76] insert failed, size(hashtable)=1406
W20240128 17:34:40.184283 585085 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240128 17:34:40.223313 584671 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=485, pq.top=485
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.214 ms                  | 16.499 ms                 |
| Forward                   | 3.364 ms                  | 4.482 ms                  |
| Backward                  | 2.810 ms                  | 5.632 ms                  |
| Optimize                  | 1.197 ms                  | 2.539 ms                  |
| BarrierTimeBeforeRank0    | 25.574 us                 | 12.318 ms                 |
| AfterBackward             | 17.180 ms                 | 23.862 ms                 |
| BlockToStepN              | 10.288 ms                 | 45.163 ms                 |
| OneStep                   | 40.930 ms                 | 91.304 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 17:34:41.019658 585084 parallel_pq_v2.h:76] insert failed, size(hashtable)=4564
[proc 2] 500 steps, total: 4.926, sample: 0.240, forward: 0.267, backward: 0.248, update: 0.110
[proc 3] 500 steps, total: 4.926, sample: 0.226, forward: 0.269, backward: 0.246, update: 0.107
[proc 1] 500 steps, total: 4.926, sample: 0.200, forward: 0.310, backward: 0.292, update: 0.124
[proc 0] 500 steps, total: 4.926, sample: 0.299, forward: 0.336, backward: 0.282, update: 0.117
Successfully xmh. training takes 23.3520827293396 seconds
before call kg_cache_controller.StopThreads()
W20240128 17:34:41.047878 584671 grad_async_v2.h:71] call StopThreads. PID = 584331
W20240128 17:34:41.047906 584671 grad_base.h:212] before processOneStepNegThread_.join();
W20240128 17:34:41.048133 584671 grad_base.h:214] after processOneStepNegThread_.join();
W20240128 17:34:41.048158 584671 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
W20240128 17:34:41.055294 584671 grad_async_v2.h:92] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.093 ms                  | 2.479 ms                  |
| ProcessBack:UpdateCache   | 1.836 ms                  | 2.616 ms                  |
| ProcessBack:UpsertPq      | 12.579 ms                 | 18.314 ms                 |
| ProcessOneStep            | 17.152 ms                 | 23.838 ms                 |
| BlockToStepN              | 10.223 ms                 | 55.235 ms                 |
+---------------------------+---------------------------+---------------------------+
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7fdff1d46450>
