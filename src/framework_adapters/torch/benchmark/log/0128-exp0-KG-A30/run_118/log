WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 14:16:54.480528 250859 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_58', no_save_emb=True, max_step=500, batch_size=2400, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='TorchNativeStdEmb', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='PySync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [250859 sampler.py:454] Start PreSampling
WARNING [250859 sampler.py:532] Before construct renumbering_dict
WARNING [250859 sampler.py:555] PreSampling done
W20240128 14:16:56.716356 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 14:16:56.716480 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 14:16:56.716500 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 14:16:56.716521 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 14:16:56.716539 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 14:16:56.716557 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 14:16:56.716575 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 14:16:56.716595 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 14:16:56.716617 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 14:16:56.716634 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 14:16:56.716653 250859 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 14:16:56.716670 250859 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 14:16:56.716683 250859 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 14:16:56.716755 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 14:16:56.716781 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 14:16:56.716799 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 14:16:56.716827 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 14:16:56.716846 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 14:16:56.716864 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 14:16:56.716881 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 14:16:56.716899 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 14:16:56.716918 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 14:16:56.716936 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 14:16:56.716953 250859 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 14:16:56.716965 250859 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 14:16:56.716979 250859 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 14:16:56.717010 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 14:16:56.717036 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 14:16:56.717056 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 14:16:56.717070 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 14:16:56.717087 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 14:16:56.717108 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 14:16:56.717126 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 14:16:56.717144 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 14:16:56.717159 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 14:16:56.717173 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 14:16:56.717192 250859 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 14:16:56.717206 250859 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 14:16:56.717221 250859 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 14:16:56.717254 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 14:16:56.717278 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 14:16:56.717293 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 14:16:56.717307 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 14:16:56.717324 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 14:16:56.717341 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 14:16:56.717360 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 14:16:56.717376 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 14:16:56.717391 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 14:16:56.717411 250859 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 14:16:56.717427 250859 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 14:16:56.717439 250859 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 14:16:56.717451 250859 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 14:16:56.844875 250859 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 14:16:56.845005 250859 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1612, 1809, 1881,  ..., 2368, 6234, 7165]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.396 seconds
[Rank1] pid = 251178
[Rank2] pid = 251242
INFO [250859 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [251307 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [251307 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [250859 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [251242 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [251178 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [251307 cache_common.py:125] TorchNativeStdEmb: weight.shape torch.Size([14951, 400])
INFO [251242 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [251178 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [250859 cache_common.py:125] TorchNativeStdEmb: weight.shape torch.Size([14951, 400])
INFO [250859 cache_common.py:139] TorchNativeStdEmb construct done
INFO [251307 cache_common.py:139] TorchNativeStdEmb construct done
WARNING [251307 DistTensor.py:56] The tensor name already exists in the kvstore
WARNING [250859 DistTensor.py:56] The tensor name already exists in the kvstore
INFO [251242 cache_common.py:125] TorchNativeStdEmb: weight.shape torch.Size([14951, 400])
INFO [251178 cache_common.py:125] TorchNativeStdEmb: weight.shape torch.Size([14951, 400])
INFO [251242 cache_common.py:139] TorchNativeStdEmb construct done
INFO [251178 cache_common.py:139] TorchNativeStdEmb construct done
WARNING [251242 DistTensor.py:56] The tensor name already exists in the kvstore
WARNING [251178 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 14:16:59.985733 251308 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 14:16:59.985782 251309 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 14:16:59.985872 251244 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 14:16:59.985960 251179 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 14:17:00.371345 251308 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 14:17:00.380353 251309 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 14:17:00.416332 251244 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 14:17:00.418418 251179 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
