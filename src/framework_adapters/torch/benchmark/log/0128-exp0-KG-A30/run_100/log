WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 13:48:32.162047 207647 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_40', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [207647 sampler.py:454] Start PreSampling
WARNING [207647 sampler.py:532] Before construct renumbering_dict
WARNING [207647 sampler.py:555] PreSampling done
W20240128 13:48:35.078006 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 13:48:35.078131 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 13:48:35.078159 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 13:48:35.078181 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 13:48:35.078202 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 13:48:35.078222 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 13:48:35.078236 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 13:48:35.078255 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 13:48:35.078280 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 13:48:35.078297 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 13:48:35.078320 207647 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 13:48:35.078337 207647 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 13:48:35.078354 207647 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 13:48:35.078447 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 13:48:35.078476 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 13:48:35.078500 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 13:48:35.078534 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 13:48:35.078555 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 13:48:35.078575 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 13:48:35.078595 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 13:48:35.078611 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 13:48:35.078631 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 13:48:35.078651 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 13:48:35.078666 207647 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 13:48:35.078681 207647 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 13:48:35.078694 207647 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 13:48:35.078732 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 13:48:35.078755 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 13:48:35.078770 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 13:48:35.078788 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 13:48:35.078804 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 13:48:35.078821 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 13:48:35.078838 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 13:48:35.078856 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 13:48:35.078873 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 13:48:35.078894 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 13:48:35.078912 207647 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 13:48:35.078927 207647 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 13:48:35.078941 207647 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 13:48:35.078974 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 13:48:35.078991 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 13:48:35.079006 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 13:48:35.079025 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 13:48:35.079042 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 13:48:35.079062 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 13:48:35.079080 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 13:48:35.079100 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 13:48:35.079128 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 13:48:35.079145 207647 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 13:48:35.079161 207647 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 13:48:35.079174 207647 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 13:48:35.079188 207647 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 13:48:35.236644 207647 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 13:48:35.236778 207647 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1607, 1861, 1939,  ..., 2131, 5585, 6117]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.108 seconds
[Rank1] pid = 207968
[Rank2] pid = 208033
INFO [207647 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [207968 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [207647 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [208033 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [208097 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [207968 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [208097 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [208033 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 13:48:38.501534 208098 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_0 [1495, 400]; dev=0; size=2.281 MB
W20240128 13:48:38.502321 208098 IPCTensor.h:368] NewIPCTensor: input_keys_0 [1000000]0x100014876000 7.629 MB
W20240128 13:48:38.502540 208098 IPCTensor.h:368] NewIPCTensor: input_keys_neg_0 [1000000]0x100015019000 7.629 MB
W20240128 13:48:38.502632 208098 IPCTensor.h:368] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000157bc000 1.49 GB
W20240128 13:48:38.502736 208098 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x100074d9f000 1.49 GB
W20240128 13:48:38.502826 208098 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 13:48:38.502764 207969 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_1 [1495, 400]; dev=1; size=2.281 MB
W20240128 13:48:38.502905 208099 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_3 [1495, 400]; dev=3; size=2.281 MB
W20240128 13:48:38.502944 208034 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_2 [1495, 400]; dev=2; size=2.281 MB
W20240128 13:48:38.508610 208098 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 13:48:38.508740 208099 IPCTensor.h:368] NewIPCTensor: input_keys_3 [1000000]0x1000d438a000 7.629 MB
W20240128 13:48:38.508781 207969 IPCTensor.h:368] NewIPCTensor: input_keys_1 [1000000]0x1000d4b2d000 7.629 MB
W20240128 13:48:38.508790 208034 IPCTensor.h:368] NewIPCTensor: input_keys_2 [1000000]0x1000d52d0000 7.629 MB
W20240128 13:48:38.508975 208099 IPCTensor.h:368] NewIPCTensor: input_keys_neg_3 [1000000]0x1000d5a73000 7.629 MB
W20240128 13:48:38.509047 207969 IPCTensor.h:368] NewIPCTensor: input_keys_neg_1 [1000000]0x1000d6216000 7.629 MB
W20240128 13:48:38.509055 208034 IPCTensor.h:368] NewIPCTensor: input_keys_neg_2 [1000000]0x1000d69b9000 7.629 MB
W20240128 13:48:38.509099 208099 IPCTensor.h:368] NewIPCTensor: backward_grads_3 [1000000, 400]0x1000d715c000 1.49 GB
W20240128 13:48:38.509169 208034 IPCTensor.h:368] NewIPCTensor: backward_grads_2 [1000000, 400]0x10013673f000 1.49 GB
W20240128 13:48:38.509181 207969 IPCTensor.h:368] NewIPCTensor: backward_grads_1 [1000000, 400]0x100195d22000 1.49 GB
W20240128 13:48:38.509208 208099 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1001f5305000 1.49 GB
W20240128 13:48:38.509281 208034 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1002548e8000 1.49 GB
W20240128 13:48:38.509292 207969 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1002b3ecb000 1.49 GB
W20240128 13:48:38.509316 208099 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 13:48:38.509368 208034 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 13:48:38.509393 207969 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 13:48:38.525813 208099 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 13:48:38.525880 208034 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 13:48:38.525933 207969 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [208033 DistTensor.py:56] The tensor name already exists in the kvstore
[Rank3] pid = 208097
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1495), (1495, 2990), (2990, 4485), (4485, 5980)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [207647 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [208097 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [207968 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 13:48:39.813556 207969 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 13:48:39.813724 208099 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 13:48:39.813783 208034 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 13:48:39.813855 208098 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240128 13:48:39.815299 208098 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.1,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240128 13:48:39.815522 208098 grad_base.h:184] Init GradProcessingBase done
I20240128 13:48:39.820308 208098 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240128 13:48:39.820408 208098 kg_controller.h:78] after init GradAsyncProcessingV2
I20240128 13:48:39.820415 208098 kg_controller.h:84] Construct KGCacheController done
I20240128 13:48:40.212261 208098 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240128 13:48:40.924986 208618 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240128 13:48:40.925356 208618 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240128 13:48:40.941421 208034 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 13:48:40.948540 208098 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:48:40.959589 208099 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:48:40.975780 207969 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240128 13:48:43.416464 208394 parallel_pq_v2.h:76] insert failed, size(hashtable)=2
W20240128 13:48:43.427172 208618 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
W20240128 13:48:43.449440 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=2, pq.top=2
E20240128 13:48:44.416038 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=11740
W20240128 13:48:44.428155 208618 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
W20240128 13:48:44.449044 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=51, pq.top=51
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 864.832 us                | 9.314 ms                  |
| Forward                   | 2.480 ms                  | 7.867 ms                  |
| Backward                  | 1.794 ms                  | 2.456 ms                  |
| Optimize                  | 848.601 us                | 1.528 ms                  |
| BarrierTimeBeforeRank0    | 41.374 us                 | 3.816 ms                  |
| AfterBackward             | 10.958 ms                 | 12.286 ms                 |
| BlockToStepN              | 2.054 ms                  | 6.176 ms                  |
| OneStep                   | 19.729 ms                 | 30.247 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.071 ms                  | 3.486 ms                  |
| ProcessBack:UpdateCache   | 1.874 ms                  | 2.007 ms                  |
| ProcessBack:UpsertPq      | 6.145 ms                  | 8.220 ms                  |
| ProcessOneStep            | 11.092 ms                 | 14.151 ms                 |
| BlockToStepN              | 2.605 ms                  | 6.446 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240128 13:48:45.416043 208618 parallel_pq_v2.h:76] insert failed, size(hashtable)=45
W20240128 13:48:45.428251 208618 grad_async_v2.h:120] Detect new sample comes, old_end4, new_end5
W20240128 13:48:45.456516 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=96, pq.top=96
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.614, sample: 0.133, forward: 1.108, backward: 0.422, update: 0.120
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.579, sample: 0.167, forward: 1.142, backward: 0.448, update: 0.121
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.595, sample: 0.173, forward: 1.204, backward: 0.455, update: 0.119
train_sampler.Prefill()
-------Step 0-------
tensor([10099,  5242,  7993,  6717,  9482,  5538, 13975,  5499, 13424,   104]) tensor([ 1939,  9871,  8054,  1229,  6791,  9637, 12397,  9969,  6564,  1240])
-------Step 1-------
tensor([10099,  5242,  7993,  6717,  9482,  5538, 13975,  5499, 13424,   104]) tensor([ 8080, 13005, 14470,  1679, 13522,  8689,  2559, 10810,  6281,  6734])
-------Step 2-------
tensor([ 7301, 11019, 10690,  4566,  4583,  7466,  8852,  8920,  9593,   334]) tensor([11404,  3079,  2465, 10293,  4606,  1361,  5903,  7281, 10208,  9089])
-------Step 3-------
tensor([ 7301, 11019, 10690,  4566,  4583,  7466,  8852,  8920,  9593,   334]) tensor([ 8919,  9474,  6356, 12781,  8788,  2015,  7888, 10805, 10322, 13104])
-------Step 4-------
tensor([12816,  2980,  3691,    10,   665,   187,   117, 14234,  9638,  7131]) tensor([ 8587,  4808,  3313, 13662,  2182,  2529, 10584,  5071, 12987,  8451])
-------Step 5-------
tensor([12816,  2980,  3691,    10,   665,   187,   117, 14234,  9638,  7131]) tensor([ 7686, 11471,  5706,  7061, 12559,  8521,  5125,  3406,  7496, 14051])
-------Step 6-------
tensor([ 8094, 10653,  4995,  8966,  2024,  7432,  7626,  3384, 12462,    81]) tensor([ 6817,  6100,  3973,  8606,  8225,  1428,  5251, 10938, 13015,  3691])
-------Step 7-------
tensor([ 8094, 10653,  4995,  8966,  2024,  7432,  7626,  3384, 12462,    81]) tensor([ 7297,  6498,  7353,  9290,  1099,   361, 13426,  8405,  4685,   840])
-------Step 8-------
tensor([ 3784, 14725,  9263, 10315,  6595,  4995, 13753,  7575,  4506,  1958]) tensor([14918,   985,  8468,  8808,  5573,   642,  7399,   987, 13523, 13510])
-------Step 9-------
tensor([ 3784, 14725,  9263, 10315,  6595,  4995, 13753,  7575,  4506,  1958]) tensor([13410, 14486, 11388,   938, 10613,  8588,  7592,  2675,  6466,  7693])
before start barrier
start train
[proc 0] 100 steps, total: 4.607, sample: 0.182, forward: 1.176, backward: 0.385, update: 0.131
E20240128 13:48:46.416018 208618 parallel_pq_v2.h:76] insert failed, size(hashtable)=109
W20240128 13:48:46.443549 208618 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
W20240128 13:48:46.462409 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=136, pq.top=136
E20240128 13:48:47.416010 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=10964
W20240128 13:48:47.444499 208618 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
W20240128 13:48:47.470732 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=179, pq.top=179
[proc 0] 200 steps, total: 2.459, sample: 0.193, forward: 0.226, backward: 0.177, update: 0.076
[proc 2] 200 steps, total: 2.459, sample: 0.160, forward: 0.209, backward: 0.199, update: 0.071
[proc 3] 200 steps, total: 2.459, sample: 0.196, forward: 0.231, backward: 0.174, update: 0.071
[proc 1] 200 steps, total: 2.459, sample: 0.187, forward: 0.217, backward: 0.199, update: 0.075
E20240128 13:48:48.416013 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=11201
W20240128 13:48:48.458619 208618 grad_async_v2.h:120] Detect new sample comes, old_end6, new_end7
W20240128 13:48:48.472667 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=217, pq.top=217
E20240128 13:48:49.416013 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=8062
W20240128 13:48:49.472060 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=255, pq.top=255
W20240128 13:48:49.479673 208618 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 984.925 us                | 9.442 ms                  |
| Forward                   | 2.482 ms                  | 4.112 ms                  |
| Backward                  | 1.795 ms                  | 3.974 ms                  |
| Optimize                  | 847.768 us                | 1.533 ms                  |
| BarrierTimeBeforeRank0    | 26.762 us                 | 3.996 ms                  |
| AfterBackward             | 11.411 ms                 | 13.979 ms                 |
| BlockToStepN              | 4.634 ms                  | 11.908 ms                 |
| OneStep                   | 23.710 ms                 | 37.489 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.057 ms                  | 2.367 ms                  |
| ProcessBack:UpdateCache   | 1.851 ms                  | 2.117 ms                  |
| ProcessBack:UpsertPq      | 6.619 ms                  | 9.031 ms                  |
| ProcessOneStep            | 11.511 ms                 | 13.949 ms                 |
| BlockToStepN              | 4.781 ms                  | 13.025 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:48:50.416019 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=9871
W20240128 13:48:50.485462 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=290, pq.top=290
W20240128 13:48:50.491387 208618 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
[proc 2] 300 steps, total: 2.776, sample: 0.164, forward: 0.208, backward: 0.205, update: 0.069
[proc 0] 300 steps, total: 2.776, sample: 0.208, forward: 0.245, backward: 0.209, update: 0.081
[proc 3] 300 steps, total: 2.776, sample: 0.183, forward: 0.243, backward: 0.177, update: 0.070
[proc 1] 300 steps, total: 2.776, sample: 0.130, forward: 0.194, backward: 0.205, update: 0.073
E20240128 13:48:51.416010 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=7093
W20240128 13:48:51.497716 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=325, pq.top=325
W20240128 13:48:51.508318 208618 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
E20240128 13:48:52.416013 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=10100
W20240128 13:48:52.516957 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=359, pq.top=359
W20240128 13:48:52.534447 208618 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
E20240128 13:48:53.416015 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=6416
W20240128 13:48:53.523653 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=392, pq.top=392
W20240128 13:48:53.536260 208618 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
[proc 2] 400 steps, total: 2.966, sample: 0.158, forward: 0.207, backward: 0.160, update: 0.066
[proc 3] 400 steps, total: 2.966, sample: 0.188, forward: 0.252, backward: 0.184, update: 0.070
[proc 1] 400 steps, total: 2.966, sample: 0.136, forward: 0.193, backward: 0.168, update: 0.064
[proc 0] 400 steps, total: 2.966, sample: 0.222, forward: 0.252, backward: 0.194, update: 0.078
E20240128 13:48:54.416014 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=8441
W20240128 13:48:54.543960 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=426, pq.top=426
W20240128 13:48:54.551407 208618 grad_async_v2.h:120] Detect new sample comes, old_end6, new_end7
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.087 ms                  | 9.626 ms                  |
| Forward                   | 2.534 ms                  | 4.043 ms                  |
| Backward                  | 1.916 ms                  | 3.879 ms                  |
| Optimize                  | 845.814 us                | 1.533 ms                  |
| BarrierTimeBeforeRank0    | 21.512 us                 | 3.816 ms                  |
| AfterBackward             | 12.052 ms                 | 14.171 ms                 |
| BlockToStepN              | 6.170 ms                  | 13.422 ms                 |
| OneStep                   | 25.658 ms                 | 40.958 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.079 ms                  | 2.992 ms                  |
| ProcessBack:UpdateCache   | 1.884 ms                  | 2.177 ms                  |
| ProcessBack:UpsertPq      | 6.997 ms                  | 9.491 ms                  |
| ProcessOneStep            | 12.044 ms                 | 14.151 ms                 |
| BlockToStepN              | 6.118 ms                  | 13.585 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:48:55.416443 208394 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
W20240128 13:48:55.562794 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=461, pq.top=461
W20240128 13:48:55.574077 208618 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
E20240128 13:48:56.417090 208617 parallel_pq_v2.h:76] insert failed, size(hashtable)=11779
W20240128 13:48:56.582871 208098 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=493, pq.top=493
W20240128 13:48:56.591529 208618 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
[proc 3] 500 steps, total: 3.044, sample: 0.191, forward: 0.258, backward: 0.186, update: 0.072
[proc 2] 500 steps, total: 3.044, sample: 0.179, forward: 0.205, backward: 0.212, update: 0.064
[proc 0] 500 steps, total: 3.044, sample: 0.230, forward: 0.256, backward: 0.198, update: 0.083
[proc 1] 500 steps, total: 3.044, sample: 0.115, forward: 0.179, backward: 0.165, update: 0.080
Successfully xmh. training takes 15.851901292800903 seconds
before call kg_cache_controller.StopThreads()
W20240128 13:48:56.800520 208098 grad_async_v2.h:71] call StopThreads. PID = 207647
W20240128 13:48:56.800554 208098 grad_base.h:212] before processOneStepNegThread_.join();
W20240128 13:48:56.800806 208098 grad_base.h:214] after processOneStepNegThread_.join();
W20240128 13:48:56.800817 208098 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
W20240128 13:48:56.803742 208098 grad_async_v2.h:91] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f1bfa307010>
