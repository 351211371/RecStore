WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 13:54:50.962285 222145 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_46', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [222145 sampler.py:454] Start PreSampling
WARNING [222145 sampler.py:532] Before construct renumbering_dict
WARNING [222145 sampler.py:555] PreSampling done
W20240128 13:54:53.171061 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 13:54:53.171190 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 13:54:53.171218 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 13:54:53.171236 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 13:54:53.171254 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 13:54:53.171269 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 13:54:53.171288 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 13:54:53.171308 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 13:54:53.171325 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 13:54:53.171348 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 13:54:53.171375 222145 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 13:54:53.171398 222145 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 13:54:53.171416 222145 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 13:54:53.171509 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 13:54:53.171528 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 13:54:53.171547 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 13:54:53.171583 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 13:54:53.171598 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 13:54:53.171614 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 13:54:53.171634 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 13:54:53.171653 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 13:54:53.171671 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 13:54:53.171685 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 13:54:53.171705 222145 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 13:54:53.171718 222145 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 13:54:53.171730 222145 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 13:54:53.171777 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 13:54:53.171799 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 13:54:53.171818 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 13:54:53.171833 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 13:54:53.171847 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 13:54:53.171861 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 13:54:53.171880 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 13:54:53.171898 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 13:54:53.171913 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 13:54:53.171929 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 13:54:53.171947 222145 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 13:54:53.171960 222145 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 13:54:53.171975 222145 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 13:54:53.172015 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 13:54:53.172034 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 13:54:53.172048 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 13:54:53.172067 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 13:54:53.172081 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 13:54:53.172099 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 13:54:53.172120 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 13:54:53.172135 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 13:54:53.172151 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 13:54:53.172173 222145 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 13:54:53.172189 222145 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 13:54:53.172202 222145 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 13:54:53.172215 222145 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1619, 1873, 1969,  ..., 2290, 7272, 6973]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.394 seconds
[Rank1] pid = 222464
[Rank2] pid = 222529
INFO [222145 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [222464 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [222593 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [222529 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [222529 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [222464 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [222593 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [222145 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
I20240128 13:54:56.793087 222595 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 13:54:56.812134 222594 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:54:56.814741 222465 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:54:56.820856 222530 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
[Rank3] pid = 222593
train_sampler.Prefill()
-------Step 0-------
tensor([ 9571,   195,  9172,  6903,  8525,  5259, 10766,  4894, 12557,    78]) tensor([ 1969,  8440,  9246,  1421,  9053,  9103, 12156,  9435,  7538,  8275])
-------Step 1-------
tensor([ 9571,   195,  9172,  6903,  8525,  5259, 10766,  4894, 12557,    78]) tensor([ 7602, 14264, 14109, 13406,  6640,  9320,  6380,  2185,  3101,  8313])
-------Step 2-------
tensor([10338,  2798,  4020,    11,   736,   289,   191, 11726, 10734,  7792]) tensor([ 9555,  4112,  3571, 13348,  2210,  2735, 12402,  5549, 12172,  8036])
-------Step 3-------
tensor([10338,  2798,  4020,    11,   736,   289,   191, 11726, 10734,  7792]) tensor([  534, 11782,  6033, 11650,   299,   559,  2498, 11045,  5472,    96])
-------Step 4-------
tensor([ 3586, 14917, 10212,  9679,  5596,  5418, 12675,  8016,  4604,  2020]) tensor([14257,   993,  9842,  9803,  4225,   703,  6504,  1066, 10551, 14758])
-------Step 5-------
tensor([ 3586, 14917, 10212,  9679,  5596,  5418, 12675,  8016,  4604,  2020]) tensor([ 8111,  6494,  8691, 14722,  1270, 12298,  3628, 12218,  6992,  7342])
-------Step 6-------
tensor([12137,   647,  7307,   179, 10131, 11895, 13620, 10212, 10477,  6308]) tensor([ 3166,  8822,  7063, 13228,  9810, 11330,  1870,  2754, 12485,  1329])
-------Step 7-------
tensor([12137,   647,  7307,   179, 10131, 11895, 13620, 10212, 10477,  6308]) tensor([ 4510, 14277, 12198,  6848,  5435,   875,  8064,   977,  9742, 11721])
-------Step 8-------
tensor([10727,  9126, 13692, 11279,  4680,  6470,  1738,  5932,  4654, 13404]) tensor([ 7307, 11391, 13702,  1722, 10864, 10133,  2400, 12235,  7407,  7914])
-------Step 9-------
tensor([10727,  9126, 13692, 11279,  4680,  6470,  1738,  5932,  4654, 13404]) tensor([12992,  9952,  1689,  3436,  2309,   621,  6575,  3429,  3101, 14493])
before start barrier
start train
[proc 0] 100 steps, total: 4.566, sample: 0.225, forward: 1.382, backward: 2.037, update: 0.576
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.564, sample: 0.216, forward: 1.330, backward: 1.966, update: 0.555
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.558, sample: 0.213, forward: 1.399, backward: 2.061, update: 0.651
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.586, sample: 0.222, forward: 1.331, backward: 1.941, update: 0.571
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 962.876 us                | 16.899 ms                 |
| Forward                   | 5.206 ms                  | 23.240 ms                 |
| Backward                  | 2.360 ms                  | 226.794 ms                |
| Optimize                  | 4.893 ms                  | 15.956 ms                 |
| OneStep                   | 15.320 ms                 | 1.224 s                   |
+---------------------------+---------------------------+---------------------------+
[proc 3] 200 steps, total: 1.699, sample: 0.222, forward: 0.515, backward: 0.150, update: 0.517
[proc 0] 200 steps, total: 1.699, sample: 0.222, forward: 0.528, backward: 0.217, update: 0.499
[proc 1] 200 steps, total: 1.699, sample: 0.220, forward: 0.511, backward: 0.212, update: 0.504
[proc 2] 200 steps, total: 1.699, sample: 0.211, forward: 0.477, backward: 0.210, update: 0.602
[proc 3] 300 steps, total: 1.799, sample: 0.224, forward: 0.506, backward: 0.152, update: 0.509
[proc 0] 300 steps, total: 1.799, sample: 0.213, forward: 0.534, backward: 0.204, update: 0.491
[proc 1] 300 steps, total: 1.799, sample: 0.207, forward: 0.515, backward: 0.212, update: 0.495
[proc 2] 300 steps, total: 1.799, sample: 0.193, forward: 0.483, backward: 0.210, update: 0.588
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 984.352 us                | 11.863 ms                 |
| Forward                   | 5.364 ms                  | 8.726 ms                  |
| Backward                  | 2.359 ms                  | 2.641 ms                  |
| Optimize                  | 4.986 ms                  | 8.668 ms                  |
| OneStep                   | 15.705 ms                 | 32.947 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 400 steps, total: 1.906, sample: 0.215, forward: 0.534, backward: 0.214, update: 0.478
[proc 3] 400 steps, total: 1.906, sample: 0.229, forward: 0.494, backward: 0.161, update: 0.489
[proc 1] 400 steps, total: 1.906, sample: 0.236, forward: 0.498, backward: 0.212, update: 0.481
[proc 2] 400 steps, total: 1.906, sample: 0.193, forward: 0.488, backward: 0.209, update: 0.583
[proc 2] 500 steps, total: 1.966, sample: 0.220, forward: 0.491, backward: 0.210, update: 0.592
[proc 3] 500 steps, total: 1.966, sample: 0.221, forward: 0.508, backward: 0.172, update: 0.509
[proc 1] 500 steps, total: 1.967, sample: 0.234, forward: 0.514, backward: 0.216, update: 0.502
[proc 0] 500 steps, total: 1.967, sample: 0.224, forward: 0.539, backward: 0.213, update: 0.498
Successfully xmh. training takes 11.937696933746338 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
