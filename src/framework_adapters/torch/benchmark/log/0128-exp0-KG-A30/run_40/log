WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 11:55:22.618546 38584 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_75', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [38584 sampler.py:454] Start PreSampling
WARNING [38584 sampler.py:532] Before construct renumbering_dict
WARNING [38584 sampler.py:555] PreSampling done
W20240128 11:55:26.152726 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 11:55:26.152868 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 11:55:26.152894 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 11:55:26.152930 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 11:55:26.152952 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 11:55:26.152981 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 11:55:26.152997 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 11:55:26.153017 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 11:55:26.153040 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 11:55:26.153059 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 11:55:26.153082 38584 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 11:55:26.153100 38584 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 11:55:26.153115 38584 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 11:55:26.153254 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 11:55:26.153280 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 11:55:26.153293 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 11:55:26.153323 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 11:55:26.153344 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 11:55:26.153364 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 11:55:26.153385 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 11:55:26.153409 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 11:55:26.153425 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 11:55:26.153440 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 11:55:26.153461 38584 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 11:55:26.153474 38584 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 11:55:26.153488 38584 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 11:55:26.153527 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 11:55:26.153549 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 11:55:26.153563 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 11:55:26.153578 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 11:55:26.153595 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 11:55:26.153612 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 11:55:26.153636 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 11:55:26.153654 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 11:55:26.153669 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 11:55:26.153687 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 11:55:26.153703 38584 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 11:55:26.153715 38584 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 11:55:26.153726 38584 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 11:55:26.153764 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 11:55:26.153784 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 11:55:26.153802 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 11:55:26.153816 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 11:55:26.153831 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 11:55:26.153849 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 11:55:26.153865 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 11:55:26.153882 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 11:55:26.153901 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 11:55:26.153916 38584 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 11:55:26.153931 38584 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 11:55:26.153944 38584 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 11:55:26.153954 38584 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 11:55:26.304251 38584 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 11:55:26.304378 38584 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1631, 1860, 1944,  ..., 2346, 5939, 9037]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.718 seconds
[Rank1] pid = 38798
[Rank2] pid = 38863
INFO [38584 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [38798 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [38927 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [38863 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [38927 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [38863 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 11:55:29.609655 38968 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_3 [1495, 400]; dev=3; size=2.281 MB
W20240128 11:55:29.609867 38864 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_2 [1495, 400]; dev=2; size=2.281 MB
W20240128 11:55:29.610263 38968 IPCTensor.h:368] NewIPCTensor: input_keys_3 [1000000]0x100014876000 7.629 MB
W20240128 11:55:29.610394 38968 IPCTensor.h:368] NewIPCTensor: input_keys_neg_3 [1000000]0x10001501b000 7.629 MB
W20240128 11:55:29.610450 38968 IPCTensor.h:368] NewIPCTensor: backward_grads_3 [1000000, 400]0x1000157be000 1.49 GB
W20240128 11:55:29.610494 38968 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x100074da1000 1.49 GB
W20240128 11:55:29.610529 38968 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 11:55:29.610546 38864 IPCTensor.h:368] NewIPCTensor: input_keys_2 [1000000]0x1000d4384000 7.629 MB
W20240128 11:55:29.610730 38864 IPCTensor.h:368] NewIPCTensor: input_keys_neg_2 [1000000]0x1000d4b27000 7.629 MB
INFO [38584 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 11:55:29.610810 38864 IPCTensor.h:368] NewIPCTensor: backward_grads_2 [1000000, 400]0x1000d52ca000 1.49 GB
W20240128 11:55:29.610888 38864 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1001348ad000 1.49 GB
W20240128 11:55:29.610954 38864 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 11:55:29.611281 38928 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_0 [1495, 400]; dev=0; size=2.281 MB
INFO [38798 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 11:55:29.613157 38799 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_1 [1495, 400]; dev=1; size=2.281 MB
W20240128 11:55:29.615710 38968 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 11:55:29.615725 38928 IPCTensor.h:368] NewIPCTensor: input_keys_0 [1000000]0x100193e98000 7.629 MB
W20240128 11:55:29.615749 38864 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 11:55:29.615835 38928 IPCTensor.h:368] NewIPCTensor: input_keys_neg_0 [1000000]0x10019463b000 7.629 MB
W20240128 11:55:29.615892 38928 IPCTensor.h:368] NewIPCTensor: backward_grads_0 [1000000, 400]0x100194dde000 1.49 GB
W20240128 11:55:29.615921 38928 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1001f4b64000 1.49 GB
W20240128 11:55:29.615922 38799 IPCTensor.h:368] NewIPCTensor: input_keys_1 [1000000]0x1001f43c1000 7.629 MB
W20240128 11:55:29.615957 38928 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 11:55:29.616106 38799 IPCTensor.h:368] NewIPCTensor: input_keys_neg_1 [1000000]0x100254147000 7.629 MB
W20240128 11:55:29.616173 38799 IPCTensor.h:368] NewIPCTensor: backward_grads_1 [1000000, 400]0x1002548ea000 1.49 GB
W20240128 11:55:29.616242 38799 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1002b3ecd000 1.49 GB
W20240128 11:55:29.616302 38799 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 11:55:29.625831 38928 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 11:55:29.625918 38799 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [38798 DistTensor.py:56] The tensor name already exists in the kvstore
[Rank3] pid = 38927
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1495), (1495, 2990), (2990, 4485), (4485, 5980)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [38584 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [38927 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [38863 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 11:55:31.035234 38864 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 11:55:31.035277 38968 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 11:55:31.035312 38928 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 11:55:31.035353 38799 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240128 11:55:31.036339 38928 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.1,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240128 11:55:31.036443 38928 grad_base.h:184] Init GradProcessingBase done
I20240128 11:55:31.040685 38928 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240128 11:55:31.040789 38928 kg_controller.h:78] after init GradAsyncProcessingV2
I20240128 11:55:31.040794 38928 kg_controller.h:84] Construct KGCacheController done
I20240128 11:55:31.404289 38928 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240128 11:55:32.097658 39339 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240128 11:55:32.097923 39339 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240128 11:55:32.114529 38864 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 11:55:32.116941 38928 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 11:55:32.148137 38968 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 11:55:32.148205 38799 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240128 11:55:34.871893 38928 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
W20240128 11:55:34.883123 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=1, pq.top=1
W20240128 11:55:34.885612 39339 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
E20240128 11:55:35.871047 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=12257
W20240128 11:55:35.883014 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=41, pq.top=41
W20240128 11:55:35.887987 39339 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 931.164 us                | 10.256 ms                 |
| Forward                   | 2.792 ms                  | 1.247 s                   |
| Backward                  | 2.689 ms                  | 396.880 ms                |
| Optimize                  | 941.878 us                | 2.235 ms                  |
| BarrierTimeBeforeRank0    | 271.971 us                | 23.666 ms                 |
| AfterBackward             | 13.800 ms                 | 1.063 s                   |
| BlockToStepN              | 1.132 ms                  | 5.599 ms                  |
| OneStep                   | 24.273 ms                 | 2.736 s                   |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.113 ms                  | 101.807 ms                |
| ProcessBack:UpdateCache   | 1.929 ms                  | 228.607 ms                |
| ProcessBack:UpsertPq      | 8.577 ms                  | 11.878 ms                 |
| ProcessOneStep            | 14.288 ms                 | 16.824 ms                 |
| BlockToStepN              | 1.802 ms                  | 5.211 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240128 11:55:36.871047 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=12333
W20240128 11:55:36.889830 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=78, pq.top=78
W20240128 11:55:36.893049 39339 grad_async_v2.h:120] Detect new sample comes, old_end8, new_end9
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 5.377, sample: 0.151, forward: 1.446, backward: 0.687, update: 0.072
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 5.377, sample: 0.166, forward: 1.454, backward: 0.705, update: 0.071
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 5.411, sample: 0.164, forward: 1.477, backward: 0.632, update: 0.079
train_sampler.Prefill()
-------Step 0-------
tensor([ 9359,  3816, 10223,  9254,  8196,  5204, 11048,  5222, 12022,   187]) tensor([ 1944,  8073, 10282,  1217,  7266,  8927, 13365,  9235,  9834,  1252])
-------Step 1-------
tensor([ 9359,  3816, 10223,  9254,  8196,  5204, 11048,  5222, 12022,   187]) tensor([ 7100, 11319, 13835,  1769, 11116, 13345,  2362, 10490,  7538,  8460])
-------Step 2-------
tensor([ 6825, 13481,  6913,  5256,  6515,  8955, 11250, 12562, 11828,   193]) tensor([9776, 3486, 2517, 9036, 5565, 1295, 7240, 4938, 8981, 5987])
-------Step 3-------
tensor([ 6825, 13481,  6913,  5256,  6515,  8955, 11250, 12562, 11828,   193]) tensor([ 5920, 11713,  7701, 10489,  8202,  2209, 11965, 12586, 14384, 11949])
-------Step 4-------
tensor([ 8570,  2747,  4094,    10,   742,   227,   100, 10395, 11303,  8907]) tensor([10618,  4184,  3918, 12213,  2320,  2872, 12345,  5891, 11589,  7904])
-------Step 5-------
tensor([ 8570,  2747,  4094,    10,   742,   227,   100, 10395, 11303,  8907]) tensor([ 7215, 10908,  5812,  8561,  8389,  6833,  6753,  3889,  8738, 13708])
-------Step 6-------
tensor([ 9862,  9372,  5933,  8333,  2117,  7181,  7848,  3072, 13547,    28]) tensor([ 7290,  5806,  3586, 10240,  7338,  1284,  4914, 12055, 13160,  4094])
-------Step 7-------
tensor([ 9862,  9372,  5933,  8333,  2117,  7181,  7848,  3072, 13547,    28]) tensor([ 6092,  7821,  9415, 10919,  1114,   291, 13823, 10514,  4836,   819])
-------Step 8-------
tensor([ 3583, 12684, 11785, 10702,  5498,  5933, 12567,  7265,  4322,  2143]) tensor([14556,   937, 10598, 10877,  4209,   625,  5946,  1111,  9337, 14247])
-------Step 9-------
tensor([ 3583, 12684, 11785, 10702,  5498,  5933, 12567,  7265,  4322,  2143]) tensor([12834, 12089, 12115,   921, 13018, 12096,  7119,  2470,  7496,  9596])
before start barrier
start train
[proc 0] 100 steps, total: 5.408, sample: 0.212, forward: 1.524, backward: 0.667, update: 0.090
E20240128 11:55:37.871031 39339 parallel_pq_v2.h:76] insert failed, size(hashtable)=93
W20240128 11:55:37.889662 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=113, pq.top=113
W20240128 11:55:37.893491 39339 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
E20240128 11:55:38.871018 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=9053
W20240128 11:55:38.889189 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=149, pq.top=149
W20240128 11:55:38.896034 39339 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
E20240128 11:55:39.871038 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=8543
W20240128 11:55:39.900878 39339 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240128 11:55:39.905926 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=184, pq.top=184
[proc 3] 200 steps, total: 2.835, sample: 0.190, forward: 0.266, backward: 0.222, update: 0.069
[proc 1] 200 steps, total: 2.835, sample: 0.190, forward: 0.266, backward: 0.237, update: 0.068
[proc 2] 200 steps, total: 2.835, sample: 0.178, forward: 0.240, backward: 0.222, update: 0.075
[proc 0] 200 steps, total: 2.835, sample: 0.230, forward: 0.275, backward: 0.240, update: 0.082
E20240128 11:55:40.871012 39339 parallel_pq_v2.h:76] insert failed, size(hashtable)=110
W20240128 11:55:40.903766 39339 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 11:55:40.914937 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=220, pq.top=220
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.127 ms                  | 10.341 ms                 |
| Forward                   | 2.792 ms                  | 6.177 ms                  |
| Backward                  | 2.424 ms                  | 4.926 ms                  |
| Optimize                  | 907.884 us                | 1.533 ms                  |
| BarrierTimeBeforeRank0    | 20.709 us                 | 1.976 ms                  |
| AfterBackward             | 14.322 ms                 | 18.461 ms                 |
| BlockToStepN              | 4.296 ms                  | 12.090 ms                 |
| OneStep                   | 27.018 ms                 | 40.215 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.098 ms                  | 3.982 ms                  |
| ProcessBack:UpdateCache   | 1.840 ms                  | 2.491 ms                  |
| ProcessBack:UpsertPq      | 8.103 ms                  | 13.092 ms                 |
| ProcessOneStep            | 13.750 ms                 | 18.439 ms                 |
| BlockToStepN              | 4.422 ms                  | 12.365 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 11:55:41.871032 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=12330
W20240128 11:55:41.914412 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=253, pq.top=253
W20240128 11:55:41.919880 39339 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
E20240128 11:55:42.871013 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=9785
W20240128 11:55:42.923679 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=286, pq.top=286
W20240128 11:55:42.929435 39339 grad_async_v2.h:120] Detect new sample comes, old_end6, new_end7
[proc 1] 300 steps, total: 2.985, sample: 0.179, forward: 0.274, backward: 0.328, update: 0.070
[proc 0] 300 steps, total: 2.984, sample: 0.209, forward: 0.274, backward: 0.256, update: 0.079
[proc 3] 300 steps, total: 2.985, sample: 0.158, forward: 0.259, backward: 0.243, update: 0.069
[proc 2] 300 steps, total: 2.984, sample: 0.156, forward: 0.230, backward: 0.226, update: 0.073
E20240128 11:55:43.871007 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=11095
W20240128 11:55:43.923164 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=319, pq.top=319
W20240128 11:55:43.931355 39339 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
E20240128 11:55:44.871021 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=8465
W20240128 11:55:44.929373 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=349, pq.top=349
W20240128 11:55:44.941831 39339 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
E20240128 11:55:45.871008 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=9027
W20240128 11:55:45.941931 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=379, pq.top=379
W20240128 11:55:45.954042 39339 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.156 ms                  | 10.126 ms                 |
| Forward                   | 2.803 ms                  | 4.488 ms                  |
| Backward                  | 2.412 ms                  | 4.884 ms                  |
| Optimize                  | 874.195 us                | 1.534 ms                  |
| BarrierTimeBeforeRank0    | 21.007 us                 | 2.332 ms                  |
| AfterBackward             | 13.724 ms                 | 18.199 ms                 |
| BlockToStepN              | 5.749 ms                  | 14.156 ms                 |
| OneStep                   | 28.698 ms                 | 43.674 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.081 ms                  | 3.063 ms                  |
| ProcessBack:UpdateCache   | 1.799 ms                  | 2.488 ms                  |
| ProcessBack:UpsertPq      | 8.084 ms                  | 12.954 ms                 |
| ProcessOneStep            | 14.124 ms                 | 18.177 ms                 |
| BlockToStepN              | 5.751 ms                  | 14.104 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 2] 400 steps, total: 3.325, sample: 0.142, forward: 0.221, backward: 0.214, update: 0.070
[proc 3] 400 steps, total: 3.325, sample: 0.162, forward: 0.261, backward: 0.242, update: 0.068
[proc 0] 400 steps, total: 3.325, sample: 0.213, forward: 0.277, backward: 0.247, update: 0.078
[proc 1] 400 steps, total: 3.325, sample: 0.148, forward: 0.261, backward: 0.263, update: 0.070
E20240128 11:55:46.871033 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=8056
W20240128 11:55:46.951344 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=408, pq.top=408
W20240128 11:55:46.962983 39339 grad_async_v2.h:120] Detect new sample comes, old_end8, new_end9
E20240128 11:55:47.871012 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=9571
W20240128 11:55:47.957603 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=437, pq.top=437
W20240128 11:55:47.970041 39339 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
E20240128 11:55:48.871066 39115 parallel_pq_v2.h:76] insert failed, size(hashtable)=1511
W20240128 11:55:48.957487 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=465, pq.top=465
W20240128 11:55:48.970599 39339 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
E20240128 11:55:49.871016 39338 parallel_pq_v2.h:76] insert failed, size(hashtable)=8268
W20240128 11:55:49.972790 38928 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=492, pq.top=492
W20240128 11:55:49.980945 39339 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
[proc 3] 500 steps, total: 3.610, sample: 0.131, forward: 0.243, backward: 0.234, update: 0.080
[proc 2] 500 steps, total: 3.610, sample: 0.144, forward: 0.212, backward: 0.213, update: 0.068
[proc 1] 500 steps, total: 3.610, sample: 0.164, forward: 0.266, backward: 0.241, update: 0.068
[proc 0] 500 steps, total: 3.610, sample: 0.223, forward: 0.280, backward: 0.290, update: 0.078
Successfully xmh. training takes 18.16365122795105 seconds
before call kg_cache_controller.StopThreads()
W20240128 11:55:50.280607 38928 grad_async_v2.h:71] call StopThreads. PID = 38584
W20240128 11:55:50.280637 38928 grad_base.h:212] before processOneStepNegThread_.join();
W20240128 11:55:50.281020 38928 grad_base.h:214] after processOneStepNegThread_.join();
W20240128 11:55:50.281028 38928 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
W20240128 11:55:50.285349 38928 grad_async_v2.h:91] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.192 ms                  | 10.090 ms                 |
| Forward                   | 2.827 ms                  | 4.488 ms                  |
| Backward                  | 2.439 ms                  | 4.859 ms                  |
| Optimize                  | 852.829 us                | 1.547 ms                  |
| BarrierTimeBeforeRank0    | 20.849 us                 | 4.802 ms                  |
| AfterBackward             | 15.075 ms                 | 18.472 ms                 |
| BlockToStepN              | 6.801 ms                  | 14.750 ms                 |
| OneStep                   | 30.308 ms                 | 45.587 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.074 ms                  | 2.519 ms                  |
| ProcessBack:UpdateCache   | 1.804 ms                  | 2.628 ms                  |
| ProcessBack:UpsertPq      | 8.331 ms                  | 13.008 ms                 |
| ProcessOneStep            | 15.051 ms                 | 18.439 ms                 |
| BlockToStepN              | 6.732 ms                  | 14.673 ms                 |
+---------------------------+---------------------------+---------------------------+
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f0d86524450>
