WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 18:57:04.433768 660657 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='SimplE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/SimplE_FB15k_45', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [660657 sampler.py:454] Start PreSampling
WARNING [660657 sampler.py:532] Before construct renumbering_dict
WARNING [660657 sampler.py:555] PreSampling done
W20240128 18:57:06.649705 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 18:57:06.649837 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 18:57:06.649857 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 18:57:06.649878 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 18:57:06.649895 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 18:57:06.649919 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 18:57:06.649937 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 18:57:06.649960 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 18:57:06.649976 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 18:57:06.649994 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 18:57:06.650022 660657 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 18:57:06.650040 660657 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 18:57:06.650054 660657 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 18:57:06.650135 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 18:57:06.650157 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 18:57:06.650173 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 18:57:06.650202 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 18:57:06.650220 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 18:57:06.650235 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 18:57:06.650250 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 18:57:06.650274 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 18:57:06.650291 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 18:57:06.650310 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 18:57:06.650324 660657 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 18:57:06.650337 660657 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 18:57:06.650350 660657 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 18:57:06.650383 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 18:57:06.650400 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 18:57:06.650419 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 18:57:06.650434 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 18:57:06.650450 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 18:57:06.650471 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 18:57:06.650488 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 18:57:06.650503 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 18:57:06.650517 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 18:57:06.650537 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 18:57:06.650552 660657 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 18:57:06.650564 660657 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 18:57:06.650578 660657 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 18:57:06.650611 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 18:57:06.650628 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 18:57:06.650643 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 18:57:06.650661 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 18:57:06.650676 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 18:57:06.650692 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 18:57:06.650715 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 18:57:06.650730 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 18:57:06.650753 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 18:57:06.650766 660657 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 18:57:06.650784 660657 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 18:57:06.650796 660657 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 18:57:06.650812 660657 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 18:57:06.773118 660657 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 18:57:06.773241 660657 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1622, 1836, 1912,  ..., 2381, 5888, 7227]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.370 seconds
[Rank1] pid = 660872
[Rank2] pid = 660937
INFO [660657 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [660872 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [660937 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [660937 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [660657 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 18:57:10.203198 661002 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_0 [1495, 400]; dev=0; size=2.281 MB
INFO [661001 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
W20240128 18:57:10.203892 661002 IPCTensor.h:368] NewIPCTensor: input_keys_0 [1000000]0x100014876000 7.629 MB
W20240128 18:57:10.204008 660938 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_2 [1495, 400]; dev=2; size=2.281 MB
W20240128 18:57:10.204106 661002 IPCTensor.h:368] NewIPCTensor: input_keys_neg_0 [1000000]0x100015019000 7.629 MB
W20240128 18:57:10.204219 661002 IPCTensor.h:368] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000157bc000 1.49 GB
INFO [661001 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 18:57:10.204278 661002 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x100074d9f000 1.49 GB
W20240128 18:57:10.204370 661002 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 18:57:10.205838 661003 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_3 [1495, 400]; dev=3; size=2.281 MB
INFO [660872 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 18:57:10.209395 661003 IPCTensor.h:368] NewIPCTensor: input_keys_3 [1000000]0x1000d4386000 7.629 MB
W20240128 18:57:10.209556 661003 IPCTensor.h:368] NewIPCTensor: input_keys_neg_3 [1000000]0x1000d4b29000 7.629 MB
W20240128 18:57:10.209609 660938 IPCTensor.h:368] NewIPCTensor: input_keys_2 [1000000]0x1000d52cc000 7.629 MB
W20240128 18:57:10.209635 661003 IPCTensor.h:368] NewIPCTensor: backward_grads_3 [1000000, 400]0x1000d5a6f000 1.49 GB
W20240128 18:57:10.209702 661003 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x100135052000 1.49 GB
W20240128 18:57:10.209769 661003 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 18:57:10.209893 660938 IPCTensor.h:368] NewIPCTensor: input_keys_neg_2 [1000000]0x100194635000 7.629 MB
W20240128 18:57:10.209996 660938 IPCTensor.h:368] NewIPCTensor: backward_grads_2 [1000000, 400]0x100194dd8000 1.49 GB
W20240128 18:57:10.210088 660938 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1001f43bb000 1.49 GB
W20240128 18:57:10.210173 660938 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 18:57:10.210180 660873 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_1 [1495, 400]; dev=1; size=2.281 MB
W20240128 18:57:10.217368 661003 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 18:57:10.217413 660873 IPCTensor.h:368] NewIPCTensor: input_keys_1 [1000000]0x1002539a6000 7.629 MB
W20240128 18:57:10.217465 660938 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 18:57:10.217514 660873 IPCTensor.h:368] NewIPCTensor: input_keys_neg_1 [1000000]0x100254149000 7.629 MB
W20240128 18:57:10.217532 661002 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 18:57:10.217574 660873 IPCTensor.h:368] NewIPCTensor: backward_grads_1 [1000000, 400]0x1002548ec000 1.49 GB
W20240128 18:57:10.217617 660873 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1002b3ecf000 1.49 GB
W20240128 18:57:10.217666 660873 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 18:57:10.230721 660873 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [660937 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [661001 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [660872 DistTensor.py:56] The tensor name already exists in the kvstore
[Rank3] pid = 661001
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1495), (1495, 2990), (2990, 4485), (4485, 5980)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [660657 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 18:57:11.962288 661002 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 18:57:11.962453 661003 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 18:57:11.962555 660873 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 18:57:11.962740 660938 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240128 18:57:11.964440 661002 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.1,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240128 18:57:11.964596 661002 grad_base.h:184] Init GradProcessingBase done
I20240128 18:57:11.969199 661002 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240128 18:57:11.969321 661002 kg_controller.h:78] after init GradAsyncProcessingV2
I20240128 18:57:11.969329 661002 kg_controller.h:84] Construct KGCacheController done
E20240128 18:57:12.342636 661003 recstore.cc:66] init folly done
E20240128 18:57:12.342667 660938 recstore.cc:66] init folly done
E20240128 18:57:12.342792 661002 recstore.cc:66] init folly done
E20240128 18:57:12.342818 660873 recstore.cc:66] init folly done
I20240128 18:57:12.343544 661002 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240128 18:57:13.059257 661416 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
E20240128 18:57:13.059680 661416 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240128 18:57:13.082485 661002 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 18:57:13.108007 660938 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 18:57:13.108644 661003 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 18:57:13.119787 660873 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240128 18:57:15.327885 661002 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
W20240128 18:57:15.349319 661416 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 18:57:15.537845 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=7, pq.top=7
E20240128 18:57:16.327008 661416 parallel_pq_v2.h:76] insert failed, size(hashtable)=901
W20240128 18:57:16.349200 661416 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
W20240128 18:57:16.544075 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=34, pq.top=34
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.021 ms                  | 14.863 ms                 |
| Forward                   | 3.271 ms                  | 778.823 ms                |
| Backward                  | 2.890 ms                  | 318.273 ms                |
| Optimize                  | 1.286 ms                  | 56.038 ms                 |
| BarrierTimeBeforeRank0    | 70.277 us                 | 45.497 ms                 |
| AfterBackward             | 17.560 ms                 | 1.027 s                   |
| BlockToStepN              | 897.022 us                | 20.474 ms                 |
| OneStep                   | 30.387 ms                 | 2.228 s                   |
+---------------------------+---------------------------+---------------------------+
E20240128 18:57:17.327065 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=6128
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.994 ms                  | 91.009 ms                 |
| ProcessBack:UpdateCache   | 1.625 ms                  | 195.448 ms                |
| ProcessBack:UpsertPq      | 11.376 ms                 | 20.919 ms                 |
| ProcessOneStep            | 16.376 ms                 | 162.398 ms                |
| BlockToStepN              | 1.780 ms                  | 16.076 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240128 18:57:17.354355 661416 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240128 18:57:17.544052 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=62, pq.top=62
E20240128 18:57:18.327046 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=7268
W20240128 18:57:18.359511 661416 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 18:57:18.578095 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=87, pq.top=87
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 5.934, sample: 0.225, forward: 1.078, backward: 0.690, update: 0.171
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 5.945, sample: 0.212, forward: 1.053, backward: 0.618, update: 0.161
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 5.945, sample: 0.223, forward: 1.083, backward: 0.618, update: 0.161
train_sampler.Prefill()
-------Step 0-------
tensor([ 8942,   189,  9617,  7612,  8354,  4967, 10659,  5025, 12555,    60]) tensor([ 1912,  8451,  9695,  1435,  7198,  8537, 12721,  8830,  7760,  8305])
-------Step 1-------
tensor([ 8942,   189,  9617,  7612,  8354,  4967, 10659,  5025, 12555,    60]) tensor([ 7074, 13546, 11116, 14886,  6993,  9326,  5940,  2353,  2972,  8881])
-------Step 2-------
tensor([ 9400,  2818,  4169,    11,   715,   239,   109, 12069, 10864,  7450]) tensor([10318,  4127,  3765, 12732,  2438,  2786, 12349,  6284, 11902,  7531])
-------Step 3-------
tensor([ 9400,  2818,  4169,    11,   715,   239,   109, 12069, 10864,  7450]) tensor([  550, 10924,  6640, 12661,   234,   546,  2536, 13873,  5626,   270])
-------Step 4-------
tensor([ 3455, 14913,  9812, 10160,  5571,  5934, 12550,  6556,  3907,  2084]) tensor([14404,  1074, 10676, 10573,  4151,   678,  6286,  1082, 10881, 14747])
-------Step 5-------
tensor([ 3455, 14913,  9812, 10160,  5571,  5934, 12550,  6556,  3907,  2084]) tensor([ 7445,  7007,  8744, 13123,  1269, 12209,  3277, 13338,  7607,  6712])
-------Step 6-------
tensor([11745,   597,  7243,    97, 11092, 11829, 14715,  9812,  9791,  7883]) tensor([ 3392,  8919,  7179, 10502,  9795, 12925,  1934,  2744, 12420,  1343])
-------Step 7-------
tensor([11745,   597,  7243,    97, 11092, 11829, 14715,  9812,  9791,  7883]) tensor([ 4924, 14369, 11279,  7114,  5594,   893,  7139,   957, 10513, 12814])
-------Step 8-------
tensor([11045,  9882, 12766, 10283,  5200,  8093,  1750,  5991,  4925, 12554]) tensor([ 7243, 11492, 14321,  1737, 10061, 10239,  2411, 11325,  8307,  8549])
-------Step 9-------
tensor([11045,  9882, 12766, 10283,  5200,  8093,  1750,  5991,  4925, 12554]) tensor([12004, 11184,  1703,  3736,  2494,   585,  6833,  3233,  2972, 14790])
before start barrier
start train
[proc 0] 100 steps, total: 5.971, sample: 0.220, forward: 1.089, backward: 0.605, update: 0.184
E20240128 18:57:19.327055 661192 parallel_pq_v2.h:76] insert failed, size(hashtable)=163
W20240128 18:57:19.366529 661416 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240128 18:57:19.578194 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=111, pq.top=111
E20240128 18:57:20.327008 661192 parallel_pq_v2.h:76] insert failed, size(hashtable)=1551
W20240128 18:57:20.369535 661416 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
W20240128 18:57:20.598901 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=134, pq.top=134
E20240128 18:57:21.327087 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=4879
W20240128 18:57:21.394378 661416 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 18:57:21.626482 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=157, pq.top=157
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.115 ms                  | 14.283 ms                 |
| Forward                   | 3.254 ms                  | 6.664 ms                  |
| Backward                  | 2.978 ms                  | 5.709 ms                  |
| Optimize                  | 1.244 ms                  | 2.481 ms                  |
| BarrierTimeBeforeRank0    | 36.627 us                 | 5.565 ms                  |
| AfterBackward             | 18.819 ms                 | 46.590 ms                 |
| BlockToStepN              | 10.224 ms                 | 26.292 ms                 |
| OneStep                   | 39.698 ms                 | 76.756 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 18:57:22.327013 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=8568
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.107 ms                  | 3.107 ms                  |
| ProcessBack:UpdateCache   | 1.902 ms                  | 2.972 ms                  |
| ProcessBack:UpsertPq      | 13.810 ms                 | 20.850 ms                 |
| ProcessOneStep            | 18.897 ms                 | 46.565 ms                 |
| BlockToStepN              | 10.170 ms                 | 28.408 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240128 18:57:22.406683 661416 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240128 18:57:22.626248 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=179, pq.top=179
E20240128 18:57:23.327009 661192 parallel_pq_v2.h:76] insert failed, size(hashtable)=866
W20240128 18:57:23.408216 661416 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
[proc 1] 200 steps, total: 4.438, sample: 0.176, forward: 0.280, backward: 0.284, update: 0.124
[proc 3] 200 steps, total: 4.438, sample: 0.254, forward: 0.311, backward: 0.343, update: 0.102
[proc 2] 200 steps, total: 4.438, sample: 0.175, forward: 0.246, backward: 0.256, update: 0.108
[proc 0] 200 steps, total: 4.438, sample: 0.307, forward: 0.336, backward: 0.351, update: 0.121
W20240128 18:57:23.626281 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=204, pq.top=204
E20240128 18:57:24.327013 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=6653
W20240128 18:57:24.408852 661416 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240128 18:57:24.655437 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=230, pq.top=230
E20240128 18:57:25.327010 661416 parallel_pq_v2.h:76] insert failed, size(hashtable)=233
W20240128 18:57:25.412655 661416 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 18:57:25.655169 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=259, pq.top=259
E20240128 18:57:26.327018 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=7359
W20240128 18:57:26.422012 661416 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
W20240128 18:57:26.682555 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=284, pq.top=284
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.185 ms                  | 14.507 ms                 |
| Forward                   | 3.282 ms                  | 5.285 ms                  |
| Backward                  | 2.957 ms                  | 5.560 ms                  |
| Optimize                  | 1.244 ms                  | 2.481 ms                  |
| BarrierTimeBeforeRank0    | 23.235 us                 | 11.549 ms                 |
| AfterBackward             | 16.672 ms                 | 27.196 ms                 |
| BlockToStepN              | 9.374 ms                  | 31.046 ms                 |
| OneStep                   | 38.496 ms                 | 77.047 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 2] 300 steps, total: 3.820, sample: 0.221, forward: 0.302, backward: 0.264, update: 0.097
[proc 1] 300 steps, total: 3.820, sample: 0.154, forward: 0.258, backward: 0.267, update: 0.116
[proc 3] 300 steps, total: 3.820, sample: 0.227, forward: 0.288, backward: 0.315, update: 0.106
[proc 0] 300 steps, total: 3.820, sample: 0.264, forward: 0.322, backward: 0.284, update: 0.121
E20240128 18:57:27.327019 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=6249
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.166 ms                  | 2.492 ms                  |
| ProcessBack:UpdateCache   | 1.818 ms                  | 2.708 ms                  |
| ProcessBack:UpsertPq      | 12.090 ms                 | 20.140 ms                 |
| ProcessOneStep            | 16.603 ms                 | 27.173 ms                 |
| BlockToStepN              | 9.322 ms                  | 30.983 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240128 18:57:27.437777 661416 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240128 18:57:27.711984 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=310, pq.top=310
E20240128 18:57:28.327009 661002 parallel_pq_v2.h:76] insert failed, size(hashtable)=415
W20240128 18:57:28.441866 661416 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
W20240128 18:57:28.731756 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=334, pq.top=334
E20240128 18:57:29.327010 661002 parallel_pq_v2.h:76] insert failed, size(hashtable)=971
W20240128 18:57:29.448307 661416 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240128 18:57:29.759404 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=358, pq.top=358
E20240128 18:57:30.327009 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=6605
W20240128 18:57:30.454298 661416 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240128 18:57:30.759163 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=381, pq.top=381
E20240128 18:57:31.327008 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=6710
W20240128 18:57:31.464439 661416 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
[proc 1] 400 steps, total: 4.285, sample: 0.235, forward: 0.293, backward: 0.266, update: 0.114
[proc 3] 400 steps, total: 4.285, sample: 0.210, forward: 0.284, backward: 0.245, update: 0.106
[proc 2] 400 steps, total: 4.285, sample: 0.229, forward: 0.314, backward: 0.259, update: 0.107
[proc 0] 400 steps, total: 4.285, sample: 0.267, forward: 0.320, backward: 0.285, update: 0.118
W20240128 18:57:31.770332 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=404, pq.top=404
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.206 ms                  | 14.555 ms                 |
| Forward                   | 3.276 ms                  | 5.006 ms                  |
| Backward                  | 2.931 ms                  | 4.440 ms                  |
| Optimize                  | 1.219 ms                  | 2.407 ms                  |
| BarrierTimeBeforeRank0    | 22.683 us                 | 12.339 ms                 |
| AfterBackward             | 16.121 ms                 | 26.581 ms                 |
| BlockToStepN              | 10.517 ms                 | 31.308 ms                 |
| OneStep                   | 40.131 ms                 | 76.756 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 18:57:32.327014 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=4500
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.087 ms                  | 2.490 ms                  |
| ProcessBack:UpdateCache   | 1.565 ms                  | 2.660 ms                  |
| ProcessBack:UpsertPq      | 11.692 ms                 | 19.811 ms                 |
| ProcessOneStep            | 16.076 ms                 | 26.556 ms                 |
| BlockToStepN              | 10.461 ms                 | 31.654 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240128 18:57:32.470841 661416 grad_async_v2.h:121] Detect new sample comes, old_end9, new_end0
W20240128 18:57:32.770206 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=425, pq.top=425
E20240128 18:57:33.327010 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=7790
W20240128 18:57:33.471431 661416 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240128 18:57:33.786208 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=448, pq.top=448
E20240128 18:57:34.327011 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=8555
W20240128 18:57:34.498502 661416 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240128 18:57:34.799945 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=469, pq.top=469
E20240128 18:57:35.327023 661415 parallel_pq_v2.h:76] insert failed, size(hashtable)=4120
W20240128 18:57:35.523144 661416 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240128 18:57:35.799317 661002 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=490, pq.top=490
[proc 1] 500 steps, total: 4.655, sample: 0.202, forward: 0.287, backward: 0.284, update: 0.110
[proc 2] 500 steps, total: 4.655, sample: 0.254, forward: 0.314, backward: 0.265, update: 0.101
[proc 0] 500 steps, total: 4.655, sample: 0.269, forward: 0.315, backward: 0.293, update: 0.106
[proc 3] 500 steps, total: 4.655, sample: 0.166, forward: 0.257, backward: 0.371, update: 0.096
Successfully xmh. training takes 23.16885280609131 seconds
before call kg_cache_controller.StopThreads()
W20240128 18:57:36.251351 661002 grad_async_v2.h:71] call StopThreads. PID = 660657
W20240128 18:57:36.251380 661002 grad_base.h:212] before processOneStepNegThread_.join();
W20240128 18:57:36.251632 661002 grad_base.h:214] after processOneStepNegThread_.join();
W20240128 18:57:36.251642 661002 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
W20240128 18:57:36.259416 661002 grad_async_v2.h:92] StopThreads done.
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.228 ms                  | 14.507 ms                 |
| Forward                   | 3.272 ms                  | 4.894 ms                  |
| Backward                  | 2.951 ms                  | 4.418 ms                  |
| Optimize                  | 1.204 ms                  | 2.334 ms                  |
| BarrierTimeBeforeRank0    | 23.622 us                 | 12.871 ms                 |
| AfterBackward             | 16.335 ms                 | 26.084 ms                 |
| BlockToStepN              | 11.183 ms                 | 32.127 ms                 |
| OneStep                   | 41.261 ms                 | 77.047 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.125 ms                  | 2.490 ms                  |
| ProcessBack:UpdateCache   | 1.724 ms                  | 2.619 ms                  |
| ProcessBack:UpsertPq      | 11.727 ms                 | 19.709 ms                 |
| ProcessOneStep            | 16.309 ms                 | 26.064 ms                 |
| BlockToStepN              | 11.121 ms                 | 32.059 ms                 |
+---------------------------+---------------------------+---------------------------+
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f50e3313550>
