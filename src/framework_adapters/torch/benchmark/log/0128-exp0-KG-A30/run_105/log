WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 13:54:02.474206 219794 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_45', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [219794 sampler.py:454] Start PreSampling
WARNING [219794 sampler.py:532] Before construct renumbering_dict
WARNING [219794 sampler.py:555] PreSampling done
W20240128 13:54:05.147954 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 13:54:05.148097 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 13:54:05.148120 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 13:54:05.148136 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 13:54:05.148151 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 13:54:05.148166 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 13:54:05.148180 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 13:54:05.148198 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 13:54:05.148223 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 13:54:05.148241 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 13:54:05.148260 219794 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 13:54:05.148277 219794 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 13:54:05.148293 219794 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 13:54:05.148375 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 13:54:05.148398 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 13:54:05.148413 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 13:54:05.148447 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 13:54:05.148473 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 13:54:05.148492 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 13:54:05.148510 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 13:54:05.148525 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 13:54:05.148541 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 13:54:05.148558 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 13:54:05.148573 219794 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 13:54:05.148587 219794 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 13:54:05.148603 219794 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 13:54:05.148643 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 13:54:05.148664 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 13:54:05.148685 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 13:54:05.148707 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 13:54:05.148734 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 13:54:05.148756 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 13:54:05.148772 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 13:54:05.148787 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 13:54:05.148805 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 13:54:05.148828 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 13:54:05.148847 219794 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 13:54:05.148861 219794 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 13:54:05.148874 219794 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 13:54:05.148909 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 13:54:05.148931 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 13:54:05.148945 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 13:54:05.148960 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 13:54:05.148979 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 13:54:05.149003 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 13:54:05.149020 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 13:54:05.149037 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 13:54:05.149055 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 13:54:05.149070 219794 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 13:54:05.149089 219794 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 13:54:05.149101 219794 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 13:54:05.149116 219794 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 13:54:05.276969 219794 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 13:54:05.277092 219794 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1633, 1883, 1949,  ..., 2354, 6142, 7630]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.835 seconds
[Rank1] pid = 220008
[Rank2] pid = 220073
INFO [219794 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [220008 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [220073 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [220137 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [220008 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [220073 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [219794 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [220137 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 13:54:07.698508 220138 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_0 [1495, 400]; dev=0; size=2.281 MB
W20240128 13:54:07.698976 220138 IPCTensor.h:368] NewIPCTensor: input_keys_0 [1000000]0x100014876000 7.629 MB
W20240128 13:54:07.698941 220009 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_1 [1495, 400]; dev=1; size=2.281 MB
W20240128 13:54:07.698942 220074 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_2 [1495, 400]; dev=2; size=2.281 MB
W20240128 13:54:07.699079 220138 IPCTensor.h:368] NewIPCTensor: input_keys_neg_0 [1000000]0x100015019000 7.629 MB
W20240128 13:54:07.699121 220138 IPCTensor.h:368] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000157bc000 1.49 GB
W20240128 13:54:07.699148 220138 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x100074d9f000 1.49 GB
W20240128 13:54:07.699183 220138 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 13:54:07.699404 220139 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_3 [1495, 400]; dev=3; size=2.281 MB
W20240128 13:54:07.701318 220009 IPCTensor.h:368] NewIPCTensor: input_keys_1 [1000000]0x1000d4386000 7.629 MB
W20240128 13:54:07.701377 220074 IPCTensor.h:368] NewIPCTensor: input_keys_2 [1000000]0x1000d4b2b000 7.629 MB
W20240128 13:54:07.701390 220138 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 13:54:07.701457 220009 IPCTensor.h:368] NewIPCTensor: input_keys_neg_1 [1000000]0x1000d52d0000 7.629 MB
W20240128 13:54:07.701510 220009 IPCTensor.h:368] NewIPCTensor: backward_grads_1 [1000000, 400]0x1000d5a73000 1.49 GB
W20240128 13:54:07.701524 220074 IPCTensor.h:368] NewIPCTensor: input_keys_neg_2 [1000000]0x100135056000 7.629 MB
W20240128 13:54:07.701552 220009 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1001357f9000 1.49 GB
W20240128 13:54:07.701584 220009 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 13:54:07.701586 220074 IPCTensor.h:368] NewIPCTensor: backward_grads_2 [1000000, 400]0x100194ddc000 1.49 GB
W20240128 13:54:07.701632 220074 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1001f4b62000 1.49 GB
W20240128 13:54:07.701622 220139 IPCTensor.h:368] NewIPCTensor: input_keys_3 [1000000]0x1001f43bf000 7.629 MB
W20240128 13:54:07.701663 220074 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 13:54:07.701802 220139 IPCTensor.h:368] NewIPCTensor: input_keys_neg_3 [1000000]0x100254145000 7.629 MB
W20240128 13:54:07.701864 220139 IPCTensor.h:368] NewIPCTensor: backward_grads_3 [1000000, 400]0x1002548e8000 1.49 GB
W20240128 13:54:07.701915 220139 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1002b3ecb000 1.49 GB
W20240128 13:54:07.701977 220139 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 13:54:07.709937 220074 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 13:54:07.709955 220009 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 13:54:07.710007 220139 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
[Rank3] pid = 220137
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1495), (1495, 2990), (2990, 4485), (4485, 5980)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [219794 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [220073 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [220137 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [220008 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 13:54:08.811012 220009 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 13:54:08.811172 220139 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 13:54:08.811214 220138 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 13:54:08.811370 220074 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240128 13:54:08.812700 220138 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.1,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240128 13:54:08.812793 220138 grad_base.h:184] Init GradProcessingBase done
I20240128 13:54:08.816359 220138 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240128 13:54:08.816452 220138 kg_controller.h:78] after init GradAsyncProcessingV2
I20240128 13:54:08.816457 220138 kg_controller.h:84] Construct KGCacheController done
I20240128 13:54:09.180019 220138 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240128 13:54:09.873062 220654 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240128 13:54:09.873342 220654 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240128 13:54:09.898824 220074 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 13:54:09.913077 220009 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:54:09.916323 220138 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:54:09.925258 220139 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240128 13:54:12.245757 220319 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
W20240128 13:54:12.260093 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=1, pq.top=0
W20240128 13:54:12.265995 220654 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
E20240128 13:54:13.245018 220138 parallel_pq_v2.h:76] insert failed, size(hashtable)=4900
W20240128 13:54:13.266914 220654 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
W20240128 13:54:13.280401 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=31, pq.top=31
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.012 ms                  | 15.166 ms                 |
| Forward                   | 2.906 ms                  | 1.258 s                   |
| Backward                  | 2.912 ms                  | 169.663 ms                |
| Optimize                  | 1.178 ms                  | 40.630 ms                 |
| BarrierTimeBeforeRank0    | 22.304 us                 | 4.156 ms                  |
| AfterBackward             | 18.012 ms                 | 864.329 ms                |
| BlockToStepN              | 4.789 ms                  | 27.121 ms                 |
| OneStep                   | 35.125 ms                 | 2.340 s                   |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.204 ms                  | 74.679 ms                 |
| ProcessBack:UpdateCache   | 1.788 ms                  | 221.220 ms                |
| ProcessBack:UpsertPq      | 12.648 ms                 | 17.192 ms                 |
| ProcessOneStep            | 17.525 ms                 | 22.902 ms                 |
| BlockToStepN              | 6.294 ms                  | 23.008 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:54:14.245009 220319 parallel_pq_v2.h:76] insert failed, size(hashtable)=1816
W20240128 13:54:14.271085 220654 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
W20240128 13:54:14.296813 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=58, pq.top=58
E20240128 13:54:15.245112 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=6002
W20240128 13:54:15.279939 220654 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
W20240128 13:54:15.307049 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=83, pq.top=83
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 6.114, sample: 0.197, forward: 0.968, backward: 0.367, update: 0.167
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 6.141, sample: 0.172, forward: 1.394, backward: 0.518, update: 0.159
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 6.127, sample: 0.216, forward: 1.041, backward: 0.503, update: 0.164
train_sampler.Prefill()
-------Step 0-------
tensor([ 9583,    57,  9255,  7369,  8339,  5247,  9137,  5443, 12319,    37]) tensor([ 1949,  8390,  9318,  1415,  7561,  9103, 13010,  9459,  8283, 11818])
-------Step 1-------
tensor([ 9583,    57,  9255,  7369,  8339,  5247,  9137,  5443, 12319,    37]) tensor([ 7639, 13239, 11747, 14031,  7086, 13434,  6471,  2245,  2608, 10497])
-------Step 2-------
tensor([ 9006,  2817,  5468,    11,   706,   226,   165, 10417, 10449, 12314]) tensor([10360,  4029,  3884, 12179,  2243,  2649, 14752,  5762, 11987,  7963])
-------Step 3-------
tensor([ 9006,  2817,  5468,    11,   706,   226,   165, 10417, 10449, 12314]) tensor([  561, 11292,  6453, 12664,   161,   517,  2370, 11521,  6090,   154])
-------Step 4-------
tensor([ 3691, 14658, 14600, 10341,  5588,  5761, 12233,  6643,  3964,  2142]) tensor([12485,  1008, 10323, 10596,  3729,   675,  5983,  1091,  9382, 12452])
-------Step 5-------
tensor([ 3691, 14658, 14600, 10341,  5588,  5761, 12233,  6643,  3964,  2142]) tensor([ 7135,  6773, 12547, 13255,  1252, 10485,  3151, 13251,  7555,  6477])
-------Step 6-------
tensor([12435,   599,  7246,    72, 11040, 10154, 13903, 14600, 10513,  6557]) tensor([ 3258,  8105,  6523, 10586, 14128, 11620,  1907,  2695, 10663,  1377])
-------Step 7-------
tensor([12435,   599,  7246,    72, 11040, 10154, 13903, 14600, 10513,  6557]) tensor([ 4759, 14273,  9101,  7501,  6059,   868,  6742,   966, 10543, 12754])
-------Step 8-------
tensor([ 9545,  9610, 13730,  9824,  4874,  6724,  1738,  5456,  4917, 13493]) tensor([ 7246, 10387, 14691,  1749, 10458, 11189,  2297,  9130,  7579,  8322])
-------Step 9-------
tensor([ 9545,  9610, 13730,  9824,  4874,  6724,  1738,  5456,  4917, 13493]) tensor([ 9692, 10711,  1761,  3638,  2384,   601,  7489,  3178,  2608, 13581])
before start barrier
start train
[proc 0] 100 steps, total: 6.123, sample: 0.276, forward: 1.558, backward: 0.439, update: 0.163
E20240128 13:54:16.245020 220319 parallel_pq_v2.h:76] insert failed, size(hashtable)=417
W20240128 13:54:16.282455 220654 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
W20240128 13:54:16.338188 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=107, pq.top=107
E20240128 13:54:17.245015 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=5002
W20240128 13:54:17.284016 220654 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 13:54:17.344112 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=131, pq.top=131
E20240128 13:54:18.245033 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=7426
W20240128 13:54:18.289012 220654 grad_async_v2.h:120] Detect new sample comes, old_end4, new_end5
W20240128 13:54:18.356937 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=157, pq.top=157
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.081 ms                  | 14.890 ms                 |
| Forward                   | 2.934 ms                  | 7.722 ms                  |
| Backward                  | 2.350 ms                  | 4.174 ms                  |
| Optimize                  | 1.164 ms                  | 2.375 ms                  |
| BarrierTimeBeforeRank0    | 22.016 us                 | 1.394 ms                  |
| AfterBackward             | 19.758 ms                 | 25.498 ms                 |
| BlockToStepN              | 7.380 ms                  | 23.060 ms                 |
| OneStep                   | 38.916 ms                 | 54.429 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.293 ms                  | 2.551 ms                  |
| ProcessBack:UpdateCache   | 1.950 ms                  | 2.934 ms                  |
| ProcessBack:UpsertPq      | 14.193 ms                 | 18.839 ms                 |
| ProcessOneStep            | 19.520 ms                 | 25.474 ms                 |
| BlockToStepN              | 7.790 ms                  | 23.008 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:54:19.245009 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=5289
W20240128 13:54:19.301049 220654 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240128 13:54:19.359174 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=185, pq.top=185
[proc 3] 200 steps, total: 3.947, sample: 0.222, forward: 0.240, backward: 0.182, update: 0.101
[proc 2] 200 steps, total: 3.947, sample: 0.260, forward: 0.284, backward: 0.218, update: 0.103
[proc 1] 200 steps, total: 3.947, sample: 0.232, forward: 0.279, backward: 0.231, update: 0.118
[proc 0] 200 steps, total: 3.947, sample: 0.297, forward: 0.295, backward: 0.230, update: 0.111
E20240128 13:54:20.245157 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=5333
W20240128 13:54:20.313135 220654 grad_async_v2.h:120] Detect new sample comes, old_end8, new_end9
W20240128 13:54:20.377879 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=210, pq.top=210
E20240128 13:54:21.245031 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=3542
W20240128 13:54:21.313300 220654 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240128 13:54:21.377200 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=235, pq.top=235
E20240128 13:54:22.245013 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=3594
W20240128 13:54:22.317355 220654 grad_async_v2.h:120] Detect new sample comes, old_end8, new_end9
W20240128 13:54:22.377269 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=260, pq.top=260
E20240128 13:54:23.245014 220138 parallel_pq_v2.h:76] insert failed, size(hashtable)=391
W20240128 13:54:23.322216 220654 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 13:54:23.377095 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=281, pq.top=281
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.110 ms                  | 14.990 ms                 |
| Forward                   | 2.981 ms                  | 5.843 ms                  |
| Backward                  | 2.174 ms                  | 4.174 ms                  |
| Optimize                  | 1.145 ms                  | 2.373 ms                  |
| BarrierTimeBeforeRank0    | 22.220 us                 | 11.695 ms                 |
| AfterBackward             | 17.584 ms                 | 24.347 ms                 |
| BlockToStepN              | 9.995 ms                  | 30.022 ms                 |
| OneStep                   | 39.834 ms                 | 59.130 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.175 ms                  | 2.509 ms                  |
| ProcessBack:UpdateCache   | 1.585 ms                  | 2.907 ms                  |
| ProcessBack:UpsertPq      | 12.983 ms                 | 18.751 ms                 |
| ProcessOneStep            | 17.522 ms                 | 24.324 ms                 |
| BlockToStepN              | 10.060 ms                 | 29.954 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:54:24.245016 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=7035
[proc 2] 300 steps, total: 4.286, sample: 0.241, forward: 0.287, backward: 0.195, update: 0.106
[proc 1] 300 steps, total: 4.286, sample: 0.243, forward: 0.291, backward: 0.211, update: 0.110
[proc 0] 300 steps, total: 4.286, sample: 0.286, forward: 0.290, backward: 0.200, update: 0.109
[proc 3] 300 steps, total: 4.286, sample: 0.153, forward: 0.208, backward: 0.186, update: 0.091
W20240128 13:54:24.332499 220654 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
W20240128 13:54:24.393621 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=303, pq.top=303
E20240128 13:54:25.245008 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=7128
W20240128 13:54:25.335870 220654 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240128 13:54:25.412096 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=325, pq.top=325
E20240128 13:54:26.245008 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=4083
W20240128 13:54:26.339221 220654 grad_async_v2.h:120] Detect new sample comes, old_end4, new_end5
W20240128 13:54:26.437826 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=347, pq.top=347
E20240128 13:54:27.245039 220138 parallel_pq_v2.h:76] insert failed, size(hashtable)=1200
W20240128 13:54:27.340127 220654 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
W20240128 13:54:27.437464 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=368, pq.top=368
E20240128 13:54:28.245038 220654 parallel_pq_v2.h:76] insert failed, size(hashtable)=16
W20240128 13:54:28.348294 220654 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
W20240128 13:54:28.454496 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=390, pq.top=390
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.144 ms                  | 15.129 ms                 |
| Forward                   | 2.982 ms                  | 4.610 ms                  |
| Backward                  | 2.162 ms                  | 4.174 ms                  |
| Optimize                  | 1.143 ms                  | 2.374 ms                  |
| BarrierTimeBeforeRank0    | 23.113 us                 | 11.940 ms                 |
| AfterBackward             | 17.054 ms                 | 24.291 ms                 |
| BlockToStepN              | 11.487 ms                 | 35.443 ms                 |
| OneStep                   | 41.544 ms                 | 59.617 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 4.661, sample: 0.219, forward: 0.274, backward: 0.210, update: 0.103
[proc 3] 400 steps, total: 4.661, sample: 0.220, forward: 0.235, backward: 0.189, update: 0.100
[proc 0] 400 steps, total: 4.661, sample: 0.282, forward: 0.289, backward: 0.211, update: 0.110
[proc 2] 400 steps, total: 4.661, sample: 0.236, forward: 0.283, backward: 0.213, update: 0.100
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.148 ms                  | 2.504 ms                  |
| ProcessBack:UpdateCache   | 1.558 ms                  | 2.883 ms                  |
| ProcessBack:UpsertPq      | 12.480 ms                 | 18.668 ms                 |
| ProcessOneStep            | 17.027 ms                 | 24.268 ms                 |
| BlockToStepN              | 11.428 ms                 | 35.535 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:54:29.245019 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=6718
W20240128 13:54:29.382863 220654 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 13:54:29.466017 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=411, pq.top=411
E20240128 13:54:30.245008 220138 parallel_pq_v2.h:76] insert failed, size(hashtable)=1796
W20240128 13:54:30.389206 220654 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 13:54:30.466218 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=431, pq.top=431
E20240128 13:54:31.245149 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=6969
W20240128 13:54:31.390998 220654 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 13:54:31.466100 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=451, pq.top=451
E20240128 13:54:32.245024 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=3585
W20240128 13:54:32.438968 220654 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 13:54:32.480597 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=470, pq.top=470
E20240128 13:54:33.245011 220653 parallel_pq_v2.h:76] insert failed, size(hashtable)=6262
W20240128 13:54:33.441092 220654 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
W20240128 13:54:33.495244 220138 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=489, pq.top=489
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.194 ms                  | 15.212 ms                 |
| Forward                   | 2.994 ms                  | 4.139 ms                  |
| Backward                  | 2.167 ms                  | 5.037 ms                  |
| Optimize                  | 1.145 ms                  | 2.440 ms                  |
| BarrierTimeBeforeRank0    | 22.500 us                 | 12.796 ms                 |
| AfterBackward             | 17.354 ms                 | 24.604 ms                 |
| BlockToStepN              | 12.144 ms                 | 36.644 ms                 |
| OneStep                   | 42.731 ms                 | 69.077 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 3] 500 steps, total: 5.150, sample: 0.239, forward: 0.266, backward: 0.191, update: 0.107
[proc 1] 500 steps, total: 5.150, sample: 0.242, forward: 0.291, backward: 0.215, update: 0.109
[proc 2] 500 steps, total: 5.150, sample: 0.230, forward: 0.269, backward: 0.223, update: 0.101
[proc 0] 500 steps, total: 5.150, sample: 0.308, forward: 0.294, backward: 0.229, update: 0.118
Successfully xmh. training takes 24.16787028312683 seconds
before call kg_cache_controller.StopThreads()
W20240128 13:54:34.084192 220138 grad_async_v2.h:71] call StopThreads. PID = 219794
W20240128 13:54:34.084223 220138 grad_base.h:212] before processOneStepNegThread_.join();
W20240128 13:54:34.084498 220138 grad_base.h:214] after processOneStepNegThread_.join();
W20240128 13:54:34.084530 220138 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
W20240128 13:54:34.092892 220138 grad_async_v2.h:91] StopThreads done.
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.189 ms                  | 2.711 ms                  |
| ProcessBack:UpdateCache   | 1.583 ms                  | 2.868 ms                  |
| ProcessBack:UpsertPq      | 12.808 ms                 | 18.885 ms                 |
| ProcessOneStep            | 17.359 ms                 | 25.258 ms                 |
| BlockToStepN              | 12.074 ms                 | 36.572 ms                 |
+---------------------------+---------------------------+---------------------------+
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7ff7ba939bd0>
