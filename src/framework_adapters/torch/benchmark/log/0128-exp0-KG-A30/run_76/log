WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 12:59:15.758090 129339 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_16', no_save_emb=True, max_step=500, batch_size=2400, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.01, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [129339 sampler.py:454] Start PreSampling
WARNING [129339 sampler.py:532] Before construct renumbering_dict
WARNING [129339 sampler.py:555] PreSampling done
W20240128 12:59:18.153028 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 12:59:18.153177 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 12:59:18.153209 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 12:59:18.153237 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 12:59:18.153270 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 12:59:18.153290 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 12:59:18.153313 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 12:59:18.153347 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 12:59:18.153376 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 12:59:18.153404 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 12:59:18.153431 129339 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 12:59:18.153460 129339 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 12:59:18.153481 129339 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 12:59:18.153584 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 12:59:18.153613 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 12:59:18.153635 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 12:59:18.153678 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 12:59:18.153705 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 12:59:18.153728 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 12:59:18.153753 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 12:59:18.153777 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 12:59:18.153802 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 12:59:18.153824 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 12:59:18.153849 129339 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 12:59:18.153868 129339 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 12:59:18.153887 129339 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 12:59:18.153935 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 12:59:18.153959 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 12:59:18.153985 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 12:59:18.154007 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 12:59:18.154027 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 12:59:18.154053 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 12:59:18.154081 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 12:59:18.154103 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 12:59:18.154129 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 12:59:18.154156 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 12:59:18.154177 129339 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 12:59:18.154196 129339 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 12:59:18.154217 129339 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 12:59:18.154259 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 12:59:18.154286 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 12:59:18.154307 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 12:59:18.154333 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 12:59:18.154358 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 12:59:18.154379 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 12:59:18.154400 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 12:59:18.154420 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 12:59:18.154443 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 12:59:18.154474 129339 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 12:59:18.154498 129339 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 12:59:18.154516 129339 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 12:59:18.154536 129339 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 37
Rank1: cached key size 37
Rank2: cached key size 37
Rank3: cached key size 37
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([ 307,  575,  654,  ..., 1120, 5579, 6467]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.578 seconds
[Rank1] pid = 129549
[Rank2] pid = 129614
INFO [129339 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [129549 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [129678 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [129614 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [129678 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [129614 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [129339 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [129549 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
I20240128 12:59:21.509025 129615 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 12:59:21.509125 129680 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 12:59:21.525521 129679 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 12:59:21.527591 129550 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.449, sample: 0.243, forward: 1.102, backward: 1.989, update: 0.750
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.430, sample: 0.255, forward: 1.140, backward: 2.011, update: 0.723
[Rank3] pid = 129678
train_sampler.Prefill()
-------Step 0-------
tensor([ 8905,  3228,  9147,  6703,  7942,  4205, 10042,  3946, 12472, 11362]) tensor([  654,  7884,  9251,  3113,  7255,  8305, 13193,  8753,  7107,  7346])
-------Step 1-------
tensor([ 8905,  3228,  9147,  6703,  7942,  4205, 10042,  3946, 12472, 11362]) tensor([ 1605,   238,  4033,  3838, 13085,    31, 13531,  4759,  4952,  7213])
-------Step 2-------
tensor([ 2469, 14419,  8503,    14,  4808,  5781, 10484,  6326,  3100,   902]) tensor([14179,  4651, 10381, 10724,  2962,  9482,  5694,   105, 10672, 13254])
-------Step 3-------
tensor([ 2469, 14419,  8503,    14,  4808,  5781, 10484,  6326,  3100,   902]) tensor([ 8411, 13664,  5825,  6778,  3609,  5924,    27,  6773,  5983, 12796])
-------Step 4-------
tensor([10894,  9457, 13688,  9761,  4092,  5090,   449,  5705,  4006, 13005]) tensor([ 6647, 12782, 14564,   489, 10427, 10068,  1170,  9388,  7047,  7903])
-------Step 5-------
tensor([10894,  9457, 13688,  9761,  4092,  5090,   449,  5705,  4006, 13005]) tensor([ 3529, 11596,  3306,  9279,  6119, 10585,  3105,   269, 14732,   845])
-------Step 6-------
tensor([ 4453,  8502, 13224, 10250,    25, 12710,  7400,  9602,  4579, 10438]) tensor([14302, 11132, 13222,   106,  9957,  9204,  6300,  1030,  6466,  9224])
-------Step 7-------
tensor([ 4453,  8502, 13224, 10250,    25, 12710,  7400,  9602,  4579, 10438]) tensor([ 5026,  6085,  9226, 12861,  4581,  8495,  7235, 12600, 13534,  7032])
-------Step 8-------
tensor([ 8522, 13213,    17,  5744,  1237,  6431,  2872,  2075,  2015,  6217]) tensor([ 6802, 11598, 12049, 11799,  6658,  8443,  5510,  1058,  1549,  8310])
-------Step 9-------
tensor([ 8522, 13213,    17,  5744,  1237,  6431,  2872,  2075,  2015,  6217]) tensor([ 1213, 12668,    44, 13217,  1609,  3654,  2347,   481, 12564, 13368])
before start barrier
start train
[proc 0] 100 steps, total: 4.432, sample: 0.220, forward: 1.144, backward: 1.984, update: 0.728
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.449, sample: 0.276, forward: 1.122, backward: 1.991, update: 0.823
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 690.600 us                | 18.037 ms                 |
| Forward                   | 5.123 ms                  | 31.363 ms                 |
| Backward                  | 2.041 ms                  | 156.082 ms                |
| Optimize                  | 6.243 ms                  | 32.679 ms                 |
| OneStep                   | 15.809 ms                 | 831.489 ms                |
+---------------------------+---------------------------+---------------------------+
[proc 0] 200 steps, total: 2.003, sample: 0.246, forward: 0.530, backward: 0.200, update: 0.602
[proc 1] 200 steps, total: 2.003, sample: 0.275, forward: 0.523, backward: 0.201, update: 0.609
[proc 3] 200 steps, total: 2.003, sample: 0.266, forward: 0.485, backward: 0.201, update: 0.640
[proc 2] 200 steps, total: 2.003, sample: 0.249, forward: 0.465, backward: 0.200, update: 0.608
[proc 3] 300 steps, total: 2.370, sample: 0.320, forward: 0.538, backward: 0.201, update: 0.664
[proc 1] 300 steps, total: 2.370, sample: 0.284, forward: 0.552, backward: 0.204, update: 0.635
[proc 0] 300 steps, total: 2.370, sample: 0.299, forward: 0.589, backward: 0.202, update: 0.627
[proc 2] 300 steps, total: 2.370, sample: 0.302, forward: 0.497, backward: 0.193, update: 0.650
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 867.965 us                | 18.301 ms                 |
| Forward                   | 5.546 ms                  | 13.255 ms                 |
| Backward                  | 2.126 ms                  | 2.405 ms                  |
| Optimize                  | 6.311 ms                  | 12.778 ms                 |
| OneStep                   | 18.168 ms                 | 44.085 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 3] 400 steps, total: 2.413, sample: 0.286, forward: 0.575, backward: 0.217, update: 0.741
[proc 2] 400 steps, total: 2.413, sample: 0.286, forward: 0.575, backward: 0.214, update: 0.733
[proc 0] 400 steps, total: 2.413, sample: 0.264, forward: 0.628, backward: 0.211, update: 0.703
[proc 1] 400 steps, total: 2.413, sample: 0.296, forward: 0.590, backward: 0.212, update: 0.709
[proc 1] 500 steps, total: 2.468, sample: 0.279, forward: 0.584, backward: 0.210, update: 0.696
[proc 0] 500 steps, total: 2.468, sample: 0.286, forward: 0.629, backward: 0.210, update: 0.677
[proc 3] 500 steps, total: 2.468, sample: 0.316, forward: 0.561, backward: 0.215, update: 0.717
[proc 2] 500 steps, total: 2.468, sample: 0.308, forward: 0.570, backward: 0.214, update: 0.709
Successfully xmh. training takes 13.686224937438965 seconds
before call kg_cache_controller.StopThreads()
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 905.647 us                | 17.809 ms                 |
| Forward                   | 5.916 ms                  | 11.245 ms                 |
| Backward                  | 2.165 ms                  | 2.441 ms                  |
| Optimize                  | 6.424 ms                  | 11.882 ms                 |
| OneStep                   | 18.910 ms                 | 41.808 ms                 |
+---------------------------+---------------------------+---------------------------+
KGCacheControllerWrapperDummy.StopThreads
