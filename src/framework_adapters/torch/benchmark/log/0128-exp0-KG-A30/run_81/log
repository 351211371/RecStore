WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 13:12:07.436704 148048 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_21', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [148048 sampler.py:454] Start PreSampling
WARNING [148048 sampler.py:532] Before construct renumbering_dict
WARNING [148048 sampler.py:555] PreSampling done
W20240128 13:12:10.488327 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 13:12:10.488479 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 13:12:10.488504 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 13:12:10.488538 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 13:12:10.488559 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 13:12:10.488585 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 13:12:10.488605 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 13:12:10.488631 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 13:12:10.488651 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 13:12:10.488672 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 13:12:10.488695 148048 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 13:12:10.488716 148048 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 13:12:10.488734 148048 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 13:12:10.488830 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 13:12:10.488857 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 13:12:10.488875 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 13:12:10.488909 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 13:12:10.488930 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 13:12:10.488950 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 13:12:10.488968 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 13:12:10.488988 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 13:12:10.489012 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 13:12:10.489034 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 13:12:10.489053 148048 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 13:12:10.489068 148048 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 13:12:10.489082 148048 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 13:12:10.489125 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 13:12:10.489149 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 13:12:10.489166 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 13:12:10.489197 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 13:12:10.489217 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 13:12:10.489241 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 13:12:10.489267 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 13:12:10.489285 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 13:12:10.489307 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 13:12:10.489327 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 13:12:10.489348 148048 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 13:12:10.489363 148048 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 13:12:10.489378 148048 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 13:12:10.489415 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 13:12:10.489434 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 13:12:10.489457 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 13:12:10.489476 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 13:12:10.489499 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 13:12:10.489524 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 13:12:10.489544 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 13:12:10.489563 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 13:12:10.489580 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 13:12:10.489598 148048 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 13:12:10.489616 148048 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 13:12:10.489632 148048 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 13:12:10.489648 148048 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 186
Rank1: cached key size 186
Rank2: cached key size 186
Rank3: cached key size 186
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([ 827, 1012, 1077,  ..., 1677, 6222, 8577]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.238 seconds
[Rank1] pid = 148369
[Rank2] pid = 148434
INFO [148048 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [148369 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [148048 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [148369 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [148434 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [148498 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [148434 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [148498 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
I20240128 13:12:14.021831 148435 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 13:12:14.022184 148370 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:12:14.028908 148500 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:12:14.030145 148499 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.206, sample: 0.192, forward: 1.149, backward: 2.012, update: 0.419
[Rank3] pid = 148498
train_sampler.Prefill()
-------Step 0-------
tensor([ 7148,  3811, 10123,  7391,  9284,  3659,   702,  4719, 11590,  9701]) tensor([ 1077,  7671, 10195,  4001,  7925,  6762, 12341,  7034,  9303,  8226])
-------Step 1-------
tensor([ 7148,  3811, 10123,  7391,  9284,  3659,   702,  4719, 11590,  9701]) tensor([  411, 10894, 14203,  1039, 10113, 12447,  1651,  9959,  7797,  8528])
-------Step 2-------
tensor([ 4928, 13722,  5053,  5155,  6007,  9415, 12290, 10177, 12066,    17]) tensor([11058,  3119,  1745,  6046,  5735,   694,  7864,  3466,  6003,  4333])
-------Step 3-------
tensor([ 4928, 13722,  5053,  5155,  6007,  9415, 12290, 10177, 12066,    17]) tensor([ 5495, 12091,  7786, 11411,  6089,  1519, 11278, 11762, 11713, 13373])
-------Step 4-------
tensor([ 8399,  2408,  3642,    42, 10752,  8972,  4696,  7771, 10567,  9835]) tensor([10820,  3515,  3380, 12974,  1595,  2270, 12472,  5863, 13369,  5855])
-------Step 5-------
tensor([ 8399,  2408,  3642,    42, 10752,  8972,  4696,  7771, 10567,  9835]) tensor([ 5259, 10797,  5032,  8827,  9642,  7133,  5284,  3424,  8614, 14840])
-------Step 6-------
tensor([10276,  6286,  5707,  6230,  1439,  6635,  7139,  2409, 12491,    45]) tensor([ 7965,  5479,  3469, 10841,  7960,   599,  3443, 12847, 13091,  3642])
-------Step 7-------
tensor([10276,  6286,  5707,  6230,  1439,  6635,  7139,  2409, 12491,    45]) tensor([ 5622,  8110,  9232, 10184,   511,   137, 13513, 10796,  4058,  9344])
-------Step 8-------
tensor([  158, 14595, 12911,  9993,  4852,  5707, 12348,  7167,  3851,  1448]) tensor([13852,  4748, 10882, 11069,  3497,  9857,  6058,   430,  6994, 13417])
-------Step 9-------
tensor([  158, 14595, 12911,  9993,  4852,  5707, 12348,  7167,  3851,  1448]) tensor([ 8708, 11187, 13398,   536, 12604,  9816,  5197,  1723,  7315,  9861])
before start barrier
start train
[proc 0] 100 steps, total: 4.198, sample: 0.189, forward: 1.209, backward: 2.196, update: 0.398
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.206, sample: 0.191, forward: 1.163, backward: 1.874, update: 0.422
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.199, sample: 0.183, forward: 1.107, backward: 1.955, update: 0.471
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 912.947 us                | 8.576 ms                  |
| Forward                   | 4.341 ms                  | 9.491 ms                  |
| Backward                  | 2.321 ms                  | 2.539 ms                  |
| Optimize                  | 3.469 ms                  | 7.703 ms                  |
| OneStep                   | 12.610 ms                 | 32.419 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 3] 200 steps, total: 1.345, sample: 0.180, forward: 0.392, backward: 0.215, update: 0.358
[proc 2] 200 steps, total: 1.345, sample: 0.176, forward: 0.372, backward: 0.222, update: 0.303
[proc 1] 200 steps, total: 1.345, sample: 0.177, forward: 0.407, backward: 0.166, update: 0.345
[proc 0] 200 steps, total: 1.345, sample: 0.175, forward: 0.420, backward: 0.219, update: 0.310
[proc 2] 300 steps, total: 1.398, sample: 0.177, forward: 0.393, backward: 0.224, update: 0.298
[proc 3] 300 steps, total: 1.398, sample: 0.182, forward: 0.431, backward: 0.225, update: 0.356
[proc 0] 300 steps, total: 1.398, sample: 0.170, forward: 0.423, backward: 0.220, update: 0.309
[proc 1] 300 steps, total: 1.398, sample: 0.169, forward: 0.412, backward: 0.171, update: 0.340
[proc 1] 400 steps, total: 1.372, sample: 0.166, forward: 0.404, backward: 0.206, update: 0.333
[proc 0] 400 steps, total: 1.372, sample: 0.170, forward: 0.435, backward: 0.225, update: 0.319
[proc 3] 400 steps, total: 1.373, sample: 0.174, forward: 0.411, backward: 0.224, update: 0.310
[proc 2] 400 steps, total: 1.373, sample: 0.177, forward: 0.381, backward: 0.224, update: 0.292
[proc 1] 500 steps, total: 1.413, sample: 0.168, forward: 0.401, backward: 0.227, update: 0.326
[proc 0] 500 steps, total: 1.413, sample: 0.177, forward: 0.445, backward: 0.221, update: 0.322
Successfully xmh. training takes 9.726842880249023 seconds
before call kg_cache_controller.StopThreads()
[proc 3] 500 steps, total: 1.413, sample: 0.176, forward: 0.392, backward: 0.225, update: 0.303
[proc 2] 500 steps, total: 1.413, sample: 0.195, forward: 0.382, backward: 0.231, update: 0.297
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 949.782 us                | 8.063 ms                  |
| Forward                   | 4.362 ms                  | 7.309 ms                  |
| Backward                  | 2.327 ms                  | 2.844 ms                  |
| Optimize                  | 3.307 ms                  | 5.031 ms                  |
| OneStep                   | 12.745 ms                 | 26.144 ms                 |
+---------------------------+---------------------------+---------------------------+
