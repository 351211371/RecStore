WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 16:46:21.101910 515632 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='ComplEx', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/ComplEx_FB15k_40', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [515632 sampler.py:454] Start PreSampling
WARNING [515632 sampler.py:532] Before construct renumbering_dict
WARNING [515632 sampler.py:555] PreSampling done
W20240128 16:46:24.311573 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 16:46:24.311722 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 16:46:24.311750 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 16:46:24.311780 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 16:46:24.311806 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 16:46:24.311828 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 16:46:24.311852 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 16:46:24.311879 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 16:46:24.311903 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 16:46:24.311928 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 16:46:24.311949 515632 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 16:46:24.311969 515632 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 16:46:24.311990 515632 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 16:46:24.312076 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 16:46:24.312110 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 16:46:24.312129 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 16:46:24.312170 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 16:46:24.312189 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 16:46:24.312211 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 16:46:24.312235 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 16:46:24.312252 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 16:46:24.312270 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 16:46:24.312291 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 16:46:24.312311 515632 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 16:46:24.312326 515632 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 16:46:24.312345 515632 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 16:46:24.312381 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 16:46:24.312404 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 16:46:24.312427 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 16:46:24.312448 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 16:46:24.312465 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 16:46:24.312489 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 16:46:24.312505 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 16:46:24.312531 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 16:46:24.312556 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 16:46:24.312577 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 16:46:24.312597 515632 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 16:46:24.312613 515632 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 16:46:24.312626 515632 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 16:46:24.312661 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 16:46:24.312682 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 16:46:24.312701 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 16:46:24.312719 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 16:46:24.312736 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 16:46:24.312757 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 16:46:24.312778 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 16:46:24.312795 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 16:46:24.312814 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 16:46:24.312836 515632 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 16:46:24.312857 515632 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 16:46:24.312871 515632 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 16:46:24.312886 515632 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 16:46:24.453758 515632 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 16:46:24.453888 515632 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1594, 1802, 1865,  ..., 2327, 6355, 7069]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.383 seconds
[Rank1] pid = 515844
[Rank2] pid = 515908
INFO [515632 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [515632 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [515844 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [515908 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [515844 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [515908 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 16:46:27.941308 515910 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_0 [1495, 400]; dev=0; size=2.281 MB
INFO [515909 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
W20240128 16:46:27.941957 515910 IPCTensor.h:368] NewIPCTensor: input_keys_0 [1000000]0x100014876000 7.629 MB
W20240128 16:46:27.942150 515910 IPCTensor.h:368] NewIPCTensor: input_keys_neg_0 [1000000]0x100015019000 7.629 MB
INFO [515909 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 16:46:27.942232 515910 IPCTensor.h:368] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000157bc000 1.49 GB
W20240128 16:46:27.942319 515910 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x100074d9f000 1.49 GB
W20240128 16:46:27.942394 515910 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 16:46:27.943082 515845 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_1 [1495, 400]; dev=1; size=2.281 MB
W20240128 16:46:27.943363 515933 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_2 [1495, 400]; dev=2; size=2.281 MB
W20240128 16:46:27.947813 515910 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 16:46:27.947983 515845 IPCTensor.h:368] NewIPCTensor: input_keys_1 [1000000]0x1000d4388000 7.629 MB
W20240128 16:46:27.948017 515933 IPCTensor.h:368] NewIPCTensor: input_keys_2 [1000000]0x1000d4b2b000 7.629 MB
W20240128 16:46:27.948208 515845 IPCTensor.h:368] NewIPCTensor: input_keys_neg_1 [1000000]0x1000d52ce000 7.629 MB
W20240128 16:46:27.948247 515933 IPCTensor.h:368] NewIPCTensor: input_keys_neg_2 [1000000]0x1000d5a71000 7.629 MB
W20240128 16:46:27.948319 515845 IPCTensor.h:368] NewIPCTensor: backward_grads_1 [1000000, 400]0x1000d6214000 1.49 GB
W20240128 16:46:27.948349 515933 IPCTensor.h:368] NewIPCTensor: backward_grads_2 [1000000, 400]0x1001357f7000 1.49 GB
W20240128 16:46:27.948406 515845 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x100194dda000 1.49 GB
W20240128 16:46:27.948427 515933 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1001f43bd000 1.49 GB
W20240128 16:46:27.948499 515845 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 16:46:27.948501 515933 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 16:46:27.948439 515931 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_3 [1495, 400]; dev=3; size=2.281 MB
W20240128 16:46:27.961283 515845 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 16:46:27.961306 515933 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 16:46:27.961618 515931 IPCTensor.h:368] NewIPCTensor: input_keys_3 [1000000]0x1002539a8000 7.629 MB
W20240128 16:46:27.961879 515931 IPCTensor.h:368] NewIPCTensor: input_keys_neg_3 [1000000]0x10025414b000 7.629 MB
W20240128 16:46:27.961984 515931 IPCTensor.h:368] NewIPCTensor: backward_grads_3 [1000000, 400]0x1002548ee000 1.49 GB
W20240128 16:46:27.962091 515931 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1002b3ed1000 1.49 GB
W20240128 16:46:27.962169 515931 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240128 16:46:27.977102 515931 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [515909 DistTensor.py:56] The tensor name already exists in the kvstore
[Rank3] pid = 515909
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1495), (1495, 2990), (2990, 4485), (4485, 5980)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [515632 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [515908 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [515844 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 16:46:29.204195 515845 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 16:46:29.204336 515910 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 16:46:29.204399 515933 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 16:46:29.204648 515931 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240128 16:46:29.205543 515910 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.1,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240128 16:46:29.205651 515910 grad_base.h:184] Init GradProcessingBase done
I20240128 16:46:29.209786 515910 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240128 16:46:29.209887 515910 kg_controller.h:78] after init GradAsyncProcessingV2
I20240128 16:46:29.209892 515910 kg_controller.h:84] Construct KGCacheController done
E20240128 16:46:30.575559 515931 recstore.cc:66] init folly done
E20240128 16:46:30.575621 515910 recstore.cc:66] init folly done
E20240128 16:46:30.575644 515933 recstore.cc:66] init folly done
E20240128 16:46:30.575659 515845 recstore.cc:66] init folly done
I20240128 16:46:30.576459 515910 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240128 16:46:31.274334 516538 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
E20240128 16:46:31.274706 516538 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240128 16:46:31.296473 515910 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 16:46:31.322894 515933 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 16:46:31.324008 515845 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 16:46:31.331810 515931 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240128 16:46:33.690173 515910 parallel_pq_v2.h:76] insert failed, size(hashtable)=0
W20240128 16:46:33.701303 516538 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 16:46:33.742017 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=3, pq.top=3
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 914.120 us                | 10.267 ms                 |
| Forward                   | 3.043 ms                  | 745.579 ms                |
| Backward                  | 2.658 ms                  | 166.201 ms                |
| Optimize                  | 833.917 us                | 39.970 ms                 |
| BarrierTimeBeforeRank0    | 23.007 us                 | 196.583 ms                |
| AfterBackward             | 10.078 ms                 | 1.217 s                   |
| BlockToStepN              | 1.376 ms                  | 33.476 ms                 |
| OneStep                   | 21.286 ms                 | 2.368 s                   |
+---------------------------+---------------------------+---------------------------+
E20240128 16:46:34.690021 516538 parallel_pq_v2.h:76] insert failed, size(hashtable)=251
W20240128 16:46:34.710500 516538 grad_async_v2.h:121] Detect new sample comes, old_end5, new_end6
W20240128 16:46:34.747779 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=47, pq.top=47
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.034 ms                  | 2.297 ms                  |
| ProcessBack:UpdateCache   | 1.889 ms                  | 2.091 ms                  |
| ProcessBack:UpsertPq      | 6.235 ms                  | 7.476 ms                  |
| ProcessOneStep            | 10.560 ms                 | 12.175 ms                 |
| BlockToStepN              | 3.567 ms                  | 8.444 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240128 16:46:35.690032 516537 parallel_pq_v2.h:76] insert failed, size(hashtable)=11557
W20240128 16:46:35.711131 516538 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240128 16:46:35.755180 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=88, pq.top=88
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.711, sample: 0.168, forward: 1.070, backward: 0.473, update: 0.118
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.710, sample: 0.163, forward: 1.054, backward: 0.538, update: 0.121
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.702, sample: 0.176, forward: 1.013, backward: 0.459, update: 0.110
train_sampler.Prefill()
-------Step 0-------
tensor([ 7711,  5087, 12190,  7268,  8797,  4381, 10675,  5003, 12613,   152]) tensor([ 1865,  8512, 12279,  1187,  7869,  7369, 14691,  7628,  7624,  1223])
-------Step 1-------
tensor([ 7711,  5087, 12190,  7268,  8797,  4381, 10675,  5003, 12613,   152]) tensor([ 7579, 11197, 13718,  1732, 11185, 10217,  2334, 10587,  7474,  8139])
-------Step 2-------
tensor([ 5664, 12369,  7486,  5382,  5223,  8834, 11913,  9679, 11149,   286]) tensor([9813, 3471, 2389, 6697, 5922, 1297, 7709, 5334, 6652, 6485])
-------Step 3-------
tensor([ 5664, 12369,  7486,  5382,  5223,  8834, 11913,  9679, 11149,   286]) tensor([ 6336, 11844,  7799, 12183,  6780,  2160,  9196, 11437, 11160, 11843])
-------Step 4-------
tensor([ 9273,  2926,  3966,    22,   683,   285,   119, 11182, 10274,  9449]) tensor([10186,  4058,  3810, 13982,  2309,  3170, 11834,  6040, 12509,  6533])
-------Step 5-------
tensor([ 9273,  2926,  3966,    22,   683,   285,   119, 11182, 10274,  9449]) tensor([ 5986, 10374,  6599,  8729, 12124,  7895,  5442,  3971,  8257, 14503])
-------Step 6-------
tensor([10044,  6924,  5966,  6900,  2182,  8089,  9030,  3010, 14726,    51]) tensor([ 7900,  5751,  3925, 10236,  7256,  1392,  4169, 13311, 12953,  3966])
-------Step 7-------
tensor([10044,  6924,  5966,  6900,  2182,  8089,  9030,  3010, 14726,    51]) tensor([ 5980,  7728, 11252,  9906,  1095,   314, 13046, 10100,  5449,   814])
-------Step 8-------
tensor([ 3199, 14910, 12489, 12439,  5697,  5966, 12305,  7219,  4262,  2084]) tensor([14333,   940, 10203, 10389,  4094,   648,  6821,  1048, 10162, 13043])
-------Step 9-------
tensor([ 3199, 14910, 12489, 12439,  5697,  5966, 12305,  7219,  4262,  2084]) tensor([ 9293, 11626, 13312,   882, 12259,  9343,  5914,  2353,  7134,  9243])
before start barrier
start train
[proc 0] 100 steps, total: 4.738, sample: 0.180, forward: 1.018, backward: 0.412, update: 0.117
E20240128 16:46:36.690016 515910 parallel_pq_v2.h:76] insert failed, size(hashtable)=570
W20240128 16:46:36.722057 516538 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240128 16:46:36.767441 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=128, pq.top=128
E20240128 16:46:37.690016 516537 parallel_pq_v2.h:76] insert failed, size(hashtable)=10397
W20240128 16:46:37.727609 516538 grad_async_v2.h:121] Detect new sample comes, old_end5, new_end6
W20240128 16:46:37.781343 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=167, pq.top=167
[proc 2] 200 steps, total: 2.636, sample: 0.181, forward: 0.242, backward: 0.225, update: 0.071
[proc 1] 200 steps, total: 2.636, sample: 0.183, forward: 0.243, backward: 0.267, update: 0.072
[proc 3] 200 steps, total: 2.636, sample: 0.194, forward: 0.271, backward: 0.221, update: 0.067
[proc 0] 200 steps, total: 2.636, sample: 0.208, forward: 0.269, backward: 0.241, update: 0.073
E20240128 16:46:38.690008 516537 parallel_pq_v2.h:76] insert failed, size(hashtable)=9396
W20240128 16:46:38.729367 516538 grad_async_v2.h:121] Detect new sample comes, old_end2, new_end3
W20240128 16:46:38.790676 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=205, pq.top=205
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 947.709 us                | 9.874 ms                  |
| Forward                   | 2.749 ms                  | 4.219 ms                  |
| Backward                  | 2.482 ms                  | 3.269 ms                  |
| Optimize                  | 791.197 us                | 1.512 ms                  |
| BarrierTimeBeforeRank0    | 21.318 us                 | 3.037 ms                  |
| AfterBackward             | 10.993 ms                 | 12.738 ms                 |
| BlockToStepN              | 4.941 ms                  | 10.277 ms                 |
| OneStep                   | 24.089 ms                 | 39.740 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 16:46:39.690013 516537 parallel_pq_v2.h:76] insert failed, size(hashtable)=10021
W20240128 16:46:39.742566 516538 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240128 16:46:39.790328 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=242, pq.top=242
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.996 ms                  | 2.400 ms                  |
| ProcessBack:UpdateCache   | 1.786 ms                  | 2.102 ms                  |
| ProcessBack:UpsertPq      | 6.439 ms                  | 8.304 ms                  |
| ProcessOneStep            | 11.113 ms                 | 12.649 ms                 |
| BlockToStepN              | 5.239 ms                  | 10.458 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 16:46:40.690099 516312 parallel_pq_v2.h:76] insert failed, size(hashtable)=275
W20240128 16:46:40.759223 516538 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
W20240128 16:46:40.812414 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=279, pq.top=279
[proc 1] 300 steps, total: 2.754, sample: 0.165, forward: 0.243, backward: 0.221, update: 0.070
[proc 2] 300 steps, total: 2.754, sample: 0.163, forward: 0.241, backward: 0.217, update: 0.072
[proc 0] 300 steps, total: 2.754, sample: 0.205, forward: 0.271, backward: 0.245, update: 0.076
[proc 3] 300 steps, total: 2.754, sample: 0.182, forward: 0.287, backward: 0.226, update: 0.072
E20240128 16:46:41.690011 516312 parallel_pq_v2.h:76] insert failed, size(hashtable)=1257
W20240128 16:46:41.771723 516538 grad_async_v2.h:121] Detect new sample comes, old_end2, new_end3
W20240128 16:46:41.816526 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=314, pq.top=314
E20240128 16:46:42.690007 516537 parallel_pq_v2.h:76] insert failed, size(hashtable)=5687
W20240128 16:46:42.771330 516538 grad_async_v2.h:121] Detect new sample comes, old_end9, new_end0
W20240128 16:46:42.816422 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=351, pq.top=351
E20240128 16:46:43.690012 516537 parallel_pq_v2.h:76] insert failed, size(hashtable)=10447
W20240128 16:46:43.771997 516538 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240128 16:46:43.819216 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=388, pq.top=388
[proc 2] 400 steps, total: 2.775, sample: 0.164, forward: 0.241, backward: 0.213, update: 0.072
[proc 1] 400 steps, total: 2.775, sample: 0.166, forward: 0.243, backward: 0.221, update: 0.069
[proc 3] 400 steps, total: 2.775, sample: 0.176, forward: 0.278, backward: 0.229, update: 0.068
[proc 0] 400 steps, total: 2.775, sample: 0.226, forward: 0.281, backward: 0.247, update: 0.077
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.093 ms                  | 9.874 ms                  |
| Forward                   | 2.797 ms                  | 3.754 ms                  |
| Backward                  | 2.499 ms                  | 3.087 ms                  |
| Optimize                  | 799.670 us                | 1.467 ms                  |
| BarrierTimeBeforeRank0    | 18.699 us                 | 2.911 ms                  |
| AfterBackward             | 11.342 ms                 | 13.368 ms                 |
| BlockToStepN              | 5.860 ms                  | 12.060 ms                 |
| OneStep                   | 25.741 ms                 | 39.740 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 16:46:44.690019 516312 parallel_pq_v2.h:76] insert failed, size(hashtable)=339
W20240128 16:46:44.772264 516538 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
W20240128 16:46:44.819255 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=420, pq.top=420
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.998 ms                  | 2.294 ms                  |
| ProcessBack:UpdateCache   | 1.787 ms                  | 2.071 ms                  |
| ProcessBack:UpsertPq      | 6.671 ms                  | 8.989 ms                  |
| ProcessOneStep            | 11.395 ms                 | 13.667 ms                 |
| BlockToStepN              | 6.194 ms                  | 13.751 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 16:46:45.690016 516537 parallel_pq_v2.h:76] insert failed, size(hashtable)=9209
W20240128 16:46:45.776225 516538 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240128 16:46:45.820788 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=453, pq.top=453
E20240128 16:46:46.690011 516537 parallel_pq_v2.h:76] insert failed, size(hashtable)=10943
W20240128 16:46:46.780517 516538 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240128 16:46:46.842130 515910 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=488, pq.top=488
[proc 3] 500 steps, total: 2.980, sample: 0.176, forward: 0.279, backward: 0.230, update: 0.066
[proc 1] 500 steps, total: 2.980, sample: 0.166, forward: 0.242, backward: 0.223, update: 0.069
[proc 2] 500 steps, total: 2.980, sample: 0.181, forward: 0.240, backward: 0.223, update: 0.071
[proc 0] 500 steps, total: 2.980, sample: 0.238, forward: 0.292, backward: 0.249, update: 0.082
Successfully xmh. training takes 15.883424997329712 seconds
before call kg_cache_controller.StopThreads()
W20240128 16:46:47.179904 515910 grad_async_v2.h:71] call StopThreads. PID = 515632
W20240128 16:46:47.179935 515910 grad_base.h:212] before processOneStepNegThread_.join();
W20240128 16:46:47.180192 515910 grad_base.h:214] after processOneStepNegThread_.join();
W20240128 16:46:47.180200 515910 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
W20240128 16:46:47.182921 515910 grad_async_v2.h:92] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
