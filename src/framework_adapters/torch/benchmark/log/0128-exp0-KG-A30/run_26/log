WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 11:24:28.746445 10909 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_61', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [10909 sampler.py:454] Start PreSampling
WARNING [10909 sampler.py:532] Before construct renumbering_dict
WARNING [10909 sampler.py:555] PreSampling done
W20240128 11:24:30.957206 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 11:24:30.957326 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 11:24:30.957345 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 11:24:30.957363 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 11:24:30.957384 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 11:24:30.957406 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 11:24:30.957425 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 11:24:30.957443 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 11:24:30.957463 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 11:24:30.957477 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 11:24:30.957511 10909 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 11:24:30.957528 10909 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 11:24:30.957546 10909 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 11:24:30.957626 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 11:24:30.957649 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 11:24:30.957664 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 11:24:30.957695 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 11:24:30.957710 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 11:24:30.957729 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 11:24:30.957748 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 11:24:30.957765 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 11:24:30.957779 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 11:24:30.957796 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 11:24:30.957811 10909 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 11:24:30.957823 10909 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 11:24:30.957835 10909 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 11:24:30.957868 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 11:24:30.957885 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 11:24:30.957903 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 11:24:30.957921 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 11:24:30.957940 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 11:24:30.957954 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 11:24:30.957968 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 11:24:30.957985 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 11:24:30.958003 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 11:24:30.958021 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 11:24:30.958035 10909 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 11:24:30.958047 10909 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 11:24:30.958060 10909 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 11:24:30.958089 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 11:24:30.958112 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 11:24:30.958127 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 11:24:30.958139 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 11:24:30.958153 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 11:24:30.958173 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 11:24:30.958189 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 11:24:30.958204 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 11:24:30.958217 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 11:24:30.958240 10909 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 11:24:30.958254 10909 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 11:24:30.958266 10909 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 11:24:30.958281 10909 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 186
Rank1: cached key size 186
Rank2: cached key size 186
Rank3: cached key size 186
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([ 840, 1061, 1110,  ..., 1571, 5980, 7122]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.379 seconds
[Rank1] pid = 11120
[Rank2] pid = 11185
INFO [10909 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [11120 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [11249 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [11185 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [11249 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [11185 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [10909 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [11120 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
I20240128 11:24:33.781181 11121 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 11:24:33.790307 11251 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 11:24:33.791877 11186 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 11:24:33.796626 11250 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 892.794 us                | 14.287 ms                 |
| Forward                   | 5.046 ms                  | 19.329 ms                 |
| Backward                  | 3.243 ms                  | 532.366 ms                |
| Optimize                  | 5.283 ms                  | 14.722 ms                 |
| OneStep                   | 17.240 ms                 | 1.575 s                   |
+---------------------------+---------------------------+---------------------------+
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 5.087, sample: 0.213, forward: 1.642, backward: 2.162, update: 0.566
[Rank3] pid = 11249
train_sampler.Prefill()
-------Step 0-------
tensor([ 7387,  3865,  9523,  7405,  8122,  3912,   741,  5857, 11629,  9027]) tensor([ 1110,  7559,  9618,   667,  7595,  7011, 10674,  7280,  7792, 10537])
-------Step 1-------
tensor([ 7387,  3865,  9523,  7405,  8122,  3912,   741,  5857, 11629,  9027]) tensor([ 6308, 12157, 11845, 12962,  5522, 11870,  5170,  1624,  1976,  8759])
-------Step 2-------
tensor([ 8897,  2225,  4505,    47,  8327,  9534,  5005, 10420, 10855,  9491]) tensor([11717,  3780,  3461, 14064,  1505,  2058, 14631,  5919, 12117,  6095])
-------Step 3-------
tensor([ 8897,  2225,  4505,    47,  8327,  9534,  5005, 10420, 10855,  9491]) tensor([ 6496, 11917,  6991, 13982,  2208, 10067,  1706, 10793,  6747,    63])
-------Step 4-------
tensor([  152, 14533, 12615,  8444,  4782,  6138, 13491,  5142,  2882,  1416]) tensor([13185,  4998,  9763, 11969,  3286,  9894,  6407,   523,  9378, 12825])
-------Step 5-------
tensor([  152, 14533, 12615,  8444,  4782,  6138, 13491,  5142,  2882,  1416]) tensor([ 6797,  6169, 11112, 11017,  9007, 10965,  2561, 14167,  8396,  6084])
-------Step 6-------
tensor([11557,  4118,   380,   137, 12194, 10617, 14561, 12615,  8118,  5991]) tensor([ 2712,  7653,  6097,  8674, 12466, 12593,  1224,  2223, 11149, 14315])
-------Step 7-------
tensor([11557,  4118,   380,   137, 12194, 10617, 14561, 12615,  8118,  5991]) tensor([ 4425, 13610,  9176,  6970,  6707,   500,  6295,  6757, 11909, 13829])
-------Step 8-------
tensor([ 9528,  8983, 12210,  9810,  4880,  6168,  1023,  4944,  3642, 10749]) tensor([  380, 10170, 14470,  1015, 10923, 10572,  1595,  9204,  7845,  7744])
-------Step 9-------
tensor([ 9528,  8983, 12210,  9810,  4880,  6168,  1023,  4944,  3642, 10749]) tensor([ 9820, 11060,   996,  3444,  1805, 11777,  8477,  2555,  1976, 13728])
before start barrier
start train
[proc 0] 100 steps, total: 5.071, sample: 0.204, forward: 1.744, backward: 2.391, update: 0.537
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 5.078, sample: 0.217, forward: 1.653, backward: 2.127, update: 0.536
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 5.076, sample: 0.208, forward: 1.639, backward: 2.051, update: 0.546
[proc 1] 200 steps, total: 1.537, sample: 0.200, forward: 0.396, backward: 0.313, update: 0.435
[proc 3] 200 steps, total: 1.537, sample: 0.207, forward: 0.397, backward: 0.310, update: 0.420
[proc 2] 200 steps, total: 1.537, sample: 0.211, forward: 0.385, backward: 0.316, update: 0.419
[proc 0] 200 steps, total: 1.537, sample: 0.199, forward: 0.432, backward: 0.309, update: 0.417
[proc 1] 300 steps, total: 2.016, sample: 0.211, forward: 0.522, backward: 0.332, update: 0.565
[proc 2] 300 steps, total: 2.015, sample: 0.222, forward: 0.493, backward: 0.327, update: 0.538
[proc 3] 300 steps, total: 2.016, sample: 0.241, forward: 0.493, backward: 0.328, update: 0.548
[proc 0] 300 steps, total: 2.016, sample: 0.210, forward: 0.583, backward: 0.327, update: 0.557
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 911.440 us                | 10.436 ms                 |
| Forward                   | 5.526 ms                  | 9.332 ms                  |
| Backward                  | 3.339 ms                  | 3.682 ms                  |
| Optimize                  | 5.271 ms                  | 12.122 ms                 |
| OneStep                   | 17.363 ms                 | 35.252 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 2.092, sample: 0.237, forward: 0.507, backward: 0.325, update: 0.570
[proc 0] 400 steps, total: 2.091, sample: 0.203, forward: 0.561, backward: 0.323, update: 0.564
[proc 3] 400 steps, total: 2.092, sample: 0.233, forward: 0.507, backward: 0.329, update: 0.554
[proc 2] 400 steps, total: 2.092, sample: 0.229, forward: 0.512, backward: 0.325, update: 0.555
[proc 2] 500 steps, total: 2.294, sample: 0.274, forward: 0.566, backward: 0.336, update: 0.617
[proc 0] 500 steps, total: 2.295, sample: 0.222, forward: 0.610, backward: 0.329, update: 0.631
[proc 1] 500 steps, total: 2.295, sample: 0.240, forward: 0.555, backward: 0.327, update: 0.625
Successfully xmh. training takes 13.010374546051025 seconds
before call kg_cache_controller.StopThreads()
[proc 3] 500 steps, total: 2.295, sample: 0.233, forward: 0.568, backward: 0.333, update: 0.626
KGCacheControllerWrapperDummy.StopThreads
