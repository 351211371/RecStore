WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 14:02:57.068045 236529 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_51', no_save_emb=True, max_step=500, batch_size=1800, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [236529 sampler.py:454] Start PreSampling
WARNING [236529 sampler.py:532] Before construct renumbering_dict
WARNING [236529 sampler.py:555] PreSampling done
W20240128 14:02:59.303416 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 14:02:59.303565 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 14:02:59.303587 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 14:02:59.303606 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 14:02:59.303623 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 14:02:59.303647 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 14:02:59.303664 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 14:02:59.303686 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 14:02:59.303709 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 14:02:59.303732 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 14:02:59.303766 236529 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 14:02:59.303788 236529 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 14:02:59.303804 236529 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 14:02:59.303895 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 14:02:59.303923 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 14:02:59.303946 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 14:02:59.303988 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 14:02:59.304008 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 14:02:59.304029 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 14:02:59.304046 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 14:02:59.304067 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 14:02:59.304088 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 14:02:59.304111 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 14:02:59.304129 236529 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 14:02:59.304144 236529 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 14:02:59.304159 236529 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 14:02:59.304200 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 14:02:59.304220 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 14:02:59.304241 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 14:02:59.304260 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 14:02:59.304279 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 14:02:59.304301 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 14:02:59.304318 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 14:02:59.304337 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 14:02:59.304353 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 14:02:59.304378 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 14:02:59.304397 236529 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 14:02:59.304411 236529 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 14:02:59.304426 236529 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 14:02:59.304461 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 14:02:59.304481 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 14:02:59.304499 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 14:02:59.304520 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 14:02:59.304543 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 14:02:59.304561 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 14:02:59.304584 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 14:02:59.304613 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 14:02:59.304634 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 14:02:59.304652 236529 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 14:02:59.304672 236529 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 14:02:59.304687 236529 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 14:02:59.304700 236529 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1600, 1822, 1884,  ..., 2385, 6638, 7548]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.423 seconds
[Rank1] pid = 236846
[Rank2] pid = 236911
INFO [236529 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [236846 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [236911 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [236975 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [236911 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [236975 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [236529 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [236846 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
I20240128 14:03:02.670802 236912 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 14:03:02.687901 236847 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 14:03:02.691531 236977 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 14:03:02.691789 236976 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
[Rank3] pid = 236975
train_sampler.Prefill()
-------Step 0-------
tensor([ 8336,   337,  9998,  7648,  8252,  4767,  1171,  4931, 12535,    51]) tensor([ 1884,  8511, 10077,  1480,  8278,  7968, 13069,  8225,  8200,  1237])
-------Step 1-------
tensor([ 8336,   337,  9998,  7648,  8252,  4767,  1171,  4931, 12535,    51]) tensor([10102, 11159,  1697,  3690,  2544,   620,  6728,  3162,  2708, 13681])
-------Step 2-------
tensor([10058,  7349,  5995,  7405,  2097,  6586,  7783,  3547, 13227,   156]) tensor([ 8315,  5603,  3645, 10965,  7590,  1394,  4518, 12173, 12604,  3820])
-------Step 3-------
tensor([10058,  7349,  5995,  7405,  2097,  6586,  7783,  3547, 13227,   156]) tensor([ 9310,  6031,  4738,   220, 14624,  9957, 13733,   336, 14396,  6280])
-------Step 4-------
tensor([11571,   722,  7134,   132, 11244, 12134, 14507, 10654,  9132,  6839]) tensor([ 3407, 10766,  8593, 11482,  9057, 12277,  1954,  2776, 12718,  1435])
-------Step 5-------
tensor([11571,   722,  7134,   132, 11244, 12134, 14507, 10654,  9132,  6839]) tensor([12135,  8517, 11203,  1306,  2116,  9800,  6576, 13151, 11101, 14262])
-------Step 6-------
tensor([   44,    73,  3741, 10593, 14731,   129,   325,    31,  3246,   350]) tensor([ 6353, 11867,  7803, 11254,  7284,  2196,   240, 14593, 11875, 12559])
-------Step 7-------
tensor([   44,    73,  3741, 10593, 14731,   129,   325,    31,  3246,   350]) tensor([11218, 13246,  7904, 12058,   683, 11449,   691, 13901, 14668,  9931])
-------Step 8-------
tensor([ 5648,   681, 13183, 10877,  3951, 11459,  8297, 10802,  5685,  7349]) tensor([ 9976, 11967, 14032,   809, 12323,  9879,  6346,  2434,  6923,  9743])
-------Step 9-------
tensor([ 5648,   681, 13183, 10877,  3951, 11459,  8297, 10802,  5685,  7349]) tensor([ 8602, 13240,  6633,  7550,  4444,  6617, 13190,  7371,  7017, 13271])
before start barrier
start train
[proc 0] 100 steps, total: 4.865, sample: 0.256, forward: 1.540, backward: 2.056, update: 0.647
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.869, sample: 0.249, forward: 1.437, backward: 1.948, update: 0.639
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.887, sample: 0.242, forward: 1.441, backward: 2.164, update: 0.586
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.866, sample: 0.246, forward: 1.418, backward: 2.033, update: 0.836
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 920.676 us                | 17.213 ms                 |
| Forward                   | 5.851 ms                  | 24.340 ms                 |
| Backward                  | 2.122 ms                  | 270.735 ms                |
| Optimize                  | 5.662 ms                  | 11.798 ms                 |
| OneStep                   | 16.387 ms                 | 1.381 s                   |
+---------------------------+---------------------------+---------------------------+
[proc 1] 200 steps, total: 1.881, sample: 0.258, forward: 0.522, backward: 0.203, update: 0.533
[proc 2] 200 steps, total: 1.881, sample: 0.258, forward: 0.510, backward: 0.197, update: 0.482
[proc 0] 200 steps, total: 1.881, sample: 0.253, forward: 0.553, backward: 0.202, update: 0.544
[proc 3] 200 steps, total: 1.881, sample: 0.235, forward: 0.440, backward: 0.205, update: 0.658
[proc 3] 300 steps, total: 2.477, sample: 0.294, forward: 0.578, backward: 0.228, update: 0.819
[proc 0] 300 steps, total: 2.477, sample: 0.270, forward: 0.674, backward: 0.216, update: 0.635
[proc 1] 300 steps, total: 2.477, sample: 0.286, forward: 0.629, backward: 0.219, update: 0.647
[proc 2] 300 steps, total: 2.477, sample: 0.288, forward: 0.633, backward: 0.177, update: 0.611
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 964.657 us                | 16.256 ms                 |
| Forward                   | 6.003 ms                  | 15.818 ms                 |
| Backward                  | 2.182 ms                  | 2.494 ms                  |
| Optimize                  | 5.766 ms                  | 10.615 ms                 |
| OneStep                   | 18.645 ms                 | 42.072 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 3] 400 steps, total: 2.512, sample: 0.278, forward: 0.584, backward: 0.234, update: 0.806
[proc 1] 400 steps, total: 2.512, sample: 0.295, forward: 0.628, backward: 0.219, update: 0.646
[proc 0] 400 steps, total: 2.512, sample: 0.287, forward: 0.666, backward: 0.211, update: 0.622
[proc 2] 400 steps, total: 2.512, sample: 0.294, forward: 0.625, backward: 0.213, update: 0.608
[proc 3] 500 steps, total: 2.079, sample: 0.229, forward: 0.479, backward: 0.215, update: 0.699
[proc 0] 500 steps, total: 2.079, sample: 0.243, forward: 0.567, backward: 0.207, update: 0.558
Successfully xmh. training takes 13.81507420539856 seconds
before call kg_cache_controller.StopThreads()
[proc 2] 500 steps, total: 2.079, sample: 0.282, forward: 0.531, backward: 0.208, update: 0.510
[proc 1] 500 steps, total: 2.080, sample: 0.249, forward: 0.541, backward: 0.214, update: 0.555
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 987.509 us                | 16.072 ms                 |
| Forward                   | 6.045 ms                  | 10.264 ms                 |
| Backward                  | 2.192 ms                  | 2.494 ms                  |
| Optimize                  | 5.842 ms                  | 9.892 ms                  |
| OneStep                   | 19.112 ms                 | 40.255 ms                 |
+---------------------------+---------------------------+---------------------------+
KGCacheControllerWrapperDummy.StopThreads
