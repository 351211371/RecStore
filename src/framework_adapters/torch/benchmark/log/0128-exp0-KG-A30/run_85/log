WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 13:17:02.066691 158302 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_25', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [158302 sampler.py:454] Start PreSampling
WARNING [158302 sampler.py:532] Before construct renumbering_dict
WARNING [158302 sampler.py:555] PreSampling done
W20240128 13:17:04.512828 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 13:17:04.512964 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 13:17:04.512991 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 13:17:04.513012 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 13:17:04.513033 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 13:17:04.513054 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 13:17:04.513072 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 13:17:04.513093 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 13:17:04.513113 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 13:17:04.513135 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 13:17:04.513162 158302 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 13:17:04.513182 158302 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 13:17:04.513201 158302 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 13:17:04.513288 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 13:17:04.513311 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 13:17:04.513334 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 13:17:04.513367 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 13:17:04.513386 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 13:17:04.513406 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 13:17:04.513430 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 13:17:04.513450 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 13:17:04.513469 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 13:17:04.513492 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 13:17:04.513509 158302 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 13:17:04.513525 158302 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 13:17:04.513540 158302 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 13:17:04.513579 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 13:17:04.513603 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 13:17:04.513621 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 13:17:04.513643 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 13:17:04.513659 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 13:17:04.513677 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 13:17:04.513701 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 13:17:04.513720 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 13:17:04.513736 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 13:17:04.513756 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 13:17:04.513772 158302 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 13:17:04.513787 158302 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 13:17:04.513803 158302 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 13:17:04.513841 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 13:17:04.513870 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 13:17:04.513886 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 13:17:04.513907 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 13:17:04.513926 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 13:17:04.513943 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 13:17:04.513963 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 13:17:04.513984 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 13:17:04.514003 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 13:17:04.514024 158302 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 13:17:04.514045 158302 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 13:17:04.514060 158302 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 13:17:04.514075 158302 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240128 13:17:04.654631 158302 IPCTensor.h:368] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240128 13:17:04.654754 158302 IPCTensor.h:368] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 186
Rank1: cached key size 186
Rank2: cached key size 186
Rank3: cached key size 186
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([ 835, 1015, 1073,  ..., 1701, 6399, 6886]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.622 seconds
[Rank1] pid = 158624
[Rank2] pid = 158688
INFO [158302 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [158624 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [158753 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [158753 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [158302 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 13:17:08.072918 158754 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240128 13:17:08.073326 158754 IPCTensor.h:368] NewIPCTensor: input_keys_0 [1000000]0x100014876000 7.629 MB
W20240128 13:17:08.073413 158754 IPCTensor.h:368] NewIPCTensor: input_keys_neg_0 [1000000]0x100015019000 7.629 MB
W20240128 13:17:08.073457 158754 IPCTensor.h:368] NewIPCTensor: backward_grads_0 [1000000, 400]0x1000157bc000 1.49 GB
W20240128 13:17:08.073479 158754 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x100074d9f000 1.49 GB
W20240128 13:17:08.073501 158754 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 13:17:08.074381 158755 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_3 [747, 400]; dev=3; size=1.14 MB
W20240128 13:17:08.075393 158754 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240128 13:17:08.075531 158755 IPCTensor.h:368] NewIPCTensor: input_keys_3 [1000000]0x1000d4386000 7.629 MB
W20240128 13:17:08.075639 158755 IPCTensor.h:368] NewIPCTensor: input_keys_neg_3 [1000000]0x1000d4b29000 7.629 MB
W20240128 13:17:08.075690 158755 IPCTensor.h:368] NewIPCTensor: backward_grads_3 [1000000, 400]0x1000d52cc000 1.49 GB
W20240128 13:17:08.075721 158755 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x1001348af000 1.49 GB
W20240128 13:17:08.075755 158755 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
INFO [158688 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [158688 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 13:17:08.078958 158755 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
INFO [158624 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240128 13:17:08.082091 158690 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_2 [747, 400]; dev=2; size=1.14 MB
W20240128 13:17:08.082576 158625 IPCTensor.h:408] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240128 13:17:08.083012 158625 IPCTensor.h:368] NewIPCTensor: input_keys_1 [1000000]0x100193e9a000 7.629 MB
W20240128 13:17:08.083118 158625 IPCTensor.h:368] NewIPCTensor: input_keys_neg_1 [1000000]0x10019463f000 7.629 MB
W20240128 13:17:08.083168 158625 IPCTensor.h:368] NewIPCTensor: backward_grads_1 [1000000, 400]0x100194de2000 1.49 GB
W20240128 13:17:08.083197 158625 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1001f43c5000 1.49 GB
W20240128 13:17:08.083233 158625 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 13:17:08.083333 158690 IPCTensor.h:368] NewIPCTensor: input_keys_2 [1000000]0x1002539a8000 7.629 MB
W20240128 13:17:08.083596 158690 IPCTensor.h:368] NewIPCTensor: input_keys_neg_2 [1000000]0x10025414b000 7.629 MB
W20240128 13:17:08.083706 158690 IPCTensor.h:368] NewIPCTensor: backward_grads_2 [1000000, 400]0x1002548ee000 1.49 GB
W20240128 13:17:08.083798 158690 IPCTensor.h:368] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1002b3ed1000 1.49 GB
W20240128 13:17:08.083896 158690 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240128 13:17:08.090850 158625 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240128 13:17:08.090977 158690 IPCTensor.h:408] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [158688 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [158753 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [158624 DistTensor.py:56] The tensor name already exists in the kvstore
[Rank3] pid = 158753
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494), (1494, 2241), (2241, 2988)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [158302 DistTensor.py:56] The tensor name already exists in the kvstore
I20240128 13:17:09.275455 158754 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240128 13:17:09.275584 158690 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 13:17:09.275638 158755 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240128 13:17:09.275704 158625 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240128 13:17:09.276914 158754 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240128 13:17:09.277045 158754 grad_base.h:184] Init GradProcessingBase done
I20240128 13:17:09.281360 158754 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240128 13:17:09.281462 158754 kg_controller.h:78] after init GradAsyncProcessingV2
I20240128 13:17:09.281468 158754 kg_controller.h:84] Construct KGCacheController done
I20240128 13:17:09.634411 158754 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240128 13:17:10.356765 159275 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240128 13:17:10.357112 159275 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240128 13:17:10.382165 158690 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 13:17:10.382263 158754 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:17:10.395692 158755 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 13:17:10.419503 158625 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240128 13:17:12.789973 158754 parallel_pq_v2.h:76] insert failed, size(hashtable)=4
W20240128 13:17:12.802908 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=1, pq.top=0
W20240128 13:17:12.808473 159275 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
E20240128 13:17:13.789007 159275 parallel_pq_v2.h:76] insert failed, size(hashtable)=836
W20240128 13:17:13.813880 159275 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end0
W20240128 13:17:13.868780 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=30, pq.top=30
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.067 ms                  | 15.441 ms                 |
| Forward                   | 2.999 ms                  | 1.203 s                   |
| Backward                  | 2.307 ms                  | 196.684 ms                |
| Optimize                  | 1.284 ms                  | 48.870 ms                 |
| BarrierTimeBeforeRank0    | 27.967 us                 | 1.561 ms                  |
| AfterBackward             | 15.683 ms                 | 933.006 ms                |
| BlockToStepN              | 1.552 ms                  | 40.678 ms                 |
| OneStep                   | 30.585 ms                 | 2.387 s                   |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.227 ms                  | 115.254 ms                |
| ProcessBack:UpdateCache   | 1.944 ms                  | 206.654 ms                |
| ProcessBack:UpsertPq      | 11.030 ms                 | 17.976 ms                 |
| ProcessOneStep            | 16.329 ms                 | 127.822 ms                |
| BlockToStepN              | 2.334 ms                  | 40.628 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:17:14.789074 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=6431
W20240128 13:17:14.825747 159275 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end7
W20240128 13:17:14.882006 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=58, pq.top=58
E20240128 13:17:15.789013 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=6391
W20240128 13:17:15.825505 159275 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
W20240128 13:17:15.881047 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=84, pq.top=84
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 6.094, sample: 0.217, forward: 0.925, backward: 0.446, update: 0.161
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 6.056, sample: 0.232, forward: 1.337, backward: 0.458, update: 0.162
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 6.080, sample: 0.201, forward: 1.395, backward: 0.465, update: 0.171
train_sampler.Prefill()
-------Step 0-------
tensor([ 6864,  3909,  8833,  7231,  9085,  3575,   736,  5249, 13438, 11457]) tensor([ 1073,  8947,  8902,   685,  8148,  6490, 12213,  6775,  7523,  7659])
-------Step 1-------
tensor([ 6864,  3909,  8833,  7231,  9085,  3575,   736,  5249, 13438, 11457]) tensor([ 6695, 12261, 12781, 14716,  6529,  8803,  5527,  1646,  1935,  8337])
-------Step 2-------
tensor([ 8825,  2344,  3401,   170,  8922,  8269,  4408, 11589,  9701,  7854]) tensor([ 9904,  3353,  3220, 13230,  1688,  1987, 11729,  6000, 13199,  5630])
-------Step 3-------
tensor([ 8825,  2344,  3401,   170,  8922,  8269,  4408, 11589,  9701,  7854]) tensor([ 4754, 10884,  6087, 12039,  2502,  6653,  1829, 12963,  6011,    15])
-------Step 4-------
tensor([  158, 14528, 10575,  9870,  5624,  5375, 11791,  8002,  4346,  1380]) tensor([13579,  4679, 10823, 10131,  3398,  9402,  6205,   557, 10457, 12373])
-------Step 5-------
tensor([  158, 14528, 10575,  9870,  5624,  5375, 11791,  8002,  4346,  1380]) tensor([ 6714,  6726,  8149, 14823,  8289, 11334,  1834, 12790,  7133,  5964])
-------Step 6-------
tensor([12827,  4853,   387,    85, 10698, 10972, 14871, 10575,  7561,  7173]) tensor([ 2734,  9908,  7836, 13269,  9327, 13863,  1242,  1995, 11515, 13646])
-------Step 7-------
tensor([12827,  4853,   387,    85, 10698, 10972, 14871, 10575,  7561,  7173]) tensor([ 4377, 14713,  9131,  6756,  5968,   465,  4236,  7037, 10080, 12303])
-------Step 8-------
tensor([10619,  9997, 12716,  9768,  4906,  7382,  1001,  6374,  4271,  9835]) tensor([  387, 12845, 13913,  1007, 10037, 10242,  1854,  9161,  8983,  8456])
-------Step 9-------
tensor([10619,  9997, 12716,  9768,  4906,  7382,  1001,  6374,  4271,  9835]) tensor([ 9744, 10802,   978,  3050,  1798, 11559,  7648,  2501,  1935, 14502])
before start barrier
start train
[proc 0] 100 steps, total: 6.093, sample: 0.245, forward: 1.496, backward: 0.425, update: 0.177
E20240128 13:17:16.789033 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=3436
W20240128 13:17:16.847863 159275 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 13:17:16.881067 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=110, pq.top=110
E20240128 13:17:17.789012 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=6100
W20240128 13:17:17.853358 159275 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240128 13:17:17.898730 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=135, pq.top=135
E20240128 13:17:18.789019 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=4475
W20240128 13:17:18.865337 159275 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
W20240128 13:17:18.917701 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=163, pq.top=163
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.043 ms                  | 14.836 ms                 |
| Forward                   | 2.876 ms                  | 6.287 ms                  |
| Backward                  | 2.224 ms                  | 4.456 ms                  |
| Optimize                  | 1.149 ms                  | 3.831 ms                  |
| BarrierTimeBeforeRank0    | 39.887 us                 | 5.535 ms                  |
| AfterBackward             | 14.570 ms                 | 70.264 ms                 |
| BlockToStepN              | 12.781 ms                 | 24.423 ms                 |
| OneStep                   | 37.199 ms                 | 79.290 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.149 ms                  | 2.433 ms                  |
| ProcessBack:UpdateCache   | 1.722 ms                  | 2.910 ms                  |
| ProcessBack:UpsertPq      | 10.187 ms                 | 16.084 ms                 |
| ProcessOneStep            | 14.669 ms                 | 70.238 ms                 |
| BlockToStepN              | 12.824 ms                 | 27.635 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:17:19.789014 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=6085
W20240128 13:17:19.865942 159275 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
W20240128 13:17:19.922734 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=189, pq.top=189
[proc 3] 200 steps, total: 3.861, sample: 0.258, forward: 0.291, backward: 0.216, update: 0.112
[proc 2] 200 steps, total: 3.861, sample: 0.260, forward: 0.286, backward: 0.200, update: 0.104
[proc 0] 200 steps, total: 3.860, sample: 0.251, forward: 0.278, backward: 0.221, update: 0.108
[proc 1] 200 steps, total: 3.861, sample: 0.265, forward: 0.298, backward: 0.226, update: 0.105
E20240128 13:17:20.789023 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=3895
W20240128 13:17:20.885327 159275 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
W20240128 13:17:20.922329 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=216, pq.top=216
E20240128 13:17:21.789011 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=4576
W20240128 13:17:21.890241 159275 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
W20240128 13:17:21.942873 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=242, pq.top=242
E20240128 13:17:22.789017 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=3895
W20240128 13:17:22.891911 159275 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240128 13:17:22.961978 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=265, pq.top=265
E20240128 13:17:23.789440 159275 parallel_pq_v2.h:76] insert failed, size(hashtable)=47
W20240128 13:17:23.920022 159275 grad_async_v2.h:120] Detect new sample comes, old_end6, new_end7
W20240128 13:17:23.961109 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=287, pq.top=287
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.162 ms                  | 15.372 ms                 |
| Forward                   | 2.985 ms                  | 5.906 ms                  |
| Backward                  | 2.266 ms                  | 4.456 ms                  |
| Optimize                  | 1.132 ms                  | 3.783 ms                  |
| BarrierTimeBeforeRank0    | 28.317 us                 | 13.107 ms                 |
| AfterBackward             | 15.411 ms                 | 37.054 ms                 |
| BlockToStepN              | 12.752 ms                 | 35.243 ms                 |
| OneStep                   | 37.891 ms                 | 79.290 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 2] 300 steps, total: 4.216, sample: 0.242, forward: 0.297, backward: 0.196, update: 0.102
[proc 3] 300 steps, total: 4.216, sample: 0.260, forward: 0.300, backward: 0.201, update: 0.110
[proc 1] 300 steps, total: 4.216, sample: 0.241, forward: 0.299, backward: 0.221, update: 0.102
[proc 0] 300 steps, total: 4.216, sample: 0.291, forward: 0.298, backward: 0.227, update: 0.109
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.117 ms                  | 2.433 ms                  |
| ProcessBack:UpdateCache   | 1.599 ms                  | 2.480 ms                  |
| ProcessBack:UpsertPq      | 10.456 ms                 | 15.932 ms                 |
| ProcessOneStep            | 15.397 ms                 | 37.029 ms                 |
| BlockToStepN              | 12.707 ms                 | 35.157 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:17:24.789017 158754 parallel_pq_v2.h:76] insert failed, size(hashtable)=1445
W20240128 13:17:24.939797 159275 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240128 13:17:24.978088 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=310, pq.top=310
E20240128 13:17:25.789009 158754 parallel_pq_v2.h:76] insert failed, size(hashtable)=2355
W20240128 13:17:25.973837 159275 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
W20240128 13:17:26.012969 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=332, pq.top=332
E20240128 13:17:26.789050 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=6408
W20240128 13:17:26.973541 159275 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
W20240128 13:17:27.012144 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=353, pq.top=353
E20240128 13:17:27.789016 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=5495
W20240128 13:17:27.990576 159275 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240128 13:17:28.031441 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=374, pq.top=374
E20240128 13:17:28.789013 159275 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
W20240128 13:17:29.010190 159275 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
W20240128 13:17:29.045043 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=396, pq.top=396
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.235 ms                  | 15.524 ms                 |
| Forward                   | 3.005 ms                  | 4.614 ms                  |
| Backward                  | 2.280 ms                  | 4.338 ms                  |
| Optimize                  | 1.131 ms                  | 2.656 ms                  |
| BarrierTimeBeforeRank0    | 26.887 us                 | 14.046 ms                 |
| AfterBackward             | 15.852 ms                 | 25.058 ms                 |
| BlockToStepN              | 13.091 ms                 | 35.934 ms                 |
| OneStep                   | 39.678 ms                 | 79.290 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 4.758, sample: 0.243, forward: 0.290, backward: 0.224, update: 0.102
[proc 3] 400 steps, total: 4.758, sample: 0.231, forward: 0.289, backward: 0.205, update: 0.105
[proc 0] 400 steps, total: 4.758, sample: 0.309, forward: 0.297, backward: 0.229, update: 0.110
[proc 2] 400 steps, total: 4.758, sample: 0.238, forward: 0.285, backward: 0.200, update: 0.100
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.116 ms                  | 2.436 ms                  |
| ProcessBack:UpdateCache   | 1.551 ms                  | 2.479 ms                  |
| ProcessBack:UpsertPq      | 10.704 ms                 | 16.084 ms                 |
| ProcessOneStep            | 15.805 ms                 | 25.031 ms                 |
| BlockToStepN              | 13.020 ms                 | 38.454 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240128 13:17:29.789016 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=5465
W20240128 13:17:30.013458 159275 grad_async_v2.h:120] Detect new sample comes, old_end4, new_end5
W20240128 13:17:30.045413 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=415, pq.top=415
E20240128 13:17:30.789023 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=7392
W20240128 13:17:31.017042 159275 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
W20240128 13:17:31.045758 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=436, pq.top=436
E20240128 13:17:31.789009 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=7487
W20240128 13:17:32.020990 159275 grad_async_v2.h:120] Detect new sample comes, old_end6, new_end7
W20240128 13:17:32.047194 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=457, pq.top=457
E20240128 13:17:32.789054 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=5320
W20240128 13:17:33.026150 159275 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
W20240128 13:17:33.047487 158754 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=478, pq.top=478
E20240128 13:17:33.789016 159274 parallel_pq_v2.h:76] insert failed, size(hashtable)=4611
[proc 2] 500 steps, total: 4.723, sample: 0.258, forward: 0.288, backward: 0.210, update: 0.097
[proc 0] 500 steps, total: 4.723, sample: 0.289, forward: 0.293, backward: 0.233, update: 0.108
[proc 3] 500 steps, total: 4.723, sample: 0.246, forward: 0.303, backward: 0.201, update: 0.112
[proc 1] 500 steps, total: 4.723, sample: 0.241, forward: 0.303, backward: 0.224, update: 0.101
Successfully xmh. training takes 23.651243209838867 seconds
before call kg_cache_controller.StopThreads()
W20240128 13:17:34.033514 158754 grad_async_v2.h:71] call StopThreads. PID = 158302
W20240128 13:17:34.033542 158754 grad_base.h:212] before processOneStepNegThread_.join();
W20240128 13:17:34.033779 158754 grad_base.h:214] after processOneStepNegThread_.join();
W20240128 13:17:34.033789 158754 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
W20240128 13:17:34.042119 158754 grad_async_v2.h:91] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.254 ms                  | 15.524 ms                 |
| Forward                   | 3.019 ms                  | 4.313 ms                  |
| Backward                  | 2.289 ms                  | 4.338 ms                  |
| Optimize                  | 1.131 ms                  | 2.544 ms                  |
| BarrierTimeBeforeRank0    | 25.864 us                 | 13.319 ms                 |
| AfterBackward             | 16.334 ms                 | 24.019 ms                 |
| BlockToStepN              | 12.981 ms                 | 40.678 ms                 |
| OneStep                   | 40.701 ms                 | 79.290 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.136 ms                  | 2.436 ms                  |
| ProcessBack:UpdateCache   | 1.589 ms                  | 2.364 ms                  |
| ProcessBack:UpsertPq      | 11.144 ms                 | 15.997 ms                 |
| ProcessOneStep            | 16.287 ms                 | 23.994 ms                 |
| BlockToStepN              | 12.920 ms                 | 40.628 ms                 |
+---------------------------+---------------------------+---------------------------+
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f6b405086d0>
