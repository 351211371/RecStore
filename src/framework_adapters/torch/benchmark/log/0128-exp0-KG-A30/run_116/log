WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240128 14:15:03.089149 246315 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='DistMult', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/DistMult_FB15k_56', no_save_emb=True, max_step=500, batch_size=2400, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [246315 sampler.py:454] Start PreSampling
WARNING [246315 sampler.py:532] Before construct renumbering_dict
WARNING [246315 sampler.py:555] PreSampling done
W20240128 14:15:05.033505 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240128 14:15:05.033624 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240128 14:15:05.033644 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240128 14:15:05.033661 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240128 14:15:05.033681 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240128 14:15:05.033697 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240128 14:15:05.033715 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240128 14:15:05.033738 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240128 14:15:05.033758 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240128 14:15:05.033777 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240128 14:15:05.033798 246315 IPCTensor.h:368] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240128 14:15:05.033815 246315 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240128 14:15:05.033833 246315 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240128 14:15:05.033910 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240128 14:15:05.033929 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240128 14:15:05.033944 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240128 14:15:05.033972 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240128 14:15:05.033990 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240128 14:15:05.034006 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240128 14:15:05.034024 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240128 14:15:05.034039 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240128 14:15:05.034057 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240128 14:15:05.034075 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240128 14:15:05.034090 246315 IPCTensor.h:368] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240128 14:15:05.034103 246315 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240128 14:15:05.034116 246315 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240128 14:15:05.034147 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240128 14:15:05.034164 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240128 14:15:05.034179 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240128 14:15:05.034193 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240128 14:15:05.034210 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240128 14:15:05.034229 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240128 14:15:05.034246 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240128 14:15:05.034265 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240128 14:15:05.034281 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240128 14:15:05.034296 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240128 14:15:05.034310 246315 IPCTensor.h:368] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240128 14:15:05.034322 246315 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240128 14:15:05.034334 246315 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240128 14:15:05.034363 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240128 14:15:05.034380 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240128 14:15:05.034394 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240128 14:15:05.034408 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240128 14:15:05.034422 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240128 14:15:05.034440 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240128 14:15:05.034461 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240128 14:15:05.034478 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240128 14:15:05.034492 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240128 14:15:05.034511 246315 IPCTensor.h:368] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240128 14:15:05.034525 246315 IPCTensor.h:368] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240128 14:15:05.034538 246315 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240128 14:15:05.034554 246315 IPCTensor.h:368] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1647, 1903, 2000,  ..., 2301, 6295, 7239]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.102 seconds
[Rank1] pid = 246523
[Rank2] pid = 246588
INFO [246315 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [246588 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [246523 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [246523 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [246315 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [246652 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [246652 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [246588 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
I20240128 14:15:08.348546 246589 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240128 14:15:08.348974 246654 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 14:15:08.353385 246653 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240128 14:15:08.358093 246524 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
[Rank3] pid = 246652
train_sampler.Prefill()
-------Step 0-------
tensor([10806,   366, 11009,  7551,  8442,  5846, 10110,  4757, 12403,   132]) tensor([ 2000,  8317, 11092,  1127,  7735, 10275, 13144, 10684,  7828,  1161])
-------Step 1-------
tensor([10806,   366, 11009,  7551,  8442,  5846, 10110,  4757, 12403,   132]) tensor([ 2828,   775,  5716,  4854, 14845,     6,   706,  5663,  5612,  7743])
-------Step 2-------
tensor([ 3987, 13933, 10562, 10485,  5518,  5957, 12117,  6793,  4114,  2168]) tensor([13997,  1037, 10421, 11248,  3941,   609,  7339,   892,  9811, 13478])
-------Step 3-------
tensor([ 3987, 13933, 10562, 10485,  5518,  5957, 12117,  6793,  4114,  2168]) tensor([ 8987, 14055,  6347,  7210,  4480,  6651, 13723,  8490,  6762, 12803])
-------Step 4-------
tensor([ 9955,  9674, 13651, 10123,  5124,  7146,  1850,  5865,  5005, 14839]) tensor([  757, 11034, 14688,  1766, 10884, 10493,  2350,  9820,  7704,  8320])
-------Step 5-------
tensor([ 9955,  9674, 13651, 10123,  5124,  7146,  1850,  5865,  5005, 14839]) tensor([ 4543, 11831,  4054,  9541,  6711,  9751,  1034,  1606, 13752,  2096])
-------Step 6-------
tensor([ 5179,   500, 12798, 10451,  3806, 11383,  7949,    56,  5454,  9343]) tensor([12727, 11108, 13323,   874, 12878,  9741,  8077,  2353,  7228,  9482])
-------Step 7-------
tensor([ 5179,   500, 12798, 10451,  3806, 11383,  7949,    56,  5454,  9343]) tensor([ 6751,  6134, 10953, 13071,  5971,  8003,  6980,   641, 14867,  6820])
-------Step 8-------
tensor([ 9082, 13635,  5936,  6329,  2447,  6721,  3862,  3221,   662,  7145]) tensor([ 7439, 11121, 12103, 14741,  7232,  9037,  6217,  2304,  2767,  8789])
-------Step 9-------
tensor([ 9082, 13635,  5936,  6329,  2447,  6721,  3862,  3221,   662,  7145]) tensor([ 2419, 12494,  3808, 13173,  2648,   514,  3371,  1785, 14676, 13693])
before start barrier
start train
[proc 0] 100 steps, total: 4.396, sample: 0.251, forward: 1.165, backward: 2.078, update: 0.695
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 4.400, sample: 0.261, forward: 1.111, backward: 1.935, update: 0.668
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.391, sample: 0.221, forward: 1.139, backward: 1.921, update: 0.678
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.401, sample: 0.219, forward: 1.062, backward: 1.944, update: 0.638
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 819.258 us                | 17.799 ms                 |
| Forward                   | 5.338 ms                  | 33.439 ms                 |
| Backward                  | 1.452 ms                  | 348.296 ms                |
| Optimize                  | 5.985 ms                  | 21.262 ms                 |
| OneStep                   | 14.843 ms                 | 975.910 ms                |
+---------------------------+---------------------------+---------------------------+
[proc 0] 200 steps, total: 1.884, sample: 0.225, forward: 0.501, backward: 0.144, update: 0.591
[proc 3] 200 steps, total: 1.884, sample: 0.255, forward: 0.488, backward: 0.205, update: 0.567
[proc 1] 200 steps, total: 1.884, sample: 0.233, forward: 0.482, backward: 0.203, update: 0.557
[proc 2] 200 steps, total: 1.883, sample: 0.238, forward: 0.462, backward: 0.189, update: 0.566
[proc 0] 300 steps, total: 2.457, sample: 0.300, forward: 0.599, backward: 0.213, update: 0.637
[proc 2] 300 steps, total: 2.457, sample: 0.326, forward: 0.543, backward: 0.207, update: 0.634
[proc 3] 300 steps, total: 2.457, sample: 0.338, forward: 0.562, backward: 0.215, update: 0.641
[proc 1] 300 steps, total: 2.457, sample: 0.284, forward: 0.556, backward: 0.210, update: 0.637
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 848.274 us                | 18.780 ms                 |
| Forward                   | 5.421 ms                  | 11.442 ms                 |
| Backward                  | 2.070 ms                  | 2.568 ms                  |
| Optimize                  | 6.083 ms                  | 12.353 ms                 |
| OneStep                   | 18.544 ms                 | 46.289 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 3] 400 steps, total: 2.664, sample: 0.278, forward: 0.675, backward: 0.225, update: 0.817
[proc 1] 400 steps, total: 2.664, sample: 0.307, forward: 0.693, backward: 0.222, update: 0.824
[proc 0] 400 steps, total: 2.664, sample: 0.281, forward: 0.719, backward: 0.219, update: 0.820
[proc 2] 400 steps, total: 2.665, sample: 0.297, forward: 0.654, backward: 0.225, update: 0.830
[proc 1] 500 steps, total: 2.406, sample: 0.275, forward: 0.583, backward: 0.202, update: 0.658
[proc 0] 500 steps, total: 2.406, sample: 0.284, forward: 0.604, backward: 0.191, update: 0.655
[proc 2] 500 steps, total: 2.406, sample: 0.322, forward: 0.543, backward: 0.213, update: 0.643
Successfully xmh. training takes 13.807477951049805 seconds
before call kg_cache_controller.StopThreads()
[proc 3] 500 steps, total: 2.407, sample: 0.313, forward: 0.546, backward: 0.205, update: 0.636
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 904.262 us                | 17.544 ms                 |
| Forward                   | 5.610 ms                  | 11.189 ms                 |
| Backward                  | 2.158 ms                  | 2.505 ms                  |
| Optimize                  | 6.261 ms                  | 12.332 ms                 |
| OneStep                   | 19.941 ms                 | 42.076 ms                 |
+---------------------------+---------------------------+---------------------------+
KGCacheControllerWrapperDummy.StopThreads
