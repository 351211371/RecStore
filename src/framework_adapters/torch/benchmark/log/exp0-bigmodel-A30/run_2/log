Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 3 parts
part 0 has 101575884 edges
part 1 has 101575884 edges
part 2 has 101575882 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2], has_edge_importance=False, hidden_dim=100, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=3, num_proc=3, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_Freebase_14', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 391.603 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.7114970970749855
[proc 0][Train](1000/10000) average neg_loss: 0.7849112832546234
[proc 0][Train](1000/10000) average loss: 0.748204190671444
[proc 0][Train](1000/10000) average regularization: 8.730259247022331e-05
[proc 0] 1000 steps, total: 22.897, sample: 10.954, forward: 6.545, backward: 2.664, update: 2.730
[proc 1][Train](1000/10000) average pos_loss: 0.7115947312116623
[proc 1][Train](1000/10000) average neg_loss: 0.7866739509105682
[proc 1][Train](1000/10000) average loss: 0.7491343401670456
[proc 1][Train](1000/10000) average regularization: 8.674215359133086e-05
[proc 1] 1000 steps, total: 22.725, sample: 11.848, forward: 5.520, backward: 2.367, update: 2.726
[proc 2][Train](1000/10000) average pos_loss: 0.7154905519485474
[proc 2][Train](1000/10000) average neg_loss: 0.7949400174617768
[proc 2][Train](1000/10000) average loss: 0.7552152842879295
[proc 2][Train](1000/10000) average regularization: 8.45812190163997e-05
[proc 2] 1000 steps, total: 22.563, sample: 9.297, forward: 6.150, backward: 2.557, update: 2.586
[proc 1][Train](2000/10000) average pos_loss: 0.6978274182081222
[proc 1][Train](2000/10000) average neg_loss: 0.7638199657201767
[proc 1][Train](2000/10000) average loss: 0.730823692560196
[proc 1][Train](2000/10000) average regularization: 0.00010046356844395632
[proc 1] 2000 steps, total: 10.164, sample: 1.839, forward: 3.298, backward: 2.490, update: 2.532
[proc 2][Train](2000/10000) average pos_loss: 0.6985223382115364
[proc 2][Train](2000/10000) average neg_loss: 0.7636134692430496
[proc 2][Train](2000/10000) average loss: 0.7310679031610489
[proc 2][Train](2000/10000) average regularization: 0.00010020357408211567
[proc 2] 2000 steps, total: 10.164, sample: 1.441, forward: 3.178, backward: 2.451, update: 2.374
[proc 0][Train](2000/10000) average pos_loss: 0.6994042435884475
[proc 0][Train](2000/10000) average neg_loss: 0.7630802869796753
[proc 0][Train](2000/10000) average loss: 0.731242264866829
[proc 0][Train](2000/10000) average regularization: 0.0001001996791746933
[proc 0] 2000 steps, total: 10.164, sample: 1.438, forward: 3.218, backward: 2.470, update: 2.420
[proc 1][Train](3000/10000) average pos_loss: 0.6898100975751876
[proc 1][Train](3000/10000) average neg_loss: 0.7524059830904007
[proc 1][Train](3000/10000) average loss: 0.7211080412864685
[proc 1][Train](3000/10000) average regularization: 0.00011080804783705388
[proc 1] 3000 steps, total: 9.625, sample: 1.516, forward: 3.213, backward: 2.407, update: 2.485
[proc 2][Train](3000/10000) average pos_loss: 0.690832200050354
[proc 2][Train](3000/10000) average neg_loss: 0.7514155231118202
[proc 2][Train](3000/10000) average loss: 0.7211238613128662
[proc 2][Train](3000/10000) average regularization: 0.00011049719528818968
[proc 2] 3000 steps, total: 9.625, sample: 1.423, forward: 3.141, backward: 2.327, update: 2.309
[proc 0][Train](3000/10000) average pos_loss: 0.6909977626800538
[proc 0][Train](3000/10000) average neg_loss: 0.7515930215120316
[proc 0][Train](3000/10000) average loss: 0.7212953937649726
[proc 0][Train](3000/10000) average regularization: 0.00011057626392721432
[proc 0] 3000 steps, total: 9.625, sample: 1.429, forward: 3.197, backward: 2.367, update: 2.355
[proc 0][Train](4000/10000) average pos_loss: 0.6846271718144417
[proc 0][Train](4000/10000) average neg_loss: 0.7434310749173164
[proc 0][Train](4000/10000) average loss: 0.7140291228890419
[proc 0][Train](4000/10000) average regularization: 0.00011835744444397279
[proc 0] 4000 steps, total: 9.276, sample: 1.433, forward: 3.193, backward: 2.344, update: 2.302
[proc 1][Train](4000/10000) average pos_loss: 0.6857169718146324
[proc 1][Train](4000/10000) average neg_loss: 0.7441795894503593
[proc 1][Train](4000/10000) average loss: 0.7149482817649842
[proc 1][Train](4000/10000) average regularization: 0.00011835700717347208
[proc 1] 4000 steps, total: 9.277, sample: 1.402, forward: 3.122, backward: 2.351, update: 2.301
[proc 2][Train](4000/10000) average pos_loss: 0.6856371794939041
[proc 2][Train](4000/10000) average neg_loss: 0.7441074612140656
[proc 2][Train](4000/10000) average loss: 0.7148723211884499
[proc 2][Train](4000/10000) average regularization: 0.00011837665475468384
[proc 2] 4000 steps, total: 9.277, sample: 1.405, forward: 3.143, backward: 2.323, update: 2.252
[proc 0][Train](5000/10000) average pos_loss: 0.6817807636260986
[proc 0][Train](5000/10000) average neg_loss: 0.73717226177454
[proc 0][Train](5000/10000) average loss: 0.7094765127301216
[proc 0][Train](5000/10000) average regularization: 0.00012422366937971674
[proc 0] 5000 steps, total: 9.525, sample: 1.546, forward: 3.225, backward: 2.497, update: 2.252
[proc 2][Train](5000/10000) average pos_loss: 0.680531169474125
[proc 2][Train](5000/10000) average neg_loss: 0.7379818742871285
[proc 2][Train](5000/10000) average loss: 0.7092565224170685
[proc 2][Train](5000/10000) average regularization: 0.0001241298724708031
[proc 2] 5000 steps, total: 9.524, sample: 1.535, forward: 3.142, backward: 2.313, update: 2.201
[proc 1][Train](5000/10000) average pos_loss: 0.6801806271076203
[proc 1][Train](5000/10000) average neg_loss: 0.7365433369278908
[proc 1][Train](5000/10000) average loss: 0.7083619815707207
[proc 1][Train](5000/10000) average regularization: 0.00012412206628505373
[proc 1] 5000 steps, total: 9.525, sample: 1.555, forward: 3.121, backward: 2.351, update: 2.231
[proc 0][Train](6000/10000) average pos_loss: 0.677940621316433
[proc 0][Train](6000/10000) average neg_loss: 0.7320000333786011
[proc 0][Train](6000/10000) average loss: 0.704970327436924
[proc 0][Train](6000/10000) average regularization: 0.0001284507099626353
[proc 0] 6000 steps, total: 9.188, sample: 1.422, forward: 3.207, backward: 2.299, update: 2.255
[proc 2][Train](6000/10000) average pos_loss: 0.6775774354338646
[proc 2][Train](6000/10000) average neg_loss: 0.731923841714859
[proc 2][Train](6000/10000) average loss: 0.7047506378889083
[proc 2][Train](6000/10000) average regularization: 0.00012848634917463642
[proc 2] 6000 steps, total: 9.188, sample: 1.421, forward: 3.158, backward: 2.304, update: 2.179
[proc 1][Train](6000/10000) average pos_loss: 0.6769614513516427
[proc 1][Train](6000/10000) average neg_loss: 0.7320966636538505
[proc 1][Train](6000/10000) average loss: 0.7045290575623512
[proc 1][Train](6000/10000) average regularization: 0.0001284864137705881
[proc 1] 6000 steps, total: 9.188, sample: 1.412, forward: 3.144, backward: 2.341, update: 2.217
[proc 0][Train](7000/10000) average pos_loss: 0.6731198872923851
[proc 0][Train](7000/10000) average neg_loss: 0.7269076613783836
[proc 0][Train](7000/10000) average loss: 0.700013774573803
[proc 0][Train](7000/10000) average regularization: 0.00013186175511509644
[proc 0] 7000 steps, total: 9.261, sample: 1.465, forward: 3.234, backward: 2.287, update: 2.263
[proc 2][Train](7000/10000) average pos_loss: 0.6740660825371743
[proc 2][Train](7000/10000) average neg_loss: 0.7269759909510612
[proc 2][Train](7000/10000) average loss: 0.7005210369229317
[proc 2][Train](7000/10000) average regularization: 0.00013182448732550255
[proc 2] 7000 steps, total: 9.261, sample: 1.472, forward: 3.241, backward: 2.342, update: 2.200
[proc 1][Train](7000/10000) average pos_loss: 0.6733353952765465
[proc 1][Train](7000/10000) average neg_loss: 0.7267386441230774
[proc 1][Train](7000/10000) average loss: 0.7000370198488235
[proc 1][Train](7000/10000) average regularization: 0.00013179517211392522
[proc 1] 7000 steps, total: 9.261, sample: 1.463, forward: 3.175, backward: 2.352, update: 2.255
[proc 1][Train](8000/10000) average pos_loss: 0.6703482674956321
[proc 1][Train](8000/10000) average neg_loss: 0.7230520203113556
[proc 1][Train](8000/10000) average loss: 0.6967001438736916
[proc 1][Train](8000/10000) average regularization: 0.0001344800217048032
[proc 1] 8000 steps, total: 9.723, sample: 1.546, forward: 3.260, backward: 2.694, update: 2.218
[proc 2][Train](8000/10000) average pos_loss: 0.6705299297571182
[proc 2][Train](8000/10000) average neg_loss: 0.7229442073106765
[proc 2][Train](8000/10000) average loss: 0.6967370674014092
[proc 2][Train](8000/10000) average regularization: 0.00013451080171216745
[proc 2] 8000 steps, total: 9.723, sample: 1.423, forward: 3.174, backward: 2.411, update: 2.110
[proc 0][Train](8000/10000) average pos_loss: 0.6710734977722168
[proc 0][Train](8000/10000) average neg_loss: 0.7229558215737343
[proc 0][Train](8000/10000) average loss: 0.6970146589279175
[proc 0][Train](8000/10000) average regularization: 0.00013452532605151646
[proc 0] 8000 steps, total: 9.723, sample: 1.590, forward: 3.328, backward: 2.311, update: 2.312
[proc 1][Train](9000/10000) average pos_loss: 0.6677515584826469
[proc 1][Train](9000/10000) average neg_loss: 0.7195231085419654
[proc 1][Train](9000/10000) average loss: 0.6936373344063759
[proc 1][Train](9000/10000) average regularization: 0.00013682438722753432
[proc 1] 9000 steps, total: 9.481, sample: 1.545, forward: 3.161, backward: 2.679, update: 2.091
[proc 0][Train](9000/10000) average pos_loss: 0.667337342619896
[proc 0][Train](9000/10000) average neg_loss: 0.7190339075922966
[proc 0][Train](9000/10000) average loss: 0.693185624241829
[proc 0][Train](9000/10000) average regularization: 0.0001367149007419357
[proc 0] 9000 steps, total: 9.480, sample: 1.499, forward: 3.178, backward: 2.310, update: 2.175
[proc 2][Train](9000/10000) average pos_loss: 0.6669216874837876
[proc 2][Train](9000/10000) average neg_loss: 0.7188109758496285
[proc 2][Train](9000/10000) average loss: 0.6928663327693939
[proc 2][Train](9000/10000) average regularization: 0.00013676209993718658
[proc 2] 9000 steps, total: 9.481, sample: 1.505, forward: 3.159, backward: 2.344, update: 2.108
[proc 1][Train](10000/10000) average pos_loss: 0.6648979917168617
[proc 1][Train](10000/10000) average neg_loss: 0.7152481673359871
[proc 1][Train](10000/10000) average loss: 0.6900730798244477
[proc 1][Train](10000/10000) average regularization: 0.00013880365279328544
[proc 1] 10000 steps, total: 9.344, sample: 1.446, forward: 3.153, backward: 2.663, update: 2.078
proc 1 takes 108.313 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.664749624311924
[proc 0][Train](10000/10000) average neg_loss: 0.7151069534420967
[proc 0][Train](10000/10000) average loss: 0.6899282877445221
[proc 0][Train](10000/10000) average regularization: 0.00013873800943838433
[proc 0] 10000 steps, total: 9.344, sample: 1.424, forward: 3.198, backward: 2.315, update: 2.154
proc 0 takes 108.485 seconds
[proc 2][Train](10000/10000) average pos_loss: 0.6648177864551544
[proc 2][Train](10000/10000) average neg_loss: 0.7158073072433472
[proc 2][Train](10000/10000) average loss: 0.6903125459551811
[proc 2][Train](10000/10000) average regularization: 0.00013874374801525847
[proc 2] 10000 steps, total: 9.344, sample: 1.420, forward: 3.166, backward: 2.357, update: 2.088
proc 2 takes 108.151 seconds
Successfully xmh. training takes 112.36935019493103 seconds
