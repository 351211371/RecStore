/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_158', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [505272 sampler.py:454] Start PreSampling
WARNING [505272 sampler.py:532] Before construct renumbering_dict
WARNING [505272 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240111 21:21:35.188689 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240111 21:21:35.188872 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240111 21:21:35.188910 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240111 21:21:35.188946 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240111 21:21:35.188975 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240111 21:21:35.189007 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240111 21:21:35.189039 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240111 21:21:35.189070 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240111 21:21:35.189107 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240111 21:21:35.189136 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240111 21:21:35.189170 505272 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240111 21:21:35.189201 505272 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240111 21:21:35.189225 505272 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240111 21:21:35.189321 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240111 21:21:35.189363 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240111 21:21:35.189396 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240111 21:21:35.189424 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240111 21:21:35.189453 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240111 21:21:35.189484 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240111 21:21:35.189527 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240111 21:21:35.189558 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240111 21:21:35.189584 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240111 21:21:35.189617 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240111 21:21:35.189644 505272 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240111 21:21:35.189671 505272 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240111 21:21:35.189697 505272 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240111 21:21:35.189750 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240111 21:21:35.189787 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240111 21:21:35.189815 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240111 21:21:35.189841 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240111 21:21:35.189867 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240111 21:21:35.189896 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240111 21:21:35.189924 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240111 21:21:35.189953 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240111 21:21:35.189980 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240111 21:21:35.190006 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240111 21:21:35.190034 505272 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240111 21:21:35.190058 505272 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240111 21:21:35.190081 505272 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240111 21:21:35.190126 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240111 21:21:35.190160 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240111 21:21:35.190188 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240111 21:21:35.190219 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240111 21:21:35.190245 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240111 21:21:35.190274 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240111 21:21:35.190304 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240111 21:21:35.190332 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240111 21:21:35.190361 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240111 21:21:35.190392 505272 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240111 21:21:35.190421 505272 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240111 21:21:35.190445 505272 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240111 21:21:35.190472 505272 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1624, 1690, 1711,  ..., 6931, 7493, 7841]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.111 seconds
[Rank1] pid = 505724
[Rank2] pid = 505788
INFO [505272 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [505724 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [505788 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [505788 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [505724 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [505853 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [505853 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [505272 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 505853
-------Step 0-------
tensor([ 6145, 12454, 13357, 12927,  5829,   154,  8970,  1919,  3873, 10514]) tensor([ 1711, 13588,  8328, 14494, 11176,  6322, 10275,  4424, 13364,  8932])
-------Step 1-------
tensor([ 6145, 12454, 13357, 12927,  5829,   154,  8970,  1919,  3873, 10514]) tensor([ 9912, 11075,  7435,  8406,  1308,  7114,  7233,  4867, 10171, 11447])
-------Step 2-------
tensor([ 3143,    62, 12550,  6380,  8144,  1952,  9194,   223,  9740,   878]) tensor([13468,  2004, 13156, 10909,  4466,  5679,  6488,  8596, 10909, 12222])
-------Step 3-------
tensor([ 3143,    62, 12550,  6380,  8144,  1952,  9194,   223,  9740,   878]) tensor([ 4281,   212, 14691,   833, 11337,   117,  1124, 14670,   658,  3288])
-------Step 4-------
tensor([ 3303, 12432,  8202,   360,  6590, 12665,   304,  8587, 14489,  3693]) tensor([ 5428,  2911, 11086,  7714,  8888,  1994, 13249, 12223, 13229,  6789])
-------Step 5-------
tensor([ 3303, 12432,  8202,   360,  6590, 12665,   304,  8587, 14489,  3693]) tensor([11810,  7293,  2685, 12938,  2244, 10897,  8194,  2845, 11345, 14334])
-------Step 6-------
tensor([12438,   197,     0,   206,  3368,   260, 12951,  5243,   319,    31]) tensor([ 6084,  4250, 13921,  3893,  2809,  3886,  6619, 11317,   606,  3337])
-------Step 7-------
tensor([12438,   197,     0,   206,  3368,   260, 12951,  5243,   319,    31]) tensor([ 6811, 11500,  1776,  9584,  5779,  2208,  5782,  4320,  4413,  5244])
-------Step 8-------
tensor([4636,  167, 5679,  190, 2319, 5027,  231,  966,  119, 1447]) tensor([ 5284,  5917, 11663, 13278,   836, 12941,  7796, 12553,  1453, 13838])
-------Step 9-------
tensor([4636,  167, 5679,  190, 2319, 5027,  231,  966,  119, 1447]) tensor([ 9864,  4255,  6993,  9329,  9504,  5478,  7288,    28, 13848,  2459])
[proc 0][Train](200/500) average pos_loss: 0.6120207009091974
[proc 0][Train](200/500) average neg_loss: 0.4906347043067217
[proc 0][Train](200/500) average loss: 0.551327701061964
[proc 0][Train](200/500) average regularization: 3.6703622475897645e-06
[proc 0] 200 steps, total: 7.976, sample: 0.553, forward: 2.681, backward: 3.537, update: 0.809
[proc 3][Train](200/500) average pos_loss: 0.6573604640178382
[proc 3][Train](200/500) average neg_loss: 0.5156625307351351
[proc 3][Train](200/500) average loss: 0.5865114979445935
[proc 3][Train](200/500) average regularization: 3.7663862804038215e-06
[proc 3] 200 steps, total: 8.004, sample: 0.712, forward: 2.309, backward: 2.465, update: 1.008
[proc 2][Train](200/500) average pos_loss: 0.6805870895460248
[proc 2][Train](200/500) average neg_loss: 0.5249042576551437
[proc 2][Train](200/500) average loss: 0.602745670825243
[proc 2][Train](200/500) average regularization: 3.742340040844283e-06
[proc 2] 200 steps, total: 7.987, sample: 0.716, forward: 2.340, backward: 2.535, update: 1.019
[proc 1][Train](200/500) average pos_loss: 0.6334283083677292
[proc 1][Train](200/500) average neg_loss: 0.5245929906517267
[proc 1][Train](200/500) average loss: 0.5790106512606144
[proc 1][Train](200/500) average regularization: 3.662913547941571e-06
[proc 1] 200 steps, total: 7.975, sample: 0.740, forward: 2.355, backward: 2.389, update: 0.997
[proc 0][Train](400/500) average pos_loss: 0.35784147441387176
[proc 0][Train](400/500) average neg_loss: 0.34385404668748376
[proc 0][Train](400/500) average loss: 0.3508477599918842
[proc 0][Train](400/500) average regularization: 3.979378974463544e-06
[proc 0] 400 steps, total: 4.965, sample: 0.499, forward: 1.643, backward: 1.674, update: 0.753
[proc 3][Train](400/500) average pos_loss: 0.42218327581882475
[proc 3][Train](400/500) average neg_loss: 0.4183566473424435
[proc 3][Train](400/500) average loss: 0.4202699610590935
[proc 3][Train](400/500) average regularization: 3.997798831960608e-06
[proc 3] 400 steps, total: 4.965, sample: 0.680, forward: 1.266, backward: 0.883, update: 0.958
[proc 2][Train](400/500) average pos_loss: 0.4603586775064468
[proc 2][Train](400/500) average neg_loss: 0.4374727641046047
[proc 2][Train](400/500) average loss: 0.44891572147607806
[proc 2][Train](400/500) average regularization: 3.900439972994718e-06
[proc 2] 400 steps, total: 4.965, sample: 0.654, forward: 1.222, backward: 0.888, update: 0.939
[proc 1][Train](400/500) average pos_loss: 0.40634815260767937
[proc 1][Train](400/500) average neg_loss: 0.4105000297725201
[proc 1][Train](400/500) average loss: 0.40842409044504163
[proc 1][Train](400/500) average regularization: 3.872422954600552e-06
[proc 1] 400 steps, total: 4.965, sample: 0.693, forward: 1.240, backward: 0.837, update: 0.945
Successfully xmh. training takes 15.466320514678955 seconds
