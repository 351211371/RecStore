/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_170', no_save_emb=True, max_step=500, batch_size=8000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [527227 sampler.py:454] Start PreSampling
WARNING [527227 sampler.py:532] Before construct renumbering_dict
WARNING [527227 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240111 21:35:08.321449 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240111 21:35:08.321628 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240111 21:35:08.321666 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240111 21:35:08.321697 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240111 21:35:08.321729 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240111 21:35:08.321763 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240111 21:35:08.321794 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240111 21:35:08.321831 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240111 21:35:08.321862 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240111 21:35:08.321897 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240111 21:35:08.321933 527227 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240111 21:35:08.321967 527227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240111 21:35:08.321996 527227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240111 21:35:08.322098 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240111 21:35:08.322135 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240111 21:35:08.322166 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240111 21:35:08.322199 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240111 21:35:08.322229 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240111 21:35:08.322263 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240111 21:35:08.322311 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240111 21:35:08.322345 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240111 21:35:08.322374 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240111 21:35:08.322407 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240111 21:35:08.322435 527227 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240111 21:35:08.322463 527227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240111 21:35:08.322489 527227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240111 21:35:08.322541 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240111 21:35:08.322577 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240111 21:35:08.322609 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240111 21:35:08.322639 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240111 21:35:08.322670 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240111 21:35:08.322700 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240111 21:35:08.322734 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240111 21:35:08.322767 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240111 21:35:08.322798 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240111 21:35:08.322827 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240111 21:35:08.322858 527227 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240111 21:35:08.322885 527227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240111 21:35:08.322911 527227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240111 21:35:08.322958 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240111 21:35:08.322994 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240111 21:35:08.323026 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240111 21:35:08.323060 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240111 21:35:08.323091 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240111 21:35:08.323123 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240111 21:35:08.323155 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240111 21:35:08.323186 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240111 21:35:08.323217 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240111 21:35:08.323248 527227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240111 21:35:08.323278 527227 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240111 21:35:08.323307 527227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240111 21:35:08.323333 527227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1738, 1882, 1911,  ..., 8221, 8271, 6629]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 1.577 seconds
[Rank1] pid = 527437
[Rank2] pid = 527502
INFO [527227 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [527566 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [527502 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [527437 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [527566 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [527227 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [527502 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [527437 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 527566
-------Step 0-------
tensor([11529,   227, 12636, 10479,  4978,  7864, 11730,  2097,  4245, 10815]) tensor([ 1911,   310,  6484, 12965, 12714,   223, 10741,  4671, 11356,  8115])
-------Step 1-------
tensor([11529,   227, 12636, 10479,  4978,  7864, 11730,  2097,  4245, 10815]) tensor([ 1404, 12442, 11903,  6431, 10264, 13461,  3381, 13050,  4503,  5120])
-------Step 2-------
tensor([14669,  8482,  5885,  6404,  1270, 14226,   672,  7625,  8952,   104]) tensor([ 7926, 13443,  8446,  9932,  9806, 13937,  8770,  1024,  7809,  4065])
-------Step 3-------
tensor([14669,  8482,  5885,  6404,  1270, 14226,   672,  7625,  8952,   104]) tensor([ 6663,  4726, 13473,  1406,  8275,  7790,  1498, 12302,  6613,  9717])
-------Step 4-------
tensor([11100,  2433, 13152,  2383,  4665,   202,  7323,  9375,  9792,  7864]) tensor([11905,  3158,  7203,  1433,  5505,  7892, 10954,   763,  7365, 11178])
-------Step 5-------
tensor([11100,  2433, 13152,  2383,  4665,   202,  7323,  9375,  9792,  7864]) tensor([ 1229,   638,   129, 13167,   822,    47,  3482, 12747,  5803,  7993])
-------Step 6-------
tensor([ 6003,  5598,  5315, 11352, 12133,  9275, 11867,  7706,  9449,  3614]) tensor([ 9316,  5251, 14822,  2110,  4905,  2570,   443,  6679,   747, 14616])
-------Step 7-------
tensor([ 6003,  5598,  5315, 11352, 12133,  9275, 11867,  7706,  9449,  3614]) tensor([ 5409, 14407,  2888,  1857, 12884,  1807,  3003, 10738, 13817,  7761])
-------Step 8-------
tensor([  233,  8256,  2885, 12034,  2496,  6766, 13538, 12982,  7401,   172]) tensor([ 6125, 12976,  2701,  8382, 12640,  8709,  7296, 12239, 13433,  1443])
-------Step 9-------
tensor([  233,  8256,  2885, 12034,  2496,  6766, 13538, 12982,  7401,   172]) tensor([12285, 10548, 11626,   648,  3475, 11015,  8097, 12170,  9640, 10598])
[proc 0][Train](200/500) average pos_loss: 0.5761314532533288
[proc 0][Train](200/500) average neg_loss: 0.27315807691047667
[proc 0][Train](200/500) average loss: 0.42464476980268956
[proc 0][Train](200/500) average regularization: 5.7680153413457444e-05
[proc 0] 200 steps, total: 33.580, sample: 1.061, forward: 13.169, backward: 16.472, update: 2.554
[proc 1][Train](200/500) average pos_loss: 0.6064835861325264
[proc 1][Train](200/500) average neg_loss: 0.3130887465417618
[proc 1][Train](200/500) average loss: 0.4597861657291651
[proc 1][Train](200/500) average regularization: 5.7107875973088086e-05
[proc 1] 200 steps, total: 33.578, sample: 1.789, forward: 6.746, backward: 5.804, update: 4.010
[proc 3][Train](200/500) average pos_loss: 0.634738321825862
[proc 3][Train](200/500) average neg_loss: 0.3180772782629356
[proc 3][Train](200/500) average loss: 0.4764078049361706
[proc 3][Train](200/500) average regularization: 5.662675915118598e-05
[proc 3] 200 steps, total: 33.585, sample: 1.787, forward: 6.974, backward: 6.197, update: 3.911
[proc 2][Train](200/500) average pos_loss: 0.6683450186997653
[proc 2][Train](200/500) average neg_loss: 0.3426366531761596
[proc 2][Train](200/500) average loss: 0.5054908376932145
[proc 2][Train](200/500) average regularization: 5.743792724388186e-05
[proc 2] 200 steps, total: 33.578, sample: 1.479, forward: 6.694, backward: 6.220, update: 3.138
[proc 0][Train](400/500) average pos_loss: 0.11446786779910326
[proc 0][Train](400/500) average neg_loss: 0.14682657666504384
[proc 0][Train](400/500) average loss: 0.1306472225487232
[proc 0][Train](400/500) average regularization: 5.040231155362562e-05
[proc 0] 400 steps, total: 31.227, sample: 1.024, forward: 12.610, backward: 14.646, update: 2.615
[proc 3][Train](400/500) average pos_loss: 0.16332248747348785
[proc 3][Train](400/500) average neg_loss: 0.1794364344328642
[proc 3][Train](400/500) average loss: 0.17137946113944053
[proc 3][Train](400/500) average regularization: 4.789204289409099e-05
[proc 3] 400 steps, total: 31.227, sample: 1.737, forward: 6.376, backward: 4.750, update: 3.927
[proc 2][Train](400/500) average pos_loss: 0.19895573131740094
[proc 2][Train](400/500) average neg_loss: 0.2036586119234562
[proc 2][Train](400/500) average loss: 0.20130717188119887
[proc 2][Train](400/500) average regularization: 4.8695463538024344e-05
[proc 2] 400 steps, total: 31.227, sample: 1.831, forward: 6.331, backward: 4.798, update: 3.422
[proc 1][Train](400/500) average pos_loss: 0.1451705675572157
[proc 1][Train](400/500) average neg_loss: 0.17394326768815518
[proc 1][Train](400/500) average loss: 0.1595569173246622
[proc 1][Train](400/500) average regularization: 4.9450396436441227e-05
[proc 1] 400 steps, total: 31.227, sample: 1.872, forward: 6.090, backward: 4.356, update: 3.928
Successfully xmh. training takes 80.27252745628357 seconds
