/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_164', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [514226 sampler.py:454] Start PreSampling
WARNING [514226 sampler.py:532] Before construct renumbering_dict
WARNING [514226 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240111 21:26:22.345369 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240111 21:26:22.345552 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240111 21:26:22.345587 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240111 21:26:22.345626 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240111 21:26:22.345662 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240111 21:26:22.345693 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240111 21:26:22.345721 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240111 21:26:22.345762 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240111 21:26:22.345798 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240111 21:26:22.345832 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240111 21:26:22.345878 514226 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240111 21:26:22.345909 514226 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240111 21:26:22.345943 514226 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240111 21:26:22.346047 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240111 21:26:22.346087 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240111 21:26:22.346122 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240111 21:26:22.346148 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240111 21:26:22.346176 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240111 21:26:22.346206 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240111 21:26:22.346249 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240111 21:26:22.346279 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240111 21:26:22.346308 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240111 21:26:22.346343 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240111 21:26:22.346374 514226 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240111 21:26:22.346397 514226 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240111 21:26:22.346421 514226 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240111 21:26:22.346472 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240111 21:26:22.346504 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240111 21:26:22.346531 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240111 21:26:22.346562 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240111 21:26:22.346591 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240111 21:26:22.346619 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240111 21:26:22.346650 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240111 21:26:22.346676 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240111 21:26:22.346704 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240111 21:26:22.346733 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240111 21:26:22.346760 514226 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240111 21:26:22.346783 514226 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240111 21:26:22.346807 514226 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240111 21:26:22.346854 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240111 21:26:22.346891 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240111 21:26:22.346920 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240111 21:26:22.346946 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240111 21:26:22.346976 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240111 21:26:22.347007 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240111 21:26:22.347038 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240111 21:26:22.347065 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240111 21:26:22.347092 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240111 21:26:22.347118 514226 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240111 21:26:22.347146 514226 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240111 21:26:22.347168 514226 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240111 21:26:22.347196 514226 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1740, 1872, 1900,  ..., 9647, 8429, 6458]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.330 seconds
[Rank1] pid = 514553
[Rank2] pid = 514618
INFO [514226 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [514553 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [514682 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [514618 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [514618 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [514682 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [514226 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [514553 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[proc 1][Train](200/500) average pos_loss: 0.5398708368092775
[proc 1][Train](200/500) average neg_loss: 0.4331564121786505
[proc 1][Train](200/500) average loss: 0.48651362761855127
[proc 1][Train](200/500) average regularization: 1.2217933967804129e-05
[proc 1] 200 steps, total: 13.229, sample: 1.077, forward: 3.315, backward: 3.181, update: 1.811
[proc 2][Train](200/500) average pos_loss: 0.6094574142992496
[proc 2][Train](200/500) average neg_loss: 0.454693997297436
[proc 2][Train](200/500) average loss: 0.5320757034420968
[proc 2][Train](200/500) average regularization: 1.2486940565850091e-05
[proc 2] 200 steps, total: 13.226, sample: 1.134, forward: 3.414, backward: 3.262, update: 1.881
[proc 3][Train](200/500) average pos_loss: 0.5743601275235415
[proc 3][Train](200/500) average neg_loss: 0.43703593033365906
[proc 3][Train](200/500) average loss: 0.5056980296969413
[proc 3][Train](200/500) average regularization: 1.2517864906840259e-05
[proc 3] 200 steps, total: 13.215, sample: 1.090, forward: 3.312, backward: 3.237, update: 1.838
[Rank3] pid = 514682
-------Step 0-------
tensor([11131, 14902, 13173,  9890,  4857,    71, 12623,  2130,  4074, 13293]) tensor([ 1900, 10585,  6310, 11781, 10253, 11437, 13093,  3819, 11235,  7580])
-------Step 1-------
tensor([11131, 14902, 13173,  9890,  4857,    71, 12623,  2130,  4074, 13293]) tensor([11152,  3097,  7754,  1184,  5234, 10668, 13372,  6029,  5791, 10816])
-------Step 2-------
tensor([11822,   827, 12781,   221,   111,  1621,   210,  9136,  6268,   115]) tensor([11408,  5299,  1494,   680,  3332,  8396,  8422,  5390,  6654,  4820])
-------Step 3-------
tensor([11822,   827, 12781,   221,   111,  1621,   210,  9136,  6268,   115]) tensor([10795, 14430,  7505,    43,    88, 10887,  8472,  4863,  4891,  7026])
-------Step 4-------
tensor([12932,  4464,   135,   506,  1512,  9870, 10631, 13408,  4339,  5201]) tensor([12607,  3130,  5753, 10978,  3670, 13742,  7393, 14853,  1078,  1228])
-------Step 5-------
tensor([12932,  4464,   135,   506,  1512,  9870, 10631, 13408,  4339,  5201]) tensor([ 9570,  2034,  1497,   969,   876,  9293,  2206,  8149, 12345,  3374])
-------Step 6-------
tensor([  853, 14768, 14902,   238, 14596, 10079, 13139,   271,   914,  6994]) tensor([ 9518, 10175,  3188, 10927,  2003,  8273,  6485,  3517, 12731, 14326])
-------Step 7-------
tensor([  853, 14768, 14902,   238, 14596, 10079, 13139,   271,   914,  6994]) tensor([ 4443,  9879,  2835,  8176,  8364, 12711,  4958, 11859,  9310,  4902])
-------Step 8-------
tensor([   57,  6994,   344,  1237,  3996, 13369, 13671,   341, 12069,   300]) tensor([ 7966, 12648,  8369,  9457,  9772, 14677,  8385,  1462,  7425,  4890])
-------Step 9-------
tensor([   57,  6994,   344,  1237,  3996, 13369, 13671,   341, 12069,   300]) tensor([ 8655,  5140, 14786,  2273,  5255,  2419,  6014,  8826,  1115, 14666])
[proc 0][Train](200/500) average pos_loss: 0.4999909891933203
[proc 0][Train](200/500) average neg_loss: 0.3825346875563264
[proc 0][Train](200/500) average loss: 0.4412628399580717
[proc 0][Train](200/500) average regularization: 1.231436917805695e-05
[proc 0] 200 steps, total: 13.229, sample: 0.698, forward: 4.657, backward: 5.769, update: 1.409
[proc 0][Train](400/500) average pos_loss: 0.17165363393723965
[proc 0][Train](400/500) average neg_loss: 0.19202071182429792
[proc 0][Train](400/500) average loss: 0.18183717340230943
[proc 0][Train](400/500) average regularization: 1.422131837443885e-05
[proc 0] 400 steps, total: 11.122, sample: 0.684, forward: 4.112, backward: 4.148, update: 1.450
[proc 1][Train](400/500) average pos_loss: 0.2096999604254961
[proc 1][Train](400/500) average neg_loss: 0.23241203963756563
[proc 1][Train](400/500) average loss: 0.22105600036680698
[proc 1][Train](400/500) average regularization: 1.3936782556811522e-05
[proc 1] 400 steps, total: 11.123, sample: 1.111, forward: 2.476, backward: 1.531, update: 1.765
[proc 3][Train](400/500) average pos_loss: 0.2355628102272749
[proc 3][Train](400/500) average neg_loss: 0.24791563525795937
[proc 3][Train](400/500) average loss: 0.24173922315239907
[proc 3][Train](400/500) average regularization: 1.3985739537929475e-05
[proc 3] 400 steps, total: 11.123, sample: 1.132, forward: 2.544, backward: 1.673, update: 1.858
[proc 2][Train](400/500) average pos_loss: 0.27888392433524134
[proc 2][Train](400/500) average neg_loss: 0.27295743234455583
[proc 2][Train](400/500) average loss: 0.27592067830264566
[proc 2][Train](400/500) average regularization: 1.378230851059925e-05
[proc 2] 400 steps, total: 11.123, sample: 1.093, forward: 2.560, backward: 1.642, update: 1.796
Successfully xmh. training takes 29.80603790283203 seconds
