/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_167', no_save_emb=True, max_step=500, batch_size=4000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [519850 sampler.py:454] Start PreSampling
WARNING [519850 sampler.py:532] Before construct renumbering_dict
WARNING [519850 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240111 21:29:50.370375 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240111 21:29:50.370558 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240111 21:29:50.370596 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240111 21:29:50.370631 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240111 21:29:50.370671 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240111 21:29:50.370702 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240111 21:29:50.370750 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240111 21:29:50.370784 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240111 21:29:50.370813 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240111 21:29:50.370839 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240111 21:29:50.370874 519850 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240111 21:29:50.370915 519850 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240111 21:29:50.370942 519850 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240111 21:29:50.371040 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240111 21:29:50.371081 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240111 21:29:50.371110 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240111 21:29:50.371140 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240111 21:29:50.371168 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240111 21:29:50.371193 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240111 21:29:50.371235 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240111 21:29:50.371265 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240111 21:29:50.371292 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240111 21:29:50.371320 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240111 21:29:50.371346 519850 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240111 21:29:50.371371 519850 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240111 21:29:50.371398 519850 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240111 21:29:50.371450 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240111 21:29:50.371487 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240111 21:29:50.371516 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240111 21:29:50.371542 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240111 21:29:50.371568 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240111 21:29:50.371598 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240111 21:29:50.371629 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240111 21:29:50.371660 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240111 21:29:50.371688 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240111 21:29:50.371716 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240111 21:29:50.371742 519850 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240111 21:29:50.371766 519850 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240111 21:29:50.371799 519850 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240111 21:29:50.371848 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240111 21:29:50.371884 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240111 21:29:50.371913 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240111 21:29:50.371941 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240111 21:29:50.371968 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240111 21:29:50.372001 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240111 21:29:50.372030 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240111 21:29:50.372056 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240111 21:29:50.372081 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240111 21:29:50.372112 519850 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240111 21:29:50.372140 519850 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240111 21:29:50.372164 519850 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240111 21:29:50.372193 519850 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1716, 1830, 1863,  ..., 7824, 6586, 7418]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 1.868 seconds
[Rank1] pid = 520082
[Rank2] pid = 520147
INFO [519850 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [520082 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [520211 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [520211 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [520082 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [520147 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [520147 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [519850 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 520211
-------Step 0-------
tensor([ 8919, 13661, 12096, 11803,  5475,   166,   104,  2036,  3540, 11607]) tensor([ 1863, 12647,  7194, 13790, 11644,   290,  9996,  4199, 13400,  9045])
-------Step 1-------
tensor([ 8919, 13661, 12096, 11803,  5475,   166,   104,  2036,  3540, 11607]) tensor([ 5562,   445,  2547,  6665, 14342,  9773,  6876, 11743, 10230, 11498])
-------Step 2-------
tensor([10675,  3800,  9088,   665,  1508, 11353,  8476, 11845,  3854,  4333]) tensor([10071,  3561,  6646, 12809,  3899, 12286,  5818, 13585,   924,  1291])
-------Step 3-------
tensor([10675,  3800,  9088,   665,  1508, 11353,  8476, 11845,  3854,  4333]) tensor([ 3123,  6774, 14916,  2320,  4399,  1760,   349,  1496,   970,  2610])
-------Step 4-------
tensor([13920,  7881,  7186,  5564,  3526, 11444,   713,  9124,  9627,    70]) tensor([ 9891, 14919,  9887, 10977, 12267, 14461,  6925,  1439,  8688,  3799])
-------Step 5-------
tensor([13920,  7881,  7186,  5564,  3526, 11444,   713,  9124,  9627,    70]) tensor([ 3591,  4687,  3176,  1776,  2989,  1229,  2100,  4461,  1744, 13805])
-------Step 6-------
tensor([ 4536,    79, 11654, 12802,  6727,   305,  4946,  7799, 12344,   211]) tensor([ 4090,  1669,   626,  9143, 11719, 12061,  7052,     9, 14220,   590])
-------Step 7-------
tensor([ 4536,    79, 11654, 12802,  6727,   305,  4946,  7799, 12344,   211]) tensor([13381,   912,  7851,  5259,  4435, 13573,  8751, 14345,  2114, 12260])
-------Step 8-------
tensor([13971,  2549, 12474,  2324,  5037, 13717,  8216, 11136,  8251,   166]) tensor([13402,  2772,  6278,  1186,  6168,  8541, 11755,  4515,  6413,  8737])
-------Step 9-------
tensor([13971,  2549, 12474,  2324,  5037, 13717,  8216, 11136,  8251,   166]) tensor([ 6027, 11378,  4530,  1443, 11374,  5580, 12948,  4670,  9229, 12647])
[proc 0][Train](200/500) average pos_loss: 0.4946569187939167
[proc 0][Train](200/500) average neg_loss: 0.31784643127117307
[proc 0][Train](200/500) average loss: 0.4062516736984253
[proc 0][Train](200/500) average regularization: 2.5491298802080565e-05
[proc 0] 200 steps, total: 20.901, sample: 0.810, forward: 7.877, backward: 9.327, update: 2.307
[proc 2][Train](200/500) average pos_loss: 0.6009985779970884
[proc 2][Train](200/500) average neg_loss: 0.39271908686263485
[proc 2][Train](200/500) average loss: 0.49685883060097696
[proc 2][Train](200/500) average regularization: 2.569553843841277e-05
[proc 2] 200 steps, total: 20.898, sample: 1.348, forward: 4.617, backward: 4.407, update: 3.754
[proc 3][Train](200/500) average pos_loss: 0.5588740157335996
[proc 3][Train](200/500) average neg_loss: 0.3696685671177693
[proc 3][Train](200/500) average loss: 0.4642712940275669
[proc 3][Train](200/500) average regularization: 2.5535492486596923e-05
[proc 3] 200 steps, total: 20.923, sample: 1.408, forward: 4.777, backward: 4.350, update: 3.246
[proc 1][Train](200/500) average pos_loss: 0.5333892634510994
[proc 1][Train](200/500) average neg_loss: 0.3646088395593688
[proc 1][Train](200/500) average loss: 0.44899904921650885
[proc 1][Train](200/500) average regularization: 2.519946836400777e-05
[proc 1] 200 steps, total: 20.937, sample: 1.374, forward: 4.871, backward: 4.237, update: 3.339
[proc 0][Train](400/500) average pos_loss: 0.13434643540531396
[proc 0][Train](400/500) average neg_loss: 0.1628772472590208
[proc 0][Train](400/500) average loss: 0.14861184123903512
[proc 0][Train](400/500) average regularization: 2.7148233202751724e-05
[proc 0] 400 steps, total: 18.598, sample: 0.825, forward: 7.347, backward: 7.539, update: 2.322
[proc 2][Train](400/500) average pos_loss: 0.22895473562180996
[proc 2][Train](400/500) average neg_loss: 0.22958656117320062
[proc 2][Train](400/500) average loss: 0.22927064850926399
[proc 2][Train](400/500) average regularization: 2.6381816833236372e-05
[proc 2] 400 steps, total: 18.598, sample: 1.467, forward: 4.051, backward: 2.793, update: 3.775
[proc 1][Train](400/500) average pos_loss: 0.16902728125452995
[proc 1][Train](400/500) average neg_loss: 0.19411959163844586
[proc 1][Train](400/500) average loss: 0.18157343603670598
[proc 1][Train](400/500) average regularization: 2.6651430025594892e-05
[proc 1] 400 steps, total: 18.598, sample: 1.398, forward: 4.090, backward: 2.553, update: 3.286
[proc 3][Train](400/500) average pos_loss: 0.19016121923923493
[proc 3][Train](400/500) average neg_loss: 0.20419636450707912
[proc 3][Train](400/500) average loss: 0.1971787916868925
[proc 3][Train](400/500) average regularization: 2.630241295264568e-05
[proc 3] 400 steps, total: 18.598, sample: 1.430, forward: 4.209, backward: 2.764, update: 3.272
Successfully xmh. training takes 48.77950096130371 seconds
