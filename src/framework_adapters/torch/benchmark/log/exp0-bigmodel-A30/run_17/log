/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_174', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KGExternelEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='PySync', L=10, kForwardItersPerStep=2, eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2188336 sampler.py:454] Start PreSampling
WARNING [2188336 sampler.py:532] Before construct renumbering_dict
WARNING [2188336 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240112 14:56:08.514567 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240112 14:56:08.514742 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240112 14:56:08.514777 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240112 14:56:08.514807 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240112 14:56:08.514835 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240112 14:56:08.514863 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240112 14:56:08.514889 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240112 14:56:08.514920 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240112 14:56:08.514948 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240112 14:56:08.514978 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240112 14:56:08.515008 2188336 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240112 14:56:08.515038 2188336 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240112 14:56:08.515064 2188336 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240112 14:56:08.515156 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240112 14:56:08.515194 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240112 14:56:08.515223 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240112 14:56:08.515249 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240112 14:56:08.515275 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240112 14:56:08.515303 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240112 14:56:08.515347 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240112 14:56:08.515374 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240112 14:56:08.515403 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240112 14:56:08.515430 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240112 14:56:08.515457 2188336 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240112 14:56:08.515481 2188336 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240112 14:56:08.515507 2188336 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240112 14:56:08.515556 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240112 14:56:08.515588 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240112 14:56:08.515616 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240112 14:56:08.515643 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240112 14:56:08.515669 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240112 14:56:08.515697 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240112 14:56:08.515724 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240112 14:56:08.515750 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240112 14:56:08.515782 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240112 14:56:08.515811 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240112 14:56:08.515838 2188336 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240112 14:56:08.515862 2188336 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240112 14:56:08.515885 2188336 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240112 14:56:08.515929 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240112 14:56:08.515962 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240112 14:56:08.515990 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240112 14:56:08.516021 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240112 14:56:08.516049 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240112 14:56:08.516077 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240112 14:56:08.516103 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240112 14:56:08.516129 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240112 14:56:08.516156 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240112 14:56:08.516182 2188336 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240112 14:56:08.516209 2188336 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240112 14:56:08.516233 2188336 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240112 14:56:08.516258 2188336 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
W20240112 14:56:08.623530 2188336 IPCTensor.h:367] NewIPCTensor: full_emb [14951, 400]0x100001ee2000
W20240112 14:56:08.623706 2188336 IPCTensor.h:367] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x1000035b4000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([ 1618,  1711,  1736,  ..., 10058,  8653, 11447]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.191 seconds
[Rank1] pid = 2188690
[Rank2] pid = 2188754
INFO [2188690 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2188336 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2188775 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2188775 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2188754 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2188690 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
WARNING [2188775 DistTensor.py:56] The tensor name already exists in the kvstore
INFO [2188754 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2188336 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
WARNING [2188690 DistTensor.py:56] The tensor name already exists in the kvstore
WARNING [2188336 DistTensor.py:56] The tensor name already exists in the kvstore
WARNING [2188754 DistTensor.py:56] The tensor name already exists in the kvstore
+---------------------------+---------------------------+---------------------------+
| Name                      | Mean                      | P99                       |
+---------------------------+---------------------------+---------------------------+
| AfterBackward             | 971.590 us                | 1.211 ms                  |
| BlockToStepN              | 309.484 us                | 423.324 us                |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | Mean                      | P99                       |
+---------------------------+---------------------------+---------------------------+
| AfterBackward             | 1.043 ms                  | 1.362 ms                  |
| BlockToStepN              | 300.994 us                | 439.078 us                |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | Mean                      | P99                       |
+---------------------------+---------------------------+---------------------------+
| AfterBackward             | 1.713 ms                  | 16.071 ms                 |
| BlockToStepN              | 307.331 us                | 450.767 us                |
+---------------------------+---------------------------+---------------------------+
[proc 2][Train](200/500) average pos_loss: 0.7377874950319528
[proc 2][Train](200/500) average neg_loss: 0.6584028013236821
[proc 2][Train](200/500) average loss: 0.6980951461195946
[proc 2][Train](200/500) average regularization: 1.5067153990457882e-05
[proc 2] 200 steps, total: 13.952, sample: 1.275, forward: 3.301, backward: 5.138, update: 0.532
[proc 1][Train](200/500) average pos_loss: 0.6934887455403804
[proc 1][Train](200/500) average neg_loss: 0.6669493056088686
[proc 1][Train](200/500) average loss: 0.6802190268039703
[proc 1][Train](200/500) average regularization: 1.4819334860476373e-05
[proc 1] 200 steps, total: 13.996, sample: 1.206, forward: 3.141, backward: 4.717, update: 0.523
[proc 3][Train](200/500) average pos_loss: 0.7380706313997507
[proc 3][Train](200/500) average neg_loss: 0.6466313362680376
[proc 3][Train](200/500) average loss: 0.6923509860038757
[proc 3][Train](200/500) average regularization: 1.4985371951752313e-05
[proc 3] 200 steps, total: 13.953, sample: 1.137, forward: 3.113, backward: 5.082, update: 0.486
[Rank3] pid = 2188775
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KGExternelEmbedding
fixed cache_range is [(0, 374), (374, 748), (748, 1122), (1122, 1495)]
-------Step 0-------
tensor([ 7035, 14157,  9297,  9387,  8479,   365, 12412,  2216,  4233, 13332]) tensor([ 1736, 10019,  5928,  9456,  9128,  7246, 12680,  3545,  9508,  6744])
-------Step 1-------
tensor([ 7035, 14157,  9297,  9387,  8479,   365, 12412,  2216,  4233, 13332]) tensor([10262,  3203,  8500,  1196,  9102, 11590, 13421,  6149,  4816, 12420])
-------Step 2-------
tensor([10527,   796, 12621,   311,    71,  1647,   159, 13052,  6443,    86]) tensor([14598,  3658,  1505,   553,  3040,  9068, 12660,  5710,  5448,  8212])
-------Step 3-------
tensor([10527,   796, 12621,   311,    71,  1647,   159, 13052,  6443,    86]) tensor([ 7143, 14208,  6122,   238,    45,  9990,  6814,  4753,  4570,  6417])
-------Step 4-------
tensor([12364,  4844,    84,   531,  1533,  7900, 10549, 13466,  5201,  5421]) tensor([12397,  4725,  5174, 10429,  3364, 13172,  7549, 14706,  1104,  1240])
-------Step 5-------
tensor([12364,  4844,    84,   531,  1533,  7900, 10549, 13466,  5201,  5421]) tensor([10744,  1986,  1499,  1025,   816,  9541,  2218,  7523, 11200,  3343])
-------Step 6-------
tensor([  815, 14105, 14157,   237, 11184,  9561, 12989,   273,   879,  5739]) tensor([14061, 10505,  3489,  9737,  1983,  7629,  5842,  3684, 12172, 13592])
-------Step 7-------
tensor([  815, 14105, 14157,   237, 11184,  9561, 12989,   273,   879,  5739]) tensor([ 4150,  6364,  2705,  7793,  7804, 12601,  4693, 10624,  7477,  4453])
-------Step 8-------
tensor([   83,  5739,   314,  1219,  2887, 13268, 13037,   335, 12250,   231]) tensor([ 7410, 10768,  7173,  8776,  9032, 14660,  5539,  1464,  7065,  4978])
-------Step 9-------
tensor([   83,  5739,   314,  1219,  2887, 13268, 13037,   335, 12250,   231]) tensor([12797,  5578, 14328,  2400,  5349,  2391,  6220, 10034,  1101, 14589])
[proc 0][Train](200/500) average pos_loss: 0.6756572625786066
[proc 0][Train](200/500) average neg_loss: 0.6513081916235387
[proc 0][Train](200/500) average loss: 0.6634827288985252
[proc 0][Train](200/500) average regularization: 1.476638771691796e-05
[proc 0] 200 steps, total: 13.957, sample: 1.113, forward: 5.010, backward: 6.815, update: 0.440
+---------------------------+---------------------------+---------------------------+
| Name                      | Mean                      | P99                       |
+---------------------------+---------------------------+---------------------------+
| AfterBackward             | 2.431 ms                  | 18.611 ms                 |
| BlockToStepN              | 305.749 us                | 450.312 us                |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | Mean                      | P99                       |
+---------------------------+---------------------------+---------------------------+
| AfterBackward             | 2.838 ms                  | 19.650 ms                 |
| BlockToStepN              | 301.975 us                | 439.078 us                |
+---------------------------+---------------------------+---------------------------+
[proc 0][Train](400/500) average pos_loss: 0.43851240649819373
[proc 0][Train](400/500) average neg_loss: 0.464636063426733
[proc 0][Train](400/500) average loss: 0.4515742339193821
[proc 0][Train](400/500) average regularization: 1.731616292090621e-05
[proc 0] 400 steps, total: 11.970, sample: 1.145, forward: 4.301, backward: 5.110, update: 0.424
[proc 1][Train](400/500) average pos_loss: 0.46693804636597636
[proc 1][Train](400/500) average neg_loss: 0.5222105966508388
[proc 1][Train](400/500) average loss: 0.4945743215084076
[proc 1][Train](400/500) average regularization: 1.7289473735218053e-05
[proc 1] 400 steps, total: 11.970, sample: 1.202, forward: 2.380, backward: 3.191, update: 0.484
[proc 3][Train](400/500) average pos_loss: 0.48928013667464254
[proc 3][Train](400/500) average neg_loss: 0.5101753982901573
[proc 3][Train](400/500) average loss: 0.4997277666628361
[proc 3][Train](400/500) average regularization: 1.745432595271268e-05
[proc 3] 400 steps, total: 11.970, sample: 1.262, forward: 2.413, backward: 3.610, update: 0.471
[proc 2][Train](400/500) average pos_loss: 0.5228261266648769
[proc 2][Train](400/500) average neg_loss: 0.5236067599058152
[proc 2][Train](400/500) average loss: 0.523216442167759
[proc 2][Train](400/500) average regularization: 1.7523864253234935e-05
[proc 2] 400 steps, total: 11.970, sample: 1.219, forward: 2.452, backward: 3.703, update: 0.471
+---------------------------+---------------------------+---------------------------+
| Name                      | Mean                      | P99                       |
+---------------------------+---------------------------+---------------------------+
| AfterBackward             | 2.871 ms                  | 21.234 ms                 |
| BlockToStepN              | 298.471 us                | 439.078 us                |
+---------------------------+---------------------------+---------------------------+
Successfully xmh. training takes 31.81298565864563 seconds
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
