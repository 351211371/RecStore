/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_161', no_save_emb=True, max_step=500, batch_size=1000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [509546 sampler.py:454] Start PreSampling
WARNING [509546 sampler.py:532] Before construct renumbering_dict
WARNING [509546 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240111 21:23:44.220099 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240111 21:23:44.220293 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240111 21:23:44.220335 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240111 21:23:44.220364 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240111 21:23:44.220396 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240111 21:23:44.220425 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240111 21:23:44.220456 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240111 21:23:44.220496 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240111 21:23:44.220526 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240111 21:23:44.220556 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240111 21:23:44.220587 509546 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240111 21:23:44.220621 509546 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240111 21:23:44.220650 509546 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240111 21:23:44.220749 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240111 21:23:44.220788 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240111 21:23:44.220819 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240111 21:23:44.220849 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240111 21:23:44.220875 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240111 21:23:44.220902 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240111 21:23:44.220958 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240111 21:23:44.220986 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240111 21:23:44.221015 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240111 21:23:44.221051 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240111 21:23:44.221086 509546 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240111 21:23:44.221112 509546 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240111 21:23:44.221134 509546 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240111 21:23:44.221185 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240111 21:23:44.221222 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240111 21:23:44.221253 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240111 21:23:44.221283 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240111 21:23:44.221311 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240111 21:23:44.221343 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240111 21:23:44.221369 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240111 21:23:44.221395 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240111 21:23:44.221422 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240111 21:23:44.221448 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240111 21:23:44.221475 509546 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240111 21:23:44.221499 509546 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240111 21:23:44.221526 509546 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240111 21:23:44.221570 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240111 21:23:44.221607 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240111 21:23:44.221635 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240111 21:23:44.221665 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240111 21:23:44.221694 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240111 21:23:44.221721 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240111 21:23:44.221747 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240111 21:23:44.221782 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240111 21:23:44.221813 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240111 21:23:44.221841 509546 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240111 21:23:44.221868 509546 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240111 21:23:44.221892 509546 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240111 21:23:44.221915 509546 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1629, 1698, 1726,  ..., 6805, 8034, 8009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.031 seconds
[Rank1] pid = 509879
[Rank2] pid = 509944
INFO [509546 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [509546 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [509879 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [509944 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [509879 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [509944 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [510008 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [510008 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 510008
-------Step 0-------
tensor([ 6481, 14465, 14499, 10612,  5893,    48, 10616,  2056,  4121, 14343]) tensor([ 1726, 11361,  7341, 11330, 12463,  6687, 12046,  3661, 11873,  8381])
-------Step 1-------
tensor([ 6481, 14465, 14499, 10612,  5893,    48, 10616,  2056,  4121, 14343]) tensor([ 8765, 12795,  8754, 10592, 10899, 14592,  5092,  1330,  8320,  4376])
-------Step 2-------
tensor([  259,    10,   123,  6043,   162,  2742,   284, 14069,  1324, 14535]) tensor([ 2516,   139,   171,  6865, 12324,  4849,  5275,  8877,  4173,  1583])
-------Step 3-------
tensor([  259,    10,   123,  6043,   162,  2742,   284, 14069,  1324, 14535]) tensor([ 7208,  4489,  9395,    43, 13026, 13695,  4036,  1759, 11977,  4058])
-------Step 4-------
tensor([12427,   871, 11665,   273,   199,  1612,  7112, 10414,  5500,   117]) tensor([12942,  3451,  1493,   694,  3340,  7157,  9441,  4837,  6329,  5348])
-------Step 5-------
tensor([12427,   871, 11665,   273,   199,  1612,  7112, 10414,  5500,   117]) tensor([ 3936,  6124,  3756,  5844,    48,  8887,  2461, 14309, 12452,  8271])
-------Step 6-------
tensor([ 3152,  8796,     9,  8585,  8982,  1679,  9524, 12610,  7355,  4825]) tensor([ 4111,  9490,  2421, 14250,  9329,  4357,  2924, 11651, 11581,  9640])
-------Step 7-------
tensor([ 3152,  8796,     9,  8585,  8982,  1679,  9524, 12610,  7355,  4825]) tensor([10968,  9349,  6329, 10494,  7880, 11376,  7460,  9628, 10399, 13331])
-------Step 8-------
tensor([11449,  4034,    64,   638,  1506,  9367,  9715, 14437,  4534,  4764]) tensor([10590,  3378,  6194, 10622,  4291, 12963,  7106, 14522,   923,  1162])
-------Step 9-------
tensor([11449,  4034,    64,   638,  1506,  9367,  9715, 14437,  4534,  4764]) tensor([ 3961,  1652, 14393, 11101,   195, 10027,  9521, 14617, 14695,   433])
[proc 0][Train](200/500) average pos_loss: 0.566879613660276
[proc 0][Train](200/500) average neg_loss: 0.45237316220998763
[proc 0][Train](200/500) average loss: 0.5096263872087001
[proc 0][Train](200/500) average regularization: 6.08822828553457e-06
[proc 0] 200 steps, total: 9.171, sample: 0.469, forward: 2.921, backward: 3.895, update: 1.090
[proc 1][Train](200/500) average pos_loss: 0.5971354218199849
[proc 1][Train](200/500) average neg_loss: 0.4962490642443299
[proc 1][Train](200/500) average loss: 0.54669224396348
[proc 1][Train](200/500) average regularization: 6.077290737493968e-06
[proc 1] 200 steps, total: 9.187, sample: 0.840, forward: 2.523, backward: 2.653, update: 1.281
[proc 3][Train](200/500) average pos_loss: 0.6177719763666392
[proc 3][Train](200/500) average neg_loss: 0.49281631998717784
[proc 3][Train](200/500) average loss: 0.5552941471338272
[proc 3][Train](200/500) average regularization: 6.256617232338613e-06
[proc 3] 200 steps, total: 9.186, sample: 0.809, forward: 2.580, backward: 2.746, update: 1.288
[proc 2][Train](200/500) average pos_loss: 0.6498391770198941
[proc 2][Train](200/500) average neg_loss: 0.504667145870626
[proc 2][Train](200/500) average loss: 0.5772531607747078
[proc 2][Train](200/500) average regularization: 6.2185895762922886e-06
[proc 2] 200 steps, total: 9.176, sample: 0.805, forward: 2.527, backward: 2.806, update: 1.313
[proc 0][Train](400/500) average pos_loss: 0.24883079409599304
[proc 0][Train](400/500) average neg_loss: 0.2641214565187693
[proc 0][Train](400/500) average loss: 0.25647612623870375
[proc 0][Train](400/500) average regularization: 6.9630473012693984e-06
[proc 0] 400 steps, total: 6.923, sample: 0.545, forward: 2.312, backward: 2.376, update: 1.107
[proc 3][Train](400/500) average pos_loss: 0.3458758966624737
[proc 3][Train](400/500) average neg_loss: 0.34463768661022187
[proc 3][Train](400/500) average loss: 0.3452567924559116
[proc 3][Train](400/500) average regularization: 6.899474149122398e-06
[proc 3] 400 steps, total: 6.923, sample: 0.851, forward: 1.725, backward: 1.136, update: 1.294
[proc 1][Train](400/500) average pos_loss: 0.30129398658871653
[proc 1][Train](400/500) average neg_loss: 0.323312896117568
[proc 1][Train](400/500) average loss: 0.3123034406453371
[proc 1][Train](400/500) average regularization: 6.7695689153879355e-06
[proc 1] 400 steps, total: 6.923, sample: 0.857, forward: 1.651, backward: 1.036, update: 1.243
[proc 2][Train](400/500) average pos_loss: 0.3862566114962101
[proc 2][Train](400/500) average neg_loss: 0.3694712632894516
[proc 2][Train](400/500) average loss: 0.3778639368712902
[proc 2][Train](400/500) average regularization: 6.712353049351805e-06
[proc 2] 400 steps, total: 6.923, sample: 0.837, forward: 1.682, backward: 1.102, update: 1.275
Successfully xmh. training takes 19.6981098651886 seconds
