WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240129 16:55:03.690102 2076836 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_182', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=3, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=3, gpu=[0, 1, 2], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Partitoning with metis
[16:55:04] /home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/src/graph/transform/metis_partition_hetero.cc:87: Partition a graph with 14951 nodes and 771659 edges into 3 parts and get 96452 edge cuts
WARNING [2076836 sampler.py:454] Start PreSampling
WARNING [2076836 sampler.py:532] Before construct renumbering_dict
WARNING [2076836 sampler.py:555] PreSampling done
W20240129 16:55:05.995074 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240129 16:55:05.995204 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240129 16:55:05.995229 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240129 16:55:05.995247 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240129 16:55:05.995265 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240129 16:55:05.995285 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240129 16:55:05.995302 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240129 16:55:05.995332 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240129 16:55:05.995353 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240129 16:55:05.995373 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240129 16:55:05.995394 2076836 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240129 16:55:05.995411 2076836 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240129 16:55:05.995426 2076836 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240129 16:55:05.995518 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240129 16:55:05.995556 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240129 16:55:05.995573 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240129 16:55:05.995589 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240129 16:55:05.995604 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240129 16:55:05.995618 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240129 16:55:05.995645 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240129 16:55:05.995661 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240129 16:55:05.995679 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240129 16:55:05.995702 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240129 16:55:05.995718 2076836 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240129 16:55:05.995730 2076836 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240129 16:55:05.995743 2076836 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240129 16:55:05.995787 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240129 16:55:05.995815 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240129 16:55:05.995833 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240129 16:55:05.995857 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240129 16:55:05.995873 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240129 16:55:05.995890 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240129 16:55:05.995914 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240129 16:55:05.995931 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240129 16:55:05.995949 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240129 16:55:05.995965 2076836 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240129 16:55:05.995982 2076836 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240129 16:55:05.995996 2076836 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240129 16:55:05.996011 2076836 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240129 16:55:06.117699 2076836 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x10000e52e000 22.81 MB
W20240129 16:55:06.117832 2076836 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x10000fc00000 58.4 kB
Convert a graph into a bidirected graph: 0.019 seconds, peak memory: 60.043 GB
Construct multi-constraint weights: 0.000 seconds, peak memory: 60.043 GB
Metis partitioning: 0.093 seconds, peak memory: 60.043 GB
Split the graph: 0.058 seconds
Construct subgraphs: 0.011 seconds
MertisPartition: part 0 has 11296 N 176344 E
MertisPartition: part 1 has 12898 N 253277 E
MertisPartition: part 2 has 12169 N 314310 E
Rank0: cached key size 249
Rank1: cached key size 249
Rank2: cached key size 249
Before renumbering graph:  {'_ID': tensor([    0,     2,    10,  ...,  8580,   176, 12835]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 2, 2])}
After renumbering graph:  {'_ID': tensor([ 753,  832, 1075,  ..., 5631, 6384, 7125]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 2, 2])}
part_g: DGLGraph(num_nodes=11296, num_edges=176344,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=11296, num_edges=176344,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.459 seconds
[Rank1] pid = 2077138
INFO [2076836 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2077203 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2077138 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2077138 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [2077203 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
W20240129 16:55:08.052220 2077139 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
INFO [2076836 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
W20240129 16:55:08.053247 2077139 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x10000fc12000 7.629 MB
W20240129 16:55:08.053357 2077139 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x1000103b5000 7.629 MB
W20240129 16:55:08.053401 2077139 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x100010b58000 1.49 GB
W20240129 16:55:08.053431 2077139 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x10007013b000 1.49 GB
W20240129 16:55:08.053465 2077139 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240129 16:55:08.055233 2077139 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240129 16:55:08.055303 2077204 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240129 16:55:08.055824 2077230 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [747, 400]; dev=2; size=1.14 MB
W20240129 16:55:08.057391 2077204 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x1000cf726000 7.629 MB
W20240129 16:55:08.057430 2077230 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x1000cfec9000 7.629 MB
W20240129 16:55:08.057579 2077230 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x1000d066c000 7.629 MB
W20240129 16:55:08.057595 2077204 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x1000d0e0f000 7.629 MB
W20240129 16:55:08.057652 2077230 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x1000d15b2000 1.49 GB
W20240129 16:55:08.057700 2077230 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x100130b95000 1.49 GB
W20240129 16:55:08.057760 2077230 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240129 16:55:08.057749 2077204 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x100190178000 1.49 GB
W20240129 16:55:08.057847 2077204 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1001ef75b000 1.49 GB
W20240129 16:55:08.057945 2077204 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240129 16:55:08.064910 2077230 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240129 16:55:08.064985 2077204 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
cudaHostRegister 0x10000e52e000
1: KnownLocalCachedEmbedding init done
WARNING [2077138 DistTensor.py:56] The tensor name already exists in the kvstore
[Rank2] pid = 2077203
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494), (1494, 2241)]
cudaHostRegister 0x10000e52e000
0: KnownLocalCachedEmbedding init done
WARNING [2076836 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x10000e52e000
2: KnownLocalCachedEmbedding init done
WARNING [2077203 DistTensor.py:56] The tensor name already exists in the kvstore
I20240129 16:55:09.039134 2077230 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 3
I20240129 16:55:09.039333 2077139 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 3
I20240129 16:55:09.039398 2077204 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 3
W20240129 16:55:09.040326 2077204 grad_base.h:55] KGCacheController, config={
        "num_gpus": 3,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240129 16:55:09.040441 2077204 grad_base.h:184] Init GradProcessingBase done
I20240129 16:55:09.044163 2077204 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240129 16:55:09.044286 2077204 kg_controller.h:78] after init GradAsyncProcessingV2
I20240129 16:55:09.044296 2077204 kg_controller.h:84] Construct KGCacheController done
E20240129 16:55:09.309155 2077204 recstore.cc:66] init folly done
E20240129 16:55:09.309170 2077139 recstore.cc:66] init folly done
E20240129 16:55:09.309191 2077230 recstore.cc:66] init folly done
I20240129 16:55:09.309785 2077204 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240129 16:55:09.716778 2077715 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
E20240129 16:55:09.717115 2077715 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240129 16:55:09.742741 2077204 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 3
I20240129 16:55:09.781340 2077139 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
I20240129 16:55:09.782382 2077230 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
E20240129 16:55:11.784693 2077540 parallel_pq_v2.h:76] insert failed, size(hashtable)=0
W20240129 16:55:11.798887 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=1, pq.top=0
W20240129 16:55:11.801149 2077715 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
E20240129 16:55:12.784353 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=4982
W20240129 16:55:12.804981 2077715 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240129 16:55:12.821310 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=27, pq.top=27
E20240129 16:55:13.784013 2077204 parallel_pq_v2.h:76] insert failed, size(hashtable)=801
W20240129 16:55:13.806205 2077715 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240129 16:55:13.821288 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=54, pq.top=54
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.054 ms                  | 20.297 ms                 |
| Forward                   | 3.628 ms                  | 7.563 ms                  |
| Backward                  | 3.122 ms                  | 7.681 ms                  |
| Optimize                  | 1.703 ms                  | 3.587 ms                  |
| BarrierTimeBeforeRank0    | 24.207 us                 | 5.752 ms                  |
| AfterBackward             | 20.436 ms                 | 27.415 ms                 |
| BlockToStepN              | 757.446 us                | 24.766 ms                 |
| OneStep                   | 35.050 ms                 | 80.981 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.383 ms                  | 68.347 ms                 |
| ProcessBack:UpdateCache   | 1.082 ms                  | 170.173 ms                |
| ProcessBack:UpsertPq      | 15.841 ms                 | 22.150 ms                 |
| ProcessOneStep            | 20.095 ms                 | 27.393 ms                 |
| BlockToStepN              | 3.223 ms                  | 24.703 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240129 16:55:14.784009 2077204 parallel_pq_v2.h:76] insert failed, size(hashtable)=1802
W20240129 16:55:14.809581 2077715 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
W20240129 16:55:14.839299 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=79, pq.top=79
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 5.937, sample: 0.307, forward: 1.421, backward: 0.557, update: 0.167
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 5.936, sample: 0.252, forward: 1.206, backward: 0.599, update: 0.144
train_sampler.Prefill()
-------Step 0-------
tensor([   83, 13601,    91, 10393,  9711,  1743, 11861, 13757, 14161,   571]) tensor([ 1075,  7727,  5852, 10736, 11427,  8595,  5342,  4391,  4827,  9070])
-------Step 1-------
tensor([   83, 13601,    91, 10393,  9711,  1743, 11861, 13757, 14161,   571]) tensor([ 1992,  6257,  8371,  2721, 10719,  8616,  8329, 13815, 14492, 14372])
-------Step 2-------
tensor([ 9218,  7373, 13841,    63, 14792,  4859,  6766,  6005,  9228,  1539]) tensor([6850, 7322,  701, 7398, 4455, 2894, 1542, 1008, 5459, 4129])
-------Step 3-------
tensor([ 9218,  7373, 13841,    63, 14792,  4859,  6766,  6005,  9228,  1539]) tensor([ 7529,  8183,  9377, 11146,  6681,  7929, 14320,  5965,  7499,  4849])
-------Step 4-------
tensor([11714,  6675,  7927,   204,  7885,  1162, 13024, 11099,    26,  5248]) tensor([12808,  5009,  2736,  4797,  6256,  2136,  9792,  1983,  4992, 10574])
-------Step 5-------
tensor([11714,  6675,  7927,   204,  7885,  1162, 13024, 11099,    26,  5248]) tensor([12221, 10256, 11939, 11136,  7413,  7968,  3346,  4363,  9477, 10088])
-------Step 6-------
tensor([ 6308,  8983,  1743,  2425, 14154,  6950,  2711,   160,   199,  7501]) tensor([12975,   591, 10413,  1586,  7545,  4329,  9532,  8978, 12906, 13993])
-------Step 7-------
tensor([ 6308,  8983,  1743,  2425, 14154,  6950,  2711,   160,   199,  7501]) tensor([14489,  7293,   241, 13655, 14260,  8262, 14681,  7800, 11223, 10507])
-------Step 8-------
tensor([ 1343,  8066,  5127, 11327,  5341,  1267,  2028, 13927,  8259,  7275]) tensor([ 6774,  9060,  6619,  4114,  2372, 12368,  8719,  5368,  7777,   621])
-------Step 9-------
tensor([ 1343,  8066,  5127, 11327,  5341,  1267,  2028, 13927,  8259,  7275]) tensor([ 5739,  2161,  1745, 14130,  7819,  7669, 11885,  4131,  6867, 12433])
before start barrier
start train
[proc 0] 100 steps, total: 5.976, sample: 0.291, forward: 1.560, backward: 0.641, update: 0.167
E20240129 16:55:15.784240 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=2753
W20240129 16:55:15.816279 2077715 grad_async_v2.h:121] Detect new sample comes, old_end2, new_end3
W20240129 16:55:15.878329 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=104, pq.top=104
E20240129 16:55:16.784010 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=4820
W20240129 16:55:16.818187 2077715 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240129 16:55:16.878054 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=126, pq.top=126
E20240129 16:55:17.784010 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=4635
W20240129 16:55:17.822575 2077715 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
W20240129 16:55:17.895485 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=150, pq.top=150
E20240129 16:55:18.784018 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=2591
W20240129 16:55:18.837055 2077715 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240129 16:55:18.908850 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=172, pq.top=172
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.053 ms                  | 20.097 ms                 |
| Forward                   | 3.376 ms                  | 6.362 ms                  |
| Backward                  | 3.039 ms                  | 7.247 ms                  |
| Optimize                  | 1.547 ms                  | 3.571 ms                  |
| BarrierTimeBeforeRank0    | 21.690 us                 | 5.886 ms                  |
| AfterBackward             | 19.119 ms                 | 26.008 ms                 |
| BlockToStepN              | 9.217 ms                  | 33.426 ms                 |
| OneStep                   | 41.521 ms                 | 80.981 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.205 ms                  | 1.567 ms                  |
| ProcessBack:UpdateCache   | 1.031 ms                  | 1.526 ms                  |
| ProcessBack:UpsertPq      | 15.773 ms                 | 19.730 ms                 |
| ProcessOneStep            | 19.034 ms                 | 25.982 ms                 |
| BlockToStepN              | 9.428 ms                  | 33.382 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240129 16:55:19.784010 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=3167
W20240129 16:55:19.844007 2077715 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240129 16:55:19.908114 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=195, pq.top=195
[proc 2] 200 steps, total: 4.426, sample: 0.341, forward: 0.324, backward: 0.267, update: 0.144
[proc 1] 200 steps, total: 4.426, sample: 0.282, forward: 0.329, backward: 0.314, update: 0.148
[proc 0] 200 steps, total: 4.426, sample: 0.315, forward: 0.351, backward: 0.301, update: 0.152
E20240129 16:55:20.784019 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=2905
W20240129 16:55:20.853957 2077715 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240129 16:55:20.930421 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=216, pq.top=216
E20240129 16:55:21.784008 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=3343
W20240129 16:55:21.856251 2077715 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240129 16:55:21.930339 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=235, pq.top=235
E20240129 16:55:22.784029 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=4978
W20240129 16:55:22.869844 2077715 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240129 16:55:22.955631 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=256, pq.top=256
E20240129 16:55:23.784008 2077540 parallel_pq_v2.h:76] insert failed, size(hashtable)=1885
W20240129 16:55:23.880669 2077715 grad_async_v2.h:121] Detect new sample comes, old_end5, new_end6
W20240129 16:55:23.955309 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=277, pq.top=277
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.156 ms                  | 21.184 ms                 |
| Forward                   | 3.601 ms                  | 6.362 ms                  |
| Backward                  | 3.003 ms                  | 6.757 ms                  |
| Optimize                  | 1.514 ms                  | 3.571 ms                  |
| BarrierTimeBeforeRank0    | 21.253 us                 | 15.124 ms                 |
| AfterBackward             | 18.751 ms                 | 24.841 ms                 |
| BlockToStepN              | 12.065 ms                 | 38.450 ms                 |
| OneStep                   | 43.333 ms                 | 80.981 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.315 ms                  | 1.842 ms                  |
| ProcessBack:UpdateCache   | 989.760 us                | 1.489 ms                  |
| ProcessBack:UpsertPq      | 14.398 ms                 | 20.444 ms                 |
| ProcessOneStep            | 18.699 ms                 | 24.820 ms                 |
| BlockToStepN              | 12.020 ms                 | 38.365 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240129 16:55:24.784008 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=8028
W20240129 16:55:24.910885 2077715 grad_async_v2.h:121] Detect new sample comes, old_end5, new_end6
W20240129 16:55:24.959450 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=296, pq.top=296
[proc 1] 300 steps, total: 4.981, sample: 0.274, forward: 0.331, backward: 0.273, update: 0.155
[proc 2] 300 steps, total: 4.981, sample: 0.311, forward: 0.353, backward: 0.267, update: 0.141
[proc 0] 300 steps, total: 4.981, sample: 0.375, forward: 0.376, backward: 0.287, update: 0.150
E20240129 16:55:25.784014 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=3924
W20240129 16:55:25.927071 2077715 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
W20240129 16:55:25.959121 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=318, pq.top=318
E20240129 16:55:26.785473 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=2572
W20240129 16:55:26.927428 2077715 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240129 16:55:26.970455 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=337, pq.top=337
E20240129 16:55:27.785015 2077204 parallel_pq_v2.h:76] insert failed, size(hashtable)=65
W20240129 16:55:27.930766 2077715 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240129 16:55:27.974805 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=354, pq.top=354
E20240129 16:55:28.785009 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=3918
W20240129 16:55:28.950218 2077715 grad_async_v2.h:121] Detect new sample comes, old_end2, new_end3
W20240129 16:55:28.978546 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=373, pq.top=373
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.288 ms                  | 22.275 ms                 |
| Forward                   | 3.663 ms                  | 5.615 ms                  |
| Backward                  | 2.999 ms                  | 6.388 ms                  |
| Optimize                  | 1.505 ms                  | 3.571 ms                  |
| BarrierTimeBeforeRank0    | 20.254 us                 | 16.095 ms                 |
| AfterBackward             | 18.270 ms                 | 24.045 ms                 |
| BlockToStepN              | 13.064 ms                 | 41.263 ms                 |
| OneStep                   | 45.105 ms                 | 84.493 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.368 ms                  | 2.307 ms                  |
| ProcessBack:UpdateCache   | 939.928 us                | 1.474 ms                  |
| ProcessBack:UpsertPq      | 14.073 ms                 | 20.267 ms                 |
| ProcessOneStep            | 18.229 ms                 | 24.025 ms                 |
| BlockToStepN              | 13.040 ms                 | 41.192 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240129 16:55:29.785009 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=4685
W20240129 16:55:29.951606 2077715 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240129 16:55:29.999070 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=392, pq.top=392
[proc 0] 400 steps, total: 5.288, sample: 0.404, forward: 0.360, backward: 0.301, update: 0.152
[proc 2] 400 steps, total: 5.288, sample: 0.321, forward: 0.347, backward: 0.272, update: 0.145
[proc 1] 400 steps, total: 5.288, sample: 0.290, forward: 0.348, backward: 0.286, update: 0.155
E20240129 16:55:30.785012 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=4770
W20240129 16:55:30.955004 2077715 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240129 16:55:30.999178 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=411, pq.top=411
E20240129 16:55:31.785012 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=3050
W20240129 16:55:31.967196 2077715 grad_async_v2.h:121] Detect new sample comes, old_end9, new_end0
W20240129 16:55:31.999192 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=430, pq.top=430
E20240129 16:55:32.785010 2077204 parallel_pq_v2.h:76] insert failed, size(hashtable)=83
W20240129 16:55:32.987385 2077715 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
W20240129 16:55:33.034037 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=449, pq.top=449
E20240129 16:55:33.785009 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=2962
W20240129 16:55:34.020939 2077715 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.341 ms                  | 22.857 ms                 |
| Forward                   | 3.683 ms                  | 5.350 ms                  |
| Backward                  | 2.995 ms                  | 6.082 ms                  |
| Optimize                  | 1.496 ms                  | 3.479 ms                  |
| BarrierTimeBeforeRank0    | 20.446 us                 | 16.486 ms                 |
| AfterBackward             | 18.171 ms                 | 23.736 ms                 |
| BlockToStepN              | 13.990 ms                 | 39.832 ms                 |
| OneStep                   | 47.330 ms                 | 80.981 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240129 16:55:34.064661 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=468, pq.top=468
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.400 ms                  | 2.294 ms                  |
| ProcessBack:UpdateCache   | 911.962 us                | 1.465 ms                  |
| ProcessBack:UpsertPq      | 14.066 ms                 | 20.180 ms                 |
| ProcessOneStep            | 18.145 ms                 | 23.710 ms                 |
| BlockToStepN              | 13.811 ms                 | 41.192 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240129 16:55:34.785033 2077204 parallel_pq_v2.h:76] insert failed, size(hashtable)=1286
W20240129 16:55:35.022356 2077715 grad_async_v2.h:121] Detect new sample comes, old_end5, new_end6
W20240129 16:55:35.064450 2077204 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=486, pq.top=486
E20240129 16:55:35.785009 2077714 parallel_pq_v2.h:76] insert failed, size(hashtable)=3286
[proc 2] 500 steps, total: 5.385, sample: 0.343, forward: 0.348, backward: 0.270, update: 0.149
[proc 0] 500 steps, total: 5.385, sample: 0.386, forward: 0.360, backward: 0.292, update: 0.143
[proc 1] 500 steps, total: 5.385, sample: 0.328, forward: 0.350, backward: 0.285, update: 0.154
Successfully xmh. training takes 26.05630087852478 seconds
before call kg_cache_controller.StopThreads()
W20240129 16:55:35.799088 2077204 grad_async_v2.h:71] call StopThreads. PID = 2076836
W20240129 16:55:35.799116 2077204 grad_base.h:212] before processOneStepNegThread_.join();
W20240129 16:55:35.799340 2077204 grad_base.h:214] after processOneStepNegThread_.join();
W20240129 16:55:35.799348 2077204 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
W20240129 16:55:35.808904 2077204 grad_async_v2.h:92] StopThreads done.
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f2b001f0750>
