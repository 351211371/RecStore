WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240129 16:58:11.948606 2086209 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_185', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=3, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=3, gpu=[0, 1, 2], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2086209 sampler.py:454] Start PreSampling
WARNING [2086209 sampler.py:532] Before construct renumbering_dict
WARNING [2086209 sampler.py:555] PreSampling done
W20240129 16:58:14.698185 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240129 16:58:14.698340 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240129 16:58:14.698374 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240129 16:58:14.698400 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240129 16:58:14.698426 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240129 16:58:14.698446 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240129 16:58:14.698464 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240129 16:58:14.698496 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240129 16:58:14.698523 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240129 16:58:14.698547 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240129 16:58:14.698570 2086209 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240129 16:58:14.698590 2086209 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240129 16:58:14.698611 2086209 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240129 16:58:14.698711 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240129 16:58:14.698736 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240129 16:58:14.698758 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240129 16:58:14.698796 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240129 16:58:14.698819 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240129 16:58:14.698837 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240129 16:58:14.698858 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240129 16:58:14.698884 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240129 16:58:14.698906 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240129 16:58:14.698927 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240129 16:58:14.698948 2086209 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240129 16:58:14.698964 2086209 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240129 16:58:14.698982 2086209 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240129 16:58:14.699018 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240129 16:58:14.699038 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240129 16:58:14.699056 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240129 16:58:14.699074 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240129 16:58:14.699095 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240129 16:58:14.699116 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240129 16:58:14.699141 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240129 16:58:14.699159 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240129 16:58:14.699177 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240129 16:58:14.699203 2086209 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240129 16:58:14.699223 2086209 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240129 16:58:14.699239 2086209 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240129 16:58:14.699257 2086209 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
{0: Graph(num_nodes=11296, num_edges=176344,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12898, num_edges=253277,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=12169, num_edges=314310,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 11296 N 176344 E
MertisPartition: part 1 has 12898 N 253277 E
MertisPartition: part 2 has 12169 N 314310 E
Rank0: cached key size 249
Rank1: cached key size 249
Rank2: cached key size 249
Before renumbering graph:  {'_ID': tensor([    0,     2,    10,  ...,  8580,   176, 12835]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 2, 2])}
After renumbering graph:  {'_ID': tensor([ 769,  830, 1136,  ..., 6720, 7252, 8707]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 2, 2])}
part_g: DGLGraph(num_nodes=11296, num_edges=176344,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=11296, num_edges=176344,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.926 seconds
[Rank1] pid = 2086733
INFO [2086209 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2086798 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2086798 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [2086733 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2086733 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [2086209 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
E20240129 16:58:17.789111 2086825 recstore.cc:66] init folly done
E20240129 16:58:17.789328 2086734 recstore.cc:66] init folly done
E20240129 16:58:17.789418 2086799 recstore.cc:66] init folly done
I20240129 16:58:17.829787 2086825 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 3
I20240129 16:58:17.867821 2086799 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
I20240129 16:58:17.872045 2086734 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
[Rank2] pid = 2086798
train_sampler.Prefill()
-------Step 0-------
tensor([   24, 14772,    52, 10299, 10794,  1873, 10413, 14333, 13752,   604]) tensor([ 1136,  8815,  7000, 11103, 11645,  9793,  6344,  4990,  5269,  6016])
-------Step 1-------
tensor([   24, 14772,    52, 10299, 10794,  1873, 10413, 14333, 13752,   604]) tensor([ 2142,  7695,  9495,  2980, 10971, 10172,  5110, 14385, 14763, 14681])
-------Step 2-------
tensor([10437,  7431, 12647,   175,  9048,  5481,  4091,  6551,  9966,  1781]) tensor([8182, 7792,  673, 9041, 5053, 3254, 1657, 1112, 3466, 2935])
-------Step 3-------
tensor([10437,  7431, 12647,   175,  9048,  5481,  4091,  6551,  9966,  1781]) tensor([ 8572,  9450,  6205, 11895,  7455,  9051,  8765,  4067,  4714,  5581])
-------Step 4-------
tensor([12043,  7699,  9120,    77,  9318,  1169,  7785, 12122,   225,  5816]) tensor([13032,  5857,  3073,  5232,  6319,  2290,  9675,  2141,  6072,  6919])
-------Step 5-------
tensor([12043,  7699,  9120,    77,  9318,  1169,  7785, 12122,   225,  5816]) tensor([13134,  5934, 12980, 12738,  8759,  9079,  3558,  5363, 10046, 10763])
-------Step 6-------
tensor([ 5839, 10221,  1873,  2668, 13629,  7966,  2934,   234,    95,  8581]) tensor([13165,   553, 11646,  1261,  4651,  2861, 11003,  8992, 13264,  8453])
-------Step 7-------
tensor([ 5839, 10221,  1873,  2668, 13629,  7966,  2934,   234,    95,  8581]) tensor([14809,  8895,   121, 13591, 14911,  9208,  9541,  9090, 11976, 10910])
-------Step 8-------
tensor([ 1409,  9226,  6172, 12893,  6309,  1042,  2185, 14302,  9824,  7339]) tensor([ 8095, 10573,  7173,  3802,  2550, 13582, 10123,  6069,  4673,   574])
-------Step 9-------
tensor([ 1409,  9226,  6172, 12893,  6309,  1042,  2185, 14302,  9824,  7339]) tensor([ 6256,  2364,  1363,  8635,  8632,  7759, 13354,  4183,  4249, 13633])
before start barrier
start train
[proc 0] 100 steps, total: 4.021, sample: 0.247, forward: 1.418, backward: 1.582, update: 0.532
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.017, sample: 0.218, forward: 1.377, backward: 1.626, update: 0.531
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 4.059, sample: 0.251, forward: 1.363, backward: 1.467, update: 0.523
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 803.822 us                | 19.113 ms                 |
| Forward                   | 6.618 ms                  | 16.472 ms                 |
| Backward                  | 3.116 ms                  | 240.616 ms                |
| Optimize                  | 5.150 ms                  | 12.977 ms                 |
| OneStep                   | 16.492 ms                 | 1.099 s                   |
+---------------------------+---------------------------+---------------------------+
[proc 1] 200 steps, total: 1.916, sample: 0.252, forward: 0.634, backward: 0.302, update: 0.546
[proc 2] 200 steps, total: 1.916, sample: 0.267, forward: 0.648, backward: 0.305, update: 0.512
[proc 0] 200 steps, total: 1.916, sample: 0.259, forward: 0.651, backward: 0.307, update: 0.523
[proc 2] 300 steps, total: 1.878, sample: 0.231, forward: 0.623, backward: 0.300, update: 0.492
[proc 1] 300 steps, total: 1.878, sample: 0.202, forward: 0.588, backward: 0.299, update: 0.507
[proc 0] 300 steps, total: 1.878, sample: 0.231, forward: 0.637, backward: 0.294, update: 0.505
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 841.919 us                | 18.012 ms                 |
| Forward                   | 6.609 ms                  | 9.733 ms                  |
| Backward                  | 3.141 ms                  | 3.593 ms                  |
| Optimize                  | 5.206 ms                  | 7.842 ms                  |
| OneStep                   | 17.367 ms                 | 34.645 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 2.258, sample: 0.274, forward: 0.620, backward: 0.311, update: 0.523
[proc 0] 400 steps, total: 2.258, sample: 0.285, forward: 0.629, backward: 0.306, update: 0.508
[proc 2] 400 steps, total: 2.258, sample: 0.272, forward: 0.635, backward: 0.305, update: 0.513
[proc 1] 500 steps, total: 2.311, sample: 0.285, forward: 0.642, backward: 0.296, update: 0.553
[proc 2] 500 steps, total: 2.311, sample: 0.292, forward: 0.656, backward: 0.309, update: 0.519
[proc 0] 500 steps, total: 2.311, sample: 0.270, forward: 0.666, backward: 0.313, update: 0.536
Successfully xmh. training takes 12.384647607803345 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
