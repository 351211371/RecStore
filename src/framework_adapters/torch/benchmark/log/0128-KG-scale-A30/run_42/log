WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240129 15:33:12.353940 1950115 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_151', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.1, shuffle=False, backwardMode='CppAsyncV2', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [1950115 sampler.py:454] Start PreSampling
WARNING [1950115 sampler.py:532] Before construct renumbering_dict
WARNING [1950115 sampler.py:555] PreSampling done
W20240129 15:33:15.262254 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240129 15:33:15.262382 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240129 15:33:15.262408 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240129 15:33:15.262430 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240129 15:33:15.262451 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240129 15:33:15.262468 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240129 15:33:15.262485 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240129 15:33:15.262506 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240129 15:33:15.262527 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240129 15:33:15.262543 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240129 15:33:15.262566 1950115 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240129 15:33:15.262584 1950115 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240129 15:33:15.262599 1950115 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240129 15:33:15.262682 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240129 15:33:15.262702 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240129 15:33:15.262718 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240129 15:33:15.262750 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240129 15:33:15.262768 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240129 15:33:15.262787 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240129 15:33:15.262802 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240129 15:33:15.262817 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240129 15:33:15.262835 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240129 15:33:15.262853 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240129 15:33:15.262872 1950115 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240129 15:33:15.262887 1950115 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240129 15:33:15.262902 1950115 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240129 15:33:15.262940 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240129 15:33:15.262961 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240129 15:33:15.262976 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240129 15:33:15.262991 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240129 15:33:15.263006 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240129 15:33:15.263021 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240129 15:33:15.263036 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240129 15:33:15.263054 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240129 15:33:15.263073 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240129 15:33:15.263092 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240129 15:33:15.263108 1950115 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240129 15:33:15.263121 1950115 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240129 15:33:15.263134 1950115 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240129 15:33:15.263164 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_0 [1000000]0x10000e52e000 7.629 MB
W20240129 15:33:15.263185 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_1 [1000000]0x10000ecd1000 7.629 MB
W20240129 15:33:15.263200 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_2 [1000000]0x10000f474000 7.629 MB
W20240129 15:33:15.263216 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_3 [1000000]0x10000fc17000 7.629 MB
W20240129 15:33:15.263233 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_4 [1000000]0x1000103ba000 7.629 MB
W20240129 15:33:15.263252 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_5 [1000000]0x100010b5d000 7.629 MB
W20240129 15:33:15.263269 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_6 [1000000]0x100011300000 7.629 MB
W20240129 15:33:15.263286 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_7 [1000000]0x100011aa3000 7.629 MB
W20240129 15:33:15.263304 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_8 [1000000]0x100012246000 7.629 MB
W20240129 15:33:15.263324 1950115 IPCTensor.h:369] NewIPCTensor: cached_sampler_r3_9 [1000000]0x1000129e9000 7.629 MB
W20240129 15:33:15.263338 1950115 IPCTensor.h:369] NewIPCTensor: step_r3 [10]0x10001318c000 80 B 
W20240129 15:33:15.263352 1950115 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r3 [1]0x10001318e000 8 B 
W20240129 15:33:15.263375 1950115 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100013190000 8 B 
W20240129 15:33:15.386713 1950115 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x100013192000 22.81 MB
W20240129 15:33:15.386839 1950115 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100014864000 58.4 kB
{0: Graph(num_nodes=10523, num_edges=182012,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=10996, num_edges=244360,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=9404, num_edges=143355,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10954, num_edges=175447,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 10523 N 182012 E
MertisPartition: part 1 has 10996 N 244360 E
MertisPartition: part 2 has 9404 N 143355 E
MertisPartition: part 3 has 10954 N 175447 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    5,    14,    17,  ..., 11245,  2040,  3009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
After renumbering graph:  {'_ID': tensor([1603, 1834, 1915,  ..., 2371, 6179, 7393]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 3, 3])}
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=10523, num_edges=182012,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.063 seconds
[Rank1] pid = 1950453
[Rank2] pid = 1950518
INFO [1950115 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [1950453 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [1950582 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [1950582 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [1950518 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [1950518 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240129 15:33:18.650179 1950584 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_3 [1495, 400]; dev=3; size=2.281 MB
INFO [1950453 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240129 15:33:18.650632 1950584 IPCTensor.h:369] NewIPCTensor: input_keys_3 [1000000]0x100014876000 7.629 MB
W20240129 15:33:18.650758 1950584 IPCTensor.h:369] NewIPCTensor: input_keys_neg_3 [1000000]0x100015019000 7.629 MB
W20240129 15:33:18.650806 1950584 IPCTensor.h:369] NewIPCTensor: backward_grads_3 [1000000, 400]0x1000157bc000 1.49 GB
W20240129 15:33:18.650838 1950584 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_3 [1000000, 400]0x100074d9f000 1.49 GB
W20240129 15:33:18.650882 1950584 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240129 15:33:18.651286 1950454 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [1495, 400]; dev=1; size=2.281 MB
W20240129 15:33:18.651716 1950519 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [1495, 400]; dev=2; size=2.281 MB
W20240129 15:33:18.653035 1950584 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_3_gpu [1000000, 400]; dev=3; size=1.49 GB
W20240129 15:33:18.653100 1950454 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x1000d4388000 7.629 MB
W20240129 15:33:18.653206 1950454 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x1000d4b2b000 7.629 MB
W20240129 15:33:18.653247 1950454 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x1000d52ce000 1.49 GB
W20240129 15:33:18.653285 1950454 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x1001348b1000 1.49 GB
W20240129 15:33:18.653299 1950519 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x100193e94000 7.629 MB
W20240129 15:33:18.653326 1950454 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240129 15:33:18.653537 1950519 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x100194637000 7.629 MB
W20240129 15:33:18.653653 1950519 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x100194dda000 1.49 GB
W20240129 15:33:18.653740 1950519 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x1001f43bd000 1.49 GB
W20240129 15:33:18.653815 1950519 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
INFO [1950115 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
W20240129 15:33:18.656476 1950583 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [1495, 400]; dev=0; size=2.281 MB
W20240129 15:33:18.660785 1950454 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240129 15:33:18.660822 1950583 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x1002539a8000 7.629 MB
W20240129 15:33:18.660892 1950583 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x10025414b000 7.629 MB
W20240129 15:33:18.660889 1950519 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240129 15:33:18.660923 1950583 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x1002548ee000 1.49 GB
W20240129 15:33:18.660960 1950583 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1002b3ed1000 1.49 GB
W20240129 15:33:18.660984 1950583 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240129 15:33:18.669471 1950583 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
cudaHostRegister 0x100013192000
3: KnownLocalCachedEmbedding init done
WARNING [1950582 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
1: KnownLocalCachedEmbedding init done
WARNING [1950453 DistTensor.py:56] The tensor name already exists in the kvstore
[Rank3] pid = 1950582
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1495), (1495, 2990), (2990, 4485), (4485, 5980)]
cudaHostRegister 0x100013192000
0: KnownLocalCachedEmbedding init done
WARNING [1950115 DistTensor.py:56] The tensor name already exists in the kvstore
cudaHostRegister 0x100013192000
2: KnownLocalCachedEmbedding init done
WARNING [1950518 DistTensor.py:56] The tensor name already exists in the kvstore
I20240129 15:33:19.958559 1950519 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 4
I20240129 15:33:19.958657 1950454 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240129 15:33:19.958752 1950583 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
I20240129 15:33:19.959017 1950584 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 4
W20240129 15:33:19.960500 1950583 grad_base.h:55] KGCacheController, config={
        "num_gpus": 4,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.1,
        "update_cache_use_omp":  0,
        "update_pq_use_omp":  0
        }
W20240129 15:33:19.960608 1950583 grad_base.h:184] Init GradProcessingBase done
I20240129 15:33:19.964893 1950583 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240129 15:33:19.965000 1950583 kg_controller.h:78] after init GradAsyncProcessingV2
I20240129 15:33:19.965006 1950583 kg_controller.h:84] Construct KGCacheController done
E20240129 15:33:21.334569 1950583 recstore.cc:66] init folly done
E20240129 15:33:21.334575 1950454 recstore.cc:66] init folly done
E20240129 15:33:21.334723 1950519 recstore.cc:66] init folly done
E20240129 15:33:21.334723 1950584 recstore.cc:66] init folly done
I20240129 15:33:21.335297 1950583 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240129 15:33:22.022783 1951047 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
E20240129 15:33:22.023226 1951047 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240129 15:33:22.041261 1950584 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240129 15:33:22.044118 1950519 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240129 15:33:22.048285 1950583 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240129 15:33:22.049333 1950454 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
E20240129 15:33:24.719363 1950583 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
W20240129 15:33:24.727700 1951047 grad_async_v2.h:121] Detect new sample comes, old_end1, new_end2
W20240129 15:33:24.748780 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=2, pq.top=0
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 727.483 us                | 8.671 ms                  |
| Forward                   | 2.688 ms                  | 925.337 ms                |
| Backward                  | 2.347 ms                  | 258.190 ms                |
| Optimize                  | 846.683 us                | 2.319 ms                  |
| BarrierTimeBeforeRank0    | 707.476 us                | 408.287 ms                |
| AfterBackward             | 10.760 ms                 | 1.081 s                   |
| BlockToStepN              | 39.434 us                 | 6.152 ms                  |
| OneStep                   | 22.633 ms                 | 2.677 s                   |
+---------------------------+---------------------------+---------------------------+
E20240129 15:33:25.719126 1950773 parallel_pq_v2.h:76] insert failed, size(hashtable)=300
W20240129 15:33:25.729305 1951047 grad_async_v2.h:121] Detect new sample comes, old_end2, new_end3
W20240129 15:33:25.748024 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=43, pq.top=43
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 2.100 ms                  | 92.258 ms                 |
| ProcessBack:UpdateCache   | 2.461 ms                  | 196.833 ms                |
| ProcessBack:UpsertPq      | 9.166 ms                  | 10.953 ms                 |
| ProcessOneStep            | 14.435 ms                 | 19.491 ms                 |
| BlockToStepN              | 2.445 ms                  | 5.994 ms                  |
+---------------------------+---------------------------+---------------------------+
E20240129 15:33:26.719197 1951046 parallel_pq_v2.h:76] insert failed, size(hashtable)=8930
W20240129 15:33:26.741328 1951047 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240129 15:33:26.763062 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=81, pq.top=81
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 5.234, sample: 0.164, forward: 1.467, backward: 0.534, update: 0.079
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 5.239, sample: 0.158, forward: 1.505, backward: 0.577, update: 0.070
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 5.242, sample: 0.166, forward: 1.407, backward: 0.572, update: 0.073
train_sampler.Prefill()
-------Step 0-------
tensor([ 8866,  4804,  9426,  7221,  8852,  4937, 10487,  5683, 12175,   164]) tensor([ 1915,  8206,  9498,  1274,  7665,  8467, 13197,  8763,  7989,  1250])
-------Step 1-------
tensor([ 8866,  4804,  9426,  7221,  8852,  4937, 10487,  5683, 12175,   164]) tensor([ 7622, 10912, 14081,  1736, 10875, 10691,  2339, 11118,  7335,  8503])
-------Step 2-------
tensor([ 6475, 13273,  7197,  5282,  5455,  8742, 10323,  9600, 11591,   222]) tensor([10110,  3397,  2579, 11484,  5277,  1321,  6731,  5108, 11398,  6201])
-------Step 3-------
tensor([ 6475, 13273,  7197,  5282,  5455,  8742, 10323,  9600, 11591,   222]) tensor([ 6021, 11034,  7219, 11856,  7746,  2178,  9619, 11608, 11077, 12381])
-------Step 4-------
tensor([ 8802,  2875,  3965,    10,   718,   282,   178, 10779, 10459,  8203]) tensor([10359,  4190,  3928, 13663,  2259,  2739, 11961,  5924, 12704,  7482])
-------Step 5-------
tensor([ 8802,  2875,  3965,    10,   718,   282,   178, 10779, 10459,  8203]) tensor([ 6859, 12030,  5724,  8083, 11075,  7630,  5434,  3826,  8366, 14637])
-------Step 6-------
tensor([ 9344, 11920,  5571,  7880,  2084,  7726,  7687,  3016, 13393,    23]) tensor([ 7696,  5717,  3863, 10089,  7427,  1376,  4655, 12194, 12561,  3965])
-------Step 7-------
tensor([ 9344, 11920,  5571,  7880,  2084,  7726,  7687,  3016, 13393,    23]) tensor([ 6219,  7623,  8684, 10072,  1116,   108, 14663, 10464,  4770,   811])
-------Step 8-------
tensor([ 3435, 14857, 10859, 10521,  5485,  5571, 13151,  7165,  4345,  2108]) tensor([14340,   932, 10546, 10613,  4098,   623,  6647,  1048,  9731, 14671])
-------Step 9-------
tensor([ 3435, 14857, 10859, 10521,  5485,  5571, 13151,  7165,  4345,  2108]) tensor([14742, 11506, 12955,   928, 12115,  9279,  6776,  2434,  7153,  9620])
before start barrier
start train
[proc 0] 100 steps, total: 5.235, sample: 0.161, forward: 1.169, backward: 0.485, update: 0.081
E20240129 15:33:27.719013 1950583 parallel_pq_v2.h:76] insert failed, size(hashtable)=203
W20240129 15:33:27.762952 1951047 grad_async_v2.h:121] Detect new sample comes, old_end7, new_end8
W20240129 15:33:27.786188 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=118, pq.top=118
E20240129 15:33:28.719007 1951046 parallel_pq_v2.h:76] insert failed, size(hashtable)=9832
W20240129 15:33:28.765348 1951047 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
W20240129 15:33:28.786008 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=155, pq.top=155
E20240129 15:33:29.719022 1951046 parallel_pq_v2.h:76] insert failed, size(hashtable)=10807
W20240129 15:33:29.769402 1951047 grad_async_v2.h:121] Detect new sample comes, old_end5, new_end6
W20240129 15:33:29.795724 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=197, pq.top=197
[proc 1] 200 steps, total: 2.614, sample: 0.174, forward: 0.242, backward: 0.217, update: 0.068
[proc 3] 200 steps, total: 2.614, sample: 0.184, forward: 0.249, backward: 0.242, update: 0.068
[proc 2] 200 steps, total: 2.614, sample: 0.168, forward: 0.234, backward: 0.228, update: 0.067
[proc 0] 200 steps, total: 2.614, sample: 0.154, forward: 0.229, backward: 0.248, update: 0.072
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 815.542 us                | 8.699 ms                  |
| Forward                   | 2.396 ms                  | 4.814 ms                  |
| Backward                  | 2.360 ms                  | 4.774 ms                  |
| Optimize                  | 799.182 us                | 1.375 ms                  |
| BarrierTimeBeforeRank0    | 131.011 us                | 3.793 ms                  |
| AfterBackward             | 13.055 ms                 | 16.642 ms                 |
| BlockToStepN              | 4.725 ms                  | 12.516 ms                 |
| OneStep                   | 25.460 ms                 | 38.533 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240129 15:33:30.719009 1951047 parallel_pq_v2.h:76] insert failed, size(hashtable)=232
W20240129 15:33:30.775780 1951047 grad_async_v2.h:121] Detect new sample comes, old_end8, new_end9
W20240129 15:33:30.798939 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=229, pq.top=229
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.846 ms                  | 2.302 ms                  |
| ProcessBack:UpdateCache   | 1.745 ms                  | 4.902 ms                  |
| ProcessBack:UpsertPq      | 7.553 ms                  | 12.474 ms                 |
| ProcessOneStep            | 13.311 ms                 | 19.491 ms                 |
| BlockToStepN              | 5.003 ms                  | 12.502 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240129 15:33:31.719014 1951046 parallel_pq_v2.h:76] insert failed, size(hashtable)=10875
W20240129 15:33:31.798038 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=264, pq.top=264
W20240129 15:33:31.803786 1951047 grad_async_v2.h:121] Detect new sample comes, old_end4, new_end5
E20240129 15:33:32.719017 1951046 parallel_pq_v2.h:76] insert failed, size(hashtable)=10532
[proc 3] 300 steps, total: 2.896, sample: 0.172, forward: 0.250, backward: 0.249, update: 0.070
[proc 1] 300 steps, total: 2.896, sample: 0.165, forward: 0.251, backward: 0.229, update: 0.077
[proc 2] 300 steps, total: 2.896, sample: 0.175, forward: 0.252, backward: 0.246, update: 0.071
[proc 0] 300 steps, total: 2.896, sample: 0.226, forward: 0.289, backward: 0.234, update: 0.083
W20240129 15:33:32.803014 1951047 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240129 15:33:32.811098 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=301, pq.top=301
E20240129 15:33:33.719014 1951046 parallel_pq_v2.h:76] insert failed, size(hashtable)=10887
W20240129 15:33:33.805130 1951047 grad_async_v2.h:121] Detect new sample comes, old_end6, new_end7
W20240129 15:33:33.813514 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=337, pq.top=337
E20240129 15:33:34.719009 1951046 parallel_pq_v2.h:76] insert failed, size(hashtable)=9612
W20240129 15:33:34.805177 1951047 grad_async_v2.h:121] Detect new sample comes, old_end0, new_end1
W20240129 15:33:34.819077 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=371, pq.top=371
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 989.173 us                | 9.654 ms                  |
| Forward                   | 2.744 ms                  | 4.373 ms                  |
| Backward                  | 2.362 ms                  | 4.793 ms                  |
| Optimize                  | 811.196 us                | 2.179 ms                  |
| BarrierTimeBeforeRank0    | 23.231 us                 | 3.402 ms                  |
| AfterBackward             | 11.421 ms                 | 17.670 ms                 |
| BlockToStepN              | 5.952 ms                  | 14.574 ms                 |
| OneStep                   | 26.822 ms                 | 42.220 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 3] 400 steps, total: 2.873, sample: 0.167, forward: 0.240, backward: 0.241, update: 0.069
[proc 2] 400 steps, total: 2.873, sample: 0.138, forward: 0.220, backward: 0.248, update: 0.079
[proc 1] 400 steps, total: 2.873, sample: 0.158, forward: 0.237, backward: 0.267, update: 0.067
[proc 0] 400 steps, total: 2.873, sample: 0.212, forward: 0.280, backward: 0.237, update: 0.080
E20240129 15:33:35.719022 1951046 parallel_pq_v2.h:76] insert failed, size(hashtable)=8238
W20240129 15:33:35.808311 1951047 grad_async_v2.h:121] Detect new sample comes, old_end5, new_end6
W20240129 15:33:35.826974 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=406, pq.top=406
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 1.855 ms                  | 2.228 ms                  |
| ProcessBack:UpdateCache   | 1.583 ms                  | 2.751 ms                  |
| ProcessBack:UpsertPq      | 7.094 ms                  | 12.204 ms                 |
| ProcessOneStep            | 11.328 ms                 | 17.649 ms                 |
| BlockToStepN              | 6.185 ms                  | 14.515 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240129 15:33:36.719058 1951047 parallel_pq_v2.h:76] insert failed, size(hashtable)=299
W20240129 15:33:36.814080 1951047 grad_async_v2.h:121] Detect new sample comes, old_end9, new_end0
W20240129 15:33:36.833845 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=440, pq.top=440
E20240129 15:33:37.719017 1950583 parallel_pq_v2.h:76] insert failed, size(hashtable)=101
W20240129 15:33:37.832617 1951047 grad_async_v2.h:121] Detect new sample comes, old_end3, new_end4
W20240129 15:33:37.851308 1950583 grad_async_v2.h:250] Sleep in <BlockToStepN>, step_no=474, pq.top=474
[proc 1] 500 steps, total: 2.973, sample: 0.158, forward: 0.237, backward: 0.209, update: 0.070
[proc 0] 500 steps, total: 2.973, sample: 0.213, forward: 0.278, backward: 0.233, update: 0.074
[proc 3] 500 steps, total: 2.973, sample: 0.155, forward: 0.235, backward: 0.250, update: 0.068
[proc 2] 500 steps, total: 2.973, sample: 0.167, forward: 0.231, backward: 0.249, update: 0.066
Successfully xmh. training takes 16.590739727020264 seconds
before call kg_cache_controller.StopThreads()
W20240129 15:33:38.639061 1950583 grad_async_v2.h:71] call StopThreads. PID = 1950115
W20240129 15:33:38.639091 1950583 grad_base.h:212] before processOneStepNegThread_.join();
W20240129 15:33:38.639485 1950583 grad_base.h:214] after processOneStepNegThread_.join();
W20240129 15:33:38.639497 1950583 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
W20240129 15:33:38.642318 1950583 grad_async_v2.h:92] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker3: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
