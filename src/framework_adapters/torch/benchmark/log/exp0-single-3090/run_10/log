Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 3 parts
part 0 has 101575884 edges
part 1 has 101575884 edges
part 2 has 101575882 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=3, num_proc=3, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_Freebase_2', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 736.577 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 2][Train](1000/10000) average pos_loss: 0.6667843103706836
[proc 2][Train](1000/10000) average neg_loss: 0.690374690592289
[proc 2][Train](1000/10000) average loss: 0.6785795013904572
[proc 2][Train](1000/10000) average regularization: 7.875671927195072e-06
[proc 2] 1000 steps, total: 44.686, sample: 22.780, forward: 12.616, backward: 2.902, update: 6.380
[proc 0][Train](1000/10000) average pos_loss: 0.6720333356261253
[proc 0][Train](1000/10000) average neg_loss: 0.6936003466844559
[proc 0][Train](1000/10000) average loss: 0.682816839993
[proc 0][Train](1000/10000) average regularization: 7.777708931371308e-06
[proc 0] 1000 steps, total: 45.723, sample: 21.996, forward: 12.077, backward: 2.833, update: 6.499
[proc 1][Train](1000/10000) average pos_loss: 0.6677021408677101
[proc 1][Train](1000/10000) average neg_loss: 0.6975012258291244
[proc 1][Train](1000/10000) average loss: 0.6826016836166382
[proc 1][Train](1000/10000) average regularization: 7.734827990361737e-06
[proc 1] 1000 steps, total: 45.191, sample: 20.950, forward: 12.919, backward: 2.840, update: 6.466
[proc 1][Train](2000/10000) average pos_loss: 0.6793258047103882
[proc 1][Train](2000/10000) average neg_loss: 0.6838488430380821
[proc 1][Train](2000/10000) average loss: 0.6815873229503632
[proc 1][Train](2000/10000) average regularization: 7.71609080993585e-06
[proc 1] 2000 steps, total: 19.138, sample: 2.311, forward: 7.512, backward: 2.763, update: 6.544
[proc 2][Train](2000/10000) average pos_loss: 0.6792084688544273
[proc 2][Train](2000/10000) average neg_loss: 0.6836357867717743
[proc 2][Train](2000/10000) average loss: 0.6814221270084381
[proc 2][Train](2000/10000) average regularization: 7.717650511949614e-06
[proc 2] 2000 steps, total: 19.141, sample: 2.364, forward: 7.383, backward: 2.900, update: 6.085
[proc 0][Train](2000/10000) average pos_loss: 0.6798920342922211
[proc 0][Train](2000/10000) average neg_loss: 0.6852559364438057
[proc 0][Train](2000/10000) average loss: 0.6825739848017692
[proc 0][Train](2000/10000) average regularization: 7.731436085123278e-06
[proc 0] 2000 steps, total: 19.140, sample: 2.265, forward: 7.006, backward: 2.791, update: 6.306
[proc 1][Train](3000/10000) average pos_loss: 0.688948518037796
[proc 1][Train](3000/10000) average neg_loss: 0.6803886198997497
[proc 1][Train](3000/10000) average loss: 0.6846685703396798
[proc 1][Train](3000/10000) average regularization: 6.845716740372154e-06
[proc 1] 3000 steps, total: 17.707, sample: 2.287, forward: 6.367, backward: 2.540, update: 6.504
[proc 2][Train](3000/10000) average pos_loss: 0.6891944535970688
[proc 2][Train](3000/10000) average neg_loss: 0.6810601863861084
[proc 2][Train](3000/10000) average loss: 0.6851273208260537
[proc 2][Train](3000/10000) average regularization: 6.8491280721900695e-06
[proc 2] 3000 steps, total: 17.707, sample: 2.280, forward: 6.316, backward: 2.841, update: 6.078
[proc 0][Train](3000/10000) average pos_loss: 0.6895801275968552
[proc 0][Train](3000/10000) average neg_loss: 0.6807234531641007
[proc 0][Train](3000/10000) average loss: 0.6851517909169197
[proc 0][Train](3000/10000) average regularization: 6.8594644221775525e-06
[proc 0] 3000 steps, total: 17.707, sample: 2.313, forward: 5.898, backward: 2.773, update: 6.388
[proc 2][Train](4000/10000) average pos_loss: 0.6954366937279701
[proc 2][Train](4000/10000) average neg_loss: 0.6761143256425858
[proc 2][Train](4000/10000) average loss: 0.6857755091190338
[proc 2][Train](4000/10000) average regularization: 6.420445778530848e-06
[proc 2] 4000 steps, total: 17.285, sample: 2.370, forward: 5.922, backward: 2.858, update: 6.127
[proc 0][Train](4000/10000) average pos_loss: 0.6953965328931808
[proc 0][Train](4000/10000) average neg_loss: 0.6765785843133927
[proc 0][Train](4000/10000) average loss: 0.6859875582456588
[proc 0][Train](4000/10000) average regularization: 6.41595921570115e-06
[proc 0] 4000 steps, total: 17.285, sample: 2.344, forward: 5.631, backward: 2.814, update: 6.331
[proc 1][Train](4000/10000) average pos_loss: 0.6955855730772018
[proc 1][Train](4000/10000) average neg_loss: 0.676173668384552
[proc 1][Train](4000/10000) average loss: 0.6858796216845512
[proc 1][Train](4000/10000) average regularization: 6.4191990732069825e-06
[proc 1] 4000 steps, total: 17.286, sample: 2.254, forward: 5.840, backward: 2.679, update: 6.393
[proc 2][Train](5000/10000) average pos_loss: 0.7008747899532318
[proc 2][Train](5000/10000) average neg_loss: 0.6707456594705582
[proc 2][Train](5000/10000) average loss: 0.685810224533081
[proc 2][Train](5000/10000) average regularization: 6.370011343733495e-06
[proc 2] 5000 steps, total: 17.027, sample: 2.403, forward: 5.754, backward: 2.833, update: 6.029
[proc 1][Train](5000/10000) average pos_loss: 0.6995909999012947
[proc 1][Train](5000/10000) average neg_loss: 0.6704601400494575
[proc 1][Train](5000/10000) average loss: 0.6850255695581436
[proc 1][Train](5000/10000) average regularization: 6.371692599259404e-06
[proc 1] 5000 steps, total: 17.027, sample: 2.335, forward: 5.591, backward: 2.730, update: 6.328
[proc 0][Train](5000/10000) average pos_loss: 0.6997288833260537
[proc 0][Train](5000/10000) average neg_loss: 0.6713439765572548
[proc 0][Train](5000/10000) average loss: 0.6855364288687706
[proc 0][Train](5000/10000) average regularization: 6.369523375269636e-06
[proc 0] 5000 steps, total: 17.028, sample: 2.437, forward: 5.408, backward: 2.757, update: 6.201
[proc 2][Train](6000/10000) average pos_loss: 0.7028257857561111
[proc 2][Train](6000/10000) average neg_loss: 0.6643592318296433
[proc 2][Train](6000/10000) average loss: 0.6835925087332726
[proc 2][Train](6000/10000) average regularization: 6.425048267374223e-06
[proc 2] 6000 steps, total: 17.205, sample: 2.269, forward: 5.838, backward: 3.237, update: 5.853
[proc 1][Train](6000/10000) average pos_loss: 0.7037798207998276
[proc 1][Train](6000/10000) average neg_loss: 0.6641320633292198
[proc 1][Train](6000/10000) average loss: 0.6839559422731399
[proc 1][Train](6000/10000) average regularization: 6.427426448226469e-06
[proc 1] 6000 steps, total: 17.205, sample: 2.136, forward: 5.577, backward: 2.759, update: 6.191
[proc 0][Train](6000/10000) average pos_loss: 0.7037725864648819
[proc 0][Train](6000/10000) average neg_loss: 0.6654569554328919
[proc 0][Train](6000/10000) average loss: 0.6846147708892822
[proc 0][Train](6000/10000) average regularization: 6.4234206452056245e-06
[proc 0] 6000 steps, total: 17.205, sample: 2.285, forward: 5.348, backward: 2.814, update: 6.121
[proc 1][Train](7000/10000) average pos_loss: 0.7054917272925377
[proc 1][Train](7000/10000) average neg_loss: 0.6592319625616073
[proc 1][Train](7000/10000) average loss: 0.6823618434071541
[proc 1][Train](7000/10000) average regularization: 6.501393135295075e-06
[proc 1] 7000 steps, total: 16.831, sample: 2.193, forward: 5.633, backward: 2.751, update: 6.245
[proc 2][Train](7000/10000) average pos_loss: 0.7056203616261483
[proc 2][Train](7000/10000) average neg_loss: 0.658881283223629
[proc 2][Train](7000/10000) average loss: 0.6822508230805397
[proc 2][Train](7000/10000) average regularization: 6.504270058485418e-06
[proc 2] 7000 steps, total: 16.833, sample: 2.356, forward: 5.627, backward: 2.788, update: 5.957
[proc 0][Train](7000/10000) average pos_loss: 0.7064812005758285
[proc 0][Train](7000/10000) average neg_loss: 0.6592664248943328
[proc 0][Train](7000/10000) average loss: 0.6828738122582435
[proc 0][Train](7000/10000) average regularization: 6.497876493540389e-06
[proc 0] 7000 steps, total: 16.832, sample: 2.418, forward: 5.240, backward: 2.778, update: 6.140
[proc 1][Train](8000/10000) average pos_loss: 0.7079197959303856
[proc 1][Train](8000/10000) average neg_loss: 0.6537068117260932
[proc 1][Train](8000/10000) average loss: 0.6808133041858673
[proc 1][Train](8000/10000) average regularization: 6.59127338167309e-06
[proc 1] 8000 steps, total: 16.833, sample: 2.217, forward: 5.577, backward: 2.745, update: 6.286
[proc 2][Train](8000/10000) average pos_loss: 0.70794876152277
[proc 2][Train](8000/10000) average neg_loss: 0.6540100032091141
[proc 2][Train](8000/10000) average loss: 0.6809793829917907
[proc 2][Train](8000/10000) average regularization: 6.589539854758186e-06
[proc 2] 8000 steps, total: 16.833, sample: 2.319, forward: 5.689, backward: 2.811, update: 5.915
[proc 0][Train](8000/10000) average pos_loss: 0.7084363502860069
[proc 0][Train](8000/10000) average neg_loss: 0.6537038223147392
[proc 0][Train](8000/10000) average loss: 0.6810700869560242
[proc 0][Train](8000/10000) average regularization: 6.59096082290489e-06
[proc 0] 8000 steps, total: 16.834, sample: 2.350, forward: 5.369, backward: 2.745, update: 6.222
[proc 2][Train](9000/10000) average pos_loss: 0.7107471144199371
[proc 2][Train](9000/10000) average neg_loss: 0.6484372459053993
[proc 2][Train](9000/10000) average loss: 0.679592179775238
[proc 2][Train](9000/10000) average regularization: 6.682990652734588e-06
[proc 2] 9000 steps, total: 16.844, sample: 2.442, forward: 5.736, backward: 2.807, update: 5.852
[proc 1][Train](9000/10000) average pos_loss: 0.7098785133361817
[proc 1][Train](9000/10000) average neg_loss: 0.6477042294740677
[proc 1][Train](9000/10000) average loss: 0.6787913711667061
[proc 1][Train](9000/10000) average regularization: 6.682186765829102e-06
[proc 1] 9000 steps, total: 16.844, sample: 2.337, forward: 5.491, backward: 2.775, update: 6.191
[proc 0][Train](9000/10000) average pos_loss: 0.7095072681307792
[proc 0][Train](9000/10000) average neg_loss: 0.6476801157593727
[proc 0][Train](9000/10000) average loss: 0.6785936927795411
[proc 0][Train](9000/10000) average regularization: 6.679584841094766e-06
[proc 0] 9000 steps, total: 16.844, sample: 2.466, forward: 5.213, backward: 2.777, update: 5.925
[proc 2][Train](10000/10000) average pos_loss: 0.7113748877048492
[proc 2][Train](10000/10000) average neg_loss: 0.6412467256784439
[proc 2][Train](10000/10000) average loss: 0.6763108075261116
[proc 2][Train](10000/10000) average regularization: 6.7740731356025205e-06
[proc 2] 10000 steps, total: 16.567, sample: 2.261, forward: 5.622, backward: 2.881, update: 5.794
proc 2 takes 200.127 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.7092738002538681
[proc 1][Train](10000/10000) average neg_loss: 0.6423124150037766
[proc 1][Train](10000/10000) average loss: 0.6757931075096131
[proc 1][Train](10000/10000) average regularization: 6.772801924398664e-06
[proc 1] 10000 steps, total: 16.567, sample: 2.070, forward: 5.378, backward: 2.725, update: 6.095
proc 1 takes 200.632 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.7099819118976594
[proc 0][Train](10000/10000) average neg_loss: 0.6424169546365738
[proc 0][Train](10000/10000) average loss: 0.6761994336843491
[proc 0][Train](10000/10000) average regularization: 6.77313413552838e-06
[proc 0] 10000 steps, total: 16.566, sample: 2.305, forward: 5.321, backward: 2.798, update: 6.047
proc 0 takes 201.164 seconds
Successfully xmh. training takes 215.28842735290527 seconds
