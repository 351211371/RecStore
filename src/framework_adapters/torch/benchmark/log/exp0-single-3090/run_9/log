Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 2 parts
part 0 has 152363825 edges
part 1 has 152363825 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_Freebase_1', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 737.507 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.6694912853837013
[proc 0][Train](1000/10000) average neg_loss: 0.6939527835845948
[proc 0][Train](1000/10000) average loss: 0.6817220335006714
[proc 0][Train](1000/10000) average regularization: 6.781193700135191e-06
[proc 0] 1000 steps, total: 55.619, sample: 34.601, forward: 11.923, backward: 2.832, update: 6.256
[proc 1][Train](1000/10000) average pos_loss: 0.6670297056436538
[proc 1][Train](1000/10000) average neg_loss: 0.7013049873113633
[proc 1][Train](1000/10000) average loss: 0.6841673474907876
[proc 1][Train](1000/10000) average regularization: 6.630834289808263e-06
[proc 1] 1000 steps, total: 55.051, sample: 31.794, forward: 12.936, backward: 2.834, update: 6.495
[proc 1][Train](2000/10000) average pos_loss: 0.6709588701725007
[proc 1][Train](2000/10000) average neg_loss: 0.6856763395071029
[proc 1][Train](2000/10000) average loss: 0.6783176038265228
[proc 1][Train](2000/10000) average regularization: 7.251949539295311e-06
[proc 1] 2000 steps, total: 18.574, sample: 2.401, forward: 7.052, backward: 2.716, update: 6.399
[proc 0][Train](2000/10000) average pos_loss: 0.6714232279062271
[proc 0][Train](2000/10000) average neg_loss: 0.6864238125681877
[proc 0][Train](2000/10000) average loss: 0.6789235199093818
[proc 0][Train](2000/10000) average regularization: 7.253766156281927e-06
[proc 0] 2000 steps, total: 18.575, sample: 2.346, forward: 7.086, backward: 2.818, update: 6.251
[proc 1][Train](3000/10000) average pos_loss: 0.6803430098295212
[proc 1][Train](3000/10000) average neg_loss: 0.6838114176392556
[proc 1][Train](3000/10000) average loss: 0.6820772143602372
[proc 1][Train](3000/10000) average regularization: 7.023024167210679e-06
[proc 1] 3000 steps, total: 17.460, sample: 2.363, forward: 5.961, backward: 2.810, update: 6.319
[proc 0][Train](3000/10000) average pos_loss: 0.6813369094729423
[proc 0][Train](3000/10000) average neg_loss: 0.6836117561459542
[proc 0][Train](3000/10000) average loss: 0.6824743315577507
[proc 0][Train](3000/10000) average regularization: 7.020342035048088e-06
[proc 0] 3000 steps, total: 17.460, sample: 2.335, forward: 5.791, backward: 3.012, update: 6.008
[proc 1][Train](4000/10000) average pos_loss: 0.6877239224910736
[proc 1][Train](4000/10000) average neg_loss: 0.681855928838253
[proc 1][Train](4000/10000) average loss: 0.6847899259328842
[proc 1][Train](4000/10000) average regularization: 6.647649246133369e-06
[proc 1] 4000 steps, total: 16.572, sample: 2.226, forward: 5.498, backward: 2.762, update: 6.080
[proc 0][Train](4000/10000) average pos_loss: 0.6874835937619209
[proc 0][Train](4000/10000) average neg_loss: 0.6808291095495224
[proc 0][Train](4000/10000) average loss: 0.684156352519989
[proc 0][Train](4000/10000) average regularization: 6.65013602883846e-06
[proc 0] 4000 steps, total: 16.572, sample: 2.209, forward: 5.321, backward: 2.937, update: 5.884
[proc 1][Train](5000/10000) average pos_loss: 0.6930445531010627
[proc 1][Train](5000/10000) average neg_loss: 0.6776752544045448
[proc 1][Train](5000/10000) average loss: 0.6853599045872688
[proc 1][Train](5000/10000) average regularization: 6.3903351024237055e-06
[proc 1] 5000 steps, total: 16.918, sample: 2.495, forward: 5.532, backward: 2.718, update: 6.165
[proc 0][Train](5000/10000) average pos_loss: 0.6909948861002922
[proc 0][Train](5000/10000) average neg_loss: 0.677787347137928
[proc 0][Train](5000/10000) average loss: 0.6843911165595055
[proc 0][Train](5000/10000) average regularization: 6.387986152276426e-06
[proc 0] 5000 steps, total: 16.917, sample: 2.456, forward: 5.282, backward: 2.781, update: 6.081
[proc 1][Train](6000/10000) average pos_loss: 0.6960940657258033
[proc 1][Train](6000/10000) average neg_loss: 0.674873209297657
[proc 1][Train](6000/10000) average loss: 0.6854836366176605
[proc 1][Train](6000/10000) average regularization: 6.3012259806782825e-06
[proc 1] 6000 steps, total: 16.434, sample: 2.246, forward: 5.305, backward: 2.684, update: 6.176
[proc 0][Train](6000/10000) average pos_loss: 0.6960523535609245
[proc 0][Train](6000/10000) average neg_loss: 0.6749256910085678
[proc 0][Train](6000/10000) average loss: 0.6854890227913857
[proc 0][Train](6000/10000) average regularization: 6.299281107658317e-06
[proc 0] 6000 steps, total: 16.434, sample: 2.197, forward: 5.185, backward: 2.807, update: 5.838
[proc 1][Train](7000/10000) average pos_loss: 0.6987764384746552
[proc 1][Train](7000/10000) average neg_loss: 0.6710034207701683
[proc 1][Train](7000/10000) average loss: 0.6848899290561676
[proc 1][Train](7000/10000) average regularization: 6.305263891135837e-06
[proc 1] 7000 steps, total: 16.715, sample: 2.390, forward: 5.454, backward: 2.760, update: 6.103
[proc 0][Train](7000/10000) average pos_loss: 0.6986315697431564
[proc 0][Train](7000/10000) average neg_loss: 0.6708790897727013
[proc 0][Train](7000/10000) average loss: 0.6847553297877311
[proc 0][Train](7000/10000) average regularization: 6.304613876636722e-06
[proc 0] 7000 steps, total: 16.715, sample: 2.354, forward: 4.995, backward: 2.777, update: 5.892
[proc 0][Train](8000/10000) average pos_loss: 0.7010863305330276
[proc 0][Train](8000/10000) average neg_loss: 0.6671291823983192
[proc 0][Train](8000/10000) average loss: 0.6841077553629875
[proc 0][Train](8000/10000) average regularization: 6.343457874663727e-06
[proc 0] 8000 steps, total: 16.267, sample: 2.313, forward: 5.197, backward: 2.790, update: 5.959
[proc 1][Train](8000/10000) average pos_loss: 0.7024564442634582
[proc 1][Train](8000/10000) average neg_loss: 0.6671113935112953
[proc 1][Train](8000/10000) average loss: 0.6847839182019234
[proc 1][Train](8000/10000) average regularization: 6.344539785914094e-06
[proc 1] 8000 steps, total: 16.268, sample: 2.216, forward: 5.229, backward: 2.768, update: 5.972
[proc 0][Train](9000/10000) average pos_loss: 0.7040168535113335
[proc 0][Train](9000/10000) average neg_loss: 0.6635164656639099
[proc 0][Train](9000/10000) average loss: 0.683766660630703
[proc 0][Train](9000/10000) average regularization: 6.3969953257583255e-06
[proc 0] 9000 steps, total: 16.330, sample: 2.409, forward: 5.271, backward: 2.750, update: 5.892
[proc 1][Train](9000/10000) average pos_loss: 0.7038159563541412
[proc 1][Train](9000/10000) average neg_loss: 0.6639642994403839
[proc 1][Train](9000/10000) average loss: 0.6838901274204254
[proc 1][Train](9000/10000) average regularization: 6.3936378687685645e-06
[proc 1] 9000 steps, total: 16.330, sample: 2.411, forward: 5.177, backward: 2.795, update: 5.867
[proc 0][Train](10000/10000) average pos_loss: 0.7059860143065453
[proc 0][Train](10000/10000) average neg_loss: 0.6598096850514412
[proc 0][Train](10000/10000) average loss: 0.6828978500366211
[proc 0][Train](10000/10000) average regularization: 6.446403905556508e-06
[proc 0] 10000 steps, total: 16.295, sample: 2.279, forward: 5.285, backward: 2.785, update: 5.939
proc 0 takes 207.186 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.7060963848829269
[proc 1][Train](10000/10000) average neg_loss: 0.6592006342411041
[proc 1][Train](10000/10000) average loss: 0.6826485087871551
[proc 1][Train](10000/10000) average regularization: 6.449903137308865e-06
[proc 1] 10000 steps, total: 16.295, sample: 2.274, forward: 5.244, backward: 2.789, update: 5.817
proc 1 takes 206.618 seconds
Successfully xmh. training takes 216.11145210266113 seconds
