Reading train triples....
Finished. Read 304727650 train triples.
Reading valid triples....
Finished. Read 16929318 valid triples.
Reading test triples....
Finished. Read 16929308 test triples.
|Train|: 304727650
random partition 304727650 edges into 3 parts
part 0 has 101575884 edges
part 1 has 101575884 edges
part 2 has 101575882 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=False, batch_size=1000, batch_size_eval=16, data_files=None, data_path='data', dataset='Freebase', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=86054151, no_eval_filter=False, no_save_emb=True, nr_gpus=3, num_proc=3, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='ckpts/TransE_l1_Freebase_12', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 16929318
|test|: 16929308
Total initialize time 721.552 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 1][Train](1000/10000) average pos_loss: 0.6660933381319046
[proc 1][Train](1000/10000) average neg_loss: 0.6929631380438804
[proc 1][Train](1000/10000) average loss: 0.6795282376408577
[proc 1][Train](1000/10000) average regularization: 8.004972033177182e-06
[proc 1] 1000 steps, total: 43.647, sample: 21.744, forward: 12.713, backward: 2.783, update: 6.399
[proc 0][Train](1000/10000) average pos_loss: 0.6672953284084797
[proc 0][Train](1000/10000) average neg_loss: 0.6938229845762253
[proc 0][Train](1000/10000) average loss: 0.6805591571331024
[proc 0][Train](1000/10000) average regularization: 7.958505151464123e-06
[proc 0] 1000 steps, total: 44.228, sample: 21.431, forward: 13.333, backward: 2.831, update: 6.449
[proc 2][Train](1000/10000) average pos_loss: 0.6731437032818794
[proc 2][Train](1000/10000) average neg_loss: 0.694099406182766
[proc 2][Train](1000/10000) average loss: 0.6836215540766716
[proc 2][Train](1000/10000) average regularization: 7.94021994488503e-06
[proc 2] 1000 steps, total: 43.067, sample: 20.595, forward: 12.381, backward: 2.803, update: 6.146
[proc 0][Train](2000/10000) average pos_loss: 0.6798279594182968
[proc 0][Train](2000/10000) average neg_loss: 0.6841934653520584
[proc 0][Train](2000/10000) average loss: 0.6820107116699219
[proc 0][Train](2000/10000) average regularization: 7.80441904998952e-06
[proc 0] 2000 steps, total: 19.127, sample: 2.417, forward: 7.513, backward: 2.812, update: 6.377
[proc 1][Train](2000/10000) average pos_loss: 0.6795168460011483
[proc 1][Train](2000/10000) average neg_loss: 0.6838689512610435
[proc 1][Train](2000/10000) average loss: 0.6816928979158402
[proc 1][Train](2000/10000) average regularization: 7.813533692569763e-06
[proc 1] 2000 steps, total: 19.129, sample: 2.336, forward: 7.344, backward: 2.788, update: 6.202
[proc 2][Train](2000/10000) average pos_loss: 0.6801035315990448
[proc 2][Train](2000/10000) average neg_loss: 0.683991674900055
[proc 2][Train](2000/10000) average loss: 0.682047603070736
[proc 2][Train](2000/10000) average regularization: 7.828134076589776e-06
[proc 2] 2000 steps, total: 19.128, sample: 2.235, forward: 7.339, backward: 2.762, update: 6.002
[proc 0][Train](3000/10000) average pos_loss: 0.6893653962612152
[proc 0][Train](3000/10000) average neg_loss: 0.6796154419779777
[proc 0][Train](3000/10000) average loss: 0.6844904196262359
[proc 0][Train](3000/10000) average regularization: 6.846258354471502e-06
[proc 0] 3000 steps, total: 17.633, sample: 2.411, forward: 6.195, backward: 2.746, update: 6.273
[proc 2][Train](3000/10000) average pos_loss: 0.6905219488143921
[proc 2][Train](3000/10000) average neg_loss: 0.680987291276455
[proc 2][Train](3000/10000) average loss: 0.6857546203136444
[proc 2][Train](3000/10000) average regularization: 6.860563880763948e-06
[proc 2] 3000 steps, total: 17.633, sample: 2.170, forward: 6.144, backward: 2.787, update: 5.955
[proc 1][Train](3000/10000) average pos_loss: 0.6897389427423477
[proc 1][Train](3000/10000) average neg_loss: 0.68136387103796
[proc 1][Train](3000/10000) average loss: 0.6855514064431191
[proc 1][Train](3000/10000) average regularization: 6.8573234430004955e-06
[proc 1] 3000 steps, total: 17.633, sample: 2.287, forward: 6.036, backward: 2.734, update: 6.273
[proc 0][Train](4000/10000) average pos_loss: 0.6958424226045609
[proc 0][Train](4000/10000) average neg_loss: 0.6766432512998581
[proc 0][Train](4000/10000) average loss: 0.6862428362965584
[proc 0][Train](4000/10000) average regularization: 6.403042000329151e-06
[proc 0] 4000 steps, total: 17.148, sample: 2.407, forward: 5.849, backward: 2.590, update: 6.295
[proc 2][Train](4000/10000) average pos_loss: 0.6948812077641487
[proc 2][Train](4000/10000) average neg_loss: 0.675306451201439
[proc 2][Train](4000/10000) average loss: 0.6850938284397126
[proc 2][Train](4000/10000) average regularization: 6.406981075087969e-06
[proc 2] 4000 steps, total: 17.148, sample: 2.187, forward: 5.761, backward: 2.651, update: 5.896
[proc 1][Train](4000/10000) average pos_loss: 0.6957137703895568
[proc 1][Train](4000/10000) average neg_loss: 0.6772385449409485
[proc 1][Train](4000/10000) average loss: 0.686476156592369
[proc 1][Train](4000/10000) average regularization: 6.397123763235868e-06
[proc 1] 4000 steps, total: 17.148, sample: 2.416, forward: 5.606, backward: 2.797, update: 6.269
[proc 0][Train](5000/10000) average pos_loss: 0.6991798801422119
[proc 0][Train](5000/10000) average neg_loss: 0.6705809566378593
[proc 0][Train](5000/10000) average loss: 0.6848804180622101
[proc 0][Train](5000/10000) average regularization: 6.3578718368262345e-06
[proc 0] 5000 steps, total: 17.344, sample: 2.584, forward: 5.714, backward: 2.797, update: 6.242
[proc 2][Train](5000/10000) average pos_loss: 0.6994815692901611
[proc 2][Train](5000/10000) average neg_loss: 0.671000338435173
[proc 2][Train](5000/10000) average loss: 0.6852409537434578
[proc 2][Train](5000/10000) average regularization: 6.3543366554768e-06
[proc 2] 5000 steps, total: 17.345, sample: 2.257, forward: 5.589, backward: 2.793, update: 5.773
[proc 1][Train](5000/10000) average pos_loss: 0.6992172451615334
[proc 1][Train](5000/10000) average neg_loss: 0.6691289427876472
[proc 1][Train](5000/10000) average loss: 0.6841730945110321
[proc 1][Train](5000/10000) average regularization: 6.35846167915588e-06
[proc 1] 5000 steps, total: 17.345, sample: 2.374, forward: 5.293, backward: 2.823, update: 6.078
[proc 0][Train](6000/10000) average pos_loss: 0.7052005109190941
[proc 0][Train](6000/10000) average neg_loss: 0.6651377218961716
[proc 0][Train](6000/10000) average loss: 0.6851691172719002
[proc 0][Train](6000/10000) average regularization: 6.419950514100492e-06
[proc 0] 6000 steps, total: 16.826, sample: 2.322, forward: 5.512, backward: 2.811, update: 6.173
[proc 1][Train](6000/10000) average pos_loss: 0.7034120179414749
[proc 1][Train](6000/10000) average neg_loss: 0.6652906016111374
[proc 1][Train](6000/10000) average loss: 0.6843513097167016
[proc 1][Train](6000/10000) average regularization: 6.418570943424129e-06
[proc 1] 6000 steps, total: 16.826, sample: 2.305, forward: 5.261, backward: 2.905, update: 6.012
[proc 2][Train](6000/10000) average pos_loss: 0.7036954385638237
[proc 2][Train](6000/10000) average neg_loss: 0.6654857326745987
[proc 2][Train](6000/10000) average loss: 0.6845905845761299
[proc 2][Train](6000/10000) average regularization: 6.41673784411978e-06
[proc 2] 6000 steps, total: 16.826, sample: 2.145, forward: 5.496, backward: 2.824, update: 5.769
[proc 0][Train](7000/10000) average pos_loss: 0.7063317342996597
[proc 0][Train](7000/10000) average neg_loss: 0.659745633482933
[proc 0][Train](7000/10000) average loss: 0.6830386838912964
[proc 0][Train](7000/10000) average regularization: 6.49978302180898e-06
[proc 0] 7000 steps, total: 16.689, sample: 2.394, forward: 5.504, backward: 2.752, update: 6.032
[proc 1][Train](7000/10000) average pos_loss: 0.707471885085106
[proc 1][Train](7000/10000) average neg_loss: 0.6592916868329048
[proc 1][Train](7000/10000) average loss: 0.683381786942482
[proc 1][Train](7000/10000) average regularization: 6.498071874830202e-06
[proc 1] 7000 steps, total: 16.689, sample: 2.357, forward: 5.362, backward: 2.903, update: 6.006
[proc 2][Train](7000/10000) average pos_loss: 0.7062793775796891
[proc 2][Train](7000/10000) average neg_loss: 0.6590571135282517
[proc 2][Train](7000/10000) average loss: 0.6826682459712029
[proc 2][Train](7000/10000) average regularization: 6.496733743915683e-06
[proc 2] 7000 steps, total: 16.689, sample: 2.063, forward: 5.403, backward: 2.793, update: 5.630
[proc 0][Train](8000/10000) average pos_loss: 0.7092247292995453
[proc 0][Train](8000/10000) average neg_loss: 0.6540304177999496
[proc 0][Train](8000/10000) average loss: 0.6816275725960732
[proc 0][Train](8000/10000) average regularization: 6.5839232611324406e-06
[proc 0] 8000 steps, total: 16.808, sample: 2.329, forward: 5.472, backward: 2.799, update: 6.201
[proc 2][Train](8000/10000) average pos_loss: 0.7086424146294594
[proc 2][Train](8000/10000) average neg_loss: 0.6540977374911309
[proc 2][Train](8000/10000) average loss: 0.6813700764775276
[proc 2][Train](8000/10000) average regularization: 6.585741184608196e-06
[proc 2] 8000 steps, total: 16.808, sample: 2.142, forward: 5.539, backward: 2.890, update: 5.671
[proc 1][Train](8000/10000) average pos_loss: 0.7093371407985687
[proc 1][Train](8000/10000) average neg_loss: 0.6535135954618454
[proc 1][Train](8000/10000) average loss: 0.6814253690838814
[proc 1][Train](8000/10000) average regularization: 6.5870182370417754e-06
[proc 1] 8000 steps, total: 16.809, sample: 2.219, forward: 5.250, backward: 2.794, update: 5.968
[proc 0][Train](9000/10000) average pos_loss: 0.7100649213194847
[proc 0][Train](9000/10000) average neg_loss: 0.6480416322946548
[proc 0][Train](9000/10000) average loss: 0.6790532772541046
[proc 0][Train](9000/10000) average regularization: 6.676049330508249e-06
[proc 0] 9000 steps, total: 17.019, sample: 2.541, forward: 5.489, backward: 2.879, update: 6.103
[proc 2][Train](9000/10000) average pos_loss: 0.7095747600793838
[proc 2][Train](9000/10000) average neg_loss: 0.6479775448441505
[proc 2][Train](9000/10000) average loss: 0.6787761529684067
[proc 2][Train](9000/10000) average regularization: 6.678453156382602e-06
[proc 2] 9000 steps, total: 17.019, sample: 2.262, forward: 5.594, backward: 2.776, update: 5.755
[proc 1][Train](9000/10000) average pos_loss: 0.709143621981144
[proc 1][Train](9000/10000) average neg_loss: 0.6482030631899833
[proc 1][Train](9000/10000) average loss: 0.6786733437776565
[proc 1][Train](9000/10000) average regularization: 6.67433078524482e-06
[proc 1] 9000 steps, total: 17.019, sample: 2.414, forward: 5.258, backward: 2.847, update: 5.907
[proc 0][Train](10000/10000) average pos_loss: 0.7091363533735275
[proc 0][Train](10000/10000) average neg_loss: 0.6422685208320618
[proc 0][Train](10000/10000) average loss: 0.6757024371623993
[proc 0][Train](10000/10000) average regularization: 6.766524447812116e-06
[proc 0] 10000 steps, total: 16.709, sample: 2.418, forward: 5.490, backward: 2.802, update: 5.992
proc 0 takes 199.533 seconds
[proc 2][Train](10000/10000) average pos_loss: 0.7100037332177163
[proc 2][Train](10000/10000) average neg_loss: 0.6418160563111305
[proc 2][Train](10000/10000) average loss: 0.6759098944067955
[proc 2][Train](10000/10000) average regularization: 6.761746910342481e-06
[proc 2] 10000 steps, total: 16.709, sample: 2.139, forward: 5.511, backward: 2.841, update: 5.624
proc 2 takes 198.373 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.7101904536485673
[proc 1][Train](10000/10000) average neg_loss: 0.6420667940378189
[proc 1][Train](10000/10000) average loss: 0.6761286244392395
[proc 1][Train](10000/10000) average regularization: 6.764911039226718e-06
[proc 1] 10000 steps, total: 16.709, sample: 2.248, forward: 5.297, backward: 2.791, update: 5.971
proc 1 takes 198.953 seconds
Successfully xmh. training takes 214.05608296394348 seconds
