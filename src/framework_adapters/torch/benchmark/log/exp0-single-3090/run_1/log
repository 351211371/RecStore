Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 2 parts
part 0 has 241571 edges
part 1 has 241571 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=2, num_proc=2, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_FB15k_7', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 0.972 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.21083221136778593
[proc 0][Train](1000/10000) average neg_loss: 0.23064855609089135
[proc 0][Train](1000/10000) average loss: 0.22074038360267878
[proc 0][Train](1000/10000) average regularization: 1.0951220770721194e-05
[proc 0] 1000 steps, total: 15.442, sample: 1.633, forward: 6.410, backward: 2.700, update: 4.692
[proc 1][Train](1000/10000) average pos_loss: 0.2160011367276311
[proc 1][Train](1000/10000) average neg_loss: 0.23018964622914792
[proc 1][Train](1000/10000) average loss: 0.22309539119899274
[proc 1][Train](1000/10000) average regularization: 1.0935328288951495e-05
[proc 1] 1000 steps, total: 15.442, sample: 1.577, forward: 6.228, backward: 2.706, update: 4.650
[proc 0][Train](2000/10000) average pos_loss: 0.07626678794622421
[proc 0][Train](2000/10000) average neg_loss: 0.1078602344840765
[proc 0][Train](2000/10000) average loss: 0.09206351133435965
[proc 0][Train](2000/10000) average regularization: 1.550565343859489e-05
[proc 0] 2000 steps, total: 13.508, sample: 1.545, forward: 4.649, backward: 2.686, update: 4.622
[proc 1][Train](2000/10000) average pos_loss: 0.07614429408311844
[proc 1][Train](2000/10000) average neg_loss: 0.10817399221658706
[proc 1][Train](2000/10000) average loss: 0.09215914309024811
[proc 1][Train](2000/10000) average regularization: 1.549576885008719e-05
[proc 1] 2000 steps, total: 13.508, sample: 1.522, forward: 4.498, backward: 2.696, update: 4.640
[proc 0][Train](3000/10000) average pos_loss: 0.06303265163674951
[proc 0][Train](3000/10000) average neg_loss: 0.09252531889081002
[proc 0][Train](3000/10000) average loss: 0.07777898522093891
[proc 0][Train](3000/10000) average regularization: 1.7395103595845286e-05
[proc 0] 3000 steps, total: 13.464, sample: 1.532, forward: 4.639, backward: 2.683, update: 4.605
[proc 1][Train](3000/10000) average pos_loss: 0.06282850341871381
[proc 1][Train](3000/10000) average neg_loss: 0.09256274564564228
[proc 1][Train](3000/10000) average loss: 0.0776956244185567
[proc 1][Train](3000/10000) average regularization: 1.7391264867910648e-05
[proc 1] 3000 steps, total: 13.463, sample: 1.513, forward: 4.488, backward: 2.695, update: 4.625
[proc 0][Train](4000/10000) average pos_loss: 0.056956216420978305
[proc 0][Train](4000/10000) average neg_loss: 0.08500716389343142
[proc 0][Train](4000/10000) average loss: 0.0709816901795566
[proc 0][Train](4000/10000) average regularization: 1.859601375508646e-05
[proc 0] 4000 steps, total: 13.562, sample: 1.668, forward: 4.608, backward: 2.693, update: 4.586
[proc 1][Train](4000/10000) average pos_loss: 0.056879238221794366
[proc 1][Train](4000/10000) average neg_loss: 0.08512739703059197
[proc 1][Train](4000/10000) average loss: 0.07100331769883633
[proc 1][Train](4000/10000) average regularization: 1.8599172617541625e-05
[proc 1] 4000 steps, total: 13.562, sample: 1.672, forward: 4.502, backward: 2.708, update: 4.634
[proc 0][Train](5000/10000) average pos_loss: 0.0533425636254251
[proc 0][Train](5000/10000) average neg_loss: 0.08055713869631291
[proc 0][Train](5000/10000) average loss: 0.0669498512595892
[proc 0][Train](5000/10000) average regularization: 1.9492016443109606e-05
[proc 0] 5000 steps, total: 13.615, sample: 1.609, forward: 4.661, backward: 2.707, update: 4.632
[proc 1][Train](5000/10000) average pos_loss: 0.05320975162833929
[proc 1][Train](5000/10000) average neg_loss: 0.08052711881324649
[proc 1][Train](5000/10000) average loss: 0.06686843520775437
[proc 1][Train](5000/10000) average regularization: 1.9492771512886976e-05
[proc 1] 5000 steps, total: 13.616, sample: 1.560, forward: 4.495, backward: 2.674, update: 4.609
[proc 1][Train](6000/10000) average pos_loss: 0.050744865629822014
[proc 1][Train](6000/10000) average neg_loss: 0.07728570642322302
[proc 1][Train](6000/10000) average loss: 0.06401528612151743
[proc 1][Train](6000/10000) average regularization: 2.0192205884086434e-05
[proc 1] 6000 steps, total: 13.948, sample: 1.627, forward: 4.787, backward: 2.717, update: 4.810
[proc 0][Train](6000/10000) average pos_loss: 0.05068545051664114
[proc 0][Train](6000/10000) average neg_loss: 0.0773381145335734
[proc 0][Train](6000/10000) average loss: 0.06401178251579404
[proc 0][Train](6000/10000) average regularization: 2.0182091275273707e-05
[proc 0] 6000 steps, total: 13.950, sample: 1.616, forward: 4.714, backward: 2.700, update: 4.663
[proc 1][Train](7000/10000) average pos_loss: 0.04891538628190756
[proc 1][Train](7000/10000) average neg_loss: 0.07498164054751397
[proc 1][Train](7000/10000) average loss: 0.061948513459414246
[proc 1][Train](7000/10000) average regularization: 2.0773690985151915e-05
[proc 1] 7000 steps, total: 13.832, sample: 1.601, forward: 4.730, backward: 2.693, update: 4.801
[proc 0][Train](7000/10000) average pos_loss: 0.048969321526587006
[proc 0][Train](7000/10000) average neg_loss: 0.0751210144534707
[proc 0][Train](7000/10000) average loss: 0.06204516794905066
[proc 0][Train](7000/10000) average regularization: 2.07565553864697e-05
[proc 0] 7000 steps, total: 13.832, sample: 1.537, forward: 4.645, backward: 2.674, update: 4.581
[proc 1][Train](8000/10000) average pos_loss: 0.04743747261911631
[proc 1][Train](8000/10000) average neg_loss: 0.07321032656356692
[proc 1][Train](8000/10000) average loss: 0.06032389960438013
[proc 1][Train](8000/10000) average regularization: 2.1251489557471358e-05
[proc 1] 8000 steps, total: 13.880, sample: 1.683, forward: 4.734, backward: 2.637, update: 4.820
[proc 0][Train](8000/10000) average pos_loss: 0.04751262505725026
[proc 0][Train](8000/10000) average neg_loss: 0.07308234066516162
[proc 0][Train](8000/10000) average loss: 0.06029748286306858
[proc 0][Train](8000/10000) average regularization: 2.124888415710302e-05
[proc 0] 8000 steps, total: 13.880, sample: 1.690, forward: 4.654, backward: 2.678, update: 4.618
[proc 1][Train](9000/10000) average pos_loss: 0.046326780401170255
[proc 1][Train](9000/10000) average neg_loss: 0.07172838944196701
[proc 1][Train](9000/10000) average loss: 0.059027585051953796
[proc 1][Train](9000/10000) average regularization: 2.1684646748326485e-05
[proc 1] 9000 steps, total: 13.878, sample: 1.613, forward: 4.735, backward: 2.731, update: 4.793
[proc 0][Train](9000/10000) average pos_loss: 0.04634227224439383
[proc 0][Train](9000/10000) average neg_loss: 0.07171458629146218
[proc 0][Train](9000/10000) average loss: 0.059028429232537746
[proc 0][Train](9000/10000) average regularization: 2.1678056386008392e-05
[proc 0] 9000 steps, total: 13.878, sample: 1.556, forward: 4.683, backward: 2.681, update: 4.647
[proc 1][Train](10000/10000) average pos_loss: 0.045347550939768555
[proc 1][Train](10000/10000) average neg_loss: 0.07048997344821692
[proc 1][Train](10000/10000) average loss: 0.057918762214481834
[proc 1][Train](10000/10000) average regularization: 2.206385827412305e-05
[proc 1] 10000 steps, total: 13.794, sample: 1.546, forward: 4.581, backward: 3.144, update: 4.516
proc 1 takes 138.924 seconds
[proc 0][Train](10000/10000) average pos_loss: 0.045486313872039316
[proc 0][Train](10000/10000) average neg_loss: 0.07058882447332143
[proc 0][Train](10000/10000) average loss: 0.05803756923601031
[proc 0][Train](10000/10000) average regularization: 2.2052435246223467e-05
[proc 0] 10000 steps, total: 13.794, sample: 1.540, forward: 4.681, backward: 2.683, update: 4.647
proc 0 takes 138.926 seconds
Successfully xmh. training takes 139.21179509162903 seconds
