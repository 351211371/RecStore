Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
|Train|: 483142
random partition 483142 edges into 3 parts
part 0 has 161048 edges
part 1 has 161048 edges
part 2 has 161046 edges
ARGS:  Namespace(adversarial_temperature=1.0, async_update=None, batch_size=1000, batch_size_eval=16, data_files=None, data_path='/home/xieminhui/dgl-data', dataset='FB15k', delimiter='\t', double_ent=False, double_rel=False, eval_filter=True, eval_interval=10000, eval_percent=1, force_sync_interval=1000, format='built_in', gamma=16.0, gpu=[0, 1, 2], has_edge_importance=False, hidden_dim=400, log_interval=1000, loss_genre='Logsigmoid', lr=0.01, margin=1.0, max_step=10000, mix_cpu_gpu=True, model_name='TransE_l1', neg_adversarial_sampling=False, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size=200, neg_sample_size_eval=14951, no_eval_filter=False, no_save_emb=True, nr_gpus=3, num_proc=3, num_thread=1, num_workers=8, pairwise=False, regularization_coef=1e-07, regularization_norm=3, rel_part=False, save_path='/tmp/ckpts/TransE_l1_FB15k_8', soft_rel_part=False, strict_rel_part=False, test=True, valid=False)
|valid|: 50000
|test|: 59071
Total initialize time 1.021 seconds
Using backend: pytorch
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl/python/dgl/base.py:45: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  return warnings.warn(message, category=category, stacklevel=1)
[proc 0][Train](1000/10000) average pos_loss: 0.16585940684378148
[proc 0][Train](1000/10000) average neg_loss: 0.19065990321338178
[proc 0][Train](1000/10000) average loss: 0.17825965493917464
[proc 0][Train](1000/10000) average regularization: 1.2293692633647879e-05
[proc 0] 1000 steps, total: 16.061, sample: 1.683, forward: 6.831, backward: 2.728, update: 4.812
[proc 1][Train](1000/10000) average pos_loss: 0.17530528843402862
[proc 1][Train](1000/10000) average neg_loss: 0.1969541096612811
[proc 1][Train](1000/10000) average loss: 0.1861296986490488
[proc 1][Train](1000/10000) average regularization: 1.212400577196604e-05
[proc 1] 1000 steps, total: 16.062, sample: 1.617, forward: 6.600, backward: 2.678, update: 4.652
[proc 2][Train](1000/10000) average pos_loss: 0.17031266643106938
[proc 2][Train](1000/10000) average neg_loss: 0.19271192721277475
[proc 2][Train](1000/10000) average loss: 0.18151229681819678
[proc 2][Train](1000/10000) average regularization: 1.2240525006973257e-05
[proc 2] 1000 steps, total: 16.043, sample: 1.650, forward: 6.757, backward: 2.708, update: 4.842
[proc 0][Train](2000/10000) average pos_loss: 0.06588311367481947
[proc 0][Train](2000/10000) average neg_loss: 0.09600091855973006
[proc 0][Train](2000/10000) average loss: 0.08094201593101025
[proc 0][Train](2000/10000) average regularization: 1.6952269632383833e-05
[proc 0] 2000 steps, total: 13.971, sample: 1.606, forward: 4.712, backward: 2.971, update: 4.675
[proc 2][Train](2000/10000) average pos_loss: 0.06609200732037425
[proc 2][Train](2000/10000) average neg_loss: 0.09618093744665385
[proc 2][Train](2000/10000) average loss: 0.08113647235929966
[proc 2][Train](2000/10000) average regularization: 1.6953975920841913e-05
[proc 2] 2000 steps, total: 13.970, sample: 1.592, forward: 4.751, backward: 2.734, update: 4.803
[proc 1][Train](2000/10000) average pos_loss: 0.06605282063037157
[proc 1][Train](2000/10000) average neg_loss: 0.09616809885203838
[proc 1][Train](2000/10000) average loss: 0.08111045974493027
[proc 1][Train](2000/10000) average regularization: 1.692336451014853e-05
[proc 1] 2000 steps, total: 13.971, sample: 1.557, forward: 4.643, backward: 2.660, update: 4.672
[proc 0][Train](3000/10000) average pos_loss: 0.055958981573581694
[proc 0][Train](3000/10000) average neg_loss: 0.08396561028435827
[proc 0][Train](3000/10000) average loss: 0.06996229588612914
[proc 0][Train](3000/10000) average regularization: 1.8807095426382147e-05
[proc 0] 3000 steps, total: 13.941, sample: 1.563, forward: 4.791, backward: 2.790, update: 4.790
[proc 1][Train](3000/10000) average pos_loss: 0.05615415211394429
[proc 1][Train](3000/10000) average neg_loss: 0.08402401851117611
[proc 1][Train](3000/10000) average loss: 0.07008908528089523
[proc 1][Train](3000/10000) average regularization: 1.8796194408423615e-05
[proc 1] 3000 steps, total: 13.940, sample: 1.588, forward: 4.703, backward: 2.678, update: 4.710
[proc 2][Train](3000/10000) average pos_loss: 0.05622881868109107
[proc 2][Train](3000/10000) average neg_loss: 0.0842029137648642
[proc 2][Train](3000/10000) average loss: 0.0702158661596477
[proc 2][Train](3000/10000) average regularization: 1.8809398738085294e-05
[proc 2] 3000 steps, total: 13.940, sample: 1.563, forward: 4.788, backward: 2.789, update: 4.782
[proc 2][Train](4000/10000) average pos_loss: 0.051608648300170895
[proc 2][Train](4000/10000) average neg_loss: 0.07844713123142719
[proc 2][Train](4000/10000) average loss: 0.06502788987755775
[proc 2][Train](4000/10000) average regularization: 1.9996320666905375e-05
[proc 2] 4000 steps, total: 14.105, sample: 1.711, forward: 4.814, backward: 2.703, update: 4.870
[proc 0][Train](4000/10000) average pos_loss: 0.051376037009060384
[proc 0][Train](4000/10000) average neg_loss: 0.07825715081766248
[proc 0][Train](4000/10000) average loss: 0.06481659393385053
[proc 0][Train](4000/10000) average regularization: 1.9990210126707097e-05
[proc 0] 4000 steps, total: 14.105, sample: 1.701, forward: 4.818, backward: 2.711, update: 4.869
[proc 1][Train](4000/10000) average pos_loss: 0.051543092742562295
[proc 1][Train](4000/10000) average neg_loss: 0.07822182123363018
[proc 1][Train](4000/10000) average loss: 0.0648824569247663
[proc 1][Train](4000/10000) average regularization: 1.998727807404066e-05
[proc 1] 4000 steps, total: 14.106, sample: 1.790, forward: 4.689, backward: 2.671, update: 4.720
[proc 0][Train](5000/10000) average pos_loss: 0.04858154998347163
[proc 0][Train](5000/10000) average neg_loss: 0.074727146204561
[proc 0][Train](5000/10000) average loss: 0.06165434805676341
[proc 0][Train](5000/10000) average regularization: 2.086301713825378e-05
[proc 0] 5000 steps, total: 14.045, sample: 1.578, forward: 4.855, backward: 2.719, update: 4.886
[proc 2][Train](5000/10000) average pos_loss: 0.04883996962010861
[proc 2][Train](5000/10000) average neg_loss: 0.0746312690898776
[proc 2][Train](5000/10000) average loss: 0.06173561931028962
[proc 2][Train](5000/10000) average regularization: 2.08726508772088e-05
[proc 2] 5000 steps, total: 14.046, sample: 1.579, forward: 4.853, backward: 2.723, update: 4.882
[proc 1][Train](5000/10000) average pos_loss: 0.048654047023504975
[proc 1][Train](5000/10000) average neg_loss: 0.07476627362146973
[proc 1][Train](5000/10000) average loss: 0.061710160378366706
[proc 1][Train](5000/10000) average regularization: 2.0857444947978365e-05
[proc 1] 5000 steps, total: 14.045, sample: 1.555, forward: 4.696, backward: 2.630, update: 4.715
[proc 0][Train](6000/10000) average pos_loss: 0.046640658881515265
[proc 0][Train](6000/10000) average neg_loss: 0.07222521252930164
[proc 0][Train](6000/10000) average loss: 0.05943293569609523
[proc 0][Train](6000/10000) average regularization: 2.154842799609469e-05
[proc 0] 6000 steps, total: 14.096, sample: 1.610, forward: 4.862, backward: 2.724, update: 4.893
[proc 2][Train](6000/10000) average pos_loss: 0.04682394498586655
[proc 2][Train](6000/10000) average neg_loss: 0.072300148319453
[proc 2][Train](6000/10000) average loss: 0.059562046617269514
[proc 2][Train](6000/10000) average regularization: 2.1549942472120166e-05
[proc 2] 6000 steps, total: 14.097, sample: 1.619, forward: 4.838, backward: 2.727, update: 4.882
[proc 1][Train](6000/10000) average pos_loss: 0.04673069074377417
[proc 1][Train](6000/10000) average neg_loss: 0.07209011439606547
[proc 1][Train](6000/10000) average loss: 0.05941040259599686
[proc 1][Train](6000/10000) average regularization: 2.1549937175223022e-05
[proc 1] 6000 steps, total: 14.097, sample: 1.576, forward: 4.689, backward: 2.635, update: 4.716
[proc 0][Train](7000/10000) average pos_loss: 0.045188920326530935
[proc 0][Train](7000/10000) average neg_loss: 0.07036667580902577
[proc 0][Train](7000/10000) average loss: 0.0577777980081737
[proc 0][Train](7000/10000) average regularization: 2.212139792391099e-05
[proc 0] 7000 steps, total: 14.075, sample: 1.621, forward: 4.845, backward: 2.730, update: 4.871
[proc 2][Train](7000/10000) average pos_loss: 0.04546070028841496
[proc 2][Train](7000/10000) average neg_loss: 0.07057991411536932
[proc 2][Train](7000/10000) average loss: 0.05802030715718865
[proc 2][Train](7000/10000) average regularization: 2.2128941616756493e-05
[proc 2] 7000 steps, total: 14.075, sample: 1.620, forward: 4.845, backward: 2.659, update: 4.904
[proc 1][Train](7000/10000) average pos_loss: 0.04529145243763923
[proc 1][Train](7000/10000) average neg_loss: 0.07039352330565453
[proc 1][Train](7000/10000) average loss: 0.05784248791262508
[proc 1][Train](7000/10000) average regularization: 2.2119909677712714e-05
[proc 1] 7000 steps, total: 14.075, sample: 1.565, forward: 4.667, backward: 2.615, update: 4.691
[proc 0][Train](8000/10000) average pos_loss: 0.04407708667218685
[proc 0][Train](8000/10000) average neg_loss: 0.06894985437020659
[proc 0][Train](8000/10000) average loss: 0.056513470444828275
[proc 0][Train](8000/10000) average regularization: 2.2600060805416434e-05
[proc 0] 8000 steps, total: 14.084, sample: 1.601, forward: 4.864, backward: 2.730, update: 4.883
[proc 2][Train](8000/10000) average pos_loss: 0.044309987667948005
[proc 2][Train](8000/10000) average neg_loss: 0.06905646237358451
[proc 2][Train](8000/10000) average loss: 0.05668322502076626
[proc 2][Train](8000/10000) average regularization: 2.2608136776398168e-05
[proc 2] 8000 steps, total: 14.084, sample: 1.606, forward: 4.861, backward: 2.687, update: 4.910
[proc 1][Train](8000/10000) average pos_loss: 0.044185217585414646
[proc 1][Train](8000/10000) average neg_loss: 0.06896635839343071
[proc 1][Train](8000/10000) average loss: 0.05657578794658184
[proc 1][Train](8000/10000) average regularization: 2.2597688663154257e-05
[proc 1] 8000 steps, total: 14.084, sample: 1.531, forward: 4.629, backward: 2.656, update: 4.646
[proc 0][Train](9000/10000) average pos_loss: 0.04323931732773781
[proc 0][Train](9000/10000) average neg_loss: 0.06793310926109553
[proc 0][Train](9000/10000) average loss: 0.05558621330559254
[proc 0][Train](9000/10000) average regularization: 2.302165034961945e-05
[proc 0] 9000 steps, total: 14.458, sample: 1.884, forward: 4.848, backward: 2.913, update: 4.806
[proc 2][Train](9000/10000) average pos_loss: 0.043406201295554635
[proc 2][Train](9000/10000) average neg_loss: 0.06792950581759215
[proc 2][Train](9000/10000) average loss: 0.055667853619903326
[proc 2][Train](9000/10000) average regularization: 2.302922933631635e-05
[proc 2] 9000 steps, total: 14.458, sample: 1.766, forward: 4.845, backward: 2.746, update: 4.870
[proc 1][Train](9000/10000) average pos_loss: 0.04335673180967569
[proc 1][Train](9000/10000) average neg_loss: 0.06786931739747525
[proc 1][Train](9000/10000) average loss: 0.055613024555146696
[proc 1][Train](9000/10000) average regularization: 2.3019097083306405e-05
[proc 1] 9000 steps, total: 14.458, sample: 1.687, forward: 4.674, backward: 2.656, update: 4.675
[proc 0][Train](10000/10000) average pos_loss: 0.04243367672711611
[proc 0][Train](10000/10000) average neg_loss: 0.06693171520158649
[proc 0][Train](10000/10000) average loss: 0.05468269601091742
[proc 0][Train](10000/10000) average regularization: 2.3392514163788293e-05
[proc 0] 10000 steps, total: 14.305, sample: 1.614, forward: 4.771, backward: 3.372, update: 4.541
proc 0 takes 143.143 seconds
[proc 2][Train](10000/10000) average pos_loss: 0.04260997215285897
[proc 2][Train](10000/10000) average neg_loss: 0.06697883603721858
[proc 2][Train](10000/10000) average loss: 0.054794404089450834
[proc 2][Train](10000/10000) average regularization: 2.3393457051497534e-05
[proc 2] 10000 steps, total: 14.305, sample: 1.604, forward: 4.785, backward: 2.702, update: 4.858
proc 2 takes 143.124 seconds
[proc 1][Train](10000/10000) average pos_loss: 0.04254008666425944
[proc 1][Train](10000/10000) average neg_loss: 0.06694024029746652
[proc 1][Train](10000/10000) average loss: 0.05474016349762678
[proc 1][Train](10000/10000) average regularization: 2.3391288517814247e-05
[proc 1] 10000 steps, total: 14.308, sample: 1.571, forward: 4.628, backward: 2.666, update: 4.634
proc 1 takes 143.147 seconds
Successfully xmh. training takes 143.56748628616333 seconds
