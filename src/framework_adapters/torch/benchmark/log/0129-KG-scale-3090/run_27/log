WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240129 13:33:03.411888 20861 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/data/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_31', no_save_emb=True, max_step=500, batch_size=2000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, update_cache_use_omp=0, update_pq_use_omp=0, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [20861 sampler.py:454] Start PreSampling
WARNING [20861 sampler.py:532] Before construct renumbering_dict
WARNING [20861 sampler.py:555] PreSampling done
W20240129 13:33:08.617201 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240129 13:33:08.617497 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240129 13:33:08.617580 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240129 13:33:08.617616 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240129 13:33:08.617686 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240129 13:33:08.617727 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240129 13:33:08.617772 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240129 13:33:08.617846 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240129 13:33:08.617888 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240129 13:33:08.617933 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240129 13:33:08.617982 20861 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240129 13:33:08.618018 20861 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240129 13:33:08.618048 20861 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240129 13:33:08.618199 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240129 13:33:08.618232 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240129 13:33:08.618263 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240129 13:33:08.618317 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240129 13:33:08.618358 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240129 13:33:08.618389 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240129 13:33:08.618425 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240129 13:33:08.618475 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240129 13:33:08.618518 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240129 13:33:08.618566 20861 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240129 13:33:08.618602 20861 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240129 13:33:08.618628 20861 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240129 13:33:08.618652 20861 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
{0: Graph(num_nodes=13804, num_edges=289155,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12626, num_edges=379866,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13804 N 289155 E
MertisPartition: part 1 has 12626 N 379866 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  772,   848,   972,  ..., 12840, 10141,  9683]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 5.592 seconds
INFO [20861 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [21287 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [20861 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [21287 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
E20240129 13:33:09.562526 21351 recstore.cc:66] init folly done
E20240129 13:33:09.562628 21288 recstore.cc:66] init folly done
I20240129 13:33:09.661219 21351 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240129 13:33:09.663656 21288 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.477, sample: 0.414, forward: 1.305, backward: 0.761, update: 0.782
[Rank1] pid = 21287
train_sampler.Prefill()
-------Step 0-------
tensor([  208,  6420, 11531,  9130,  2071, 12290,  3406,  8230,  6203,  7767]) tensor([ 1028,  8095, 13227, 13919, 14595,  8744,  5351,   549,  5326, 10892])
-------Step 1-------
tensor([  208,  6420, 11531,  9130,  2071, 12290,  3406,  8230,  6203,  7767]) tensor([ 9702,  2410,   447,   384,  8177, 10336, 13724, 12621,  2407,  3283])
-------Step 2-------
tensor([ 4429,  6435,    59,  3910,  7268,  3987, 12543,   565,  1813, 12823]) tensor([ 2981,   438,  1279,  2190,  3988,  6310, 14871, 14918, 13479,  5702])
-------Step 3-------
tensor([ 4429,  6435,    59,  3910,  7268,  3987, 12543,   565,  1813, 12823]) tensor([ 2591,   471,  8047, 10288,  2681,   566, 14234,  8430,  2235,  6374])
-------Step 4-------
tensor([ 8961, 14320,   168,   244,  3156, 14530,  8276,  4239,  7273,  8785]) tensor([8705, 3110, 4710, 6207, 9072, 4907, 6549, 9850,  780, 7060])
-------Step 5-------
tensor([ 8961, 14320,   168,   244,  3156, 14530,  8276,  4239,  7273,  8785]) tensor([ 8867, 13376,  8672, 13515,  1897,  7598, 13068,  9983,  6118, 11696])
-------Step 6-------
tensor([  359, 13027,   361,   133,   788,  5999,  9568,  7718,    50, 11517]) tensor([10831,  3507,  4043,  4600,  6307,  9249, 11300, 14237, 10175,  3702])
-------Step 7-------
tensor([  359, 13027,   361,   133,   788,  5999,  9568,  7718,    50, 11517]) tensor([ 9745,    73,  2969,  8321,   933,  8870,  1055, 11151,  9575, 10858])
-------Step 8-------
tensor([14238,  8402,   282,    51,  4131,  4329,  5387,  7049,  1715, 10708]) tensor([  360,  4293,   156,  2397, 11467,  8682,  5640,  2751, 14747, 14746])
-------Step 9-------
tensor([14238,  8402,   282,    51,  4131,  4329,  5387,  7049,  1715, 10708]) tensor([ 8908, 13484,  4347,  3866,  2384,  9422,  8340,  8830,  5967, 11473])
before start barrier
start train
[proc 0] 100 steps, total: 3.475, sample: 0.415, forward: 1.339, backward: 0.766, update: 0.785
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.165 ms                  | 29.741 ms                 |
| Forward                   | 7.791 ms                  | 17.432 ms                 |
| Backward                  | 6.107 ms                  | 9.434 ms                  |
| Optimize                  | 7.398 ms                  | 15.651 ms                 |
| OneStep                   | 24.109 ms                 | 60.132 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 200 steps, total: 2.846, sample: 0.492, forward: 0.824, backward: 0.608, update: 0.779
[proc 1] 200 steps, total: 2.846, sample: 0.482, forward: 0.809, backward: 0.576, update: 0.752
[proc 0] 300 steps, total: 2.799, sample: 0.444, forward: 0.800, backward: 0.613, update: 0.778
[proc 1] 300 steps, total: 2.799, sample: 0.428, forward: 0.785, backward: 0.577, update: 0.788
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.161 ms                  | 36.579 ms                 |
| Forward                   | 7.700 ms                  | 13.773 ms                 |
| Backward                  | 6.109 ms                  | 7.070 ms                  |
| Optimize                  | 7.346 ms                  | 14.553 ms                 |
| OneStep                   | 23.854 ms                 | 61.868 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 2.811, sample: 0.419, forward: 0.797, backward: 0.567, update: 0.767
[proc 0] 400 steps, total: 2.811, sample: 0.407, forward: 0.814, backward: 0.603, update: 0.746
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.178 ms                  | 32.454 ms                 |
| Forward                   | 7.736 ms                  | 17.119 ms                 |
| Backward                  | 6.099 ms                  | 7.089 ms                  |
| Optimize                  | 7.330 ms                  | 14.553 ms                 |
| OneStep                   | 24.160 ms                 | 60.738 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 500 steps, total: 3.241, sample: 0.507, forward: 0.854, backward: 0.580, update: 0.849
[proc 0] 500 steps, total: 3.241, sample: 0.434, forward: 0.887, backward: 0.582, update: 0.821
Successfully xmh. training takes 15.17128849029541 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
