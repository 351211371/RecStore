WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240228 16:15:32.560258 268257 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_26', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, nr_background_threads=32, update_cache_use_omp=1, update_pq_use_omp=2, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [268257 sampler.py:454] Start PreSampling
WARNING [268257 sampler.py:532] Before construct renumbering_dict
WARNING [268257 sampler.py:555] PreSampling done
W20240228 16:15:35.005159 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240228 16:15:35.005399 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240228 16:15:35.005424 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240228 16:15:35.005445 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240228 16:15:35.005466 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240228 16:15:35.005484 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240228 16:15:35.005504 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240228 16:15:35.005530 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240228 16:15:35.005549 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240228 16:15:35.005565 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240228 16:15:35.005592 268257 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240228 16:15:35.005609 268257 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240228 16:15:35.005628 268257 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240228 16:15:35.005719 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240228 16:15:35.005743 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240228 16:15:35.005765 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240228 16:15:35.005798 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240228 16:15:35.005820 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240228 16:15:35.005836 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240228 16:15:35.005856 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240228 16:15:35.005873 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240228 16:15:35.005892 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240228 16:15:35.005908 268257 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240228 16:15:35.005925 268257 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240228 16:15:35.005939 268257 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240228 16:15:35.005951 268257 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240228 16:15:35.141711 268257 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x1000098ca000 22.81 MB
W20240228 16:15:35.169087 268257 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x10000af9c000 58.4 kB
{0: Graph(num_nodes=13804, num_edges=289155,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12626, num_edges=379866,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13804 N 289155 E
MertisPartition: part 1 has 12626 N 379866 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  749,   778,   852,  ..., 13039,  8281,  7788]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13804, num_edges=289155,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.640 seconds
INFO [268594 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [268257 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [268594 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [268257 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
W20240228 16:15:36.320153 268595 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240228 16:15:36.322010 268628 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240228 16:15:36.324295 268595 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x10000afae000 7.629 MB
W20240228 16:15:36.324457 268595 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x10000b751000 7.629 MB
W20240228 16:15:36.324541 268595 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x10000bef4000 1.49 GB
W20240228 16:15:36.324607 268595 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x10006b4d7000 1.49 GB
W20240228 16:15:36.324692 268595 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240228 16:15:36.325232 268628 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x1000caabc000 7.629 MB
W20240228 16:15:36.325330 268628 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x1000cb25f000 7.629 MB
W20240228 16:15:36.325377 268628 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x1000cba02000 1.49 GB
W20240228 16:15:36.325410 268628 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x10012afe5000 1.49 GB
W20240228 16:15:36.325440 268628 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240228 16:15:36.330773 268628 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240228 16:15:36.332379 268595 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
[Rank1] pid = 268594
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494)]
cudaHostRegister 0x1000098ca000
0: KnownLocalCachedEmbedding init done
WARNING [268257 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x1000098ca000
1: KnownLocalCachedEmbedding init done
WARNING [268594 DistTensor.py:59] The tensor name already exists in the kvstore
I20240228 16:15:37.325366 268628 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 2
I20240228 16:15:37.325419 268595 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 2
W20240228 16:15:37.326373 268595 grad_base.h:56] KGCacheController, config={
        "num_gpus": 2,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 0.01,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05,
        "update_cache_use_omp":  1,
        "update_pq_use_omp":  2
        }
W20240228 16:15:37.326491 268595 grad_base.h:185] Init GradProcessingBase done
I20240228 16:15:37.330214 268595 grad_async_v2.h:42] Use main thread to update emb.
W20240228 16:15:37.330358 268595 kg_controller.h:78] after init GradAsyncProcessingV2
I20240228 16:15:37.330367 268595 kg_controller.h:84] Construct KGCacheController done
E20240228 16:15:37.583962 268595 recstore.cc:67] init folly done
E20240228 16:15:37.584239 268628 recstore.cc:67] init folly done
I20240228 16:15:37.584739 268595 grad_base.h:61] GraphEnv RegTensorsPerProcess
W20240228 16:15:37.877651 268865 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
E20240228 16:15:37.877907 268865 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
I20240228 16:15:37.903061 268595 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240228 16:15:37.945905 268628 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
E20240228 16:15:39.270772 268925 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
W20240228 16:15:39.302471 268865 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
E20240228 16:15:39.982234 268595 grad_async_v2.h:404] Stalled in ProcessBackward: rank=0, step_no=49, sample_step_cpp_seen_[rank]=48
E20240228 16:15:40.329072 268865 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
W20240228 16:15:40.337090 268865 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end2
train_sampler.Prefill()
-------Step 0-------
tensor([  298,  9446,  6714, 11304,  2057, 14170,  2905, 11808,  5133, 11625]) tensor([  866,  6815,  8048, 13589, 14909,  4456,  4438,   397,  4598, 11738])
-------Step 1-------
tensor([  298,  9446,  6714, 11304,  2057, 14170,  2905, 11808,  5133, 11625]) tensor([ 8786,  1392,  3606,  3135,  5627,  7419,  7295, 12403,  7724,  2840])
-------Step 2-------
tensor([14170,     4,   231,   286, 10648, 10887,  1297, 13258, 11527,  7588]) tensor([ 1782,  3817, 14602,  8235,  9423,  5327,  9051,  1644, 10406,  3554])
-------Step 3-------
tensor([14170,     4,   231,   286, 10648, 10887,  1297, 13258, 11527,  7588]) tensor([14265,  1745,   152,  3964, 10449, 12388,  5898,   959, 14558,  8430])
-------Step 4-------
tensor([ 4568,  3530,   238,  1406,  6140, 10812, 13662,  6043,    42,  4406]) tensor([ 4157, 14224,  6508, 11582,  7984,  4508,  4793, 11659,  8793, 11558])
-------Step 5-------
tensor([ 4568,  3530,   238,  1406,  6140, 10812, 13662,  6043,    42,  4406]) tensor([11292,  2291,  7572, 10041,  6380, 12301,    18,   767, 10838,  5294])
-------Step 6-------
tensor([10689,  6347, 11108,   256,  1065,    58, 14170,  4595,    87,   355]) tensor([ 9256,  9627,  5546,  5701,  1092, 10823,  3058,  8932, 14489,  6592])
-------Step 7-------
tensor([10689,  6347, 11108,   256,  1065,    58, 14170,  4595,    87,   355]) tensor([11514,  2862, 14325,  8544, 14466, 11621,  3353,   550,   143, 11386])
-------Step 8-------
tensor([ 3445,  6885,  4405,  3385,  9446, 10265, 10648,  4568, 13703,  8406]) tensor([ 8995,  4974, 14401, 10122,  4393,  6277,  1895,  5129,  7829, 13592])
-------Step 9-------
tensor([ 3445,  6885,  4405,  3385,  9446, 10265, 10648,  4568, 13703,  8406]) tensor([ 7760,  6634,  7967, 10082, 14051,  3100,  4937, 12403, 13394,  2414])
before start barrier
start train
[proc 0] 100 steps, total: 2.664, sample: 0.183, forward: 1.039, backward: 0.659, update: 0.122
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 2.621, sample: 0.168, forward: 1.004, backward: 0.708, update: 0.101
W20240228 16:15:41.342077 268865 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
[proc 0] 200 steps, total: 1.658, sample: 0.187, forward: 0.272, backward: 0.308, update: 0.102
[proc 1] 200 steps, total: 1.658, sample: 0.296, forward: 0.378, backward: 0.620, update: 0.123
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 613.652 us                | 12.304 ms                 |
| Forward                   | 2.788 ms                  | 5.138 ms                  |
| Backward                  | 2.559 ms                  | 6.257 ms                  |
| Optimize                  | 1.085 ms                  | 2.497 ms                  |
| BarrierTimeBeforeRank0    | 2.205 ms                  | 12.613 ms                 |
| AfterBackward             | 1.921 ms                  | 3.195 ms                  |
| BlockToStepN              | 76.183 us                 | 126.781 us                |
| OneStep                   | 14.168 ms                 | 32.071 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240228 16:15:42.342993 268865 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end9
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 38.730 us                 | 206.332 us                |
| ProcessBack:Shuffle       | 548.417 us                | 979.250 us                |
| ProcessBack:UpdateCache   | 303.209 us                | 531.548 us                |
| ProcessBack:UpsertPq      | 24.313 us                 | 43.105 us                 |
| ProcessOneStep            | 1.902 ms                  | 3.165 ms                  |
| BlockToStepN              | 43.777 us                 | 63.219 us                 |
+---------------------------+---------------------------+---------------------------+
W20240228 16:15:43.346782 268865 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
[proc 1] 300 steps, total: 1.602, sample: 0.267, forward: 0.376, backward: 0.605, update: 0.125
[proc 0] 300 steps, total: 1.602, sample: 0.168, forward: 0.264, backward: 0.311, update: 0.095
W20240228 16:15:44.354610 268865 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
W20240228 16:15:45.355154 268865 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
[proc 0] 400 steps, total: 1.640, sample: 0.160, forward: 0.257, backward: 0.290, update: 0.103
[proc 1] 400 steps, total: 1.640, sample: 0.274, forward: 0.381, backward: 0.620, update: 0.127
W20240228 16:15:46.362361 268865 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
[proc 1] 500 steps, total: 1.645, sample: 0.277, forward: 0.381, backward: 0.622, update: 0.129
[proc 0] 500 steps, total: 1.645, sample: 0.154, forward: 0.241, backward: 0.276, update: 0.091
Successfully xmh. training takes 9.208057165145874 seconds
before call kg_cache_controller.StopThreads()
W20240228 16:15:47.111157 268595 grad_async_v2.h:84] call StopThreads. PID = 268257
W20240228 16:15:47.111176 268595 grad_base.h:213] before processOneStepNegThread_.join();
W20240228 16:15:47.111215 268595 grad_base.h:215] after processOneStepNegThread_.join();
W20240228 16:15:47.111220 268595 grad_async_v2.h:86] call GradProcessingBase::StopThreads.
W20240228 16:15:47.111620 268595 grad_async_v2.h:105] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 608.394 us                | 10.401 ms                 |
| Forward                   | 2.724 ms                  | 3.545 ms                  |
| Backward                  | 2.531 ms                  | 6.237 ms                  |
| Optimize                  | 1.018 ms                  | 2.174 ms                  |
| BarrierTimeBeforeRank0    | 5.543 ms                  | 14.241 ms                 |
| AfterBackward             | 1.919 ms                  | 2.777 ms                  |
| BlockToStepN              | 73.453 us                 | 109.466 us                |
| OneStep                   | 14.607 ms                 | 31.177 ms                 |
+---------------------------+---------------------------+---------------------------+
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7efd0332f4d0>
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 38.730 us                 | 206.332 us                |
| ProcessBack:Shuffle       | 549.698 us                | 984.919 us                |
| ProcessBack:UpdateCache   | 308.216 us                | 465.882 us                |
| ProcessBack:UpsertPq      | 23.674 us                 | 39.751 us                 |
| ProcessOneStep            | 1.902 ms                  | 2.751 ms                  |
| BlockToStepN              | 43.065 us                 | 59.303 us                 |
+---------------------------+---------------------------+---------------------------+
