WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240228 16:15:59.506767 275713 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_27', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=3, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=3, gpu=[0, 1, 2], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, nr_background_threads=32, update_cache_use_omp=1, update_pq_use_omp=2, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Partitoning with metis
[16:16:00] /home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/src/graph/transform/metis_partition_hetero.cc:87: Partition a graph with 14951 nodes and 771659 edges into 3 parts and get 83249 edge cuts
WARNING [275713 sampler.py:454] Start PreSampling
WARNING [275713 sampler.py:532] Before construct renumbering_dict
WARNING [275713 sampler.py:555] PreSampling done
W20240228 16:16:02.458216 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_0 [1000000]0x100000002000 7.629 MB
W20240228 16:16:02.458352 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_1 [1000000]0x1000007a5000 7.629 MB
W20240228 16:16:02.458380 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_2 [1000000]0x100000f48000 7.629 MB
W20240228 16:16:02.458401 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_3 [1000000]0x1000016eb000 7.629 MB
W20240228 16:16:02.458423 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_4 [1000000]0x100001e8e000 7.629 MB
W20240228 16:16:02.458442 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_5 [1000000]0x100002631000 7.629 MB
W20240228 16:16:02.458462 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_6 [1000000]0x100002dd4000 7.629 MB
W20240228 16:16:02.458482 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_7 [1000000]0x100003577000 7.629 MB
W20240228 16:16:02.458505 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_8 [1000000]0x100003d1a000 7.629 MB
W20240228 16:16:02.458528 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r0_9 [1000000]0x1000044bd000 7.629 MB
W20240228 16:16:02.458547 275713 IPCTensor.h:369] NewIPCTensor: step_r0 [10]0x100004c60000 80 B 
W20240228 16:16:02.458565 275713 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r0 [1]0x100004c62000 8 B 
W20240228 16:16:02.458583 275713 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x100004c64000 8 B 
W20240228 16:16:02.458659 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_0 [1000000]0x100004c66000 7.629 MB
W20240228 16:16:02.458695 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_1 [1000000]0x100005409000 7.629 MB
W20240228 16:16:02.458710 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_2 [1000000]0x100005bac000 7.629 MB
W20240228 16:16:02.458742 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_3 [1000000]0x10000634f000 7.629 MB
W20240228 16:16:02.458761 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_4 [1000000]0x100006af2000 7.629 MB
W20240228 16:16:02.458782 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_5 [1000000]0x100007295000 7.629 MB
W20240228 16:16:02.458803 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_6 [1000000]0x100007a38000 7.629 MB
W20240228 16:16:02.458823 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_7 [1000000]0x1000081db000 7.629 MB
W20240228 16:16:02.458837 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_8 [1000000]0x10000897e000 7.629 MB
W20240228 16:16:02.458856 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r1_9 [1000000]0x100009121000 7.629 MB
W20240228 16:16:02.458871 275713 IPCTensor.h:369] NewIPCTensor: step_r1 [10]0x1000098c4000 80 B 
W20240228 16:16:02.458884 275713 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r1 [1]0x1000098c6000 8 B 
W20240228 16:16:02.458901 275713 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x1000098c8000 8 B 
W20240228 16:16:02.458938 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_0 [1000000]0x1000098ca000 7.629 MB
W20240228 16:16:02.458959 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_1 [1000000]0x10000a06d000 7.629 MB
W20240228 16:16:02.458974 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_2 [1000000]0x10000a810000 7.629 MB
W20240228 16:16:02.458990 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_3 [1000000]0x10000afb3000 7.629 MB
W20240228 16:16:02.459004 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_4 [1000000]0x10000b756000 7.629 MB
W20240228 16:16:02.459022 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_5 [1000000]0x10000bef9000 7.629 MB
W20240228 16:16:02.459048 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_6 [1000000]0x10000c69c000 7.629 MB
W20240228 16:16:02.459069 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_7 [1000000]0x10000ce3f000 7.629 MB
W20240228 16:16:02.459093 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_8 [1000000]0x10000d5e2000 7.629 MB
W20240228 16:16:02.459115 275713 IPCTensor.h:369] NewIPCTensor: cached_sampler_r2_9 [1000000]0x10000dd85000 7.629 MB
W20240228 16:16:02.459131 275713 IPCTensor.h:369] NewIPCTensor: step_r2 [10]0x10000e528000 80 B 
W20240228 16:16:02.459143 275713 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_r2 [1]0x10000e52a000 8 B 
W20240228 16:16:02.459156 275713 IPCTensor.h:369] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x10000e52c000 8 B 
W20240228 16:16:02.594038 275713 IPCTensor.h:369] NewIPCTensor: full_emb [14951, 400]0x10000e52e000 22.81 MB
W20240228 16:16:02.622761 275713 IPCTensor.h:369] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x10000fc00000 58.4 kB
Convert a graph into a bidirected graph: 0.018 seconds, peak memory: 61.289 GB
Construct multi-constraint weights: 0.000 seconds, peak memory: 61.289 GB
Metis partitioning: 0.092 seconds, peak memory: 61.289 GB
Split the graph: 0.063 seconds
Construct subgraphs: 0.010 seconds
MertisPartition: part 0 has 11830 N 226999 E
MertisPartition: part 1 has 12183 N 196001 E
MertisPartition: part 2 has 10785 N 298158 E
Rank0: cached key size 249
Rank1: cached key size 249
Rank2: cached key size 249
Before renumbering graph:  {'_ID': tensor([    6,     7,    10,  ..., 11079, 14365,  6189]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 2, 1])}
After renumbering graph:  {'_ID': tensor([  923,   948,  1016,  ..., 10999, 10475,  4527]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 2, 1])}
part_g: DGLGraph(num_nodes=11830, num_edges=226999,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=11830, num_edges=226999,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.146 seconds
[Rank1] pid = 276091
INFO [275713 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [276155 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [276091 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [276091 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
INFO [276155 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
W20240228 16:16:05.119468 276218 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_2 [747, 400]; dev=2; size=1.14 MB
W20240228 16:16:05.119853 276092 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240228 16:16:05.119974 276218 IPCTensor.h:369] NewIPCTensor: input_keys_2 [1000000]0x10000fc12000 7.629 MB
W20240228 16:16:05.120146 276218 IPCTensor.h:369] NewIPCTensor: input_keys_neg_2 [1000000]0x1000103b5000 7.629 MB
W20240228 16:16:05.120222 276218 IPCTensor.h:369] NewIPCTensor: backward_grads_2 [1000000, 400]0x100010b58000 1.49 GB
W20240228 16:16:05.120267 276218 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_2 [1000000, 400]0x10007013b000 1.49 GB
W20240228 16:16:05.120317 276218 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_2_gpu [1000000, 400]; dev=2; size=1.49 GB
INFO [275713 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
W20240228 16:16:05.120640 276092 IPCTensor.h:369] NewIPCTensor: input_keys_1 [1000000]0x1000cf720000 7.629 MB
W20240228 16:16:05.120873 276092 IPCTensor.h:369] NewIPCTensor: input_keys_neg_1 [1000000]0x1000cfec3000 7.629 MB
W20240228 16:16:05.120978 276092 IPCTensor.h:369] NewIPCTensor: backward_grads_1 [1000000, 400]0x1000d0666000 1.49 GB
W20240228 16:16:05.121050 276092 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_1 [1000000, 400]0x10012fc49000 1.49 GB
W20240228 16:16:05.121131 276092 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240228 16:16:05.121186 276156 IPCTensor.h:409] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240228 16:16:05.127418 276218 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_2_gpu [1000000, 400]; dev=2; size=1.49 GB
W20240228 16:16:05.127492 276092 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_1_gpu [1000000, 400]; dev=1; size=1.49 GB
W20240228 16:16:05.127528 276156 IPCTensor.h:369] NewIPCTensor: input_keys_0 [1000000]0x10018f232000 7.629 MB
W20240228 16:16:05.127671 276156 IPCTensor.h:369] NewIPCTensor: input_keys_neg_0 [1000000]0x10018f9d5000 7.629 MB
W20240228 16:16:05.127753 276156 IPCTensor.h:369] NewIPCTensor: backward_grads_0 [1000000, 400]0x100190178000 1.49 GB
W20240228 16:16:05.127832 276156 IPCTensor.h:369] NewIPCTensor: backward_grads_neg_0 [1000000, 400]0x1001ef75b000 1.49 GB
W20240228 16:16:05.127907 276156 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_0_gpu [1000000, 400]; dev=0; size=1.49 GB
W20240228 16:16:05.138942 276156 IPCTensor.h:409] NewIPCGPUTensor: backward_grads_neg_0_gpu [1000000, 400]; dev=0; size=1.49 GB
cudaHostRegister 0x10000e52e000
2: KnownLocalCachedEmbedding init done
WARNING [276155 DistTensor.py:59] The tensor name already exists in the kvstore
[Rank2] pid = 276155
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494), (1494, 2241)]
cudaHostRegister 0x10000e52e000
0: KnownLocalCachedEmbedding init done
WARNING [275713 DistTensor.py:59] The tensor name already exists in the kvstore
cudaHostRegister 0x10000e52e000
1: KnownLocalCachedEmbedding init done
WARNING [276091 DistTensor.py:59] The tensor name already exists in the kvstore
I20240228 16:16:06.330202 276092 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 3
I20240228 16:16:06.330310 276156 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 3
I20240228 16:16:06.330475 276218 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 3
W20240228 16:16:06.331987 276156 grad_base.h:56] KGCacheController, config={
        "num_gpus": 3,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 0.01,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05,
        "update_cache_use_omp":  1,
        "update_pq_use_omp":  2
        }
W20240228 16:16:06.332273 276156 grad_base.h:185] Init GradProcessingBase done
I20240228 16:16:06.336908 276156 grad_async_v2.h:42] Use main thread to update emb.
W20240228 16:16:06.337091 276156 kg_controller.h:78] after init GradAsyncProcessingV2
I20240228 16:16:06.337103 276156 kg_controller.h:84] Construct KGCacheController done
E20240228 16:16:07.617337 276156 recstore.cc:67] init folly done
E20240228 16:16:07.617784 276218 recstore.cc:67] init folly done
E20240228 16:16:07.617842 276092 recstore.cc:67] init folly done
I20240228 16:16:07.619118 276156 grad_base.h:61] GraphEnv RegTensorsPerProcess
W20240228 16:16:08.175408 276498 grad_async_v2.h:137] Detect new sample comes, old_end0, new_end1
E20240228 16:16:08.175666 276498 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
I20240228 16:16:08.201315 276156 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 3
I20240228 16:16:08.234066 276092 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
I20240228 16:16:08.237831 276218 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 3
E20240228 16:16:09.986753 276558 parallel_pq_v2.h:79] insert failed, size(hashtable)=0
W20240228 16:16:10.053134 276498 grad_async_v2.h:137] Detect new sample comes, old_end1, new_end2
E20240228 16:16:10.996567 276498 parallel_pq_v2.h:79] insert failed, size(hashtable)=1
W20240228 16:16:11.057072 276498 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 682.874 us                | 10.770 ms                 |
| Forward                   | 3.043 ms                  | 4.545 ms                  |
| Backward                  | 5.310 ms                  | 73.630 ms                 |
| Optimize                  | 1.086 ms                  | 2.185 ms                  |
| BarrierTimeBeforeRank0    | 1.184 ms                  | 6.270 ms                  |
| AfterBackward             | 4.330 ms                  | 6.994 ms                  |
| BlockToStepN              | 69.236 us                 | 118.722 us                |
| OneStep                   | 15.788 ms                 | 87.055 ms                 |
+---------------------------+---------------------------+---------------------------+
train_sampler.Prefill()
-------Step 0-------
tensor([ 6517, 14597,   797,    30, 11558,  9514,  2846,  7112,    57, 12967]) tensor([ 1016, 13084,  9094, 10145,  8637,  8064,  4833,  8498, 10553,  7718])
-------Step 1-------
tensor([ 6517, 14597,   797,    30, 11558,  9514,  2846,  7112,    57, 12967]) tensor([10128, 10459,  9225,  4826, 14644,  2864,  6810, 12480,   530,   906])
-------Step 2-------
tensor([ 3383,  2057,  3526, 13934,    77,  3913, 11195,   113,  5173,    35]) tensor([ 3424,  7212,  9087,  4015,  7657,  2390, 10326, 10064,  9042,   263])
-------Step 3-------
tensor([ 3383,  2057,  3526, 13934,    77,  3913, 11195,   113,  5173,    35]) tensor([ 7391,  5264,  4953,  8098,  7605,  1135,  6058,  4772,  4081, 12145])
-------Step 4-------
tensor([10520, 10507,  3088,  6498, 10266, 14204,  7357, 13683,  7550,    70]) tensor([ 7855,  3122,   334, 14376, 11669, 10355,  1920,  6580,  6312,  4963])
-------Step 5-------
tensor([10520, 10507,  3088,  6498, 10266, 14204,  7357, 13683,  7550,    70]) tensor([13341,  7192,  2271,  8260,  8443,  7896,   166,  1051, 13022,  3325])
-------Step 6-------
tensor([    6,     5,  1110, 13291,   170,  5269, 10196,  4442,    90, 12059]) tensor([ 2139, 13886,  4154,  6838,  9812, 13713,   972,   194, 13386,  5452])
-------Step 7-------
tensor([    6,     5,  1110, 13291,   170,  5269, 10196,  4442,    90, 12059]) tensor([ 6093,  2586,  5894,  4002,  6146,  2995,   572,  8661,  3012, 14361])
-------Step 8-------
tensor([ 4597,  4345, 10892,  2336, 13682,   100, 14298, 13458,  8489,   138]) tensor([12576,  2200,  2876,  5178,   663,  9429,  3259, 10429,  3713,  8707])
-------Step 9-------
tensor([ 4597,  4345, 10892,  2336, 13682,   100, 14298, 13458,  8489,   138]) tensor([ 8865, 11292,   964,  4717, 10783, 11741,  9883, 12480,  6389,  2960])
before start barrier
start train
[proc 0] 100 steps, total: 3.617, sample: 0.179, forward: 1.222, backward: 0.828, update: 0.104
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 3.580, sample: 0.205, forward: 1.219, backward: 0.958, update: 0.114
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.584, sample: 0.158, forward: 1.200, backward: 0.746, update: 0.112
W20240228 16:16:12.058686 276498 grad_async_v2.h:137] Detect new sample comes, old_end3, new_end4
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 117.778 us                | 310.695 us                |
| ProcessBack:Shuffle       | 1.111 ms                  | 1.947 ms                  |
| ProcessBack:UpdateCache   | 977.502 us                | 1.179 ms                  |
| ProcessBack:UpsertPq      | 27.717 us                 | 59.938 us                 |
| ProcessOneStep            | 4.235 ms                  | 6.950 ms                  |
| BlockToStepN              | 33.847 us                 | 58.527 us                 |
+---------------------------+---------------------------+---------------------------+
W20240228 16:16:13.060736 276498 grad_async_v2.h:137] Detect new sample comes, old_end4, new_end5
[proc 0] 200 steps, total: 1.689, sample: 0.185, forward: 0.279, backward: 0.378, update: 0.100
[proc 2] 200 steps, total: 1.689, sample: 0.232, forward: 0.297, backward: 0.584, update: 0.107
[proc 1] 200 steps, total: 1.689, sample: 0.183, forward: 0.279, backward: 0.328, update: 0.109
W20240228 16:16:14.063123 276498 grad_async_v2.h:137] Detect new sample comes, old_end2, new_end3
W20240228 16:16:15.065615 276498 grad_async_v2.h:137] Detect new sample comes, old_end9, new_end1
[proc 1] 300 steps, total: 1.724, sample: 0.154, forward: 0.270, backward: 0.374, update: 0.105
[proc 0] 300 steps, total: 1.724, sample: 0.181, forward: 0.300, backward: 0.456, update: 0.100
[proc 2] 300 steps, total: 1.724, sample: 0.216, forward: 0.307, backward: 0.616, update: 0.105
W20240228 16:16:16.072355 276498 grad_async_v2.h:137] Detect new sample comes, old_end8, new_end0
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 657.905 us                | 10.770 ms                 |
| Forward                   | 2.968 ms                  | 3.637 ms                  |
| Backward                  | 4.408 ms                  | 6.499 ms                  |
| Optimize                  | 1.061 ms                  | 2.009 ms                  |
| BarrierTimeBeforeRank0    | 2.429 ms                  | 7.972 ms                  |
| AfterBackward             | 4.259 ms                  | 5.923 ms                  |
| BlockToStepN              | 68.957 us                 | 105.287 us                |
| OneStep                   | 15.786 ms                 | 29.004 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 0] 400 steps, total: 1.723, sample: 0.180, forward: 0.290, backward: 0.365, update: 0.100
[proc 1] 400 steps, total: 1.723, sample: 0.156, forward: 0.261, backward: 0.327, update: 0.101
[proc 2] 400 steps, total: 1.723, sample: 0.187, forward: 0.277, backward: 0.598, update: 0.097
W20240228 16:16:17.080447 276498 grad_async_v2.h:137] Detect new sample comes, old_end7, new_end8
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| clean                     | 117.778 us                | 310.695 us                |
| ProcessBack:Shuffle       | 1.102 ms                  | 1.477 ms                  |
| ProcessBack:UpdateCache   | 970.950 us                | 1.149 ms                  |
| ProcessBack:UpsertPq      | 28.466 us                 | 52.827 us                 |
| ProcessOneStep            | 4.238 ms                  | 5.900 ms                  |
| BlockToStepN              | 34.685 us                 | 54.723 us                 |
+---------------------------+---------------------------+---------------------------+
W20240228 16:16:18.084419 276498 grad_async_v2.h:137] Detect new sample comes, old_end5, new_end6
[proc 0] 500 steps, total: 1.764, sample: 0.195, forward: 0.289, backward: 0.375, update: 0.098
[proc 1] 500 steps, total: 1.764, sample: 0.145, forward: 0.260, backward: 0.338, update: 0.102
[proc 2] 500 steps, total: 1.764, sample: 0.192, forward: 0.271, backward: 0.611, update: 0.095
Successfully xmh. training takes 10.516290187835693 seconds
before call kg_cache_controller.StopThreads()
W20240228 16:16:18.717626 276156 grad_async_v2.h:84] call StopThreads. PID = 275713
W20240228 16:16:18.717648 276156 grad_base.h:213] before processOneStepNegThread_.join();
W20240228 16:16:18.717677 276156 grad_base.h:215] after processOneStepNegThread_.join();
W20240228 16:16:18.717684 276156 grad_async_v2.h:86] call GradProcessingBase::StopThreads.
W20240228 16:16:18.718160 276156 grad_async_v2.h:105] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker2: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f340f696290>
