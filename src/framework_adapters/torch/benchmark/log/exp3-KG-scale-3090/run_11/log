WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240123 01:40:09.642043 63724 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_26', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [63724 sampler.py:454] Start PreSampling
WARNING [63724 sampler.py:532] Before construct renumbering_dict
WARNING [63724 sampler.py:555] PreSampling done
W20240123 01:40:12.370672 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240123 01:40:12.370808 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240123 01:40:12.370848 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240123 01:40:12.370872 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240123 01:40:12.370895 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240123 01:40:12.370919 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240123 01:40:12.370944 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240123 01:40:12.370973 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240123 01:40:12.371011 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240123 01:40:12.371038 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240123 01:40:12.371083 63724 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240123 01:40:12.371104 63724 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240123 01:40:12.371127 63724 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240123 01:40:12.371241 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240123 01:40:12.371273 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240123 01:40:12.371290 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240123 01:40:12.371309 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240123 01:40:12.371326 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240123 01:40:12.371366 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240123 01:40:12.371387 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240123 01:40:12.371408 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240123 01:40:12.371426 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240123 01:40:12.371451 63724 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240123 01:40:12.371469 63724 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240123 01:40:12.371484 63724 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240123 01:40:12.371500 63724 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
{0: Graph(num_nodes=13500, num_edges=273181,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12803, num_edges=385691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13500 N 273181 E
MertisPartition: part 1 has 12803 N 385691 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  758,   824,   929,  ..., 13134, 10069, 13544]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13500, num_edges=273181,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13500, num_edges=273181,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.972 seconds
INFO [63724 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [64077 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [64077 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [63724 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
I20240123 01:40:13.533326 64080 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240123 01:40:13.537685 64079 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
[Rank1] pid = 64077
train_sampler.Prefill()
-------Step 0-------
tensor([  922, 10768,  6773,  9932,    25,  8240, 13364,     2,  3100, 14746]) tensor([  957,  4666,  7662,  3662, 11278,  6182, 10597,  7696,  9522, 11472])
-------Step 1-------
tensor([  922, 10768,  6773,  9932,    25,  8240, 13364,     2,  3100, 14746]) tensor([14621,  8742,  9216, 12391,  5666,  5545,  6473,  1711, 12060,  4492])
-------Step 2-------
tensor([ 3982,    11,  4527, 10426,  2251, 10137,  3809, 12689,  3706,  5845]) tensor([ 9145,  8087,  4586,  4902, 14100,  3315,   391,  5150, 14402,  4544])
-------Step 3-------
tensor([ 3982,    11,  4527, 10426,  2251, 10137,  3809, 12689,  3706,  5845]) tensor([ 8579, 10663, 12433, 14592,  1395,  7995,  9294,  7405,  6363,  6544])
-------Step 4-------
tensor([  19, 3555,  906, 8251, 5964,  157,   73, 4851,  119,   54]) tensor([13592,  6598,  6640,  3357,  2257, 12050, 14577,  8032,  6399,  3629])
-------Step 5-------
tensor([  19, 3555,  906, 8251, 5964,  157,   73, 4851,  119,   54]) tensor([ 3997,  1681,  2960, 13991, 13625,   806,  8062,  3732, 14894,  1857])
-------Step 6-------
tensor([10588, 10188, 13901, 14111,  6036,   249,  4130,  6727,  4393,  1828]) tensor([ 6813,  5765,  1017, 12478, 12505, 12799, 13933,  5940, 12767,  3872])
-------Step 7-------
tensor([10588, 10188, 13901, 14111,  6036,   249,  4130,  6727,  4393,  1828]) tensor([ 6846,   256,  8215,  4806,  3641,  5678,  8525, 14043, 13234,  8516])
-------Step 8-------
tensor([ 2119,  2558, 12455, 14169,  8632,  9036, 13308,  5615,   221,  5453]) tensor([ 3410,  7993, 13375,  6514,  3693, 10794, 12356,  7927, 11950,  2106])
-------Step 9-------
tensor([ 2119,  2558, 12455, 14169,  8632,  9036, 13308,  5615,   221,  5453]) tensor([13195,  6957, 10025,  1274,  9683,  1251,  6473,  3850,  9219, 13862])
before start barrier
start train
[proc 0] 100 steps, total: 2.301, sample: 0.211, forward: 1.005, backward: 0.551, update: 0.429
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 2.296, sample: 0.211, forward: 0.961, backward: 0.550, update: 0.446
[proc 1] 200 steps, total: 1.657, sample: 0.219, forward: 0.478, backward: 0.387, update: 0.451
[proc 0] 200 steps, total: 1.657, sample: 0.210, forward: 0.517, backward: 0.401, update: 0.417
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 737.656 us                | 17.955 ms                 |
| Forward                   | 5.103 ms                  | 11.694 ms                 |
| Backward                  | 4.015 ms                  | 5.250 ms                  |
| Optimize                  | 4.152 ms                  | 7.999 ms                  |
| OneStep                   | 15.078 ms                 | 39.145 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 300 steps, total: 1.802, sample: 0.239, forward: 0.549, backward: 0.390, update: 0.510
[proc 0] 300 steps, total: 1.802, sample: 0.235, forward: 0.585, backward: 0.397, update: 0.475
[proc 1] 400 steps, total: 1.717, sample: 0.235, forward: 0.516, backward: 0.388, update: 0.482
[proc 0] 400 steps, total: 1.717, sample: 0.213, forward: 0.554, backward: 0.399, update: 0.448
[proc 1] 500 steps, total: 1.947, sample: 0.232, forward: 0.556, backward: 0.393, update: 0.490
[proc 0] 500 steps, total: 1.947, sample: 0.269, forward: 0.611, backward: 0.407, update: 0.474
Successfully xmh. training takes 9.423533201217651 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 748.964 us                | 17.955 ms                 |
| Forward                   | 5.141 ms                  | 10.459 ms                 |
| Backward                  | 4.014 ms                  | 5.250 ms                  |
| Optimize                  | 4.231 ms                  | 7.166 ms                  |
| OneStep                   | 15.285 ms                 | 39.145 ms                 |
+---------------------------+---------------------------+---------------------------+
