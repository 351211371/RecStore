WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240123 01:32:49.960184 34594 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_20', no_save_emb=True, max_step=500, batch_size=800, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [34594 sampler.py:454] Start PreSampling
WARNING [34594 sampler.py:532] Before construct renumbering_dict
WARNING [34594 sampler.py:555] PreSampling done
W20240123 01:32:53.205420 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240123 01:32:53.205756 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240123 01:32:53.205809 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240123 01:32:53.205864 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240123 01:32:53.205893 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240123 01:32:53.205919 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240123 01:32:53.205962 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240123 01:32:53.206003 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240123 01:32:53.206034 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240123 01:32:53.206063 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240123 01:32:53.206117 34594 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240123 01:32:53.206148 34594 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240123 01:32:53.206180 34594 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240123 01:32:53.206303 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240123 01:32:53.206338 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240123 01:32:53.206365 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240123 01:32:53.206393 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240123 01:32:53.206419 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240123 01:32:53.206486 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240123 01:32:53.206514 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240123 01:32:53.206542 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240123 01:32:53.206583 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240123 01:32:53.206610 34594 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240123 01:32:53.206637 34594 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240123 01:32:53.206660 34594 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240123 01:32:53.206682 34594 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240123 01:32:53.400713 34594 IPCTensor.h:367] NewIPCTensor: full_emb [14951, 400]0x100000f72000
W20240123 01:32:53.400876 34594 IPCTensor.h:367] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100002644000
{0: Graph(num_nodes=13500, num_edges=273181,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12803, num_edges=385691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13500 N 273181 E
MertisPartition: part 1 has 12803 N 385691 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  765,   858,   970,  ..., 11299,  7266,  6942]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13500, num_edges=273181,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13500, num_edges=273181,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.475 seconds
INFO [34594 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [35094 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [34594 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [35094 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
W20240123 01:32:55.435918 35096 IPCTensor.h:406] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240123 01:32:55.436432 35095 IPCTensor.h:406] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240123 01:32:55.461398 35096 IPCTensor.h:367] NewIPCTensor: input_keys_0 [100000]0x100002658000
W20240123 01:32:55.461455 35095 IPCTensor.h:367] NewIPCTensor: input_keys_1 [100000]0x10000271d000
W20240123 01:32:55.461539 35096 IPCTensor.h:367] NewIPCTensor: input_keys_neg_0 [100000]0x1000027e2000
W20240123 01:32:55.461576 35095 IPCTensor.h:367] NewIPCTensor: input_keys_neg_1 [100000]0x1000028a7000
W20240123 01:32:55.461582 35096 IPCTensor.h:367] NewIPCTensor: backward_grads_0 [100000, 400]0x10000296c000
W20240123 01:32:55.461633 35096 IPCTensor.h:367] NewIPCTensor: backward_grads_neg_0 [100000, 400]0x10000c204000
W20240123 01:32:55.461647 35095 IPCTensor.h:367] NewIPCTensor: backward_grads_1 [100000, 400]0x100015a9c000
W20240123 01:32:55.461659 35096 IPCTensor.h:406] NewIPCGPUTensor: backward_grads_0_gpu [100000, 400]; dev=0; size=152.6 MB
W20240123 01:32:55.461690 35095 IPCTensor.h:367] NewIPCTensor: backward_grads_neg_1 [100000, 400]0x10001f334000
W20240123 01:32:55.461727 35095 IPCTensor.h:406] NewIPCGPUTensor: backward_grads_1_gpu [100000, 400]; dev=1; size=152.6 MB
W20240123 01:32:55.462504 35096 IPCTensor.h:406] NewIPCGPUTensor: backward_grads_neg_0_gpu [100000, 400]; dev=0; size=152.6 MB
W20240123 01:32:55.462543 35095 IPCTensor.h:406] NewIPCGPUTensor: backward_grads_neg_1_gpu [100000, 400]; dev=1; size=152.6 MB
[Rank1] pid = 35094
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494)]
cudaHostRegister 0x100000f72000
0: KnownLocalCachedEmbedding init done
cudaHostRegister 0x100000f72000
1: KnownLocalCachedEmbedding init done
WARNING [35094 DistTensor.py:56] The tensor name already exists in the kvstore
WARNING [34594 DistTensor.py:56] The tensor name already exists in the kvstore
I20240123 01:32:55.594834 35096 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 2
I20240123 01:32:55.594870 35095 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 2
W20240123 01:32:55.595880 35096 grad_base.h:55] KGCacheController, config={
        "num_gpus": 2,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05
        }
W20240123 01:32:55.595955 35096 grad_base.h:172] Init GradProcessingBase done
I20240123 01:32:55.598927 35096 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240123 01:32:55.599018 35096 kg_controller.h:78] after init GradAsyncProcessingV2
I20240123 01:32:55.599023 35096 kg_controller.h:84] Construct KGCacheController done
I20240123 01:32:55.809582 35096 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240123 01:32:56.067812 35640 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240123 01:32:56.068187 35640 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240123 01:32:56.100625 35096 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240123 01:32:56.115664 35095 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
W20240123 01:32:57.021209 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=1, pq.top=1
E20240123 01:32:57.068008 35096 parallel_pq_v2.h:76] insert failed, size(hashtable)=77
W20240123 01:32:57.074185 35640 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240123 01:32:58.021227 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=37, pq.top=37
E20240123 01:32:58.068008 35640 parallel_pq_v2.h:76] insert failed, size(hashtable)=131
W20240123 01:32:58.111999 35640 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
W20240123 01:32:59.021739 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=72, pq.top=72
E20240123 01:32:59.068051 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=379
W20240123 01:32:59.118517 35640 grad_async_v2.h:120] Detect new sample comes, old_end6, new_end7
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 3.611, sample: 0.266, forward: 0.845, backward: 0.559, update: 0.107
train_sampler.Prefill()
-------Step 0-------
tensor([ 1025,  7664,  3508, 10195,    65,  6002, 13132,    16,  2349, 14799]) tensor([  971,  5150,  8218,  4947, 12341,  8887, 13521,  8666, 12088, 12671])
-------Step 1-------
tensor([ 1025,  7664,  3508, 10195,    65,  6002, 13132,    16,  2349, 14799]) tensor([ 9736,  9707, 13739,  4073,  4134,  2511,  9312, 10022,  9853,  9625])
-------Step 2-------
tensor([ 5859,    43,  6846, 13443, 12092,  5718,  3871,   217,   156,  6581]) tensor([10807, 12291,  1364,  6857, 12896,  6105, 12615, 12316,  1618,   361])
-------Step 3-------
tensor([ 5859,    43,  6846, 13443, 12092,  5718,  3871,   217,   156,  6581]) tensor([ 3021,  1403,  6363, 13533,  7418,  6326,  4724, 11151,  6355,  2457])
-------Step 4-------
tensor([ 2552,  7826,     7,   332,    93,  8791,  5533,  7510, 10292,    44]) tensor([ 9366, 11665,  5997,  8008,  3789,  5386,  6009, 12713, 13066,  3950])
-------Step 5-------
tensor([ 2552,  7826,     7,   332,    93,  8791,  5533,  7510, 10292,    44]) tensor([12966,  6759, 11472,  8633,  2601,  5759,  2475,  4906, 11933,  5372])
-------Step 6-------
tensor([  17, 4690,  841, 5998, 4476,  164,  140, 6714,  356,  179]) tensor([14417,  4830,  3409,  5824,  1400,  8553, 12922, 10867,  7158,  2024])
-------Step 7-------
tensor([  17, 4690,  841, 5998, 4476,  164,  140, 6714,  356,  179]) tensor([ 8259,  3610,  1372,  6831,  3759,  5308,  2241, 10858,  1475, 10396])
-------Step 8-------
tensor([ 7427,   136,  8997,   216,   139, 14055, 10848,   283,  2156, 13983]) tensor([13624,  6990, 13649, 10541,  1875,  8390, 10118,  5066,  4341,  2631])
-------Step 9-------
tensor([ 7427,   136,  8997,   216,   139, 14055, 10848,   283,  2156, 13983]) tensor([13918,  5629, 12359, 14253,  9264,  2928,  9140,  1160, 13732,  3333])
before start barrier
start train
[proc 0] 100 steps, total: 3.627, sample: 0.336, forward: 1.019, backward: 0.561, update: 0.135
W20240123 01:33:00.029701 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=111, pq.top=111
E20240123 01:33:00.068009 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=2116
W20240123 01:33:00.138191 35640 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.395 ms                  | 17.790 ms                 |
| Forward                   | 4.496 ms                  | 10.927 ms                 |
| Backward                  | 3.719 ms                  | 4.794 ms                  |
| Optimize                  | 1.416 ms                  | 2.232 ms                  |
| BarrierTimeBeforeRank0    | 30.098 us                 | 1.259 ms                  |
| AfterBackward             | 8.280 ms                  | 12.561 ms                 |
| BlockToStepN              | 4.463 ms                  | 19.766 ms                 |
| OneStep                   | 25.438 ms                 | 67.021 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 696.399 us                | 1.481 ms                  |
| ProcessBack:UpdateCache   | 610.410 us                | 1.145 ms                  |
| ProcessBack:UpsertPq      | 5.626 ms                  | 9.765 ms                  |
| ProcessOneStep            | 8.181 ms                  | 12.530 ms                 |
| BlockToStepN              | 5.089 ms                  | 19.627 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240123 01:33:01.029042 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=149, pq.top=149
E20240123 01:33:01.070221 35640 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
W20240123 01:33:01.152990 35640 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
W20240123 01:33:02.044454 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=190, pq.top=190
E20240123 01:33:02.070325 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=9272
W20240123 01:33:02.164897 35640 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
[proc 1] 200 steps, total: 2.577, sample: 0.292, forward: 0.353, backward: 0.366, update: 0.110
[proc 0] 200 steps, total: 2.577, sample: 0.331, forward: 0.423, backward: 0.359, update: 0.127
W20240123 01:33:03.059377 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=229, pq.top=229
E20240123 01:33:03.070010 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=10767
W20240123 01:33:03.167112 35640 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
W20240123 01:33:04.061277 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=265, pq.top=265
E20240123 01:33:04.070006 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=4178
W20240123 01:33:04.167186 35640 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
[proc 1] 300 steps, total: 2.685, sample: 0.272, forward: 0.367, backward: 0.373, update: 0.116
[proc 0] 300 steps, total: 2.684, sample: 0.277, forward: 0.368, backward: 0.374, update: 0.128
W20240123 01:33:05.061156 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=303, pq.top=303
E20240123 01:33:05.070127 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=10223
W20240123 01:33:05.171023 35640 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.318 ms                  | 17.604 ms                 |
| Forward                   | 4.191 ms                  | 7.837 ms                  |
| Backward                  | 3.710 ms                  | 4.794 ms                  |
| Optimize                  | 1.376 ms                  | 2.092 ms                  |
| BarrierTimeBeforeRank0    | 28.438 us                 | 2.025 ms                  |
| AfterBackward             | 7.634 ms                  | 12.561 ms                 |
| BlockToStepN              | 5.657 ms                  | 17.887 ms                 |
| OneStep                   | 25.263 ms                 | 52.159 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 664.568 us                | 1.481 ms                  |
| ProcessBack:UpdateCache   | 572.897 us                | 876.999 us                |
| ProcessBack:UpsertPq      | 5.229 ms                  | 9.498 ms                  |
| ProcessOneStep            | 7.623 ms                  | 12.530 ms                 |
| BlockToStepN              | 5.595 ms                  | 18.893 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240123 01:33:06.070008 35096 parallel_pq_v2.h:76] insert failed, size(hashtable)=109
W20240123 01:33:06.071908 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=339, pq.top=339
W20240123 01:33:06.175107 35640 grad_async_v2.h:120] Detect new sample comes, old_end2, new_end3
E20240123 01:33:07.070022 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=10077
W20240123 01:33:07.071514 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=375, pq.top=375
W20240123 01:33:07.179911 35640 grad_async_v2.h:120] Detect new sample comes, old_end8, new_end9
[proc 1] 400 steps, total: 2.811, sample: 0.253, forward: 0.355, backward: 0.358, update: 0.111
[proc 0] 400 steps, total: 2.811, sample: 0.300, forward: 0.378, backward: 0.362, update: 0.127
E20240123 01:33:08.070008 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=11354
W20240123 01:33:08.090457 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=410, pq.top=410
W20240123 01:33:08.183431 35640 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
E20240123 01:33:09.070406 35506 parallel_pq_v2.h:76] insert failed, size(hashtable)=213
W20240123 01:33:09.099406 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=447, pq.top=447
W20240123 01:33:09.184303 35640 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240123 01:33:10.070011 35639 parallel_pq_v2.h:76] insert failed, size(hashtable)=8929
W20240123 01:33:10.113931 35096 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=484, pq.top=484
W20240123 01:33:10.184238 35640 grad_async_v2.h:120] Detect new sample comes, old_end6, new_end7
[proc 1] 500 steps, total: 2.752, sample: 0.265, forward: 0.380, backward: 0.386, update: 0.118
[proc 0] 500 steps, total: 2.752, sample: 0.311, forward: 0.389, backward: 0.364, update: 0.129
Successfully xmh. training takes 14.451032161712646 seconds
before call kg_cache_controller.StopThreads()
W20240123 01:33:10.551767 35096 grad_async_v2.h:71] call StopThreads. PID = 34594
W20240123 01:33:10.551802 35096 grad_base.h:210] before processOneStepNegThread_.join();
W20240123 01:33:10.552109 35096 grad_base.h:212] after processOneStepNegThread_.join();
W20240123 01:33:10.552124 35096 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
W20240123 01:33:10.554781 35096 grad_async_v2.h:91] StopThreads done.
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.358 ms                  | 17.264 ms                 |
| Forward                   | 4.004 ms                  | 6.711 ms                  |
| Backward                  | 3.697 ms                  | 5.400 ms                  |
| Optimize                  | 1.368 ms                  | 2.040 ms                  |
| BarrierTimeBeforeRank0    | 27.882 us                 | 1.723 ms                  |
| AfterBackward             | 7.706 ms                  | 12.194 ms                 |
| BlockToStepN              | 6.057 ms                  | 19.911 ms                 |
| OneStep                   | 25.578 ms                 | 53.485 ms                 |
+---------------------------+---------------------------+---------------------------+
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7f0ef6c13250>
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 622.320 us                | 1.433 ms                  |
| ProcessBack:UpdateCache   | 549.052 us                | 828.340 us                |
| ProcessBack:UpsertPq      | 5.229 ms                  | 9.453 ms                  |
| ProcessOneStep            | 7.676 ms                  | 11.993 ms                 |
| BlockToStepN              | 5.989 ms                  | 19.807 ms                 |
+---------------------------+---------------------------+---------------------------+
