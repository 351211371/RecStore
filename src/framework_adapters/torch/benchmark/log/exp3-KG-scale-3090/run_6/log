WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240123 01:33:21.790803 37024 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_21', no_save_emb=True, max_step=500, batch_size=800, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [37024 sampler.py:454] Start PreSampling
WARNING [37024 sampler.py:532] Before construct renumbering_dict
WARNING [37024 sampler.py:555] PreSampling done
W20240123 01:33:24.894559 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240123 01:33:24.894812 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240123 01:33:24.894845 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240123 01:33:24.894870 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240123 01:33:24.894889 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240123 01:33:24.894912 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240123 01:33:24.894935 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240123 01:33:24.894974 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240123 01:33:24.895006 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240123 01:33:24.895031 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240123 01:33:24.895083 37024 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240123 01:33:24.895102 37024 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240123 01:33:24.895117 37024 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240123 01:33:24.895239 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240123 01:33:24.895267 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240123 01:33:24.895284 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240123 01:33:24.895309 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240123 01:33:24.895326 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240123 01:33:24.895376 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240123 01:33:24.895395 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240123 01:33:24.895431 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240123 01:33:24.895460 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240123 01:33:24.895491 37024 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240123 01:33:24.895515 37024 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240123 01:33:24.895530 37024 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240123 01:33:24.895545 37024 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
{0: Graph(num_nodes=13500, num_edges=273181,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12803, num_edges=385691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13500 N 273181 E
MertisPartition: part 1 has 12803 N 385691 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  749,   804,   910,  ...,  9120, 12650,  9168]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13500, num_edges=273181,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13500, num_edges=273181,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.329 seconds
INFO [37757 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [37024 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [37024 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [37757 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
I20240123 01:33:27.196632 37758 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240123 01:33:27.200511 37761 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 2.035, sample: 0.174, forward: 0.901, backward: 0.519, update: 0.310
[Rank1] pid = 37757
train_sampler.Prefill()
-------Step 0-------
tensor([ 1012, 14390,  8604, 11186,    68, 10339, 11270,     2,  3529, 14873]) tensor([  945,  5347,  7492,  3639,  9499,  6291, 11789,  8767, 10796, 10575])
-------Step 1-------
tensor([ 1012, 14390,  8604, 11186,    68, 10339, 11270,     2,  3529, 14873]) tensor([ 7847, 10196, 13681,  4058,  2831,  2864,  7705, 10884, 10443, 10151])
-------Step 2-------
tensor([13024,    94,  4923, 12176, 14394,  6831,  4794,   241,    98, 13778]) tensor([ 5731, 10823,  1040,  9082, 13364,  2963,  7429, 10856,  1569,   365])
-------Step 3-------
tensor([13024,    94,  4923, 12176, 14394,  6831,  4794,   241,    98, 13778]) tensor([ 2101,  1541,  8611, 14062,  5300, 13667,  5894,  8901,  4073,  5640])
-------Step 4-------
tensor([ 3194,  7957,    34,   141,   296,  4068,  3573,  4707, 10677,    43]) tensor([ 9703,  9488, 13091, 11068,  9059,  4310,  7707, 10621, 13777,  6476])
-------Step 5-------
tensor([ 3194,  7957,    34,   141,   296,  4068,  3573,  4707, 10677,    43]) tensor([14728,  6474,  6296,  3895,  1513,  4270,  1799, 11911,  6717,  6428])
-------Step 6-------
tensor([  22, 3084,  874, 8153, 7446,  214,   81, 4291,  262,  329]) tensor([ 9783, 11686,  4198,  3829,  1599, 14731, 11665,  9646,  5365,  2380])
-------Step 7-------
tensor([  22, 3084,  874, 8153, 7446,  214,   81, 4291,  262,  329]) tensor([ 7518,  5914,  1528,  4325,  2589,  7360,  5024, 13610,  1161,  7829])
-------Step 8-------
tensor([ 8996,   149,  6514,   371,   189, 12408,  5743,   119,  2108, 12376]) tensor([12327,  4515, 11949, 11323,  1491,  6143, 10158,  8605,  2255,  4135])
-------Step 9-------
tensor([ 8996,   149,  6514,   371,   189, 12408,  5743,   119,  2108, 12376]) tensor([13829,  7179, 10456, 12718,  4247,  6940,  5709,  1279, 12467,  5423])
before start barrier
start train
[proc 0] 100 steps, total: 2.039, sample: 0.171, forward: 0.896, backward: 0.559, update: 0.328
[proc 1] 200 steps, total: 1.482, sample: 0.209, forward: 0.432, backward: 0.394, update: 0.339
[proc 0] 200 steps, total: 1.482, sample: 0.206, forward: 0.418, backward: 0.400, update: 0.331
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 737.910 us                | 13.029 ms                 |
| Forward                   | 4.035 ms                  | 8.703 ms                  |
| Backward                  | 4.037 ms                  | 9.200 ms                  |
| Optimize                  | 3.271 ms                  | 5.371 ms                  |
| OneStep                   | 12.752 ms                 | 31.155 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 300 steps, total: 1.495, sample: 0.213, forward: 0.452, backward: 0.387, update: 0.332
[proc 0] 300 steps, total: 1.495, sample: 0.193, forward: 0.444, backward: 0.407, update: 0.337
[proc 1] 400 steps, total: 1.477, sample: 0.190, forward: 0.442, backward: 0.391, update: 0.341
[proc 0] 400 steps, total: 1.477, sample: 0.174, forward: 0.437, backward: 0.401, update: 0.347
[proc 1] 500 steps, total: 1.464, sample: 0.171, forward: 0.443, backward: 0.422, update: 0.327
[proc 0] 500 steps, total: 1.464, sample: 0.173, forward: 0.422, backward: 0.409, update: 0.331
Successfully xmh. training takes 7.957871198654175 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
