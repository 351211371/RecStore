WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240123 02:01:35.675446 47211 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_41', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [47211 sampler.py:454] Start PreSampling
WARNING [47211 sampler.py:532] Before construct renumbering_dict
WARNING [47211 sampler.py:555] PreSampling done
W20240123 02:01:38.759786 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240123 02:01:38.759934 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240123 02:01:38.759959 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240123 02:01:38.759981 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240123 02:01:38.760011 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240123 02:01:38.760036 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240123 02:01:38.760061 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240123 02:01:38.760093 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240123 02:01:38.760123 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240123 02:01:38.760143 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240123 02:01:38.760172 47211 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240123 02:01:38.760191 47211 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240123 02:01:38.760212 47211 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240123 02:01:38.760315 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240123 02:01:38.760337 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240123 02:01:38.760365 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240123 02:01:38.760389 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240123 02:01:38.760416 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240123 02:01:38.760450 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240123 02:01:38.760476 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240123 02:01:38.760499 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240123 02:01:38.760522 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240123 02:01:38.760546 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240123 02:01:38.760565 47211 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240123 02:01:38.760581 47211 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240123 02:01:38.760599 47211 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240123 02:01:38.760643 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240123 02:01:38.760670 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240123 02:01:38.760694 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240123 02:01:38.760721 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240123 02:01:38.760746 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240123 02:01:38.760766 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240123 02:01:38.760802 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240123 02:01:38.760843 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240123 02:01:38.760869 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240123 02:01:38.760888 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240123 02:01:38.760907 47211 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240123 02:01:38.760923 47211 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240123 02:01:38.760946 47211 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240123 02:01:38.760986 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240123 02:01:38.761011 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240123 02:01:38.761030 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240123 02:01:38.761054 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240123 02:01:38.761072 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240123 02:01:38.761092 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240123 02:01:38.761116 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240123 02:01:38.761135 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240123 02:01:38.761157 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240123 02:01:38.761180 47211 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240123 02:01:38.761204 47211 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240123 02:01:38.761219 47211 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240123 02:01:38.761238 47211 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9703, num_edges=161860,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11374, num_edges=168961,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=10715, num_edges=190828,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=11184, num_edges=240046,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9703 N 161860 E
MertisPartition: part 1 has 11374 N 168961 E
MertisPartition: part 2 has 10715 N 190828 E
MertisPartition: part 3 has 11184 N 240046 E
Rank0: cached key size 186
Rank1: cached key size 186
Rank2: cached key size 186
Rank3: cached key size 186
Before renumbering graph:  {'_ID': tensor([   6,   10,   11,  ..., 5824, 6189, 2559]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 2])}
After renumbering graph:  {'_ID': tensor([ 826,  875,  888,  ..., 5620, 4579, 7850]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 2])}
part_g: DGLGraph(num_nodes=9703, num_edges=161860,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9703, num_edges=161860,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.325 seconds
[Rank1] pid = 47534
[Rank2] pid = 47559
INFO [47211 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [47534 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [47559 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [47644 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [47211 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [47534 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [47644 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [47559 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
I20240123 02:01:40.644631 47535 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240123 02:01:40.645495 47599 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240123 02:01:40.647502 47663 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240123 02:01:40.648047 47699 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 2.519, sample: 0.208, forward: 1.116, backward: 0.528, update: 0.471
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 2.516, sample: 0.210, forward: 1.089, backward: 0.547, update: 0.482
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 2.520, sample: 0.207, forward: 1.087, backward: 0.544, update: 0.465
[Rank3] pid = 47644
train_sampler.Prefill()
-------Step 0-------
tensor([ 6020,  8079, 13082,  5316,    36,  5228,  8874,    92,    90, 11168]) tensor([  888, 10213,  2544, 14131,  2807,  3880,  3745,  6430,  4403, 13581])
-------Step 1-------
tensor([ 6020,  8079, 13082,  5316,    36,  5228,  8874,    92,    90, 11168]) tensor([ 3601,  7911, 10484,  7960,  6738, 11247, 10535,  2712,  5568,  7086])
-------Step 2-------
tensor([13360, 10249,  8431,  2304,   108,  2739,     9,  8391,  3983,  3212]) tensor([11157,  1939,  6518,  7812,  9281,    16, 13427,  9081, 10034, 11754])
-------Step 3-------
tensor([13360, 10249,  8431,  2304,   108,  2739,     9,  8391,  3983,  3212]) tensor([ 9614,  1729, 14293,  3385,  8064,  3415, 13083,  2870,  6416, 11854])
-------Step 4-------
tensor([12762,  7852,  6968,  2238,  5853, 11577,  8985, 14058,   114, 10342]) tensor([  567,  5249, 11225,  8905,  4085,    98,  2674,  4050, 11049,  7794])
-------Step 5-------
tensor([12762,  7852,  6968,  2238,  5853, 11577,  8985, 14058,   114, 10342]) tensor([ 6980,  4897,  3675, 14243, 11959, 11185,  5727, 11261,  4391, 13983])
-------Step 6-------
tensor([ 1915,  2811,  2942, 14136,   140, 10883, 12411,  4902,   124,  3054]) tensor([ 4425, 14755, 13149,  3984, 10737,  5491,  2238,  6591, 14300,  8817])
-------Step 7-------
tensor([ 1915,  2811,  2942, 14136,   140, 10883, 12411,  4902,   124,  3054]) tensor([10603,  5423, 10466,  5229,  2064,   892,  2588,  3363,  4686,  1622])
-------Step 8-------
tensor([   13,  9680,    65,  8570,  5351, 11331, 12687,  5529,    69,  3516]) tensor([ 8008,  3304,  1480,  8244,  8976, 14080,  1587,  7469,  8514, 13249])
-------Step 9-------
tensor([   13,  9680,    65,  8570,  5351, 11331, 12687,  5529,    69,  3516]) tensor([ 5669,  7398,  8598,  3195, 12367,  2219, 14841,  2712,  5085,  4543])
before start barrier
start train
[proc 0] 100 steps, total: 2.517, sample: 0.217, forward: 1.149, backward: 0.565, update: 0.435
[proc 3] 200 steps, total: 1.862, sample: 0.248, forward: 0.546, backward: 0.388, update: 0.469
[proc 0] 200 steps, total: 1.862, sample: 0.263, forward: 0.591, backward: 0.405, update: 0.417
[proc 1] 200 steps, total: 1.862, sample: 0.256, forward: 0.521, backward: 0.387, update: 0.456
[proc 2] 200 steps, total: 1.862, sample: 0.240, forward: 0.572, backward: 0.431, update: 0.447
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 836.575 us                | 16.094 ms                 |
| Forward                   | 5.750 ms                  | 11.391 ms                 |
| Backward                  | 4.153 ms                  | 5.109 ms                  |
| Optimize                  | 4.197 ms                  | 6.103 ms                  |
| OneStep                   | 16.279 ms                 | 36.854 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 2] 300 steps, total: 2.010, sample: 0.230, forward: 0.600, backward: 0.434, update: 0.460
[proc 3] 300 steps, total: 2.011, sample: 0.227, forward: 0.562, backward: 0.388, update: 0.489
[proc 1] 300 steps, total: 2.011, sample: 0.238, forward: 0.563, backward: 0.390, update: 0.496
[proc 0] 300 steps, total: 2.011, sample: 0.244, forward: 0.631, backward: 0.416, update: 0.433
[proc 1] 400 steps, total: 2.357, sample: 0.279, forward: 0.608, backward: 0.391, update: 0.525
[proc 3] 400 steps, total: 2.357, sample: 0.311, forward: 0.588, backward: 0.389, update: 0.498
[proc 0] 400 steps, total: 2.357, sample: 0.245, forward: 0.689, backward: 0.344, update: 0.466
[proc 2] 400 steps, total: 2.357, sample: 0.323, forward: 0.631, backward: 0.390, update: 0.486
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 968.697 us                | 16.094 ms                 |
| Forward                   | 5.913 ms                  | 11.734 ms                 |
| Backward                  | 4.156 ms                  | 5.412 ms                  |
| Optimize                  | 4.272 ms                  | 7.349 ms                  |
| OneStep                   | 18.024 ms                 | 39.946 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 500 steps, total: 2.537, sample: 0.310, forward: 0.648, backward: 0.395, update: 0.533
[proc 3] 500 steps, total: 2.537, sample: 0.362, forward: 0.679, backward: 0.390, update: 0.549
[proc 2] 500 steps, total: 2.537, sample: 0.332, forward: 0.683, backward: 0.393, update: 0.530
[proc 0] 500 steps, total: 2.537, sample: 0.277, forward: 0.732, backward: 0.391, update: 0.478
Successfully xmh. training takes 11.284139156341553 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
