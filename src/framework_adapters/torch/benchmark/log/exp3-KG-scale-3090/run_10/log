WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240123 01:39:33.390285 60893 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_25', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=2, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=2, gpu=[0, 1], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='KnownLocalCachedEmbedding', use_my_emb=True, cache_ratio=0.05, shuffle=False, backwardMode='CppAsyncV2', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [60893 sampler.py:454] Start PreSampling
WARNING [60893 sampler.py:532] Before construct renumbering_dict
WARNING [60893 sampler.py:555] PreSampling done
W20240123 01:39:36.052266 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240123 01:39:36.052430 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240123 01:39:36.052464 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240123 01:39:36.052484 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240123 01:39:36.052510 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240123 01:39:36.052527 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240123 01:39:36.052551 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240123 01:39:36.052578 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240123 01:39:36.052600 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240123 01:39:36.052623 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240123 01:39:36.052646 60893 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240123 01:39:36.052664 60893 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240123 01:39:36.052678 60893 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240123 01:39:36.052778 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240123 01:39:36.052812 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240123 01:39:36.052832 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240123 01:39:36.052851 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240123 01:39:36.052871 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240123 01:39:36.052901 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240123 01:39:36.052922 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240123 01:39:36.052939 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240123 01:39:36.052955 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240123 01:39:36.052975 60893 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240123 01:39:36.052991 60893 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240123 01:39:36.053005 60893 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240123 01:39:36.053020 60893 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240123 01:39:36.228575 60893 IPCTensor.h:367] NewIPCTensor: full_emb [14951, 400]0x100000f72000
W20240123 01:39:36.228719 60893 IPCTensor.h:367] NewIPCTensor: full_emb_SparseRowWiseAdaGrad_sum [14951]0x100002644000
{0: Graph(num_nodes=13500, num_edges=273181,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=12803, num_edges=385691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 13500 N 273181 E
MertisPartition: part 1 has 12803 N 385691 E
Rank0: cached key size 373
Rank1: cached key size 373
Before renumbering graph:  {'_ID': tensor([    0,     2,     6,  ..., 11079,  2237, 14365]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
After renumbering graph:  {'_ID': tensor([  746,   790,   865,  ..., 11004, 11922,  9217]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 1])}
part_g: DGLGraph(num_nodes=13500, num_edges=273181,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=13500, num_edges=273181,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.873 seconds
INFO [60893 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [61624 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [61624 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [60893 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
W20240123 01:39:38.031853 61625 IPCTensor.h:406] NewIPCGPUTensor: embedding_cache_0 [747, 400]; dev=0; size=1.14 MB
W20240123 01:39:38.032387 61632 IPCTensor.h:406] NewIPCGPUTensor: embedding_cache_1 [747, 400]; dev=1; size=1.14 MB
W20240123 01:39:38.058460 61625 IPCTensor.h:367] NewIPCTensor: input_keys_0 [100000]0x100002658000
W20240123 01:39:38.058509 61632 IPCTensor.h:367] NewIPCTensor: input_keys_1 [100000]0x10000271d000
W20240123 01:39:38.058595 61632 IPCTensor.h:367] NewIPCTensor: input_keys_neg_1 [100000]0x1000027e2000
W20240123 01:39:38.058601 61625 IPCTensor.h:367] NewIPCTensor: input_keys_neg_0 [100000]0x1000028a7000
W20240123 01:39:38.058636 61632 IPCTensor.h:367] NewIPCTensor: backward_grads_1 [100000, 400]0x10000296c000
W20240123 01:39:38.058650 61625 IPCTensor.h:367] NewIPCTensor: backward_grads_0 [100000, 400]0x10000c204000
W20240123 01:39:38.058666 61632 IPCTensor.h:367] NewIPCTensor: backward_grads_neg_1 [100000, 400]0x100015a9c000
W20240123 01:39:38.058677 61625 IPCTensor.h:367] NewIPCTensor: backward_grads_neg_0 [100000, 400]0x10001f334000
W20240123 01:39:38.058710 61625 IPCTensor.h:406] NewIPCGPUTensor: backward_grads_0_gpu [100000, 400]; dev=0; size=152.6 MB
W20240123 01:39:38.058715 61632 IPCTensor.h:406] NewIPCGPUTensor: backward_grads_1_gpu [100000, 400]; dev=1; size=152.6 MB
W20240123 01:39:38.059402 61632 IPCTensor.h:406] NewIPCGPUTensor: backward_grads_neg_1_gpu [100000, 400]; dev=1; size=152.6 MB
W20240123 01:39:38.059435 61625 IPCTensor.h:406] NewIPCGPUTensor: backward_grads_neg_0_gpu [100000, 400]; dev=0; size=152.6 MB
[Rank1] pid = 61624
New CachedEmbedding, name=full_emb, shape=(14951, 400), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 747), (747, 1494)]
cudaHostRegister 0x100000f72000
0: KnownLocalCachedEmbedding init done
cudaHostRegister 0x100000f72000
1: KnownLocalCachedEmbedding init done
WARNING [61624 DistTensor.py:56] The tensor name already exists in the kvstore
WARNING [60893 DistTensor.py:56] The tensor name already exists in the kvstore
I20240123 01:39:38.193013 61625 IPC_barrier.h:118] CreateBarrier: new barrier, name: kgcachecontroller, count: 2
I20240123 01:39:38.193053 61632 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: kgcachecontroller, count: 2
W20240123 01:39:38.193847 61625 grad_base.h:55] KGCacheController, config={
        "num_gpus": 2,
        "L": 10,
        "backgrad_init": "both", 
        "kForwardItersPerStep": 2,
        "clr": 1,
        "nr_background_threads": 32,
        "backwardMode": "CppAsyncV2",
        "cache_ratio": 0.05
        }
W20240123 01:39:38.193948 61625 grad_base.h:172] Init GradProcessingBase done
I20240123 01:39:38.196980 61625 grad_async_v2.h:32] Use background thread to update emb. nr_background_threads=32
W20240123 01:39:38.197075 61625 kg_controller.h:78] after init GradAsyncProcessingV2
I20240123 01:39:38.197082 61625 kg_controller.h:84] Construct KGCacheController done
I20240123 01:39:38.400130 61625 grad_base.h:60] GraphEnv RegTensorsPerProcess
W20240123 01:39:38.543486 61938 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240123 01:39:38.543807 61938 parallel_pq_v2.h:76] insert failed, size(hashtable)=1
I20240123 01:39:38.576357 61625 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 2
I20240123 01:39:38.608211 61632 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 2
E20240123 01:39:39.644626 61625 parallel_pq_v2.h:76] insert failed, size(hashtable)=0
W20240123 01:39:39.654124 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=1, pq.top=1
W20240123 01:39:39.666453 61938 grad_async_v2.h:120] Detect new sample comes, old_end1, new_end2
E20240123 01:39:40.644080 61810 parallel_pq_v2.h:76] insert failed, size(hashtable)=114
W20240123 01:39:40.654011 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=34, pq.top=34
W20240123 01:39:40.691561 61938 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
E20240123 01:39:41.644016 61625 parallel_pq_v2.h:76] insert failed, size(hashtable)=37
W20240123 01:39:41.654103 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=63, pq.top=63
W20240123 01:39:41.695477 61938 grad_async_v2.h:120] Detect new sample comes, old_end4, new_end5
E20240123 01:39:42.644258 61937 parallel_pq_v2.h:76] insert failed, size(hashtable)=3542
W20240123 01:39:42.675208 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=92, pq.top=92
W20240123 01:39:42.714900 61938 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 4.313, sample: 0.355, forward: 1.053, backward: 0.668, update: 0.151
train_sampler.Prefill()
-------Step 0-------
tensor([  956, 14248,  5290, 12564,    28,  7938, 11482,     2,  2913, 14701]) tensor([  881,  5957,  6879,  2779, 14161,  4685, 10785, 10048, 12468, 10787])
-------Step 1-------
tensor([  956, 14248,  5290, 12564,    28,  7938, 11482,     2,  2913, 14701]) tensor([14548,  7388,  9234, 12336,  4520,  4363,  6418,  1355, 13930,  4302])
-------Step 2-------
tensor([ 3987,     9,  4511, 13111,  2773,  8417,  3734, 13211,  3903,  6291]) tensor([ 8016,  5365,  5195,  6406, 11235,  3018,   398,  6021, 13262,  3754])
-------Step 3-------
tensor([ 3987,     9,  4511, 13111,  2773,  8417,  3734, 13211,  3903,  6291]) tensor([ 9861, 14232, 14881, 12804,  1400,  7589,  7496, 12048,  9779,  5705])
-------Step 4-------
tensor([  24, 5065,  988, 7847, 7016,  348,  211, 4811,  107,  221]) tensor([10536, 10783,  4430,  3349,  1690, 14739, 13013,  6427,  6084,  2531])
-------Step 5-------
tensor([  24, 5065,  988, 7847, 7016,  348,  211, 4811,  107,  221]) tensor([ 3252,  1654,  2449, 12169, 13873,   801, 12662,  5311, 13711,  1565])
-------Step 6-------
tensor([12301,  7918,  9671, 12322,  5880,   220,  4472,  5842,  6336,  2079]) tensor([ 7819,  6520,  1057, 12396, 13492, 10593, 13055,  5131, 11641,  3072])
-------Step 7-------
tensor([12301,  7918,  9671, 12322,  5880,   220,  4472,  5842,  6336,  2079]) tensor([ 5715,   336, 11267,  4038,  3882,  4936,  9787, 14784, 11359, 12677])
-------Step 8-------
tensor([ 2036,  1874, 10228, 13531, 10223,  6603, 13742,  5595,    89,  3704]) tensor([ 3246,  7880, 12683,  8734,  4111, 12023, 11467,  7124, 10804,  2074])
-------Step 9-------
tensor([ 2036,  1874, 10228, 13531, 10223,  6603, 13742,  5595,    89,  3704]) tensor([13237,  5505, 12636,  1305,  9259,  1499,  6418,  3869,  8714, 12027])
before start barrier
start train
[proc 0] 100 steps, total: 4.345, sample: 0.392, forward: 0.960, backward: 0.645, update: 0.190
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.369 ms                  | 23.523 ms                 |
| Forward                   | 4.371 ms                  | 7.328 ms                  |
| Backward                  | 4.410 ms                  | 11.974 ms                 |
| Optimize                  | 1.906 ms                  | 2.944 ms                  |
| BarrierTimeBeforeRank0    | 26.664 us                 | 9.931 ms                  |
| AfterBackward             | 13.252 ms                 | 16.856 ms                 |
| BlockToStepN              | 4.487 ms                  | 12.401 ms                 |
| OneStep                   | 30.927 ms                 | 63.062 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 730.946 us                | 1.724 ms                  |
| ProcessBack:UpdateCache   | 562.234 us                | 955.778 us                |
| ProcessBack:UpsertPq      | 8.819 ms                  | 14.772 ms                 |
| ProcessOneStep            | 13.027 ms                 | 16.825 ms                 |
| BlockToStepN              | 4.583 ms                  | 12.346 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240123 01:39:43.644007 61937 parallel_pq_v2.h:76] insert failed, size(hashtable)=7037
W20240123 01:39:43.685065 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=124, pq.top=124
W20240123 01:39:43.721086 61938 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
E20240123 01:39:44.644088 61938 parallel_pq_v2.h:76] insert failed, size(hashtable)=132
W20240123 01:39:44.686378 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=156, pq.top=156
W20240123 01:39:44.726744 61938 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
E20240123 01:39:45.644016 61937 parallel_pq_v2.h:76] insert failed, size(hashtable)=5575
W20240123 01:39:45.698218 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=188, pq.top=188
W20240123 01:39:45.737772 61938 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
[proc 1] 200 steps, total: 3.206, sample: 0.334, forward: 0.340, backward: 0.433, update: 0.141
[proc 0] 200 steps, total: 3.206, sample: 0.393, forward: 0.428, backward: 0.427, update: 0.173
E20240123 01:39:46.644181 61938 parallel_pq_v2.h:76] insert failed, size(hashtable)=4
W20240123 01:39:46.718833 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=218, pq.top=218
W20240123 01:39:46.757704 61938 grad_async_v2.h:120] Detect new sample comes, old_end9, new_end0
E20240123 01:39:47.644007 61937 parallel_pq_v2.h:76] insert failed, size(hashtable)=8805
W20240123 01:39:47.745339 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=248, pq.top=248
W20240123 01:39:47.759918 61938 grad_async_v2.h:120] Detect new sample comes, old_end8, new_end9
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.370 ms                  | 21.456 ms                 |
| Forward                   | 4.339 ms                  | 6.975 ms                  |
| Backward                  | 4.427 ms                  | 5.679 ms                  |
| Optimize                  | 1.803 ms                  | 3.159 ms                  |
| BarrierTimeBeforeRank0    | 24.636 us                 | 2.252 ms                  |
| AfterBackward             | 10.635 ms                 | 16.525 ms                 |
| BlockToStepN              | 6.342 ms                  | 13.582 ms                 |
| OneStep                   | 30.984 ms                 | 62.277 ms                 |
+---------------------------+---------------------------+---------------------------+
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 699.639 us                | 1.210 ms                  |
| ProcessBack:UpdateCache   | 558.068 us                | 714.383 us                |
| ProcessBack:UpsertPq      | 8.154 ms                  | 14.573 ms                 |
| ProcessOneStep            | 10.596 ms                 | 16.487 ms                 |
| BlockToStepN              | 6.305 ms                  | 13.523 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240123 01:39:48.644008 61625 parallel_pq_v2.h:76] insert failed, size(hashtable)=668
W20240123 01:39:48.745187 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=277, pq.top=277
W20240123 01:39:48.761132 61938 grad_async_v2.h:120] Detect new sample comes, old_end7, new_end8
[proc 1] 300 steps, total: 3.469, sample: 0.317, forward: 0.358, backward: 0.405, update: 0.140
[proc 0] 300 steps, total: 3.469, sample: 0.369, forward: 0.439, backward: 0.442, update: 0.173
E20240123 01:39:49.644018 61937 parallel_pq_v2.h:76] insert failed, size(hashtable)=9563
W20240123 01:39:49.745565 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=305, pq.top=305
W20240123 01:39:49.763767 61938 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
E20240123 01:39:50.644032 61938 parallel_pq_v2.h:76] insert failed, size(hashtable)=22
W20240123 01:39:50.758227 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=333, pq.top=333
W20240123 01:39:50.773139 61938 grad_async_v2.h:120] Detect new sample comes, old_end3, new_end4
E20240123 01:39:51.644012 61937 parallel_pq_v2.h:76] insert failed, size(hashtable)=9879
W20240123 01:39:51.765527 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=360, pq.top=360
W20240123 01:39:51.796010 61938 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240123 01:39:52.644011 61937 parallel_pq_v2.h:76] insert failed, size(hashtable)=8134
W20240123 01:39:52.770924 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=387, pq.top=387
W20240123 01:39:52.816740 61938 grad_async_v2.h:120] Detect new sample comes, old_end8, new_end9
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.398 ms                  | 21.456 ms                 |
| Forward                   | 4.348 ms                  | 6.975 ms                  |
| Backward                  | 4.357 ms                  | 5.916 ms                  |
| Optimize                  | 1.751 ms                  | 3.135 ms                  |
| BarrierTimeBeforeRank0    | 24.502 us                 | 2.153 ms                  |
| AfterBackward             | 10.659 ms                 | 16.303 ms                 |
| BlockToStepN              | 7.420 ms                  | 21.324 ms                 |
| OneStep                   | 31.951 ms                 | 68.612 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 1] 400 steps, total: 3.693, sample: 0.345, forward: 0.394, backward: 0.393, update: 0.164
[proc 0] 400 steps, total: 3.693, sample: 0.368, forward: 0.427, backward: 0.407, update: 0.166
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 701.829 us                | 1.193 ms                  |
| ProcessBack:UpdateCache   | 549.251 us                | 707.555 us                |
| ProcessBack:UpsertPq      | 7.999 ms                  | 14.453 ms                 |
| ProcessOneStep            | 10.641 ms                 | 16.277 ms                 |
| BlockToStepN              | 7.433 ms                  | 21.255 ms                 |
+---------------------------+---------------------------+---------------------------+
E20240123 01:39:53.644007 61625 parallel_pq_v2.h:76] insert failed, size(hashtable)=2348
W20240123 01:39:53.785686 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=413, pq.top=413
W20240123 01:39:53.834007 61938 grad_async_v2.h:120] Detect new sample comes, old_end4, new_end5
E20240123 01:39:54.644011 61937 parallel_pq_v2.h:76] insert failed, size(hashtable)=10728
W20240123 01:39:54.785615 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=439, pq.top=439
W20240123 01:39:54.852586 61938 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
E20240123 01:39:55.644007 61625 parallel_pq_v2.h:76] insert failed, size(hashtable)=126
W20240123 01:39:55.792382 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=463, pq.top=463
W20240123 01:39:55.882979 61938 grad_async_v2.h:120] Detect new sample comes, old_end5, new_end6
E20240123 01:39:56.644012 61938 parallel_pq_v2.h:76] insert failed, size(hashtable)=328
W20240123 01:39:56.792951 61625 grad_async_v2.h:249] Sleep in <BlockToStepN>, step_no=488, pq.top=488
W20240123 01:39:56.883627 61938 grad_async_v2.h:120] Detect new sample comes, old_end0, new_end1
[proc 0] 500 steps, total: 3.987, sample: 0.418, forward: 0.434, backward: 0.406, update: 0.167
[proc 1] 500 steps, total: 3.987, sample: 0.352, forward: 0.397, backward: 0.400, update: 0.167
Successfully xmh. training takes 18.70030975341797 seconds
before call kg_cache_controller.StopThreads()
W20240123 01:39:57.276777 61625 grad_async_v2.h:71] call StopThreads. PID = 60893
W20240123 01:39:57.276837 61625 grad_base.h:210] before processOneStepNegThread_.join();
W20240123 01:39:57.277093 61625 grad_base.h:212] after processOneStepNegThread_.join();
W20240123 01:39:57.277107 61625 grad_async_v2.h:73] call GradProcessingBase::StopThreads.
W20240123 01:39:57.281466 61625 grad_async_v2.h:91] StopThreads done.
[W tensorpipe_agent.cpp:725] RPC agent for worker0 encountered error when reading incoming request from worker1: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
On rank0, prepare to call self.controller.StopThreads(), self=<python.controller_process.KGCacheControllerWrapper object at 0x7fcb061b1bd0>
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| ProcessBack:Shuffle       | 704.533 us                | 1.210 ms                  |
| ProcessBack:UpdateCache   | 544.167 us                | 706.083 us                |
| ProcessBack:UpsertPq      | 7.947 ms                  | 14.414 ms                 |
| ProcessOneStep            | 10.782 ms                 | 16.277 ms                 |
| BlockToStepN              | 8.293 ms                  | 22.257 ms                 |
+---------------------------+---------------------------+---------------------------+
W20240123 01:39:58.967793 60893 HazptrDomain.h:148] Tagged objects remain. This may indicate a higher-level leak of object(s) that use hazptr_obj_cohort.
