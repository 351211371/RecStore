WARNING: Logging before InitGoogleLogging() is written to STDERR
I20240123 01:49:03.124475 35277 IPC_barrier.h:128] MultiProcessBarrierFactory->ClearIPCMemory()
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_FB15k_31', no_save_emb=True, max_step=500, batch_size=400, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=100, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=0.0, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.05, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [35277 sampler.py:454] Start PreSampling
WARNING [35277 sampler.py:532] Before construct renumbering_dict
WARNING [35277 sampler.py:555] PreSampling done
W20240123 01:49:07.792315 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240123 01:49:07.792500 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240123 01:49:07.792536 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240123 01:49:07.792570 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240123 01:49:07.792601 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240123 01:49:07.792635 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240123 01:49:07.792670 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240123 01:49:07.792716 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240123 01:49:07.792747 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240123 01:49:07.792775 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240123 01:49:07.792819 35277 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240123 01:49:07.792848 35277 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240123 01:49:07.792876 35277 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240123 01:49:07.792999 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240123 01:49:07.793032 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240123 01:49:07.793074 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240123 01:49:07.793108 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240123 01:49:07.793136 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240123 01:49:07.793188 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240123 01:49:07.793318 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240123 01:49:07.793354 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240123 01:49:07.793386 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240123 01:49:07.793422 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240123 01:49:07.793448 35277 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240123 01:49:07.793473 35277 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240123 01:49:07.793494 35277 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240123 01:49:07.793553 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240123 01:49:07.793601 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240123 01:49:07.793628 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240123 01:49:07.793655 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240123 01:49:07.793690 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240123 01:49:07.793718 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240123 01:49:07.793745 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240123 01:49:07.793798 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240123 01:49:07.793826 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240123 01:49:07.793869 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240123 01:49:07.793896 35277 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240123 01:49:07.793920 35277 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240123 01:49:07.793942 35277 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240123 01:49:07.793995 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240123 01:49:07.794025 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240123 01:49:07.794052 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240123 01:49:07.794093 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240123 01:49:07.794126 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240123 01:49:07.794159 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240123 01:49:07.794186 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240123 01:49:07.794219 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240123 01:49:07.794247 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240123 01:49:07.794274 35277 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240123 01:49:07.794301 35277 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240123 01:49:07.794323 35277 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240123 01:49:07.794348 35277 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9703, num_edges=161860,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11374, num_edges=168961,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=10715, num_edges=190828,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=11184, num_edges=240046,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9703 N 161860 E
MertisPartition: part 1 has 11374 N 168961 E
MertisPartition: part 2 has 10715 N 190828 E
MertisPartition: part 3 has 11184 N 240046 E
Rank0: cached key size 186
Rank1: cached key size 186
Rank2: cached key size 186
Rank3: cached key size 186
Before renumbering graph:  {'_ID': tensor([   6,   10,   11,  ..., 5824, 6189, 2559]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 2])}
After renumbering graph:  {'_ID': tensor([ 993, 1110, 1148,  ..., 5227, 2991, 8485]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 1, 1, 2])}
part_g: DGLGraph(num_nodes=9703, num_edges=161860,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9703, num_edges=161860,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 4.925 seconds
[Rank1] pid = 35692
[Rank2] pid = 35720
INFO [35277 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [35692 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [35720 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [35821 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [35692 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [35720 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [35821 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [35277 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
I20240123 01:49:10.699504 35693 IPC_barrier.h:118] CreateBarrier: new barrier, name: start_barrier, count: 4
I20240123 01:49:10.700912 35757 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240123 01:49:10.701910 35885 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
I20240123 01:49:10.703191 35822 IPC_barrier.h:112] CreateBarrier: find existing barrier, name: start_barrier, count: 4
train_sampler.Prefill()
before start barrier
start train
[proc 1] 100 steps, total: 2.289, sample: 0.206, forward: 1.032, backward: 0.552, update: 0.305
train_sampler.Prefill()
before start barrier
start train
[proc 2] 100 steps, total: 2.288, sample: 0.205, forward: 1.052, backward: 0.545, update: 0.330
[Rank3] pid = 35821
train_sampler.Prefill()
-------Step 0-------
tensor([ 9114,  5045, 12146,  5346,   140,  5579, 12066,   167,    87, 13562]) tensor([ 1148,  6436,  3073, 14341,  2755, 11121,  5231,  6581,  2987, 10550])
-------Step 1-------
tensor([ 9114,  5045, 12146,  5346,   140,  5579, 12066,   167,    87, 13562]) tensor([  893, 14426,  6802,  2487,  3632,   360,  8344, 11451,  8978,  5081])
-------Step 2-------
tensor([  131, 14785,  4556,   886,  5157,  8011, 14514,   153,   851,    84]) tensor([11593,   106,  9564,  2578,  9053,   866,  5013,  6721, 13079,   210])
-------Step 3-------
tensor([  131, 14785,  4556,   886,  5157,  8011, 14514,   153,   851,    84]) tensor([ 4211,  9435, 14347,  5726,  6972, 14169,  2834,  4172, 10793, 11832])
-------Step 4-------
tensor([1560, 4021, 2499, 7284, 5384,  137, 8458, 1530, 6188, 2065]) tensor([10368,  6517,  2708,  7393, 11091,  3966, 14129,  5108,   449,  6910])
-------Step 5-------
tensor([1560, 4021, 2499, 7284, 5384,  137, 8458, 1530, 6188, 2065]) tensor([12191,  1223,  1391,  1019, 10640, 12006,   867,  1180,  6146,  6617])
-------Step 6-------
tensor([ 8410, 12831, 11636,  6344,    38,  1941,   143, 11515,  4802,  4118]) tensor([11177,  1679,  9844, 11153, 12170,   169,  8909,   445,  6272, 13818])
-------Step 7-------
tensor([ 8410, 12831, 11636,  6344,    38,  1941,   143, 11515,  4802,  4118]) tensor([13181, 12946,  6573,  5904, 10127,  1744,  5257,  5880,  1504,  5855])
-------Step 8-------
tensor([ 3666,   101, 14600,  5918, 14360,  3164,  6969, 10708,  2882, 12657]) tensor([ 4225,  9938, 12337,  9517,  6866, 13741,  1595,  8941,  1757,  3474])
-------Step 9-------
tensor([ 3666,   101, 14600,  5918, 14360,  3164,  6969, 10708,  2882, 12657]) tensor([ 5001,  3279,  1151,  5123,  9549, 14656,  1856, 10624, 10316,  8327])
before start barrier
start train
[proc 0] 100 steps, total: 2.287, sample: 0.190, forward: 1.040, backward: 0.552, update: 0.285
train_sampler.Prefill()
before start barrier
start train
[proc 3] 100 steps, total: 2.285, sample: 0.204, forward: 1.021, backward: 0.553, update: 0.306
[proc 2] 200 steps, total: 1.649, sample: 0.222, forward: 0.490, backward: 0.390, update: 0.328
[proc 3] 200 steps, total: 1.649, sample: 0.248, forward: 0.482, backward: 0.393, update: 0.314
[proc 0] 200 steps, total: 1.649, sample: 0.225, forward: 0.494, backward: 0.406, update: 0.301
[proc 1] 200 steps, total: 1.649, sample: 0.244, forward: 0.473, backward: 0.395, update: 0.320
+---------------------------+---------------------------+---------------------------+
| Name                      | P50                       | P99                       |
+---------------------------+---------------------------+---------------------------+
| GenInput                  | 1.062 ms                  | 12.265 ms                 |
| Forward                   | 4.865 ms                  | 9.138 ms                  |
| Backward                  | 4.086 ms                  | 5.910 ms                  |
| Optimize                  | 3.007 ms                  | 4.969 ms                  |
| OneStep                   | 15.030 ms                 | 28.079 ms                 |
+---------------------------+---------------------------+---------------------------+
[proc 3] 300 steps, total: 1.548, sample: 0.199, forward: 0.462, backward: 0.396, update: 0.303
[proc 2] 300 steps, total: 1.548, sample: 0.202, forward: 0.457, backward: 0.392, update: 0.327
[proc 1] 300 steps, total: 1.548, sample: 0.204, forward: 0.454, backward: 0.404, update: 0.309
[proc 0] 300 steps, total: 1.548, sample: 0.196, forward: 0.480, backward: 0.397, update: 0.288
[proc 2] 400 steps, total: 1.486, sample: 0.189, forward: 0.438, backward: 0.392, update: 0.316
[proc 3] 400 steps, total: 1.486, sample: 0.201, forward: 0.438, backward: 0.391, update: 0.296
[proc 1] 400 steps, total: 1.486, sample: 0.194, forward: 0.435, backward: 0.401, update: 0.295
[proc 0] 400 steps, total: 1.486, sample: 0.191, forward: 0.454, backward: 0.400, update: 0.278
[proc 1] 500 steps, total: 1.417, sample: 0.180, forward: 0.425, backward: 0.395, update: 0.274
[proc 2] 500 steps, total: 1.417, sample: 0.179, forward: 0.417, backward: 0.389, update: 0.291
[proc 3] 500 steps, total: 1.417, sample: 0.187, forward: 0.421, backward: 0.401, update: 0.280
[proc 0] 500 steps, total: 1.417, sample: 0.172, forward: 0.436, backward: 0.388, update: 0.267
Successfully xmh. training takes 8.3881676197052 seconds
before call kg_cache_controller.StopThreads()
KGCacheControllerWrapperDummy.StopThreads
