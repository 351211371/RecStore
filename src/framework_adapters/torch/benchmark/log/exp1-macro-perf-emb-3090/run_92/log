perf_emb.py:126: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("Before init DistEmbedding")
WARNING [perf_emb.py:126] Before init DistEmbedding
perf_emb.py:129: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("After init DistEmbedding")
WARNING [perf_emb.py:129] After init DistEmbedding
========== Running Perf with routine <function routine_local_cache_helper at 0x7f4bd87b6ee0>==========
Worker 0 pid=65069
Worker 1 pid=65070
Worker 2 pid=65071
Worker 3 pid=65072
Worker 4 pid=65078
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 4
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 5
INFO [distributed_c10d.py:466] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
Step99:rank3, time: 21.948, per_step: 0.219476
Step99:rank4, time: 21.977, per_step: 0.219775
Step99:rank2, time: 22.121, per_step: 0.221212
Step99:rank5, time: 21.985, per_step: 0.219848
Step99:rank1, time: 21.883, per_step: 0.218834
Step99:rank0, time: 21.980, per_step: 0.219798
Step199:rank2, time: 20.321, per_step: 0.201195
Step199:rank3, time: 20.355, per_step: 0.201533
Step199:rank1, time: 20.335, per_step: 0.201339
Step199:rank4, time: 20.356, per_step: 0.201544
Step199:rank5, time: 20.351, per_step: 0.201499
Step199:rank0, time: 20.391, per_step: 0.201894
Step299:rank5, time: 20.390, per_step: 0.201878
Step299:rank4, time: 20.393, per_step: 0.201912
Step299:rank2, time: 20.433, per_step: 0.202306
Step299:rank3, time: 20.414, per_step: 0.202122
Step299:rank1, time: 20.415, per_step: 0.202131
Step299:rank0, time: 20.395, per_step: 0.201926
Step399:rank5, time: 19.901, per_step: 0.197035
Step399:rank1, time: 19.915, per_step: 0.197176
Step399:rank3, time: 19.933, per_step: 0.197359
Step399:rank2, time: 19.948, per_step: 0.197503
Step399:rank4, time: 19.961, per_step: 0.197630
Step399:rank0, time: 19.937, per_step: 0.197396
Step499:rank2, time: 20.658, per_step: 0.204536
Step499:rank4, time: 20.659, per_step: 0.204544
Step499:rank3, time: 20.678, per_step: 0.204730
Step499:rank1, time: 20.695, per_step: 0.204898
Step499:rank5, time: 20.733, per_step: 0.205279
Step499:rank0, time: 20.706, per_step: 0.205006
Worker 5 pid=65079
Successfully xmh
