perf_emb.py:126: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("Before init DistEmbedding")
WARNING [perf_emb.py:126] Before init DistEmbedding
perf_emb.py:129: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("After init DistEmbedding")
WARNING [perf_emb.py:129] After init DistEmbedding
========== Running Perf with routine <function routine_local_cache_helper at 0x7f31df7ddee0>==========
Worker 0 pid=50373
Worker 1 pid=50374
Worker 2 pid=50375
Worker 3 pid=50376
Worker 4 pid=50377
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 4
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 5
INFO [distributed_c10d.py:466] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([100000000, 32])
Step99:rank2, time: 21.371, per_step: 0.213707
Step99:rank3, time: 23.434, per_step: 0.234335
Step99:rank1, time: 21.649, per_step: 0.216487
Step99:rank5, time: 21.532, per_step: 0.215324
Step99:rank4, time: 21.617, per_step: 0.216174
Step99:rank0, time: 21.731, per_step: 0.217306
Step199:rank5, time: 20.141, per_step: 0.199415
Step199:rank1, time: 20.172, per_step: 0.199719
Step199:rank2, time: 20.214, per_step: 0.200138
Step199:rank4, time: 20.182, per_step: 0.199823
Step199:rank3, time: 20.225, per_step: 0.200251
Step199:rank0, time: 20.183, per_step: 0.199828
Step299:rank3, time: 19.876, per_step: 0.196791
Step299:rank1, time: 19.929, per_step: 0.197319
Step299:rank2, time: 19.905, per_step: 0.197076
Step299:rank4, time: 19.903, per_step: 0.197056
Step299:rank5, time: 19.968, per_step: 0.197707
Step299:rank0, time: 19.920, per_step: 0.197225
Step399:rank3, time: 20.005, per_step: 0.198068
Step399:rank2, time: 20.003, per_step: 0.198053
Step399:rank5, time: 20.004, per_step: 0.198064
Step399:rank1, time: 20.030, per_step: 0.198321
Step399:rank4, time: 20.029, per_step: 0.198310
Step399:rank0, time: 20.025, per_step: 0.198266
Step499:rank1, time: 20.303, per_step: 0.201017
Step499:rank5, time: 20.319, per_step: 0.201174
Step499:rank4, time: 20.318, per_step: 0.201168
Step499:rank3, time: 20.352, per_step: 0.201507
Step499:rank2, time: 20.358, per_step: 0.201560
Step499:rank0, time: 20.325, per_step: 0.201233
Worker 5 pid=50378
Successfully xmh
