perf_emb.py:126: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("Before init DistEmbedding")
WARNING [perf_emb.py:126] Before init DistEmbedding
perf_emb.py:129: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("After init DistEmbedding")
WARNING [perf_emb.py:129] After init DistEmbedding
========== Running Perf with routine <function routine_local_cache_helper at 0x7f3f37b3cee0>==========
Worker 0 pid=50159
Worker 1 pid=50160
Worker 2 pid=50161
Worker 3 pid=50162
Worker 4 pid=50163
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 5
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 4
INFO [distributed_c10d.py:466] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
Step99:rank1, time: 19.186, per_step: 0.191865
Step99:rank4, time: 19.172, per_step: 0.191720
Step99:rank3, time: 19.424, per_step: 0.194243
Step99:rank5, time: 19.204, per_step: 0.192042
Step99:rank2, time: 19.161, per_step: 0.191606
Step99:rank0, time: 19.281, per_step: 0.192812
Step199:rank5, time: 17.389, per_step: 0.172171
Step199:rank2, time: 17.401, per_step: 0.172286
Step199:rank3, time: 17.410, per_step: 0.172381
Step199:rank4, time: 17.411, per_step: 0.172387
Step199:rank1, time: 17.426, per_step: 0.172536
Step199:rank0, time: 17.390, per_step: 0.172182
Step299:rank2, time: 17.596, per_step: 0.174219
Step299:rank5, time: 17.611, per_step: 0.174367
Step299:rank1, time: 17.594, per_step: 0.174195
Step299:rank3, time: 17.607, per_step: 0.174328
Step299:rank4, time: 17.615, per_step: 0.174403
Step299:rank0, time: 17.607, per_step: 0.174324
Step399:rank2, time: 16.862, per_step: 0.166950
Step399:rank5, time: 16.878, per_step: 0.167111
Step399:rank4, time: 16.864, per_step: 0.166967
Step399:rank3, time: 16.876, per_step: 0.167088
Step399:rank1, time: 16.885, per_step: 0.167182
Step399:rank0, time: 16.855, per_step: 0.166879
Step499:rank3, time: 17.049, per_step: 0.168798
Step499:rank2, time: 17.091, per_step: 0.169217
Step499:rank5, time: 17.081, per_step: 0.169118
Step499:rank4, time: 17.084, per_step: 0.169153
Step499:rank1, time: 17.082, per_step: 0.169130
Step499:rank0, time: 17.096, per_step: 0.169268
Worker 5 pid=50169
Successfully xmh
