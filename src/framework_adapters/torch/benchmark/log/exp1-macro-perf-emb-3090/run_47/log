perf_emb.py:126: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("Before init DistEmbedding")
WARNING [perf_emb.py:126] Before init DistEmbedding
perf_emb.py:129: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead
  logging.warn("After init DistEmbedding")
WARNING [perf_emb.py:129] After init DistEmbedding
========== Running Perf with routine <function routine_local_cache_helper at 0x7f5f840a4e50>==========
Worker 0 pid=5730
Worker 1 pid=5731
Worker 2 pid=5732
Worker 3 pid=5733
Worker 4 pid=5734
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [distributed_c10d.py:466] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 4
INFO [distributed_c10d.py:432] Added key: store_based_barrier_key:1 to store for rank: 5
INFO [distributed_c10d.py:466] Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
INFO [distributed_c10d.py:466] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 6 nodes.
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
cudaHostRegister cudaError.success, type(r)=<class 'torch._C._cudart.cudaError'>
weight.shape torch.Size([10000000, 32])
Step99:rank5, time: 27.813, per_step: 0.278128
Step99:rank3, time: 27.856, per_step: 0.278563
Step99:rank2, time: 27.817, per_step: 0.278173
Step99:rank1, time: 27.811, per_step: 0.278114
Step99:rank4, time: 27.839, per_step: 0.278387
Step99:rank0, time: 27.985, per_step: 0.279854
Step199:rank1, time: 26.498, per_step: 0.262356
Step199:rank3, time: 26.508, per_step: 0.262455
Step199:rank2, time: 26.509, per_step: 0.262462
Step199:rank4, time: 26.491, per_step: 0.262285
Step199:rank5, time: 26.534, per_step: 0.262709
Step199:rank0, time: 26.502, per_step: 0.262400
Worker 5 pid=5741
Successfully xmh
