/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_239', no_save_emb=True, max_step=500, batch_size=8400, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.2, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2434840 sampler.py:454] Start PreSampling
WARNING [2434840 sampler.py:532] Before construct renumbering_dict
WARNING [2434840 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:59:47.654698 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:59:47.654882 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:59:47.654919 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:59:47.654947 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:59:47.654975 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:59:47.655004 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:59:47.655032 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:59:47.655064 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:59:47.655095 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:59:47.655124 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:59:47.655155 2434840 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:59:47.655187 2434840 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:59:47.655212 2434840 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:59:47.655316 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:59:47.655356 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:59:47.655385 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:59:47.655412 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:59:47.655438 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:59:47.655475 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:59:47.655527 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:59:47.655558 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:59:47.655588 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:59:47.655615 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:59:47.655651 2434840 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:59:47.655679 2434840 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:59:47.655702 2434840 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:59:47.655761 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:59:47.655807 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:59:47.655838 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:59:47.655865 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:59:47.655901 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:59:47.655930 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:59:47.655957 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:59:47.655983 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:59:47.656011 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:59:47.656046 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:59:47.656075 2434840 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:59:47.656100 2434840 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:59:47.656123 2434840 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:59:47.656172 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:59:47.656204 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:59:47.656241 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:59:47.656271 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:59:47.656298 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:59:47.656324 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:59:47.656351 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:59:47.656378 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:59:47.656404 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:59:47.656430 2434840 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:59:47.656457 2434840 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:59:47.656482 2434840 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:59:47.656512 2434840 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 747
Rank1: cached key size 747
Rank2: cached key size 747
Rank3: cached key size 747
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([3163, 3253, 3282,  ..., 9422, 8146, 7524]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 1.584 seconds
[Rank1] pid = 2435051
[Rank2] pid = 2435116
INFO [2434840 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2435051 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2435180 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2435116 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2435116 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2435180 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2434840 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2435051 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2435180
-------Step 0-------
tensor([10566,   376, 14793, 10655,  6087,  7840,    89,  3626,  4998, 13045]) tensor([ 3282,   249,  7489, 11757, 13534,    39, 12385,  5197,  2112,  8194])
-------Step 1-------
tensor([10566,   376, 14793, 10655,  6087,  7840,    89,  3626,  4998, 13045]) tensor([ 6966, 14754, 11000,  5182,  1748,  9934,  9842,   900,  2770, 11880])
-------Step 2-------
tensor([10823,    85, 14666,   236,  4723,   447, 14544, 11852,  4286,  7435]) tensor([ 6883, 10216, 13098,  8373,  8068,  1597,  6030,  2437,  2785, 10388])
-------Step 3-------
tensor([10823,    85, 14666,   236,  4723,   447, 14544, 11852,  4286,  7435]) tensor([13656,  9520, 10306,  5980, 12667, 10945, 12548,  4904,  7507,  9197])
-------Step 4-------
tensor([ 5280,  5788,  7118,   574,    35, 10395,  9863,   349,  1973,  2561]) tensor([ 1725,  6186, 13011, 10241,  9285,  1226,  4695, 10290,  8497,  3727])
-------Step 5-------
tensor([ 5280,  5788,  7118,   574,    35, 10395,  9863,   349,  1973,  2561]) tensor([ 8227,  5565,    76, 10027, 12985,  5253,  1633,  3403, 10395,  5410])
-------Step 6-------
tensor([ 7435, 13701,  8758,   568,  5991,  7735,   737, 11713,    18,  5378]) tensor([   53,  1022,  9371,  6144,  4182,  9535,  5667, 12695, 12577,   851])
-------Step 7-------
tensor([ 7435, 13701,  8758,   568,  5991,  7735,   737, 11713,    18,  5378]) tensor([   60,  3340,   558, 14660, 14343, 11261, 13696,  9823, 14330,  8635])
-------Step 8-------
tensor([12599, 14159,  6032,  6277, 10502,  5513,  7650,  4643,  1950, 11167]) tensor([13601, 14503, 10999, 13896, 14723, 10984,  9234, 11648,  8878,  7825])
-------Step 9-------
tensor([12599, 14159,  6032,  6277, 10502,  5513,  7650,  4643,  1950, 11167]) tensor([  276,  9217,  9371,  2274,   355,   449, 13608,   868,   504, 11356])
[proc 0][Train](200/500) average pos_loss: 0.5910414746031165
[proc 0][Train](200/500) average neg_loss: 0.27056643075367903
[proc 0][Train](200/500) average loss: 0.43080394744873046
[proc 0][Train](200/500) average regularization: 6.194550236614305e-05
[proc 0] 200 steps, total: 35.413, sample: 1.056, forward: 13.903, backward: 17.193, update: 2.923
[proc 3][Train](200/500) average pos_loss: 0.6488439976423979
[proc 3][Train](200/500) average neg_loss: 0.31696171243849675
[proc 3][Train](200/500) average loss: 0.482902852371335
[proc 3][Train](200/500) average regularization: 6.073809997360513e-05
[proc 3] 200 steps, total: 35.408, sample: 1.909, forward: 6.993, backward: 6.601, update: 4.531
[proc 2][Train](200/500) average pos_loss: 0.6829212638735771
[proc 2][Train](200/500) average neg_loss: 0.3409414174722042
[proc 2][Train](200/500) average loss: 0.5119313438981772
[proc 2][Train](200/500) average regularization: 6.157854029879672e-05
[proc 2] 200 steps, total: 35.418, sample: 1.800, forward: 7.021, backward: 6.324, update: 4.171
[proc 1][Train](200/500) average pos_loss: 0.6209441830217838
[proc 1][Train](200/500) average neg_loss: 0.31140953541733324
[proc 1][Train](200/500) average loss: 0.4661768529564142
[proc 1][Train](200/500) average regularization: 6.12527808516461e-05
[proc 1] 200 steps, total: 35.410, sample: 1.899, forward: 6.725, backward: 6.236, update: 4.345
[proc 2][Train](400/500) average pos_loss: 0.19769627086818217
[proc 2][Train](400/500) average neg_loss: 0.20275727085769177
[proc 2][Train](400/500) average loss: 0.20022677078843118
[proc 2][Train](400/500) average regularization: 5.065827710495796e-05
[proc 2] 400 steps, total: 32.649, sample: 1.962, forward: 6.504, backward: 5.013, update: 4.264
[proc 0][Train](400/500) average pos_loss: 0.11364024002104997
[proc 0][Train](400/500) average neg_loss: 0.14614886090159415
[proc 0][Train](400/500) average loss: 0.1298945502564311
[proc 0][Train](400/500) average regularization: 5.251387234238791e-05
[proc 0] 400 steps, total: 32.649, sample: 1.094, forward: 13.057, backward: 15.324, update: 2.827
[proc 3][Train](400/500) average pos_loss: 0.16246946796774864
[proc 3][Train](400/500) average neg_loss: 0.1786239092797041
[proc 3][Train](400/500) average loss: 0.17054668858647345
[proc 3][Train](400/500) average regularization: 4.9829377294372536e-05
[proc 3] 400 steps, total: 32.649, sample: 1.767, forward: 6.225, backward: 4.996, update: 4.584
[proc 1][Train](400/500) average pos_loss: 0.1442674446478486
[proc 1][Train](400/500) average neg_loss: 0.17294056624174117
[proc 1][Train](400/500) average loss: 0.1586040049791336
[proc 1][Train](400/500) average regularization: 5.153215444806847e-05
[proc 1] 400 steps, total: 32.649, sample: 1.925, forward: 5.817, backward: 4.550, update: 4.318
Successfully xmh. training takes 84.24034142494202 seconds
