/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_231', no_save_emb=True, max_step=500, batch_size=6600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.2, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2420608 sampler.py:454] Start PreSampling
WARNING [2420608 sampler.py:532] Before construct renumbering_dict
WARNING [2420608 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:41:40.018110 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:41:40.018304 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:41:40.018339 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:41:40.018369 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:41:40.018399 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:41:40.018429 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:41:40.018458 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:41:40.018492 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:41:40.018520 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:41:40.018549 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:41:40.018582 2420608 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:41:40.018615 2420608 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:41:40.018640 2420608 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:41:40.018747 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:41:40.018786 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:41:40.018815 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:41:40.018841 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:41:40.018877 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:41:40.018904 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:41:40.018949 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:41:40.018976 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:41:40.019003 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:41:40.019032 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:41:40.019068 2420608 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:41:40.019094 2420608 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:41:40.019117 2420608 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:41:40.019170 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:41:40.019205 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:41:40.019233 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:41:40.019261 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:41:40.019299 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:41:40.019327 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:41:40.019356 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:41:40.019382 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:41:40.019409 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:41:40.019438 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:41:40.019464 2420608 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:41:40.019490 2420608 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:41:40.019512 2420608 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:41:40.019558 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:41:40.019593 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:41:40.019620 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:41:40.019647 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:41:40.019675 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:41:40.019703 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:41:40.019730 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:41:40.019766 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:41:40.019805 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:41:40.019834 2420608 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:41:40.019862 2420608 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:41:40.019887 2420608 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:41:40.019910 2420608 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 747
Rank1: cached key size 747
Rank2: cached key size 747
Rank3: cached key size 747
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([3161, 3245, 3274,  ..., 8970, 8021, 7634]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 1.651 seconds
[Rank1] pid = 2420822
[Rank2] pid = 2420886
INFO [2420608 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2420886 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2420951 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2420951 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2420822 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2420822 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2420608 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2420886 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2420951
-------Step 0-------
tensor([ 9900,   468, 12338, 11785,  6134,    87,   482,  3452,  4957, 12542]) tensor([ 3274,   221,  7559, 13306, 12703,   620, 11251,  5322,  1821,  8990])
-------Step 1-------
tensor([ 9900,   468, 12338, 11785,  6134,    87,   482,  3452,  4957, 12542]) tensor([ 2090,  7638, 14194,  6519,  6922,  3472,  3266, 13551,  6872,  8361])
-------Step 2-------
tensor([12179,  9883,  8035,   630,  4270,  5387,   490, 14726, 14067,  8054]) tensor([6818, 1777, 1010, 9179, 6634, 3545, 8848, 6030, 5915, 1198])
-------Step 3-------
tensor([12179,  9883,  8035,   630,  4270,  5387,   490, 14726, 14067,  8054]) tensor([  271, 13784,  4802,  7334, 10685,  6100, 11153,  8240, 14588,  9554])
-------Step 4-------
tensor([ 7595,  7405,  7900, 12010, 13834,  8661, 12902,   310,  4894,   686]) tensor([ 5547,  7971,  9770, 14343,  5244,  2892, 13941, 10839,  7316,  3917])
-------Step 5-------
tensor([ 7595,  7405,  7900, 12010, 13834,  8661, 12902,   310,  4894,   686]) tensor([  220, 11687,  6622, 13260,   271,  4933,  5220,  4264, 10777, 12902])
-------Step 6-------
tensor([ 3102,   309,  4785,   722,  6699,  4190, 14841,  7716, 13229,   292]) tensor([ 1133,  5253,  1065,   320,  9878, 13450, 11760,   498, 11615,  6986])
-------Step 7-------
tensor([ 3102,   309,  4785,   722,  6699,  4190, 14841,  7716, 13229,   292]) tensor([ 5301,  3516,  7241, 13928,  6256, 14094,  1272,  4151,  7720, 10507])
-------Step 8-------
tensor([ 8456,  3713,  6000,   233,   565,   614, 10828,   469,  7486,  8343]) tensor([11501,  5439, 13063, 12818,  6179,  6268, 12169,  2930,   826, 13957])
-------Step 9-------
tensor([ 8456,  3713,  6000,   233,   565,   614, 10828,   469,  7486,  8343]) tensor([ 7042, 13251,  4005, 11790,  4260, 10642,  9855,   220,  3996,  4069])
[proc 0][Train](200/500) average pos_loss: 0.5396560035273432
[proc 0][Train](200/500) average neg_loss: 0.28130913457192946
[proc 0][Train](200/500) average loss: 0.4104825659841299
[proc 0][Train](200/500) average regularization: 4.560178058454767e-05
[proc 0] 200 steps, total: 28.559, sample: 0.967, forward: 11.097, backward: 13.855, update: 2.300
[proc 2][Train](200/500) average pos_loss: 0.6422148625552654
[proc 2][Train](200/500) average neg_loss: 0.35256588877149625
[proc 2][Train](200/500) average loss: 0.4973903814703226
[proc 2][Train](200/500) average regularization: 4.556281492114067e-05
[proc 2] 200 steps, total: 28.554, sample: 1.745, forward: 5.846, backward: 5.607, update: 3.634
[proc 3][Train](200/500) average pos_loss: 0.6024474892020225
[proc 3][Train](200/500) average neg_loss: 0.32918315439426804
[proc 3][Train](200/500) average loss: 0.46581532157957556
[proc 3][Train](200/500) average regularization: 4.500076225667726e-05
[proc 3] 200 steps, total: 28.594, sample: 1.695, forward: 5.797, backward: 5.568, update: 3.606
[proc 1][Train](200/500) average pos_loss: 0.5642663756012917
[proc 1][Train](200/500) average neg_loss: 0.324848347309744
[proc 1][Train](200/500) average loss: 0.4445573571324348
[proc 1][Train](200/500) average regularization: 4.505016217990487e-05
[proc 1] 200 steps, total: 28.618, sample: 1.707, forward: 5.613, backward: 5.143, update: 3.901
[proc 0][Train](400/500) average pos_loss: 0.11874383300542832
[proc 0][Train](400/500) average neg_loss: 0.15028131853789092
[proc 0][Train](400/500) average loss: 0.13451257515698672
[proc 0][Train](400/500) average regularization: 4.2638551785785236e-05
[proc 0] 400 steps, total: 25.839, sample: 0.975, forward: 10.258, backward: 12.130, update: 2.131
[proc 3][Train](400/500) average pos_loss: 0.1699210150539875
[proc 3][Train](400/500) average neg_loss: 0.18476675540208817
[proc 3][Train](400/500) average loss: 0.1773438849300146
[proc 3][Train](400/500) average regularization: 4.0632089530845404e-05
[proc 3] 400 steps, total: 25.838, sample: 1.769, forward: 5.003, backward: 4.029, update: 3.573
[proc 2][Train](400/500) average pos_loss: 0.20539523892104625
[proc 2][Train](400/500) average neg_loss: 0.20949635207653045
[proc 2][Train](400/500) average loss: 0.20744579538702965
[proc 2][Train](400/500) average regularization: 4.1183814082614845e-05
[proc 2] 400 steps, total: 25.839, sample: 1.805, forward: 5.271, backward: 4.054, update: 3.662
[proc 1][Train](400/500) average pos_loss: 0.14972444262355566
[proc 1][Train](400/500) average neg_loss: 0.1776631436496973
[proc 1][Train](400/500) average loss: 0.16369379341602325
[proc 1][Train](400/500) average regularization: 4.1715596707945224e-05
[proc 1] 400 steps, total: 25.838, sample: 1.733, forward: 5.008, backward: 3.682, update: 3.813
Successfully xmh. training takes 67.38397312164307 seconds
