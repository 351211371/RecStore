/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_211', no_save_emb=True, max_step=500, batch_size=3000, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2386121 sampler.py:454] Start PreSampling
WARNING [2386121 sampler.py:532] Before construct renumbering_dict
WARNING [2386121 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:09:04.146992 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:09:04.147162 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:09:04.147198 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:09:04.147228 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:09:04.147256 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:09:04.147284 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:09:04.147311 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:09:04.147343 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:09:04.147373 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:09:04.147403 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:09:04.147444 2386121 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:09:04.147476 2386121 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:09:04.147501 2386121 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:09:04.147604 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:09:04.147643 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:09:04.147675 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:09:04.147703 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:09:04.147732 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:09:04.147758 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:09:04.147819 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:09:04.147850 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:09:04.147878 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:09:04.147907 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:09:04.147934 2386121 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:09:04.147961 2386121 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:09:04.147985 2386121 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:09:04.148039 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:09:04.148082 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:09:04.148113 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:09:04.148141 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:09:04.148169 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:09:04.148196 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:09:04.148224 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:09:04.148250 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:09:04.148277 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:09:04.148304 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:09:04.148332 2386121 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:09:04.148357 2386121 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:09:04.148381 2386121 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:09:04.148428 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:09:04.148461 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:09:04.148490 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:09:04.148519 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:09:04.148545 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:09:04.148574 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:09:04.148602 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:09:04.148628 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:09:04.148656 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:09:04.148684 2386121 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:09:04.148711 2386121 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:09:04.148736 2386121 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:09:04.148759 2386121 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1668, 1767, 1790,  ..., 8010, 6517, 7307]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.034 seconds
[Rank1] pid = 2386335
[Rank2] pid = 2386400
INFO [2386121 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2386335 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2386335 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2386121 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2386400 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2386464 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2386400 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2386464 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2386464
-------Step 0-------
tensor([ 8965, 12712, 14770, 11348,  5454,    54, 10333,  2035,  3478, 11932]) tensor([ 1790, 12201,  7141, 13298, 14745,    58, 10099,  4033, 13274,  8619])
-------Step 1-------
tensor([ 8965, 12712, 14770, 11348,  5454,    54, 10333,  2035,  3478, 11932]) tensor([10557,  4588, 14043,  2173,  4393,  2777,  4814,  7464,  1097, 14537])
-------Step 2-------
tensor([ 3091,  7636,   340,   339,  9548,  1658, 10205, 14633,  5986,  5054]) tensor([ 3775,  7510,  2302, 14342,  8685,  4411,  2854, 10979, 13494,  8317])
-------Step 3-------
tensor([ 3091,  7636,   340,   339,  9548,  1658, 10205, 14633,  5986,  5054]) tensor([ 7589,  6715, 14027, 13139,  6637,   964,  1569,  1968,  4497,  8401])
-------Step 4-------
tensor([  803, 13998, 12712,   301, 14445, 11577, 11158,   354,  1019,  7648]) tensor([11220,  8429,  2855, 12780,  2091,  9669,  7293,  3033,  9945, 13032])
-------Step 5-------
tensor([  803, 13998, 12712,   301, 14445, 11577, 11158,   354,  1019,  7648]) tensor([ 6681, 13909, 10957,  2670,  2922,  3478,  1337,  9125,  9485,  5834])
-------Step 6-------
tensor([ 7593,  2057, 12013, 13711,   301, 13212,   215,   218,  6750, 12918]) tensor([ 7784,  4647,  7145,   264, 10641, 11997,  4429,  1794, 13414,  5245])
-------Step 7-------
tensor([ 7593,  2057, 12013, 13711,   301, 13212,   215,   218,  6750, 12918]) tensor([ 7786, 12860,  5433,  6942,  9981,  6191,  8576, 11452,  9901,  1153])
-------Step 8-------
tensor([ 4448,   162, 11835, 13361,  6259,   210,  4602, 10412, 12377,   180]) tensor([ 4007,  1660, 12031,  9250,   213, 11651,  7241, 13358, 13883,   641])
-------Step 9-------
tensor([ 4448,   162, 11835, 13361,  6259,   210,  4602, 10412, 12377,   180]) tensor([ 3133,  7052, 14593,  2389,   292,  1750,   161,  1504,   890,  2625])
[proc 0][Train](200/500) average pos_loss: 0.490964882299304
[proc 0][Train](200/500) average neg_loss: 0.34123293748591094
[proc 0][Train](200/500) average loss: 0.4160989096015692
[proc 0][Train](200/500) average regularization: 1.8823036580215557e-05
[proc 0] 200 steps, total: 16.846, sample: 0.724, forward: 6.366, backward: 7.394, update: 1.884
[proc 1][Train](200/500) average pos_loss: 0.5219314330816269
[proc 1][Train](200/500) average neg_loss: 0.3895125841256231
[proc 1][Train](200/500) average loss: 0.4557220097631216
[proc 1][Train](200/500) average regularization: 1.8646376147444244e-05
[proc 1] 200 steps, total: 16.894, sample: 1.277, forward: 3.681, backward: 3.370, update: 3.010
[proc 2][Train](200/500) average pos_loss: 0.5922806282341481
[proc 2][Train](200/500) average neg_loss: 0.41504632638767364
[proc 2][Train](200/500) average loss: 0.5036634770035744
[proc 2][Train](200/500) average regularization: 1.9050179930673038e-05
[proc 2] 200 steps, total: 16.879, sample: 1.291, forward: 3.868, backward: 3.584, update: 2.704
[proc 3][Train](200/500) average pos_loss: 0.5520875195413828
[proc 3][Train](200/500) average neg_loss: 0.3943243733560666
[proc 3][Train](200/500) average loss: 0.4732059462368488
[proc 3][Train](200/500) average regularization: 1.9029928253075923e-05
[proc 3] 200 steps, total: 16.874, sample: 1.267, forward: 3.979, backward: 3.575, update: 2.655
[proc 0][Train](400/500) average pos_loss: 0.14654551893472673
[proc 0][Train](400/500) average neg_loss: 0.17281217470765114
[proc 0][Train](400/500) average loss: 0.15967884704470633
[proc 0][Train](400/500) average regularization: 2.0845786293648418e-05
[proc 0] 400 steps, total: 14.937, sample: 0.742, forward: 5.694, backward: 5.846, update: 2.010
[proc 3][Train](400/500) average pos_loss: 0.20987836070358754
[proc 3][Train](400/500) average neg_loss: 0.22030361644923688
[proc 3][Train](400/500) average loss: 0.2150909885764122
[proc 3][Train](400/500) average regularization: 2.0363207477203103e-05
[proc 3] 400 steps, total: 14.937, sample: 1.318, forward: 3.381, backward: 2.247, update: 2.624
[proc 1][Train](400/500) average pos_loss: 0.18185080759227276
[proc 1][Train](400/500) average neg_loss: 0.20740077711641788
[proc 1][Train](400/500) average loss: 0.19462579250335693
[proc 1][Train](400/500) average regularization: 2.0466378391574835e-05
[proc 1] 400 steps, total: 14.937, sample: 1.257, forward: 3.169, backward: 2.045, update: 2.990
[proc 2][Train](400/500) average pos_loss: 0.24556706435978412
[proc 2][Train](400/500) average neg_loss: 0.24418873801827432
[proc 2][Train](400/500) average loss: 0.2448779012262821
[proc 2][Train](400/500) average regularization: 2.0319268160164938e-05
[proc 2] 400 steps, total: 14.937, sample: 1.255, forward: 3.327, backward: 2.239, update: 2.737
Successfully xmh. training takes 39.21381855010986 seconds
