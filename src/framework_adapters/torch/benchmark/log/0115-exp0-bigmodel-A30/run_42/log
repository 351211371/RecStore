/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_227', no_save_emb=True, max_step=500, batch_size=6600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2412790 sampler.py:454] Start PreSampling
WARNING [2412790 sampler.py:532] Before construct renumbering_dict
WARNING [2412790 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:33:33.112483 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:33:33.112671 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:33:33.112710 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:33:33.112741 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:33:33.112771 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:33:33.112798 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:33:33.112829 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:33:33.112859 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:33:33.112890 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:33:33.112917 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:33:33.112949 2412790 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:33:33.112980 2412790 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:33:33.113008 2412790 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:33:33.113113 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:33:33.113160 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:33:33.113193 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:33:33.113224 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:33:33.113250 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:33:33.113282 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:33:33.113327 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:33:33.113355 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:33:33.113387 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:33:33.113417 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:33:33.113447 2412790 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:33:33.113473 2412790 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:33:33.113497 2412790 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:33:33.113548 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:33:33.113582 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:33:33.113612 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:33:33.113643 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:33:33.113669 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:33:33.113696 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:33:33.113723 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:33:33.113749 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:33:33.113778 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:33:33.113811 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:33:33.113838 2412790 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:33:33.113862 2412790 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:33:33.113885 2412790 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:33:33.113932 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:33:33.113965 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:33:33.113991 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:33:33.114022 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:33:33.114050 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:33:33.114077 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:33:33.114109 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:33:33.114136 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:33:33.114163 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:33:33.114192 2412790 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:33:33.114229 2412790 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:33:33.114256 2412790 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:33:33.114281 2412790 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1702, 1828, 1858,  ..., 8248, 7042, 6678]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 1.649 seconds
[Rank1] pid = 2413000
[Rank2] pid = 2413065
INFO [2412790 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2413000 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2413129 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2413065 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2413065 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2413000 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2413129 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2412790 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2413129
-------Step 0-------
tensor([ 9467,   112, 14739, 10825,  4950,  6679,    85,  2128,  3654, 12882]) tensor([ 1858,   226,  6752, 11659, 14713,   343, 11082,  3819, 11539,  8386])
-------Step 1-------
tensor([ 9467,   112, 14739, 10825,  4950,  6679,    85,  2128,  3654, 12882]) tensor([ 6183,  6652, 13927,  5695,  5700,  2158,  1827, 12021,  6186,  6995])
-------Step 2-------
tensor([14696, 12044,  6582, 13900,  3035,  1024,   317, 12866, 14740,  6980]) tensor([ 5176, 14162,  1867,  8636,  6673,  2080,  6868,  4919,  5012,  6180])
-------Step 3-------
tensor([14696, 12044,  6582, 13900,  3035,  1024,   317, 12866, 14740,  6980]) tensor([11357, 13921,  1185,  5576,  9370,  4591, 10075,  7395, 14364,  9447])
-------Step 4-------
tensor([ 6575,  6639,  6321, 12569, 13401,  7442, 12625, 13252,  3940,  6998]) tensor([ 4522,  7112,  1214, 14092,  4244,  1169, 14014,  9561,  6549,  2788])
-------Step 5-------
tensor([ 6575,  6639,  6321, 12569, 13401,  7442, 12625, 13252,  3940,  6998]) tensor([ 7589, 10358,  5448, 12353, 11357,  3587,  3993,  2928, 10230, 12625])
-------Step 6-------
tensor([ 1589,   336,  3527,  9330,  5788,  2926,   287,  6308, 12579,  9659]) tensor([ 6435,  4705,  6922,   266,  8817, 14805,  9448, 11102,  9299,  7316])
-------Step 7-------
tensor([ 1589,   336,  3527,  9330,  5788,  2926,   287,  6308, 12579,  9659]) tensor([ 4016,  1946,  5937, 13686,  5143, 14097,  6632,  2900,  7016,  8918])
-------Step 8-------
tensor([ 7921,   877,  5599,  3129,    27,   135, 10516, 13119,  6294,  7298]) tensor([ 9875,  4010, 13246, 11116,  4569,  5560, 11701,  5258,  3909, 13971])
-------Step 9-------
tensor([ 7921,   877,  5599,  3129,    27,   135, 10516, 13119,  6294,  7298]) tensor([ 5899, 12968,  2680, 12264,  2963,  9049,  8741,  7589,  2596,  2753])
[proc 0][Train](200/500) average pos_loss: 0.5358938674628735
[proc 0][Train](200/500) average neg_loss: 0.2815108965523541
[proc 0][Train](200/500) average loss: 0.40870238073170184
[proc 0][Train](200/500) average regularization: 4.539578904768859e-05
[proc 0] 200 steps, total: 27.888, sample: 0.735, forward: 10.864, backward: 13.795, update: 2.100
[proc 2][Train](200/500) average pos_loss: 0.6452446514368058
[proc 2][Train](200/500) average neg_loss: 0.35306703912327064
[proc 2][Train](200/500) average loss: 0.4991558441519737
[proc 2][Train](200/500) average regularization: 4.537042930678581e-05
[proc 2] 200 steps, total: 27.922, sample: 1.688, forward: 5.966, backward: 5.716, update: 3.666
[proc 3][Train](200/500) average pos_loss: 0.5965989715605974
[proc 3][Train](200/500) average neg_loss: 0.32988133967272004
[proc 3][Train](200/500) average loss: 0.46324015632271764
[proc 3][Train](200/500) average regularization: 4.4782575723729675e-05
[proc 3] 200 steps, total: 27.913, sample: 1.620, forward: 5.926, backward: 5.558, update: 3.723
[proc 1][Train](200/500) average pos_loss: 0.5654453245550394
[proc 1][Train](200/500) average neg_loss: 0.3238798258337192
[proc 1][Train](200/500) average loss: 0.44466257899999617
[proc 1][Train](200/500) average regularization: 4.490672009524132e-05
[proc 1] 200 steps, total: 27.906, sample: 1.686, forward: 5.388, backward: 5.237, update: 3.773
[proc 0][Train](400/500) average pos_loss: 0.11858698908239602
[proc 0][Train](400/500) average neg_loss: 0.15015465650707482
[proc 0][Train](400/500) average loss: 0.13437082279473544
[proc 0][Train](400/500) average regularization: 4.2637037095119015e-05
[proc 0] 400 steps, total: 25.288, sample: 0.720, forward: 10.177, backward: 12.109, update: 2.011
[proc 3][Train](400/500) average pos_loss: 0.16964704483747484
[proc 3][Train](400/500) average neg_loss: 0.1847505873441696
[proc 3][Train](400/500) average loss: 0.1771988159418106
[proc 3][Train](400/500) average regularization: 4.064135984663153e-05
[proc 3] 400 steps, total: 25.287, sample: 1.715, forward: 5.158, backward: 4.030, update: 3.560
[proc 2][Train](400/500) average pos_loss: 0.20570141404867173
[proc 2][Train](400/500) average neg_loss: 0.20969209380447865
[proc 2][Train](400/500) average loss: 0.20769675351679326
[proc 2][Train](400/500) average regularization: 4.119489951335709e-05
[proc 2] 400 steps, total: 25.288, sample: 1.754, forward: 5.135, backward: 4.058, update: 3.650
[proc 1][Train](400/500) average pos_loss: 0.14992139644920827
[proc 1][Train](400/500) average neg_loss: 0.17792846605181695
[proc 1][Train](400/500) average loss: 0.16392493121325968
[proc 1][Train](400/500) average regularization: 4.178790981313796e-05
[proc 1] 400 steps, total: 25.288, sample: 1.683, forward: 4.678, backward: 3.688, update: 3.736
Successfully xmh. training takes 65.89710116386414 seconds
