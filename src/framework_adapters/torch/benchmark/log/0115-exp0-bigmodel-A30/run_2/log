/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_187', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2353227 sampler.py:454] Start PreSampling
WARNING [2353227 sampler.py:532] Before construct renumbering_dict
WARNING [2353227 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 00:47:17.393707 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 00:47:17.393885 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 00:47:17.393920 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 00:47:17.393949 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 00:47:17.393983 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 00:47:17.394017 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 00:47:17.394048 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 00:47:17.394084 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 00:47:17.394116 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 00:47:17.394145 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 00:47:17.394177 2353227 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 00:47:17.394209 2353227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 00:47:17.394237 2353227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 00:47:17.394335 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 00:47:17.394374 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 00:47:17.394407 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 00:47:17.394436 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 00:47:17.394469 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 00:47:17.394497 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 00:47:17.394541 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 00:47:17.394568 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 00:47:17.394598 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 00:47:17.394631 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 00:47:17.394662 2353227 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 00:47:17.394687 2353227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 00:47:17.394713 2353227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 00:47:17.394767 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 00:47:17.394802 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 00:47:17.394830 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 00:47:17.394860 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 00:47:17.394886 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 00:47:17.394918 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 00:47:17.394949 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 00:47:17.394976 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 00:47:17.395004 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 00:47:17.395030 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 00:47:17.395061 2353227 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 00:47:17.395085 2353227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 00:47:17.395108 2353227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 00:47:17.395154 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 00:47:17.395186 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 00:47:17.395217 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 00:47:17.395246 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 00:47:17.395274 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 00:47:17.395306 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 00:47:17.395334 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 00:47:17.395363 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 00:47:17.395390 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 00:47:17.395418 2353227 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 00:47:17.395449 2353227 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 00:47:17.395474 2353227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 00:47:17.395498 2353227 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([ 1669,  1761,  1788,  ..., 10953,  7465,  6009]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.106 seconds
[Rank1] pid = 2353451
[Rank2] pid = 2353516
INFO [2353227 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2353451 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2353580 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2353516 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2353580 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2353516 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2353451 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2353227 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2353580
-------Step 0-------
tensor([ 8127, 14348, 14464, 10354,  4579,   149, 10998,  2059,  3818, 12519]) tensor([ 1788, 11127,  6580, 10836, 12625,  8429, 11965,  3775, 13214,  7009])
-------Step 1-------
tensor([ 8127, 14348, 14464, 10354,  4579,   149, 10998,  2059,  3818, 12519]) tensor([11162,  8574,  6540,  9061,  1364,  7972,  9291,  7284, 12525, 13936])
-------Step 2-------
tensor([ 3647,    53, 13592,  8036, 10460,  2071, 10380,   342,  9665,   826]) tensor([11294,  1859, 10136,  8441,  4093,  7119,  8688,  7484,  8441, 14013])
-------Step 3-------
tensor([ 3647,    53, 13592,  8036, 10460,  2071, 10380,   342,  9665,   826]) tensor([ 4830,   188, 12272,   869, 10251,    47,  1146, 12736,   607,  4453])
-------Step 4-------
tensor([ 2930, 14375,  7401,   362,  8872, 12315,   367,  6654, 13921,  4610]) tensor([ 5557,  3179, 13633,  5978,  8580,  1927, 10340, 14296, 11563,  5525])
-------Step 5-------
tensor([ 2930, 14375,  7401,   362,  8872, 12315,   367,  6654, 13921,  4610]) tensor([ 9050, 11573,  2915,  9993,  1993,  8814,  6630,  3375, 11285, 13711])
-------Step 6-------
tensor([ 9944,   274,     0,   282,  3733,   350, 14150,  6037,   366,    44]) tensor([ 6980,  4814, 11856,  3190,  3089,  4917,  8430, 12982,   627,  3295])
-------Step 7-------
tensor([ 9944,   274,     0,   282,  3733,   350, 14150,  6037,   366,    44]) tensor([ 4870, 13325,  1797,  8352,  6940,  2003,  7433,  4729,  5020,  8073])
-------Step 8-------
tensor([5320,  245, 7119,  137, 2616, 5277,  299,  878,  182, 1369]) tensor([ 4207,  7578, 10583, 14617,   845, 14532, 12362, 10923,  1418, 13085])
-------Step 9-------
tensor([5320,  245, 7119,  137, 2616, 5277,  299,  878,  182, 1369]) tensor([11829,  3812,  8556, 13811,  7298,  7231, 11190,   364, 14733,  2185])
[proc 0][Train](200/500) average pos_loss: 0.6109499363973737
[proc 0][Train](200/500) average neg_loss: 0.4894201897829771
[proc 0][Train](200/500) average loss: 0.5501850609481335
[proc 0][Train](200/500) average regularization: 3.6680821079926316e-06
[proc 0] 200 steps, total: 8.423, sample: 0.575, forward: 2.793, backward: 3.761, update: 0.835
[proc 3][Train](200/500) average pos_loss: 0.6578765574842691
[proc 3][Train](200/500) average neg_loss: 0.5157096589356661
[proc 3][Train](200/500) average loss: 0.5867931093275547
[proc 3][Train](200/500) average regularization: 3.7626595656092832e-06
[proc 3] 200 steps, total: 8.444, sample: 0.733, forward: 2.429, backward: 2.632, update: 1.027
[proc 2][Train](200/500) average pos_loss: 0.681277241781354
[proc 2][Train](200/500) average neg_loss: 0.5244440568983555
[proc 2][Train](200/500) average loss: 0.6028606498241424
[proc 2][Train](200/500) average regularization: 3.7366135336469597e-06
[proc 2] 200 steps, total: 8.421, sample: 0.723, forward: 2.409, backward: 2.825, update: 1.071
[proc 1][Train](200/500) average pos_loss: 0.6309826018847525
[proc 1][Train](200/500) average neg_loss: 0.5233832225948573
[proc 1][Train](200/500) average loss: 0.5771829117834568
[proc 1][Train](200/500) average regularization: 3.657874923987947e-06
[proc 1] 200 steps, total: 8.423, sample: 0.753, forward: 2.322, backward: 2.490, update: 1.058
[proc 0][Train](400/500) average pos_loss: 0.3554307807981968
[proc 0][Train](400/500) average neg_loss: 0.3413931693136692
[proc 0][Train](400/500) average loss: 0.3484119762480259
[proc 0][Train](400/500) average regularization: 3.981671467272463e-06
[proc 0] 400 steps, total: 4.955, sample: 0.519, forward: 1.675, backward: 1.678, update: 0.717
[proc 3][Train](400/500) average pos_loss: 0.42340736895799636
[proc 3][Train](400/500) average neg_loss: 0.4196156385540962
[proc 3][Train](400/500) average loss: 0.42151150465011594
[proc 3][Train](400/500) average regularization: 3.992502843175316e-06
[proc 3] 400 steps, total: 4.955, sample: 0.679, forward: 1.307, backward: 0.908, update: 0.912
[proc 1][Train](400/500) average pos_loss: 0.4060092020779848
[proc 1][Train](400/500) average neg_loss: 0.40863038212060926
[proc 1][Train](400/500) average loss: 0.4073197916150093
[proc 1][Train](400/500) average regularization: 3.874793923159814e-06
[proc 1] 400 steps, total: 4.955, sample: 0.673, forward: 1.230, backward: 0.843, update: 0.956
[proc 2][Train](400/500) average pos_loss: 0.46086894512176513
[proc 2][Train](400/500) average neg_loss: 0.43887331888079645
[proc 2][Train](400/500) average loss: 0.44987113192677497
[proc 2][Train](400/500) average regularization: 3.895100597901546e-06
[proc 2] 400 steps, total: 4.955, sample: 0.699, forward: 1.288, backward: 0.899, update: 0.902
Successfully xmh. training takes 15.900267839431763 seconds
