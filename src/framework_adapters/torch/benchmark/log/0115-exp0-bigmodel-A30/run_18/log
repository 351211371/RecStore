/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_203', no_save_emb=True, max_step=500, batch_size=1800, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2374443 sampler.py:454] Start PreSampling
WARNING [2374443 sampler.py:532] Before construct renumbering_dict
WARNING [2374443 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:00:26.329512 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:00:26.329684 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:00:26.329720 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:00:26.329751 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:00:26.329779 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:00:26.329808 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:00:26.329835 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:00:26.329869 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:00:26.329900 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:00:26.329926 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:00:26.329959 2374443 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:00:26.329991 2374443 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:00:26.330016 2374443 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:00:26.330114 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:00:26.330153 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:00:26.330183 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:00:26.330209 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:00:26.330237 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:00:26.330264 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:00:26.330307 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:00:26.330333 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:00:26.330360 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:00:26.330387 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:00:26.330415 2374443 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:00:26.330440 2374443 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:00:26.330464 2374443 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:00:26.330514 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:00:26.330547 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:00:26.330580 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:00:26.330610 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:00:26.330637 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:00:26.330665 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:00:26.330693 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:00:26.330719 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:00:26.330749 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:00:26.330775 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:00:26.330803 2374443 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:00:26.330828 2374443 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:00:26.330852 2374443 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:00:26.330901 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:00:26.330938 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:00:26.330967 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:00:26.330994 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:00:26.331022 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:00:26.331048 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:00:26.331079 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:00:26.331106 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:00:26.331132 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:00:26.331159 2374443 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:00:26.331187 2374443 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:00:26.331212 2374443 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:00:26.331235 2374443 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1669, 1790, 1817,  ..., 8676, 7611, 6382]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.138 seconds
[Rank1] pid = 2374679
[Rank2] pid = 2374743
INFO [2374443 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2374679 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2374775 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2374743 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2374775 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2374743 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2374443 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2374679 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2374775
-------Step 0-------
tensor([ 8431, 14035, 14465,  8610,  4791,   192, 11449,  2073,  3901, 13506]) tensor([ 1817,  9227,  7060, 11287, 12861,  8698, 13628,  3774, 10874,  7096])
-------Step 1-------
tensor([ 8431, 14035, 14465,  8610,  4791,   192, 11449,  2073,  3901, 13506]) tensor([  696, 10401,   793,  7040,  1719,  2616, 13765, 14942, 11838,  5362])
-------Step 2-------
tensor([ 8293,   306,     6,   371,  4273,   321, 14743,  7345,     7,   223]) tensor([ 8546,  5469, 11935,  3359,  3136,  5124,  8378, 14314,  2588,  3350])
-------Step 3-------
tensor([ 8293,   306,     6,   371,  4273,   321, 14743,  7345,     7,   223]) tensor([12097, 13893, 10344, 10835, 14288,  2597,  3874,  6659,  5497,  8313])
-------Step 4-------
tensor([ 5923, 13582,  9310,   111,  7020, 14075,  6663,  1433,  6288,  8098]) tensor([13436,  4857,  7178,   581,  3822, 12311, 12785,  5011, 11005, 10815])
-------Step 5-------
tensor([ 5923, 13582,  9310,   111,  7020, 14075,  6663,  1433,  6288,  8098]) tensor([12283, 13924,  7223,   347,   284, 11662,  8120,  5294,  4885,  6894])
-------Step 6-------
tensor([ 6052,    88,  3275, 14866,  8802,  8359, 12045,  4920,   236,  8739]) tensor([ 5812,   100, 13056,  1094,  9432,    57,  1348, 12874,   555,  3854])
-------Step 7-------
tensor([ 6052,    88,  3275, 14866,  8802,  8359, 12045,  4920,   236,  8739]) tensor([ 5649,  4626,  8011,  5470,  8139, 13341, 10646, 11507, 10446,  6978])
-------Step 8-------
tensor([  164,  6204,   333,   110,  4383,  4592, 11369,   277,  8772,  3395]) tensor([12545,  3697,  8279, 11612,  8009,  7462,  9703,    73, 14569,  2247])
-------Step 9-------
tensor([  164,  6204,   333,   110,  4383,  4592, 11369,   277,  8772,  3395]) tensor([ 3210,  8454,  3821, 13819,  3875,   359,  2067,  3423,  4302,   249])
[proc 0][Train](200/500) average pos_loss: 0.5132742544263601
[proc 0][Train](200/500) average neg_loss: 0.3939112193603069
[proc 0][Train](200/500) average loss: 0.4535927376151085
[proc 0][Train](200/500) average regularization: 1.1043196445825743e-05
[proc 0] 200 steps, total: 12.283, sample: 0.535, forward: 4.255, backward: 5.663, update: 1.371
[proc 3][Train](200/500) average pos_loss: 0.581938182041049
[proc 3][Train](200/500) average neg_loss: 0.44717381976544857
[proc 3][Train](200/500) average loss: 0.514556001573801
[proc 3][Train](200/500) average regularization: 1.1260762198617158e-05
[proc 3] 200 steps, total: 12.258, sample: 1.019, forward: 3.070, backward: 3.171, update: 2.023
[proc 2][Train](200/500) average pos_loss: 0.6124248623847961
[proc 2][Train](200/500) average neg_loss: 0.46490959253162145
[proc 2][Train](200/500) average loss: 0.5386672250926494
[proc 2][Train](200/500) average regularization: 1.1211569935767329e-05
[proc 2] 200 steps, total: 12.246, sample: 1.066, forward: 2.999, backward: 3.073, update: 1.987
[proc 1][Train](200/500) average pos_loss: 0.5501493754982948
[proc 1][Train](200/500) average neg_loss: 0.44486034302040933
[proc 1][Train](200/500) average loss: 0.49750485628843305
[proc 1][Train](200/500) average regularization: 1.0953886499009968e-05
[proc 1] 200 steps, total: 12.284, sample: 1.067, forward: 2.940, backward: 3.008, update: 1.969
[proc 1][Train](400/500) average pos_loss: 0.216365564763546
[proc 1][Train](400/500) average neg_loss: 0.23971773833036422
[proc 1][Train](400/500) average loss: 0.2280416516959667
[proc 1][Train](400/500) average regularization: 1.2537671950667573e-05
[proc 1] 400 steps, total: 10.215, sample: 1.120, forward: 2.326, backward: 1.454, update: 1.963
[proc 2][Train](400/500) average pos_loss: 0.29179896086454393
[proc 2][Train](400/500) average neg_loss: 0.28384266249835494
[proc 2][Train](400/500) average loss: 0.28782081209123134
[proc 2][Train](400/500) average regularization: 1.2418708129189327e-05
[proc 2] 400 steps, total: 10.215, sample: 1.030, forward: 2.351, backward: 1.557, update: 2.028
[proc 0][Train](400/500) average pos_loss: 0.1780737164244056
[proc 0][Train](400/500) average neg_loss: 0.1982715878635645
[proc 0][Train](400/500) average loss: 0.18817265212535858
[proc 0][Train](400/500) average regularization: 1.2815755999326939e-05
[proc 0] 400 steps, total: 10.215, sample: 0.589, forward: 3.555, backward: 3.811, update: 1.420
[proc 3][Train](400/500) average pos_loss: 0.2465979243069887
[proc 3][Train](400/500) average neg_loss: 0.2586797592043877
[proc 3][Train](400/500) average loss: 0.2526388417929411
[proc 3][Train](400/500) average regularization: 1.2630457795239637e-05
[proc 3] 400 steps, total: 10.216, sample: 1.018, forward: 2.330, backward: 1.574, update: 2.008
Successfully xmh. training takes 27.766585111618042 seconds
