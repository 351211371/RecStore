/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_223', no_save_emb=True, max_step=500, batch_size=4800, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.2, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2407190 sampler.py:454] Start PreSampling
WARNING [2407190 sampler.py:532] Before construct renumbering_dict
WARNING [2407190 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:26:27.227763 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:26:27.227944 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:26:27.227980 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:26:27.228013 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:26:27.228041 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:26:27.228070 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:26:27.228096 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:26:27.228128 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:26:27.228157 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:26:27.228186 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:26:27.228219 2407190 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:26:27.228250 2407190 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:26:27.228276 2407190 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:26:27.228384 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:26:27.228423 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:26:27.228461 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:26:27.228492 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:26:27.228518 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:26:27.228545 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:26:27.228587 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:26:27.228614 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:26:27.228650 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:26:27.228679 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:26:27.228714 2407190 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:26:27.228741 2407190 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:26:27.228766 2407190 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:26:27.228819 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:26:27.228853 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:26:27.228881 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:26:27.228909 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:26:27.228945 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:26:27.228981 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:26:27.229008 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:26:27.229038 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:26:27.229065 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:26:27.229094 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:26:27.229120 2407190 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:26:27.229144 2407190 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:26:27.229167 2407190 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:26:27.229215 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:26:27.229250 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:26:27.229279 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:26:27.229305 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:26:27.229333 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:26:27.229362 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:26:27.229387 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:26:27.229414 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:26:27.229441 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:26:27.229468 2407190 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:26:27.229496 2407190 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:26:27.229519 2407190 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:26:27.229543 2407190 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 747
Rank1: cached key size 747
Rank2: cached key size 747
Rank3: cached key size 747
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([3149, 3250, 3271,  ..., 9396, 7725, 8780]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 1.835 seconds
[Rank1] pid = 2407406
[Rank2] pid = 2407470
INFO [2407190 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2407406 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2407493 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2407493 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2407470 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2407470 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2407190 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2407406 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2407493
-------Step 0-------
tensor([ 8821,   373, 13349, 13667,  6844,   148,   505,  3397,  4919, 13336]) tensor([ 3271,   688,  7367, 14324, 11201,   455, 12206,  5273, 14287, 10319])
-------Step 1-------
tensor([ 8821,   373, 13349, 13667,  6844,   148,   505,  3397,  4919, 13336]) tensor([ 9979, 11588,  5193, 14085,  3887,  4822,   256,  1827, 14095,  1750])
-------Step 2-------
tensor([    1, 13379,  7653,  1471,  1948,  9551,  4398,   142, 12634,  8737]) tensor([ 9420, 12415,  9136,  9663,  4343,  7380,  7616,  6314, 10973,  2381])
-------Step 3-------
tensor([    1, 13379,  7653,  1471,  1948,  9551,  4398,   142, 12634,  8737]) tensor([12578,  6297, 14434, 12978, 11065, 12531, 12482,  4645, 11453,  7177])
-------Step 4-------
tensor([13222,  7376,   569,  6919,  3355,  6350, 12045, 10714, 13448,    17]) tensor([ 6908,  5219, 10232, 11539, 10546,  6606,   333, 14512,  7571,  6494])
-------Step 5-------
tensor([13222,  7376,   569,  6919,  3355,  6350, 12045, 10714, 13448,    17]) tensor([ 6742, 13348,   826,  2425, 13227,   606,  2096,  6009, 10474,   688])
-------Step 6-------
tensor([  123,    10,  4706,   295, 12842,   184, 11597,  5562,   346,   531]) tensor([ 1066, 13815,  1694,   336,  3320,  3724, 12534, 14512, 11223,  6840])
-------Step 7-------
tensor([  123,    10,  4706,   295, 12842,   184, 11597,  5562,   346,   531]) tensor([ 8515,  7260, 13145,  6128,  7457,  3575,  3252, 13924,  6834,  9466])
-------Step 8-------
tensor([  355,  3667, 10068,  8605,  4970,  6823,  4025,   651, 13400, 14013]) tensor([ 6406,  3587,   457, 13220,   715,  9099,  5339,  6003,   308,  2870])
-------Step 9-------
tensor([  355,  3667, 10068,  8605,  4970,  6823,  4025,   651, 13400, 14013]) tensor([10608, 11549,  7586,  8727,   500,  2683, 10197, 10626,  9948,  3653])
[proc 0][Train](200/500) average pos_loss: 0.5027078471705317
[proc 0][Train](200/500) average neg_loss: 0.30250847681192683
[proc 0][Train](200/500) average loss: 0.4026081573963165
[proc 0][Train](200/500) average regularization: 3.124189473965089e-05
[proc 0] 200 steps, total: 22.160, sample: 0.818, forward: 8.567, backward: 10.571, update: 1.841
[proc 1][Train](200/500) average pos_loss: 0.5283623227477073
[proc 1][Train](200/500) average neg_loss: 0.34606736492132767
[proc 1][Train](200/500) average loss: 0.43721484184265136
[proc 1][Train](200/500) average regularization: 3.087028009758797e-05
[proc 1] 200 steps, total: 22.168, sample: 1.491, forward: 4.611, backward: 4.320, update: 3.037
[proc 3][Train](200/500) average pos_loss: 0.5675784830749034
[proc 3][Train](200/500) average neg_loss: 0.3528619793127291
[proc 3][Train](200/500) average loss: 0.46022022821009156
[proc 3][Train](200/500) average regularization: 3.110050120994856e-05
[proc 3] 200 steps, total: 22.157, sample: 1.489, forward: 4.569, backward: 4.685, update: 3.321
[proc 2][Train](200/500) average pos_loss: 0.608698551952839
[proc 2][Train](200/500) average neg_loss: 0.37575525980442764
[proc 2][Train](200/500) average loss: 0.4922269068658352
[proc 2][Train](200/500) average regularization: 3.1402719191646614e-05
[proc 2] 200 steps, total: 22.117, sample: 1.481, forward: 4.747, backward: 4.657, update: 3.117
[proc 0][Train](400/500) average pos_loss: 0.12743878249078988
[proc 0][Train](400/500) average neg_loss: 0.15737145412713288
[proc 0][Train](400/500) average loss: 0.14240511864423752
[proc 0][Train](400/500) average regularization: 3.200430419383338e-05
[proc 0] 400 steps, total: 19.761, sample: 0.807, forward: 7.811, backward: 8.872, update: 1.853
[proc 3][Train](400/500) average pos_loss: 0.18272317804396151
[proc 3][Train](400/500) average neg_loss: 0.19647679679095745
[proc 3][Train](400/500) average loss: 0.18959998719394208
[proc 3][Train](400/500) average regularization: 3.0836964288027954e-05
[proc 3] 400 steps, total: 19.760, sample: 1.505, forward: 3.892, backward: 3.171, update: 3.245
[proc 1][Train](400/500) average pos_loss: 0.15958283081650734
[proc 1][Train](400/500) average neg_loss: 0.18677560158073903
[proc 1][Train](400/500) average loss: 0.17317921586334706
[proc 1][Train](400/500) average regularization: 3.146313170873327e-05
[proc 1] 400 steps, total: 19.761, sample: 1.556, forward: 4.107, backward: 2.911, update: 3.064
[proc 2][Train](400/500) average pos_loss: 0.2188446833193302
[proc 2][Train](400/500) average neg_loss: 0.22096771970391274
[proc 2][Train](400/500) average loss: 0.21990620076656342
[proc 2][Train](400/500) average regularization: 3.108714243353461e-05
[proc 2] 400 steps, total: 19.761, sample: 1.507, forward: 4.087, backward: 3.178, update: 3.035
Successfully xmh. training takes 51.77127480506897 seconds
