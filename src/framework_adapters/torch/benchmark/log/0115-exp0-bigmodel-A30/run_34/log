/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_219', no_save_emb=True, max_step=500, batch_size=4800, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2399219 sampler.py:454] Start PreSampling
WARNING [2399219 sampler.py:532] Before construct renumbering_dict
WARNING [2399219 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:19:53.934479 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:19:53.934650 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:19:53.934686 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:19:53.934716 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:19:53.934746 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:19:53.934773 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:19:53.934803 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:19:53.934835 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:19:53.934866 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:19:53.934893 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:19:53.934926 2399219 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:19:53.934957 2399219 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:19:53.934981 2399219 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:19:53.935082 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:19:53.935119 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:19:53.935148 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:19:53.935174 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:19:53.935200 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:19:53.935227 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:19:53.935269 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:19:53.935297 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:19:53.935333 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:19:53.935364 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:19:53.935393 2399219 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:19:53.935418 2399219 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:19:53.935442 2399219 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:19:53.935495 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:19:53.935529 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:19:53.935556 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:19:53.935583 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:19:53.935611 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:19:53.935637 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:19:53.935663 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:19:53.935690 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:19:53.935725 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:19:53.935753 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:19:53.935788 2399219 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:19:53.935815 2399219 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:19:53.935838 2399219 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:19:53.935886 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:19:53.935922 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:19:53.935950 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:19:53.935979 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:19:53.936007 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:19:53.936035 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:19:53.936064 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:19:53.936092 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:19:53.936120 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:19:53.936148 2399219 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:19:53.936177 2399219 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:19:53.936200 2399219 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:19:53.936223 2399219 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1652, 1739, 1762,  ..., 7036, 6181, 8144]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 1.799 seconds
[Rank1] pid = 2399434
[Rank2] pid = 2399499
INFO [2399219 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2399434 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2399563 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2399499 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2399499 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2399219 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2399563 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2399434 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2399563
-------Step 0-------
tensor([ 7954, 14672, 13034, 12961,  5969,  5820,    88,  1965,  3296, 10204]) tensor([ 1762,   305,  8122, 13764, 10408,   124,  9272,  4626, 13767, 10135])
-------Step 1-------
tensor([ 7954, 14672, 13034, 12961,  5969,  5820,    88,  1965,  3296, 10204]) tensor([ 7508, 13687,  3485, 13727,  2608,  3525,  9224,  2309, 14824, 10097])
-------Step 2-------
tensor([    2, 13876,  8059,   386,   843,  8270,  3467,   186, 11794,   259]) tensor([ 8555, 12515,  8633,  8898,  2965,  6283,  6529,  4764, 10322, 11105])
-------Step 3-------
tensor([    2, 13876,  8059,   386,   843,  8270,  3467,   186, 11794,   259]) tensor([12895,  4968, 14935, 10049, 10621, 12604, 14872,  3951, 11404,  6077])
-------Step 4-------
tensor([12861,  6580,  7873,  6236,  1872,  4290,  1093, 10188, 13368,   152]) tensor([ 5711,  4282, 10134, 10984,  9750,  6634,   134, 14946,  7771,  5329])
-------Step 5-------
tensor([12861,  6580,  7873,  6236,  1872,  4290,  1093, 10188, 13368,   152]) tensor([ 5095, 12517,  5405,  7879, 13283,  6559, 13584,  5089, 10425,   305])
-------Step 6-------
tensor([ 2474,    23,  3278,   153, 13766,   113, 11183,  4270, 12716,  4064]) tensor([  488, 13675,  6026,   176,  1842,  2300,  9723, 14946,  8475,  6727])
-------Step 7-------
tensor([ 2474,    23,  3278,   153, 13766,   113, 11183,  4270, 12716,  4064]) tensor([ 7866,  5691, 12111,  4799,  6735,  1982,  1883, 13778,  7752,  8639])
-------Step 8-------
tensor([   28,  2161,  1383,  8003,  3452,  7265,  2299,   170, 13336, 13666]) tensor([ 6482,  2101,   102, 11590,  3796, 11518,  3998,  4667,    35,  9614])
-------Step 9-------
tensor([   28,  2161,  1383,  8003,  3452,  7265,  2299,   170, 13336, 13666]) tensor([   30,  1333,  6843,  7352,   104,  1361, 10799, 12983,  9188,  1123])
[proc 0][Train](200/500) average pos_loss: 0.5017155108600855
[proc 0][Train](200/500) average neg_loss: 0.3026386050367728
[proc 0][Train](200/500) average loss: 0.4021770612895489
[proc 0][Train](200/500) average regularization: 3.1253731540346054e-05
[proc 0] 200 steps, total: 22.252, sample: 0.848, forward: 8.553, backward: 10.603, update: 1.865
[proc 1][Train](200/500) average pos_loss: 0.5303501852601766
[proc 1][Train](200/500) average neg_loss: 0.3477827101177536
[proc 1][Train](200/500) average loss: 0.4390664478391409
[proc 1][Train](200/500) average regularization: 3.0847860043650146e-05
[proc 1] 200 steps, total: 22.257, sample: 1.524, forward: 4.490, backward: 4.298, update: 3.185
[proc 3][Train](200/500) average pos_loss: 0.5676307369023561
[proc 3][Train](200/500) average neg_loss: 0.35352423103293407
[proc 3][Train](200/500) average loss: 0.460577487051487
[proc 3][Train](200/500) average regularization: 3.1118912829697365e-05
[proc 3] 200 steps, total: 22.251, sample: 1.514, forward: 4.873, backward: 4.564, update: 2.998
[proc 2][Train](200/500) average pos_loss: 0.6061940532922745
[proc 2][Train](200/500) average neg_loss: 0.376592187146889
[proc 2][Train](200/500) average loss: 0.49139312267303464
[proc 2][Train](200/500) average regularization: 3.141098668493214e-05
[proc 2] 200 steps, total: 22.253, sample: 1.519, forward: 4.734, backward: 4.592, update: 3.049
[proc 0][Train](400/500) average pos_loss: 0.12721207965165376
[proc 0][Train](400/500) average neg_loss: 0.15765978772193193
[proc 0][Train](400/500) average loss: 0.14243593368679286
[proc 0][Train](400/500) average regularization: 3.203718016266066e-05
[proc 0] 400 steps, total: 19.498, sample: 0.814, forward: 7.679, backward: 8.876, update: 1.739
[proc 1][Train](400/500) average pos_loss: 0.16003726795315742
[proc 1][Train](400/500) average neg_loss: 0.1869010630249977
[proc 1][Train](400/500) average loss: 0.17346916563808917
[proc 1][Train](400/500) average regularization: 3.1415564408234786e-05
[proc 1] 400 steps, total: 19.498, sample: 1.555, forward: 3.750, backward: 2.883, update: 3.068
[proc 3][Train](400/500) average pos_loss: 0.18306624464690685
[proc 3][Train](400/500) average neg_loss: 0.1965586344897747
[proc 3][Train](400/500) average loss: 0.1898124397546053
[proc 3][Train](400/500) average regularization: 3.084484575992974e-05
[proc 3] 400 steps, total: 19.498, sample: 1.510, forward: 4.064, backward: 3.134, update: 2.980
[proc 2][Train](400/500) average pos_loss: 0.2188428221642971
[proc 2][Train](400/500) average neg_loss: 0.221102789118886
[proc 2][Train](400/500) average loss: 0.21997280597686766
[proc 2][Train](400/500) average regularization: 3.10788465776568e-05
[proc 2] 400 steps, total: 19.498, sample: 1.521, forward: 3.988, backward: 3.154, update: 2.857
Successfully xmh. training takes 51.490291357040405 seconds
