/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_191', no_save_emb=True, max_step=500, batch_size=600, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.2, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2358090 sampler.py:454] Start PreSampling
WARNING [2358090 sampler.py:532] Before construct renumbering_dict
WARNING [2358090 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 00:50:05.119671 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 00:50:05.119870 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 00:50:05.119908 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 00:50:05.119941 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 00:50:05.119969 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 00:50:05.120002 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 00:50:05.120033 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 00:50:05.120065 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 00:50:05.120100 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 00:50:05.120131 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 00:50:05.120167 2358090 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 00:50:05.120201 2358090 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 00:50:05.120226 2358090 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 00:50:05.120323 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 00:50:05.120361 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 00:50:05.120395 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 00:50:05.120422 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 00:50:05.120450 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 00:50:05.120481 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 00:50:05.120523 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 00:50:05.120559 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 00:50:05.120589 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 00:50:05.120616 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 00:50:05.120646 2358090 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 00:50:05.120671 2358090 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 00:50:05.120697 2358090 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 00:50:05.120748 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 00:50:05.120786 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 00:50:05.120815 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 00:50:05.120848 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 00:50:05.120877 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 00:50:05.120905 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 00:50:05.120935 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 00:50:05.120963 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 00:50:05.120990 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 00:50:05.121021 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 00:50:05.121052 2358090 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 00:50:05.121076 2358090 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 00:50:05.121104 2358090 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 00:50:05.121152 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 00:50:05.121186 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 00:50:05.121212 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 00:50:05.121240 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 00:50:05.121268 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 00:50:05.121297 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 00:50:05.121330 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 00:50:05.121356 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 00:50:05.121385 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 00:50:05.121413 2358090 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 00:50:05.121441 2358090 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 00:50:05.121465 2358090 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 00:50:05.121488 2358090 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 747
Rank1: cached key size 747
Rank2: cached key size 747
Rank3: cached key size 747
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([3166, 3271, 3298,  ..., 9540, 7059, 7281]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.153 seconds
[Rank1] pid = 2358310
[Rank2] pid = 2358375
INFO [2358090 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2358310 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2358439 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2358439 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2358375 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2358310 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2358375 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2358090 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2358439
-------Step 0-------
tensor([   55, 12229, 13408, 14760,  5862,    30,   234,  3507,  4632, 13139]) tensor([ 3298, 14826,  7607, 10501, 13440,   599, 11112,  4978,  9388,  9572])
-------Step 1-------
tensor([   55, 12229, 13408, 14760,  5862,    30,   234,  3507,  4632, 13139]) tensor([11755, 11535,  6811,  6647,  4467,  8959, 10047,  6995,  2851, 14161])
-------Step 2-------
tensor([ 4390,   733, 13063,  8992, 11020,  3556, 11844,   688,  8485,  9225]) tensor([11906,  3244, 11082,  9229,  5286,  8196,  9752,  7636,  9229,  2108])
-------Step 3-------
tensor([ 4390,   733, 13063,  8992, 11020,  3556, 11844,   688,  8485,  9225]) tensor([ 5689,   621, 13020,  1838, 10979,   509,  2695, 12398,  1156,  5072])
-------Step 4-------
tensor([ 4137, 14610,   274,   725,  9960, 10845,   270, 10520, 10492,  6032]) tensor([ 1277,  4359, 13527,  6935,  8104,  3383, 10678, 14524, 10791,  6862])
-------Step 5-------
tensor([ 4137, 14610,   274,   725,  9960, 10845,   270, 10520, 10492,  6032]) tensor([10064, 10001,  4379, 13554,  3445,    86,  7860,  4850,  1512,  2141])
-------Step 6-------
tensor([14584,   113,     0,    12,  5213,    95, 14464,  6617,  7918,   280]) tensor([ 7329,  6270,  1219,  4537,  4235,  6358,  9312, 12012,  3673,  4286])
-------Step 7-------
tensor([14584,   113,     0,    12,  5213,    95, 14464,  6617,  7918,   280]) tensor([ 5745, 14856,  3178,  8268,  6967,  3626,  8769,  6287,  6476,  1210])
-------Step 8-------
tensor([ 6817,   636,  8196,   667,  4496,    49,   143, 14311,  9731,  7075]) tensor([ 5480,  8901, 11272, 14783,  1939, 14746, 10534, 10233, 14606, 12121])
-------Step 9-------
tensor([ 6817,   636,  8196,   667,  4496,    49,   143, 14311,  9731,  7075]) tensor([14565,  4643,  1675, 12051,  8068,  8505,  9907,   512, 13596,  3608])
[proc 0][Train](200/500) average pos_loss: 0.6127678532898426
[proc 0][Train](200/500) average neg_loss: 0.4904425483942032
[proc 0][Train](200/500) average loss: 0.5516052021086216
[proc 0][Train](200/500) average regularization: 3.6714613997901324e-06
[proc 0] 200 steps, total: 7.850, sample: 0.532, forward: 2.577, backward: 3.542, update: 0.795
[proc 2][Train](200/500) average pos_loss: 0.6812574047781527
[proc 2][Train](200/500) average neg_loss: 0.524774014800787
[proc 2][Train](200/500) average loss: 0.603015711158514
[proc 2][Train](200/500) average regularization: 3.741890168384998e-06
[proc 2] 200 steps, total: 7.847, sample: 0.727, forward: 2.148, backward: 2.594, update: 0.965
[proc 3][Train](200/500) average pos_loss: 0.6593686667270958
[proc 3][Train](200/500) average neg_loss: 0.516521729156375
[proc 3][Train](200/500) average loss: 0.5879451987147332
[proc 3][Train](200/500) average regularization: 3.7648861518846387e-06
[proc 3] 200 steps, total: 7.868, sample: 0.733, forward: 2.270, backward: 2.421, update: 0.964
[proc 1][Train](200/500) average pos_loss: 0.6338807648420334
[proc 1][Train](200/500) average neg_loss: 0.5254091683775186
[proc 1][Train](200/500) average loss: 0.5796449659764766
[proc 1][Train](200/500) average regularization: 3.6625315334504195e-06
[proc 1] 200 steps, total: 7.882, sample: 0.720, forward: 2.190, backward: 2.490, update: 1.034
[proc 3][Train](400/500) average pos_loss: 0.42404833048582075
[proc 3][Train](400/500) average neg_loss: 0.41980968981981276
[proc 3][Train](400/500) average loss: 0.42192901179194453
[proc 3][Train](400/500) average regularization: 3.99400557739682e-06
[proc 3] 400 steps, total: 5.010, sample: 0.695, forward: 1.329, backward: 0.896, update: 0.912
[proc 0][Train](400/500) average pos_loss: 0.3560679829865694
[proc 0][Train](400/500) average neg_loss: 0.3423007186502218
[proc 0][Train](400/500) average loss: 0.34918435126543046
[proc 0][Train](400/500) average regularization: 3.987519647807858e-06
[proc 0] 400 steps, total: 5.010, sample: 0.500, forward: 1.687, backward: 1.681, update: 0.737
[proc 1][Train](400/500) average pos_loss: 0.40723832972347734
[proc 1][Train](400/500) average neg_loss: 0.4110588483512402
[proc 1][Train](400/500) average loss: 0.40914858877658844
[proc 1][Train](400/500) average regularization: 3.873192530363667e-06
[proc 1] 400 steps, total: 5.010, sample: 0.678, forward: 1.260, backward: 0.842, update: 0.979
[proc 2][Train](400/500) average pos_loss: 0.46157440170645714
[proc 2][Train](400/500) average neg_loss: 0.43801069736480713
[proc 2][Train](400/500) average loss: 0.4497925500571728
[proc 2][Train](400/500) average regularization: 3.899244711647043e-06
[proc 2] 400 steps, total: 5.010, sample: 0.692, forward: 1.315, backward: 0.912, update: 0.897
Successfully xmh. training takes 15.379838466644287 seconds
