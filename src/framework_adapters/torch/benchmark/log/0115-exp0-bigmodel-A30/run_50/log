/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_235', no_save_emb=True, max_step=500, batch_size=8400, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2426952 sampler.py:454] Start PreSampling
WARNING [2426952 sampler.py:532] Before construct renumbering_dict
WARNING [2426952 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:50:12.177613 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:50:12.177784 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:50:12.177819 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:50:12.177850 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:50:12.177879 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:50:12.177906 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:50:12.177937 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:50:12.177968 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:50:12.177999 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:50:12.178027 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:50:12.178059 2426952 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:50:12.178092 2426952 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:50:12.178117 2426952 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:50:12.178232 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:50:12.178272 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:50:12.178316 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:50:12.178346 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:50:12.178373 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:50:12.178400 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:50:12.178450 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:50:12.178479 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:50:12.178506 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:50:12.178534 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:50:12.178562 2426952 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:50:12.178588 2426952 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:50:12.178611 2426952 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:50:12.178668 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:50:12.178704 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:50:12.178733 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:50:12.178761 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:50:12.178787 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:50:12.178824 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:50:12.178853 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:50:12.178879 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:50:12.178905 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:50:12.178933 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:50:12.178961 2426952 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:50:12.178985 2426952 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:50:12.179009 2426952 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:50:12.179057 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:50:12.179091 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:50:12.179118 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:50:12.179147 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:50:12.179174 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:50:12.179210 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:50:12.179241 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:50:12.179276 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:50:12.179306 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:50:12.179332 2426952 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:50:12.179359 2426952 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:50:12.179384 2426952 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:50:12.179407 2426952 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1676, 1762, 1794,  ..., 8385, 6800, 6928]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 1.573 seconds
[Rank1] pid = 2427165
[Rank2] pid = 2427230
INFO [2426952 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2427165 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2427230 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2427230 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2427294 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2427294 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2426952 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2427165 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2427294
-------Step 0-------
tensor([ 8763,    80, 14558, 10769,  5163,  6424, 10554,  1972,  3600, 13053]) tensor([ 1794,    69,  6994, 12335, 12713,    34, 10968,  4068, 12235,  8386])
-------Step 1-------
tensor([ 8763,    80, 14558, 10769,  5163,  6424, 10554,  1972,  3600, 13053]) tensor([ 5729, 14800, 11880,  4144, 13807,  8778, 10272,   479,  5520, 12071])
-------Step 2-------
tensor([ 8567,    90, 14924,  9164,  3741, 12568, 14895, 10116,  2886,  5542]) tensor([ 6202, 10718, 13743,  8013,  7088,  1013,  5237,  1422, 11964,  9264])
-------Step 3-------
tensor([ 8567,    90, 14924,  9164,  3741, 12568, 14895, 10116,  2886,  5542]) tensor([13843,  8378,  9801,  5443, 13097,  9951, 11338,  3727,  7330,  9225])
-------Step 4-------
tensor([ 3799,  5179,  6425,  7349,   267, 10649,  8799,  7473,  3313,  1230]) tensor([ 5908,  5703, 13521, 10236,  8179,  9326,  3636, 10088,  7627,  2484])
-------Step 5-------
tensor([ 3799,  5179,  6425,  7349,   267, 10649,  8799,  7473,  3313,  1230]) tensor([ 7639,  4499,  3470,  1218, 13556,  3814, 14377,  2045, 10649,  4670])
-------Step 6-------
tensor([ 5542, 13066,  7835,  6130,  5197,  7623,  3806,   155, 11019,  3153]) tensor([ 3056,  4656,  7536,  5305,  2781,  9673,  4369, 11164, 13263,  2288])
-------Step 7-------
tensor([ 5542, 13066,  7835,  6130,  5197,  7623,  3806,   155, 11019,  3153]) tensor([ 2208,  1970,  6078, 14293, 10507, 10568, 14106, 10244, 14114,  7292])
-------Step 8-------
tensor([12908,   925,  5473,  3770,  9376,  4457,  7105,  3133, 14422, 11914]) tensor([12861, 14549,  9128, 14250, 14675,  9331,  9653, 12181,  8405,  7867])
-------Step 9-------
tensor([12908,   925,  5473,  3770,  9376,  4457,  7105,  3133, 14422, 11914]) tensor([10477,  9542,  7536,  9788,   152,  9296, 13948,   515,   106, 11327])
[proc 0][Train](200/500) average pos_loss: 0.5892778227478266
[proc 0][Train](200/500) average neg_loss: 0.27017783041577786
[proc 0][Train](200/500) average loss: 0.4297278261184692
[proc 0][Train](200/500) average regularization: 6.175611978505913e-05
[proc 0] 200 steps, total: 34.972, sample: 0.955, forward: 13.708, backward: 17.364, update: 2.640
[proc 3][Train](200/500) average pos_loss: 0.64935592032969
[proc 3][Train](200/500) average neg_loss: 0.31641593393549555
[proc 3][Train](200/500) average loss: 0.4828859265893698
[proc 3][Train](200/500) average regularization: 6.054374631276005e-05
[proc 3] 200 steps, total: 34.925, sample: 1.849, forward: 7.156, backward: 6.771, update: 4.276
[proc 1][Train](200/500) average pos_loss: 0.6096983599662781
[proc 1][Train](200/500) average neg_loss: 0.31045763747533783
[proc 1][Train](200/500) average loss: 0.4600780001282692
[proc 1][Train](200/500) average regularization: 6.0968489533479444e-05
[proc 1] 200 steps, total: 34.983, sample: 1.857, forward: 6.650, backward: 5.793, update: 4.537
[proc 2][Train](200/500) average pos_loss: 0.6928656189888716
[proc 2][Train](200/500) average neg_loss: 0.3406568477395922
[proc 2][Train](200/500) average loss: 0.5167612318694591
[proc 2][Train](200/500) average regularization: 6.143073911516694e-05
[proc 2] 200 steps, total: 34.961, sample: 1.882, forward: 7.092, backward: 6.843, update: 4.348
[proc 0][Train](400/500) average pos_loss: 0.1133190406113863
[proc 0][Train](400/500) average neg_loss: 0.14627563033252955
[proc 0][Train](400/500) average loss: 0.12979733508080243
[proc 0][Train](400/500) average regularization: 5.263376926450292e-05
[proc 0] 400 steps, total: 32.764, sample: 1.126, forward: 13.049, backward: 15.356, update: 2.891
[proc 2][Train](400/500) average pos_loss: 0.1982642364501953
[proc 2][Train](400/500) average neg_loss: 0.20313508734107016
[proc 2][Train](400/500) average loss: 0.20069966174662113
[proc 2][Train](400/500) average regularization: 5.0739705038722604e-05
[proc 2] 400 steps, total: 32.763, sample: 1.927, forward: 6.156, backward: 5.011, update: 4.461
[proc 3][Train](400/500) average pos_loss: 0.16242638625204564
[proc 3][Train](400/500) average neg_loss: 0.1785524994879961
[proc 3][Train](400/500) average loss: 0.17048944234848024
[proc 3][Train](400/500) average regularization: 4.9924984541576126e-05
[proc 3] 400 steps, total: 32.764, sample: 1.751, forward: 6.151, backward: 4.996, update: 4.304
[proc 1][Train](400/500) average pos_loss: 0.14360052824020386
[proc 1][Train](400/500) average neg_loss: 0.17226821094751357
[proc 1][Train](400/500) average loss: 0.15793436981737613
[proc 1][Train](400/500) average regularization: 5.158108813702711e-05
[proc 1] 400 steps, total: 32.764, sample: 1.883, forward: 6.043, backward: 4.539, update: 4.409
Successfully xmh. training takes 84.11165618896484 seconds
