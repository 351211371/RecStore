/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_195', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.1, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2362823 sampler.py:454] Start PreSampling
WARNING [2362823 sampler.py:532] Before construct renumbering_dict
WARNING [2362823 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 00:53:12.179076 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 00:53:12.179247 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 00:53:12.179293 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 00:53:12.179327 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 00:53:12.179355 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 00:53:12.179384 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 00:53:12.179414 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 00:53:12.179445 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 00:53:12.179476 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 00:53:12.179502 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 00:53:12.179536 2362823 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 00:53:12.179569 2362823 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 00:53:12.179592 2362823 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 00:53:12.179688 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 00:53:12.179728 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 00:53:12.179765 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 00:53:12.179812 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 00:53:12.179843 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 00:53:12.179870 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 00:53:12.179913 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 00:53:12.179940 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 00:53:12.179968 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 00:53:12.179996 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 00:53:12.180024 2362823 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 00:53:12.180050 2362823 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 00:53:12.180074 2362823 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 00:53:12.180128 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 00:53:12.180160 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 00:53:12.180188 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 00:53:12.180217 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 00:53:12.180243 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 00:53:12.180271 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 00:53:12.180298 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 00:53:12.180327 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 00:53:12.180354 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 00:53:12.180382 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 00:53:12.180409 2362823 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 00:53:12.180433 2362823 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 00:53:12.180456 2362823 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 00:53:12.180502 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 00:53:12.180536 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 00:53:12.180567 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 00:53:12.180595 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 00:53:12.180622 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 00:53:12.180650 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 00:53:12.180678 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 00:53:12.180706 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 00:53:12.180733 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 00:53:12.180760 2362823 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 00:53:12.180788 2362823 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 00:53:12.180812 2362823 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 00:53:12.180836 2362823 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 373
Rank1: cached key size 373
Rank2: cached key size 373
Rank3: cached key size 373
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([1659, 1761, 1795,  ..., 8626, 7629, 6690]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.376 seconds
[Rank1] pid = 2363045
[Rank2] pid = 2363110
INFO [2362823 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2363045 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2363110 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2363174 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2363174 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2363045 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2362823 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2363110 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2363174
-------Step 0-------
tensor([ 8324, 14669, 14433, 11408,  4962,   214, 13416,  2218,  4008, 13479]) tensor([ 1795, 12157,  7371, 10420, 12623,  8629, 11925,  3813, 11808,  8321])
-------Step 1-------
tensor([ 8324, 14669, 14433, 11408,  4962,   214, 13416,  2218,  4008, 13479]) tensor([ 7002,  3556,  7196, 12235,  7126,  7547, 13738, 14928,  6062,  6383])
-------Step 2-------
tensor([ 2882, 14025,  6938,    96,  9065, 11599,   266,  6744, 13159,  4737]) tensor([ 5219,  3147, 14508,  5212,  8078,  1941,  8912, 13910, 11461,  5764])
-------Step 3-------
tensor([ 2882, 14025,  6938,    96,  9065, 11599,   266,  6744, 13159,  4737]) tensor([14691,  2058,  3191,  6476,  7555,  3960,  8001, 12247,  8146, 12064])
-------Step 4-------
tensor([5793,   29, 7994,   20, 2540, 4499,  244,  955,  239, 1389]) tensor([ 4264,  7044,  9860, 14386,   803, 14249,  9720, 10829,  1259, 12907])
-------Step 5-------
tensor([5793,   29, 7994,   20, 2540, 4499,  244,  955,  239, 1389]) tensor([ 3274,  1673, 13545, 10919,   190, 10562,  8241, 14263, 14709,   602])
-------Step 6-------
tensor([ 5922, 13586,  9059,    18,  7761, 14243,  6663,  1443,   862,  8180]) tensor([13110,  4333,  7322,   663,  4715, 11758, 13921,  4782, 10001, 12878])
-------Step 7-------
tensor([ 5922, 13586,  9059,    18,  7761, 14243,  6663,  1443,   862,  8180]) tensor([ 4756,  6295,  1466, 14338,  3990,  1209, 13184,  7964,  7086,  2873])
-------Step 8-------
tensor([  325, 11221,  9412,  7087,   847, 10348,  3905,  9244, 10487,     3]) tensor([10871, 10307,  6413,  7388,  1291,  7684, 10511,  5837, 14315, 13501])
-------Step 9-------
tensor([  325, 11221,  9412,  7087,   847, 10348,  3905,  9244, 10487,     3]) tensor([10414, 10428,  7869,  6531,  1826,  2887, 12812, 14928, 11470,  5325])
[proc 0][Train](200/500) average pos_loss: 0.5511388477310538
[proc 0][Train](200/500) average neg_loss: 0.4350833146087825
[proc 0][Train](200/500) average loss: 0.4931110815703869
[proc 0][Train](200/500) average regularization: 7.308365019298435e-06
[proc 0] 200 steps, total: 10.133, sample: 0.596, forward: 3.247, backward: 4.452, update: 1.214
[proc 1][Train](200/500) average pos_loss: 0.5852951510250568
[proc 1][Train](200/500) average neg_loss: 0.4829679996520281
[proc 1][Train](200/500) average loss: 0.5341315744817257
[proc 1][Train](200/500) average regularization: 7.27831875224183e-06
[proc 1] 200 steps, total: 10.132, sample: 0.919, forward: 2.703, backward: 2.798, update: 1.482
[proc 2][Train](200/500) average pos_loss: 0.6368225793540477
[proc 2][Train](200/500) average neg_loss: 0.49400442697107794
[proc 2][Train](200/500) average loss: 0.565413504242897
[proc 2][Train](200/500) average regularization: 7.446809697739809e-06
[proc 2] 200 steps, total: 10.131, sample: 0.923, forward: 2.735, backward: 2.991, update: 1.492
[proc 3][Train](200/500) average pos_loss: 0.6043152565136551
[proc 3][Train](200/500) average neg_loss: 0.479277420938015
[proc 3][Train](200/500) average loss: 0.541796338558197
[proc 3][Train](200/500) average regularization: 7.499175168277361e-06
[proc 3] 200 steps, total: 10.148, sample: 0.928, forward: 2.696, backward: 2.885, update: 1.523
[proc 0][Train](400/500) average pos_loss: 0.21749239198863507
[proc 0][Train](400/500) average neg_loss: 0.23704478479921817
[proc 0][Train](400/500) average loss: 0.22726858757436275
[proc 0][Train](400/500) average regularization: 8.469720305583906e-06
[proc 0] 400 steps, total: 7.636, sample: 0.598, forward: 2.635, backward: 2.746, update: 1.179
[proc 1][Train](400/500) average pos_loss: 0.26651908732950685
[proc 1][Train](400/500) average neg_loss: 0.2917923714965582
[proc 1][Train](400/500) average loss: 0.2791557289659977
[proc 1][Train](400/500) average regularization: 8.240670117629634e-06
[proc 1] 400 steps, total: 7.636, sample: 0.828, forward: 1.806, backward: 1.137, update: 1.363
[proc 3][Train](400/500) average pos_loss: 0.30222953110933304
[proc 3][Train](400/500) average neg_loss: 0.3137066442519426
[proc 3][Train](400/500) average loss: 0.3079680872708559
[proc 3][Train](400/500) average regularization: 8.371644053113414e-06
[proc 3] 400 steps, total: 7.636, sample: 0.898, forward: 1.909, backward: 1.225, update: 1.469
[proc 2][Train](400/500) average pos_loss: 0.36089284405112265
[proc 2][Train](400/500) average neg_loss: 0.34067496567964556
[proc 2][Train](400/500) average loss: 0.35078390419483185
[proc 2][Train](400/500) average regularization: 8.143589438986964e-06
[proc 2] 400 steps, total: 7.637, sample: 0.911, forward: 1.890, backward: 1.220, update: 1.464
Successfully xmh. training takes 21.664953470230103 seconds
