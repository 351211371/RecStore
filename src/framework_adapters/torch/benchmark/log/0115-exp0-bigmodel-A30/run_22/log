/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_207', no_save_emb=True, max_step=500, batch_size=1800, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.2, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2379149 sampler.py:454] Start PreSampling
WARNING [2379149 sampler.py:532] Before construct renumbering_dict
WARNING [2379149 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 01:04:37.535521 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 01:04:37.535715 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 01:04:37.535753 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 01:04:37.535790 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 01:04:37.535820 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 01:04:37.535849 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 01:04:37.535877 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 01:04:37.535909 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 01:04:37.535938 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 01:04:37.535965 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 01:04:37.536008 2379149 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 01:04:37.536041 2379149 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 01:04:37.536067 2379149 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 01:04:37.536160 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 01:04:37.536198 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 01:04:37.536227 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 01:04:37.536253 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 01:04:37.536279 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 01:04:37.536305 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 01:04:37.536350 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 01:04:37.536377 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 01:04:37.536404 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 01:04:37.536430 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 01:04:37.536458 2379149 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 01:04:37.536482 2379149 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 01:04:37.536506 2379149 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 01:04:37.536556 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 01:04:37.536590 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 01:04:37.536621 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 01:04:37.536648 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 01:04:37.536675 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 01:04:37.536701 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 01:04:37.536727 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 01:04:37.536754 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 01:04:37.536783 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 01:04:37.536810 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 01:04:37.536837 2379149 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 01:04:37.536862 2379149 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 01:04:37.536886 2379149 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 01:04:37.536931 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 01:04:37.536965 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 01:04:37.536993 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 01:04:37.537020 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 01:04:37.537046 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 01:04:37.537073 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 01:04:37.537101 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 01:04:37.537127 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 01:04:37.537153 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 01:04:37.537180 2379149 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 01:04:37.537206 2379149 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 01:04:37.537231 2379149 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 01:04:37.537253 2379149 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 747
Rank1: cached key size 747
Rank2: cached key size 747
Rank3: cached key size 747
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([3130, 3250, 3274,  ..., 9123, 8722, 7342]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 2.146 seconds
[Rank1] pid = 2379366
[Rank2] pid = 2379431
INFO [2379149 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2379366 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2379495 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2379495 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2379149 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2379366 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2379431 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2379431 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[proc 2][Train](200/500) average pos_loss: 0.6114077714830637
[proc 2][Train](200/500) average neg_loss: 0.46530306747183203
[proc 2][Train](200/500) average loss: 0.5383554202318191
[proc 2][Train](200/500) average regularization: 1.1196533007478138e-05
[proc 2] 200 steps, total: 13.143, sample: 0.904, forward: 3.182, backward: 3.253, update: 2.003
[proc 1][Train](200/500) average pos_loss: 0.5531647249311209
[proc 1][Train](200/500) average neg_loss: 0.4455720296502113
[proc 1][Train](200/500) average loss: 0.49936837777495385
[proc 1][Train](200/500) average regularization: 1.094736636559901e-05
[proc 1] 200 steps, total: 13.144, sample: 1.105, forward: 3.271, backward: 3.271, update: 2.030
[Rank3] pid = 2379495
-------Step 0-------
tensor([   83, 14843, 14500, 10997,  5904,   727,   353,  3531,  5266, 12424]) tensor([ 3274,   724,  7745, 11140, 12902,   214, 13498,  5162, 12222,  8877])
-------Step 1-------
tensor([   83, 14843, 14500, 10997,  5904,   727,   353,  3531,  5266, 12424]) tensor([ 1329, 11251,  2130,   307,  3245,  4011, 13664, 14944, 10607,  6662])
-------Step 2-------
tensor([10617,   147,     5,   182,  4908,   720, 14059,  7815,  7265,   247]) tensor([ 8816,  5843,  1361,  4523,  4409,  5866,  7835, 14183,  4153,  4773])
-------Step 3-------
tensor([10617,   147,     5,   182,  4908,   720, 14059,  7815,  7265,   247]) tensor([12572, 13949, 10340, 10731, 14566,  3959,  4988,  7678,  7172,   605])
-------Step 4-------
tensor([  701, 13642,   707,    68,  8540, 14147,  7903, 13490,  7193,  9193]) tensor([13455,  6403,  7962,  1087,  5537, 14288, 11219,  6910, 11528, 11455])
-------Step 5-------
tensor([  701, 13642,   707,    68,  8540, 14147,  7903, 13490,  7193,  9193]) tensor([12751, 14077,  1932,   653, 14924, 11544,  8481,  6118,  6164,   135])
-------Step 6-------
tensor([ 8101,    38,  4876, 14738,  9062,  9552, 12803,  6791,  6234, 10433]) tensor([ 6559,     9, 12775,  1730, 10195,   744,  2329, 12945,  1462,  5185])
-------Step 7-------
tensor([ 8101,    38,  4876, 14738,  9062,  9552, 12803,  6791,  6234, 10433]) tensor([ 7134,   677,  8859,   372, 10552, 13395,  9432,   323,  9298,  8851])
-------Step 8-------
tensor([13161,  6852,   746,    66,  5386,  5550,   462,   713,   151,   737]) tensor([12332,  5020,  1906, 11755,  8351,  7694, 10400,   111, 14948,  3652])
-------Step 9-------
tensor([13161,  6852,   746,    66,  5386,  5550,   462,   713,   151,   737]) tensor([  693,  7390,  5048, 13829,  5407,   118,  3456,  2143,  5828,   226])
[proc 0][Train](200/500) average pos_loss: 0.5156568095088006
[proc 0][Train](200/500) average neg_loss: 0.3974496172554791
[proc 0][Train](200/500) average loss: 0.4565532150119543
[proc 0][Train](200/500) average regularization: 1.102159787706114e-05
[proc 0] 200 steps, total: 13.142, sample: 0.630, forward: 4.651, backward: 5.847, update: 1.537
[proc 3][Train](200/500) average pos_loss: 0.5794465696066617
[proc 3][Train](200/500) average neg_loss: 0.44731862514279785
[proc 3][Train](200/500) average loss: 0.513382598310709
[proc 3][Train](200/500) average regularization: 1.1252266460815008e-05
[proc 3] 200 steps, total: 13.154, sample: 1.059, forward: 3.360, backward: 3.304, update: 2.028
[proc 0][Train](400/500) average pos_loss: 0.1798871335014701
[proc 0][Train](400/500) average neg_loss: 0.19895307570695878
[proc 0][Train](400/500) average loss: 0.18942010447382926
[proc 0][Train](400/500) average regularization: 1.279691782201553e-05
[proc 0] 400 steps, total: 10.476, sample: 0.673, forward: 3.656, backward: 3.818, update: 1.492
[proc 1][Train](400/500) average pos_loss: 0.21666360691189765
[proc 1][Train](400/500) average neg_loss: 0.2404291732609272
[proc 1][Train](400/500) average loss: 0.2285463899374008
[proc 1][Train](400/500) average regularization: 1.2541628730105003e-05
[proc 1] 400 steps, total: 10.476, sample: 1.132, forward: 2.275, backward: 1.455, update: 1.954
[proc 2][Train](400/500) average pos_loss: 0.2910921794176102
[proc 2][Train](400/500) average neg_loss: 0.2835462656617165
[proc 2][Train](400/500) average loss: 0.2873192225396633
[proc 2][Train](400/500) average regularization: 1.242071596607275e-05
[proc 2] 400 steps, total: 10.476, sample: 0.969, forward: 2.301, backward: 1.558, update: 1.983
[proc 3][Train](400/500) average pos_loss: 0.2463137037307024
[proc 3][Train](400/500) average neg_loss: 0.2577746284753084
[proc 3][Train](400/500) average loss: 0.2520441658049822
[proc 3][Train](400/500) average regularization: 1.2644325256587762e-05
[proc 3] 400 steps, total: 10.476, sample: 1.025, forward: 2.302, backward: 1.623, update: 2.016
Successfully xmh. training takes 28.89843463897705 seconds
