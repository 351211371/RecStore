/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/_deprecate/graph.py:1023: DGLWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.
  dgl_warning("multigraph will be deprecated." \
/home/xieminhui/RecStore/src/framework_adapters/torch/kg/dgl-0.9.1/python/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
Reading train triples....
Finished. Read 483142 train triples.
Reading valid triples....
Finished. Read 50000 valid triples.
Reading test triples....
Finished. Read 59071 test triples.
ARGS:  Namespace(model_name='TransE_l1', data_path='/home/xieminhui/dgl-data', dataset='FB15k', format='built_in', data_files=None, delimiter='\t', save_path='/tmp/ckpts/TransE_l1_FB15k_199', no_save_emb=True, max_step=500, batch_size=1200, batch_size_eval=16, neg_sample_size=200, neg_deg_sample=False, neg_deg_sample_eval=False, neg_sample_size_eval=14951, eval_percent=1, no_eval_filter=False, log_interval=200, eval_interval=10000, test=False, num_proc=4, num_thread=1, force_sync_interval=1, hidden_dim=400, lr=0.01, gamma=16.0, double_ent=False, double_rel=False, neg_adversarial_sampling=False, adversarial_temperature=1.0, regularization_coef=1e-07, regularization_norm=3, pairwise=False, loss_genre='Logsigmoid', margin=1.0, nr_gpus=4, gpu=[0, 1, 2, 3], mix_cpu_gpu=True, valid=False, rel_part=False, async_update=None, has_edge_importance=False, cached_emb_type='None', use_my_emb=False, cache_ratio=0.2, shuffle=False, backwardMode='CppSync', L=10, kForwardItersPerStep=2, backgrad_init='both', eval_filter=True, soft_rel_part=False)
|Train|: 483142
original graph:  DGLGraph(num_nodes=14951, num_edges=592213,
         ndata_schemes={}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Loading cached metis
WARNING [2368526 sampler.py:454] Start PreSampling
WARNING [2368526 sampler.py:532] Before construct renumbering_dict
WARNING [2368526 sampler.py:555] PreSampling done
WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240115 00:56:42.587730 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000002000
W20240115 00:56:42.587935 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_1 [100000]0x1000000c7000
W20240115 00:56:42.587978 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_2 [100000]0x10000018c000
W20240115 00:56:42.588014 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000251000
W20240115 00:56:42.588047 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000316000
W20240115 00:56:42.588080 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_5 [100000]0x1000003db000
W20240115 00:56:42.588111 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_6 [100000]0x1000004a0000
W20240115 00:56:42.588148 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_7 [100000]0x100000565000
W20240115 00:56:42.588176 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_8 [100000]0x10000062a000
W20240115 00:56:42.588205 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000006ef000
W20240115 00:56:42.588243 2368526 IPCTensor.h:367] NewIPCTensor: step_r0 [10]0x1000007b4000
W20240115 00:56:42.588276 2368526 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r0 [1]0x1000007b6000
W20240115 00:56:42.588303 2368526 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000007b8000
W20240115 00:56:42.588405 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000007ba000
W20240115 00:56:42.588445 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000087f000
W20240115 00:56:42.588479 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_2 [100000]0x100000944000
W20240115 00:56:42.588512 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_3 [100000]0x100000a09000
W20240115 00:56:42.588539 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_4 [100000]0x100000ace000
W20240115 00:56:42.588570 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_5 [100000]0x100000b93000
W20240115 00:56:42.588616 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_6 [100000]0x100000c58000
W20240115 00:56:42.588651 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_7 [100000]0x100000d1d000
W20240115 00:56:42.588677 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_8 [100000]0x100000de2000
W20240115 00:56:42.588713 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000ea7000
W20240115 00:56:42.588752 2368526 IPCTensor.h:367] NewIPCTensor: step_r1 [10]0x100000f6c000
W20240115 00:56:42.588779 2368526 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r1 [1]0x100000f6e000
W20240115 00:56:42.588802 2368526 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000f70000
W20240115 00:56:42.588855 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_0 [100000]0x100000f72000
W20240115 00:56:42.588888 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_1 [100000]0x100001037000
W20240115 00:56:42.588917 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_2 [100000]0x1000010fc000
W20240115 00:56:42.588948 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_3 [100000]0x1000011c1000
W20240115 00:56:42.588979 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_4 [100000]0x100001286000
W20240115 00:56:42.589010 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_5 [100000]0x10000134b000
W20240115 00:56:42.589037 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_6 [100000]0x100001410000
W20240115 00:56:42.589067 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_7 [100000]0x1000014d5000
W20240115 00:56:42.589097 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_8 [100000]0x10000159a000
W20240115 00:56:42.589128 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r2_9 [100000]0x10000165f000
W20240115 00:56:42.589154 2368526 IPCTensor.h:367] NewIPCTensor: step_r2 [10]0x100001724000
W20240115 00:56:42.589179 2368526 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r2 [1]0x100001726000
W20240115 00:56:42.589203 2368526 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r2 [1]0x100001728000
W20240115 00:56:42.589251 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_0 [100000]0x10000172a000
W20240115 00:56:42.589285 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_1 [100000]0x1000017ef000
W20240115 00:56:42.589313 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_2 [100000]0x1000018b4000
W20240115 00:56:42.589342 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_3 [100000]0x100001979000
W20240115 00:56:42.589373 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_4 [100000]0x100001a3e000
W20240115 00:56:42.589402 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_5 [100000]0x100001b03000
W20240115 00:56:42.589428 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_6 [100000]0x100001bc8000
W20240115 00:56:42.589454 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_7 [100000]0x100001c8d000
W20240115 00:56:42.589481 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_8 [100000]0x100001d52000
W20240115 00:56:42.589511 2368526 IPCTensor.h:367] NewIPCTensor: cached_sampler_r3_9 [100000]0x100001e17000
W20240115 00:56:42.589538 2368526 IPCTensor.h:367] NewIPCTensor: step_r3 [10]0x100001edc000
W20240115 00:56:42.589562 2368526 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_r3 [1]0x100001ede000
W20240115 00:56:42.589589 2368526 IPCTensor.h:367] NewIPCTensor: circle_buffer_end_cppseen_r3 [1]0x100001ee0000
{0: Graph(num_nodes=9480, num_edges=154759,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 1: Graph(num_nodes=11158, num_edges=169559,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 2: Graph(num_nodes=11355, num_edges=241153,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)}), 3: Graph(num_nodes=10394, num_edges=202691,
      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_node': Scheme(shape=(), dtype=torch.int32), 'part_id': Scheme(shape=(), dtype=torch.int64)}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'inner_edge': Scheme(shape=(), dtype=torch.int8)})}
MertisPartition: part 0 has 9480 N 154759 E
MertisPartition: part 1 has 11158 N 169559 E
MertisPartition: part 2 has 11355 N 241153 E
MertisPartition: part 3 has 10394 N 202691 E
Rank0: cached key size 747
Rank1: cached key size 747
Rank2: cached key size 747
Rank3: cached key size 747
Before renumbering graph:  {'_ID': tensor([    6,    10,    11,  ...,  2559,  7188, 13282]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
After renumbering graph:  {'_ID': tensor([ 3120,  3195,  3219,  ..., 11704,  8415,  7456]), 'inner_node': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32), 'part_id': tensor([0, 0, 0,  ..., 2, 1, 3])}
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
part_g: DGLGraph(num_nodes=9480, num_edges=154759,
         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}
         edata_schemes={'tid': Scheme(shape=(), dtype=torch.int64)})
Total initialize time 3.160 seconds
[Rank1] pid = 2368748
[Rank2] pid = 2368813
INFO [2368813 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 2
INFO [2368526 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [2368877 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 3
INFO [2368748 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [2368877 distributed_c10d.py:476] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2368748 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2368813 distributed_c10d.py:476] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO [2368526 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[Rank3] pid = 2368877
-------Step 0-------
tensor([   45, 14365, 14623, 11084,  5975,   447,   687,  3540,  5222, 13012]) tensor([ 3219, 11702,  7638, 12110, 12946,   250, 12517,  4864, 12786,  8379])
-------Step 1-------
tensor([   45, 14365, 14623, 11084,  5975,   447,   687,  3540,  5222, 13012]) tensor([ 8076,  4727,  8787, 13576,  8764,  8074,   126, 14943,  6820,  7664])
-------Step 2-------
tensor([ 4107, 14414,   432,   738,  7991, 11679,   266,  8329, 13564,  5183]) tensor([  773,  4600, 13434,  7156,  8584,  3360, 11222, 14320, 10789,  6623])
-------Step 3-------
tensor([ 4107, 14414,   432,   738,  7991, 11679,   266,  8329, 13564,  5183]) tensor([13554,  3507,  4332,  6995,  8158,  2216,  1882, 12388,  9359, 11662])
-------Step 4-------
tensor([ 6524,   618,  7866,   333,  4122,   636,   191, 14129, 12571,  7202]) tensor([ 5651,  8333,  9741, 14679,  1764, 14577, 12993, 10249, 12165, 12714])
-------Step 5-------
tensor([ 6524,   618,  7866,   333,  4122,   636,   191, 14129, 12571,  7202]) tensor([ 5060,  3174, 13081, 11550, 13451, 10709,  8548,   362, 14939,  1065])
-------Step 6-------
tensor([  350, 13601,   610,   306,  8369, 14855,  7375, 12761,  7234,  8063]) tensor([13396,  6232,  7926,  1174,  5584, 13037, 12608,  6258, 10916, 11166])
-------Step 7-------
tensor([  350, 13601,   610,   306,  8369, 14855,  7375, 12761,  7234,  8063]) tensor([ 6012,  6218, 10435, 14245,  1832,  2332, 14386, 10167,  7636,  4147])
-------Step 8-------
tensor([  204, 11494,  9522,   850,  2110, 11227,  5000,   693,   680, 11226]) tensor([11628,  9895,  6709,  8736,  4802,  8706,  9567,  7034,  2477, 13919])
-------Step 9-------
tensor([  204, 11494,  9522,   850,  2110, 11227,  5000,   693,   680, 11226]) tensor([  934,  9897,  1871,   201,  3258,  3984, 14198, 14943, 11149,  6215])
[proc 0][Train](200/500) average pos_loss: 0.5516606691107154
[proc 0][Train](200/500) average neg_loss: 0.4350136110186577
[proc 0][Train](200/500) average loss: 0.4933371415734291
[proc 0][Train](200/500) average regularization: 7.323187902557038e-06
[proc 0] 200 steps, total: 10.647, sample: 0.636, forward: 3.664, backward: 4.566, update: 1.146
[proc 3][Train](200/500) average pos_loss: 0.6030723798274994
[proc 3][Train](200/500) average neg_loss: 0.4792403155565262
[proc 3][Train](200/500) average loss: 0.5411563484370708
[proc 3][Train](200/500) average regularization: 7.508751835985095e-06
[proc 3] 200 steps, total: 10.681, sample: 0.798, forward: 2.574, backward: 2.573, update: 1.522
[proc 2][Train](200/500) average pos_loss: 0.6355866289511323
[proc 2][Train](200/500) average neg_loss: 0.4935448219440877
[proc 2][Train](200/500) average loss: 0.5645657281577587
[proc 2][Train](200/500) average regularization: 7.4573881295236785e-06
[proc 2] 200 steps, total: 10.635, sample: 0.885, forward: 2.783, backward: 3.065, update: 1.674
[proc 1][Train](200/500) average pos_loss: 0.5842415322363377
[proc 1][Train](200/500) average neg_loss: 0.48288749624043703
[proc 1][Train](200/500) average loss: 0.5335645149648189
[proc 1][Train](200/500) average regularization: 7.288756110028771e-06
[proc 1] 200 steps, total: 10.664, sample: 0.907, forward: 2.807, backward: 2.684, update: 1.559
[proc 2][Train](400/500) average pos_loss: 0.3613575556874275
[proc 2][Train](400/500) average neg_loss: 0.34054367199540136
[proc 2][Train](400/500) average loss: 0.3509506151080132
[proc 2][Train](400/500) average regularization: 8.15366701772291e-06
[proc 2] 400 steps, total: 7.736, sample: 0.838, forward: 1.752, backward: 1.222, update: 1.586
[proc 0][Train](400/500) average pos_loss: 0.2179512293636799
[proc 0][Train](400/500) average neg_loss: 0.2375881002098322
[proc 0][Train](400/500) average loss: 0.22776966489851475
[proc 0][Train](400/500) average regularization: 8.485121311423427e-06
[proc 0] 400 steps, total: 7.736, sample: 0.635, forward: 2.727, backward: 2.758, update: 1.074
[proc 1][Train](400/500) average pos_loss: 0.26579691506922243
[proc 1][Train](400/500) average neg_loss: 0.2919125032424927
[proc 1][Train](400/500) average loss: 0.27885470911860466
[proc 1][Train](400/500) average regularization: 8.253905239143933e-06
[proc 1] 400 steps, total: 7.736, sample: 0.878, forward: 1.867, backward: 1.148, update: 1.438
[proc 3][Train](400/500) average pos_loss: 0.3029181534051895
[proc 3][Train](400/500) average neg_loss: 0.313989140316844
[proc 3][Train](400/500) average loss: 0.30845364682376386
[proc 3][Train](400/500) average regularization: 8.38012247641018e-06
[proc 3] 400 steps, total: 7.736, sample: 0.827, forward: 1.870, backward: 1.229, update: 1.469
Successfully xmh. training takes 22.307997941970825 seconds
