WARNING: Logging before InitGoogleLogging() is written to STDERR
W20240102 14:45:07.120138 659002 IPCTensor.h:350] NewIPCTensor: full_emb [20000, 3]0x100000002000
xmh:  {'test_cache': 'KnownLocalCachedEmbedding', 'cache_ratio': 0.1, 'kForwardItersPerStep': 1, 'BackwardMode': 'CppAsync', 'L': 10, 'nr_background_threads': 32}
========== Running Test with routine <bound method TestShardedCache.routine_cache_helper of <__main__.TestShardedCache object at 0x7efb43d639d0>> {'test_cache': 'KnownLocalCachedEmbedding', 'cache_ratio': 0.1, 'kForwardItersPerStep': 1, 'BackwardMode': 'CppAsync', 'L': 10, 'nr_background_threads': 32}==========
INFO [659002 test_emb.py:115] Worker 0 pid=659245
INFO [659002 test_emb.py:115] Worker 1 pid=659246
INFO [659245 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 0
INFO [659246 distributed_c10d.py:442] Added key: store_based_barrier_key:1 to store for rank: 1
INFO [659245 distributed_c10d.py:476] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
INFO [659246 distributed_c10d.py:476] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
WARNING: Logging before InitGoogleLogging() is written to STDERR
E20240102 14:45:11.036584 659245 IPCTensor.h:329] IPCTensor full_emb already exists
WARNING: Logging before InitGoogleLogging() is written to STDERR
E20240102 14:45:11.078040 659246 IPCTensor.h:329] IPCTensor full_emb already exists
INFO [659245 test_emb.py:128] emb.data_ptr=0x100000002000
INFO [659246 test_emb.py:128] emb.data_ptr=0x100000002000
rank 0 start initing emb
  0%|          | 0/10000 [00:00<?, ?it/s] 79%|███████▊  | 7872/10000 [00:00<00:00, 78707.88it/s]100%|██████████| 10000/10000 [00:00<00:00, 80375.44it/s]
E20240102 14:45:12.485309 659246 IPCTensor.h:367] Called NewIPCGPUTensor: embedding_cache_1 [1000, 3] 1
W20240102 14:45:12.485359 659246 IPCTensor.h:389] NewIPCGPUTensor: embedding_cache_1 [1000, 3] 1
E20240102 14:45:12.485451 659245 IPCTensor.h:367] Called NewIPCGPUTensor: embedding_cache_0 [1000, 3] 0
W20240102 14:45:12.485468 659246 IPCTensor.h:350] NewIPCTensor: input_keys_1 [100000]0x10000003f050
W20240102 14:45:12.485493 659245 IPCTensor.h:389] NewIPCGPUTensor: embedding_cache_0 [1000, 3] 0
W20240102 14:45:12.485560 659246 IPCTensor.h:350] NewIPCTensor: input_keys_neg_1 [100000]0x1000001050a0
E20240102 14:45:12.485599 659246 IPCTensor.h:367] Called NewIPCGPUTensor: backward_grads_1 [100000, 3] 1
W20240102 14:45:12.485605 659246 IPCTensor.h:389] NewIPCGPUTensor: backward_grads_1 [100000, 3] 1
W20240102 14:45:12.485605 659245 IPCTensor.h:350] NewIPCTensor: input_keys_0 [100000]0x1000001ca0a0
E20240102 14:45:12.485661 659246 IPCTensor.h:367] Called NewIPCGPUTensor: backward_grads_neg_1 [100000, 3] 1
W20240102 14:45:12.485669 659246 IPCTensor.h:389] NewIPCGPUTensor: backward_grads_neg_1 [100000, 3] 1
W20240102 14:45:12.485679 659245 IPCTensor.h:350] NewIPCTensor: input_keys_neg_0 [100000]0x1000002900f0
E20240102 14:45:12.485707 659245 IPCTensor.h:367] Called NewIPCGPUTensor: backward_grads_0 [100000, 3] 0
W20240102 14:45:12.485714 659245 IPCTensor.h:389] NewIPCGPUTensor: backward_grads_0 [100000, 3] 0
E20240102 14:45:12.485765 659245 IPCTensor.h:367] Called NewIPCGPUTensor: backward_grads_neg_0 [100000, 3] 0
W20240102 14:45:12.485772 659245 IPCTensor.h:389] NewIPCGPUTensor: backward_grads_neg_0 [100000, 3] 0
weight.shape torch.Size([20000, 3])
cudaHostRegister 0x100000002000
1: KnownLocalCachedEmbedding init done
W20240102 14:45:12.510573 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_0 [100000]0x1000003581e0
W20240102 14:45:12.510710 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_1 [100000]0x10000041d1e0
W20240102 14:45:12.510811 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_2 [100000]0x1000004e21e0
W20240102 14:45:12.510907 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_3 [100000]0x1000005a71e0
W20240102 14:45:12.511010 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_4 [100000]0x10000066c1e0
W20240102 14:45:12.511030 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_5 [100000]0x1000007311e0
W20240102 14:45:12.511067 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_6 [100000]0x1000007f61e0
W20240102 14:45:12.511088 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_7 [100000]0x1000008bb1e0
W20240102 14:45:12.511111 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_8 [100000]0x1000009801e0
W20240102 14:45:12.511142 659246 IPCTensor.h:350] NewIPCTensor: cached_sampler_r1_9 [100000]0x100000a451e0
W20240102 14:45:12.511169 659246 IPCTensor.h:350] NewIPCTensor: step_r1 [10]0x100000b0a1e0
W20240102 14:45:12.511186 659246 IPCTensor.h:350] NewIPCTensor: circle_buffer_end_r1 [1]0x100000b0c1e0
W20240102 14:45:12.511204 659246 IPCTensor.h:350] NewIPCTensor: circle_buffer_end_cppseen_r1 [1]0x100000b0e1e0
------------json------------
{
            "num_gpus": 2,
            "L": 10,
            "kForwardItersPerStep": 1,
            "clr": 2,
            "BackwardMode": "CppAsync",
            "nr_background_threads": 32
        }
weight.shape torch.Size([20000, 3])
New CachedEmbedding, name=full_emb, shape=(20000, 3), cache_type=KnownLocalCachedEmbedding
fixed cache_range is [(0, 1000), (1000, 2000)]
cudaHostRegister 0x100000002000
0: KnownLocalCachedEmbedding init done
W20240102 14:45:12.512639 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_0 [100000]0x100000b101e0
W20240102 14:45:12.512696 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_1 [100000]0x100000bd51e0
W20240102 14:45:12.512727 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_2 [100000]0x100000c9a1e0
W20240102 14:45:12.512764 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_3 [100000]0x100000d5f1e0
W20240102 14:45:12.512785 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_4 [100000]0x100000e241e0
W20240102 14:45:12.512822 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_5 [100000]0x100000ee91e0
W20240102 14:45:12.512854 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_6 [100000]0x100000fae1e0
W20240102 14:45:12.512883 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_7 [100000]0x1000010731e0
W20240102 14:45:12.512910 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_8 [100000]0x1000011381e0
W20240102 14:45:12.512938 659245 IPCTensor.h:350] NewIPCTensor: cached_sampler_r0_9 [100000]0x1000011fd1e0
W20240102 14:45:12.512964 659245 IPCTensor.h:350] NewIPCTensor: step_r0 [10]0x1000012c21e0
W20240102 14:45:12.512984 659245 IPCTensor.h:350] NewIPCTensor: circle_buffer_end_r0 [1]0x1000012c41e0
W20240102 14:45:12.513008 659245 IPCTensor.h:350] NewIPCTensor: circle_buffer_end_cppseen_r0 [1]0x1000012c61e0
W20240102 14:45:12.513396 659245 kg_controller.cc:52] KGCacheController, config={
            "num_gpus": 2,
            "L": 10,
            "kForwardItersPerStep": 1,
            "clr": 2,
            "BackwardMode": "CppAsync",
            "nr_background_threads": 32
        }
W20240102 14:45:12.513435 659245 kg_controller.cc:148] Init GradProcessingBase done
W20240102 14:45:12.516158 659245 kg_controller.cc:774] after init GradAsyncProcessing
  0%|          | 0/1000 [00:00<?, ?it/s]========== Step 0 ========== 
  0%|          | 0/1000 [00:00<?, ?it/s]========== Step 0 ========== 
  0%|          | 1/1000 [00:01<26:06,  1.57s/it]========== Step 1 ========== 
  0%|          | 1/1000 [00:01<26:01,  1.56s/it]========== Step 1 ========== 
INFO [659245 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
INFO [659246 distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
========== Step 2 ========== 
========== Step 2 ========== 
========== Step 3 ========== 
========== Step 3 ========== 
========== Step 4 ========== 
========== Step 4 ========== 
  0%|          | 5/1000 [00:01<04:17,  3.87it/s]  0%|          | 5/1000 [00:01<04:16,  3.88it/s]========== Step 5 ========== 
========== Step 5 ========== 
========== Step 6 ========== 
========== Step 6 ========== 
========== Step 7 ========== 
========== Step 7 ========== 
  1%|          | 8/1000 [00:01<02:34,  6.41it/s]  1%|          | 8/1000 [00:01<02:34,  6.43it/s]========== Step 8 ========== 
========== Step 8 ========== 
========== Step 9 ========== 
========== Step 9 ========== 
========== Step 10 ========== 
========== Step 10 ========== 
  1%|          | 11/1000 [00:01<01:51,  8.87it/s]  1%|          | 11/1000 [00:01<01:51,  8.89it/s]========== Step 11 ========== 
========== Step 11 ========== 
ERROR [659245 test_emb.py:266] rank0: forward failed, input_key=16573,                                     embed_value=tensor([16571., 16571., 16571.], device='cuda:0', grad_fn=<SelectBackward0>),                                     std_embed_value=tensor([16570., 16570., 16570.], device='cuda:0', grad_fn=<SelectBackward0>)
  1%|          | 11/1000 [00:02<03:15,  5.05it/s]
Process Process-1:
Traceback (most recent call last):
  File "/home/xieminhui/miniconda3/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/xieminhui/miniconda3/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/xieminhui/RecStore/src/framework_adapters/torch/python/test_emb.py", line 66, in worker_main
    routine(worker_id, num_workers, emb_context, args)
  File "/home/xieminhui/RecStore/src/framework_adapters/torch/python/test_emb.py", line 272, in routine_cache_helper
    assert False, "forward is error"
AssertionError: forward is error
On rank0, prepare to call self.controller.StopThreads(), self=<controller_process.KGCacheControllerWrapper object at 0x7f40d85ab710>
  1%|          | 11/1000 [00:02<03:40,  4.48it/s]
Process Process-2:
Traceback (most recent call last):
  File "/home/xieminhui/miniconda3/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/xieminhui/miniconda3/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/xieminhui/RecStore/src/framework_adapters/torch/python/test_emb.py", line 66, in worker_main
    routine(worker_id, num_workers, emb_context, args)
  File "/home/xieminhui/RecStore/src/framework_adapters/torch/python/test_emb.py", line 284, in routine_cache_helper
    kg_cache_controller.AfterBackward()
  File "/home/xieminhui/RecStore/src/framework_adapters/torch/python/controller_process.py", line 322, in AfterBackward
    dist.barrier()
  File "/home/xieminhui/miniconda3/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 3335, in barrier
    work.wait()
RuntimeError: [/home/xieminhui/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [127.0.1.1]:33204
[W tensorpipe_agent.cpp:725] RPC agent for worker1 encountered error when reading incoming request from worker0: eof (this error originated at tensorpipe/transport/shm/connection_impl.cc:259)
join all processes done
